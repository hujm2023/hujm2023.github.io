[{"content":" this is my first post\n","permalink":"http://localhost:1313/posts/hello/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003ethis is my first post\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"images/4.png\"\u003e\u003c/p\u003e","title":"Hello"},{"content":"前言 堆，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作 根节点（root node），根节点本身没有 父节点（parent node）。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\n优先级队列 是计算机科学中的一类抽象数据类型。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。优先队列往往用堆来实现。\nGolang实现一：根据原理简单实现 package minheap import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; ) /* * @CreateTime: 2021/7/6 21:57 * @Author: hujiaming * @Description: Golang实现最小堆 */ var ErrMinHeapEmpty = errors.New(\u0026#34;minHeap is empty\u0026#34;) const HeapHeadTag int64 = math.MinInt64 type MinHeap struct { elements []int64 } // NewMinHeap 创建一个最小堆实例 func NewMinHeap() *MinHeap { return \u0026amp;MinHeap{elements: []int64{HeapHeadTag}} } /* Add 将一个元素添加到最小堆中，并且添加后要使其满足最小堆的特性 首先将该元素插入到数组最后，然后对这最后一个元素进行 “上浮” 操作： 该元素与父元素进行大小比较，如果小于父元素，则和父元素交换位置，如此循环，直到 到达堆顶 或 子元素小于父元素。 */ func (mh *MinHeap) Add(v int64) { // 1. 先将元素插在数组最后面 mh.elements = append(mh.elements, v) // 2. 将最后一个元素上浮，使其符合最小堆的性质。其实是为 v 找位置 i := len(mh.elements) - 1 for ; mh.elements[i/2] \u0026gt; v; i /= 2 { mh.elements[i] = mh.elements[i/2] } mh.elements[i] = v } /* PopMin 弹出堆中最小的元素 对最小堆而言，移除元素，只能移除堆顶(最小值)的元素。 首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作： 将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。 */ func (mh *MinHeap) PopMin() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } res := mh.elements[1] last := mh.elements[len(mh.elements)-1] // idx 表示最后一个元素应该在的位置 var idx int for idx = 1; idx*2 \u0026lt; len(mh.elements); { // 找出子节点中较小的元素的 index minChildIdx := idx * 2 if minChildIdx \u0026lt; len(mh.elements)-1 \u0026amp;\u0026amp; mh.elements[minChildIdx+1] \u0026lt; mh.elements[minChildIdx] { minChildIdx++ } // 当前结点 大于 较小子节点，和这个较小子节点交换位置，继续循环 if last \u0026gt; mh.elements[minChildIdx] { mh.elements[idx] = mh.elements[minChildIdx] idx = minChildIdx continue } break } mh.elements[idx] = last mh.elements = mh.elements[:len(mh.elements)-1] return res, nil } // PeekHead 只返回堆顶元素(最小值)，不进行下沉操作 func (mh *MinHeap) PeekHead() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } return mh.elements[1], nil } // IsEmpty 最小堆是否是空的 func (mh *MinHeap) IsEmpty() bool { if len(mh.elements) == 0 || (len(mh.elements) == 1 \u0026amp;\u0026amp; mh.elements[0] == HeapHeadTag) { return true } return false } // Length 返回最小堆中的元素个数 func (mh *MinHeap) Length() int { return len(mh.elements) - 1 } // Print 打印代表最小堆的数组 func (mh *MinHeap) Print() { fmt.Println(mh.elements[1:]) } Test 如下：\nfunc TestMinHeap(t *testing.T) { mh := NewMinHeap() mh.Add(4) mh.Add(2) mh.Add(7) mh.Add(9) mh.Add(1) mh.Add(5) mh.Add(10) mh.Add(3) mh.Add(2) mh.Print() for !mh.IsEmpty() { fmt.Println(mh.PopMin()) } assert.Equal(t, mh.Length(), 0) } // 输出 /* [1 2 5 2 4 7 10 9 3] 1 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 3 \u0026lt;nil\u0026gt; 4 \u0026lt;nil\u0026gt; 5 \u0026lt;nil\u0026gt; 7 \u0026lt;nil\u0026gt; 9 \u0026lt;nil\u0026gt; 10 \u0026lt;nil\u0026gt; */ Golang 实现二：实现标准库 heap.Interface 接口 先看下标准库中的 Interface，位置在 container/heap/heap.go：\n// The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // An implementation of Interface can be sorted by the routines in this package. // The methods refer to elements of the underlying collection by integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the \u0026lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } 我们以此为基础，实现一个 优先级队列:\npackage priorityqueen type Item struct { value int64 // 实际值 priority int64 // 优先级 index int // 当前 item 在数组中的 index } // PriorityQueen 表示优先级队列 type PriorityQueen []*Item func (mh2 PriorityQueen) Len() int { return len(mh2) } func (mh2 PriorityQueen) Less(i, j int) bool { return mh2[i].priority \u0026lt; mh2[j].priority } func (mh2 PriorityQueen) Swap(i, j int) { mh2[i], mh2[j] = mh2[j], mh2[i] mh2[i].index = i mh2[j].index = j } // Push 将 x 添加到数组最后 func (mh2 *PriorityQueen) Push(x interface{}) { l := len(*mh2) c := cap(*mh2) if l+1 \u0026gt; c { cmh2 := make([]*Item, l, c/2) copy(*mh2, cmh2) *mh2 = cmh2 } *mh2 = (*mh2)[:l+1] item := (x).(*Item) item.index = l (*mh2)[l] = item } // Pop 返回数组最后一个元素 func (mh2 *PriorityQueen) Pop() interface{} { l := len(*mh2) c := cap(*mh2) if l \u0026lt; c/2 \u0026amp;\u0026amp; c \u0026gt; 25 { cmh2 := make([]*Item, l, c/2) copy(cmh2, *mh2) *mh2 = cmh2 } item := (*mh2)[l-1] item.index = -1 // for safety *mh2 = (*mh2)[:l-1] return item } // PopHead 弹出堆顶元素 func (mh2 *PriorityQueen) PopHead() *Item { if mh2.Len() == 0 { return nil } item := (*mh2)[0] heap.Remove(mh2, 0) return item } // PopWithPriority 弹出优先级小于 maxP 的堆顶元素，如果没有，返回 nil 和 当前堆顶和maxP的距离 func (mh2 *PriorityQueen) PopWithPriority(maxP int64) (*Item, int64) { if mh2.Len() == 0 { return nil, 0 } item := (*mh2)[0] if item.priority \u0026gt; maxP { return nil, item.priority - maxP } heap.Remove(mh2, 0) return item, 0 } // PeekHead 显示堆顶元素 func (mh2 *PriorityQueen) PeekHead() *Item { if mh2.Len() == 0 { return nil } heap.Init(mh2) item := (*mh2)[0] return item } 测试一下：\nfunc TestPriorityQueen(t *testing.T) { items := make([]*Item, 0) rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 10; i++ { v := rand.Int63n(100) items = append(items, \u0026amp;Item{ value: v, priority: v, index: i, }) } q := PriorityQueen(items) heap.Init(\u0026amp;q) fmt.Println(q.PeekHead()) maxP := int64(50) for _, i := range q { if i.priority \u0026lt; maxP { fmt.Println(fmt.Sprintf(\u0026#34;p: %d, v: %d\u0026#34;, i.priority, i.value)) } } fmt.Println(\u0026#34;====\u0026#34;) for i := 0; i \u0026lt; 10; i++ { item, _ := q.PopWithPriority(maxP) if item != nil { fmt.Println(item) } } fmt.Println(\u0026#34;====\u0026#34;) for { item := q.PopHead() if item == nil { break } fmt.Println(item) } } // 输出 /* \u0026amp;{5 5 0} p: 5, v: 5 p: 11, v: 11 p: 6, v: 6 p: 33, v: 33 ==== \u0026amp;{5 5 -1} \u0026amp;{6 6 -1} \u0026amp;{11 11 -1} \u0026amp;{33 33 -1} \u0026amp;{50 50 -1} ==== \u0026amp;{52 52 -1} \u0026amp;{73 73 -1} \u0026amp;{85 85 -1} \u0026amp;{97 97 -1} \u0026amp;{99 99 -1} */ Golang 标准库 heap.Interface 源码解析 整个包的实现非常简洁，加上注释以及空行，整个文件才只有120 行：\n// Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package heap provides heap operations for any type that implements // heap.Interface. A heap is a tree with the property that each node is the // minimum-valued node in its subtree. // // The minimum element in the tree is the root, at index 0. // // A heap is a common way to implement a priority queue. To build a priority // queue, implement the Heap interface with the (negative) priority as the // ordering for the Less method, so Push adds items while Pop removes the // highest-priority item from the queue. The Examples include such an // implementation; the file example_pq_test.go has the complete source. // package heap import \u0026#34;sort\u0026#34; // The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // Init establishes the heap invariants required by the other routines in this package. // Init is idempotent with respect to the heap invariants // and may be called whenever the heap invariants may have been invalidated. // The complexity is O(n) where n = h.Len(). func Init(h Interface) { // heapify n := h.Len() // (n/2 - 1) 处的结点是最后一棵子树(没有孩子结点)的根节点 for i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) } } // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 h.Swap(0, n) down(h, 0, n) return h.Pop() } // Remove removes and returns the element at index i from the heap. // The complexity is O(log n) where n = h.Len(). func Remove(h Interface, i int) interface{} { n := h.Len() - 1 if n != i { h.Swap(i, n) if !down(h, i, n) { up(h, i) } } return h.Pop() } // Fix re-establishes the heap ordering after the element at index i has changed its value. // Changing the value of the element at index i and then calling Fix is equivalent to, // but less expensive than, calling Remove(h, i) followed by a Push of the new value. // The complexity is O(log n) where n = h.Len(). func Fix(h Interface, i int) { if !down(h, i, h.Len()) { up(h, i) } } func up(h Interface, j int) { for { i := (j - 1) / 2 // parent if i == j || !h.Less(j, i) { break } h.Swap(i, j) j = i } } func down(h Interface, i0, n int) bool { i := i0 for { j1 := 2*i + 1 if j1 \u0026gt;= n || j1 \u0026lt; 0 { // j1 \u0026lt; 0 after int overflow break } j := j1 // left child if j2 := j1 + 1; j2 \u0026lt; n \u0026amp;\u0026amp; h.Less(j2, j1) { j = j2 // = 2*i + 2 // right child } if !h.Less(j, i) { break } h.Swap(i, j) i = j } return i \u0026gt; i0 } 我们关注其中几个核心实现：\ndown(h Interface, idx, heapLen int) 下沉操作：\n首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作：\n将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。\n为什么元素 i 比它的两个子节点都小，就可以跳出循环，不再继续下去呢？这是由于，在 Init 函数中，第一个开始 down 的元素是第 n/2 - 1 个，可以保证总是从最后一棵子树开始 down，因此可以保证 Init-\u0026gt;down 时，如果元素 i 比它的两个子节点都小，那么该元素对应的子树，就是最小堆。\nup(h Interface, curIdx int) 上浮操作：\n主要用在 Push 中，当我们向最小堆插入一个元素时，现将其插入到数组最后，之后进行上浮操作，此时的 curIdx 就是数组最后一个元素的 index，即 h.Len() - 1。当前元素与其父元素进行比较，如果当前元素小于父元素，则与父元素交换位置，如此往复，直到堆顶或者当前元素大于父元素。\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E5%B0%8F%E5%A0%86%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E7%9A%84golang%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/%E5%A0%86%E7%A9%8D\"\u003e堆\u003c/a\u003e，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为\u003cstrong\u003e最小堆（min heap）\u003c/strong\u003e；反之，若母节点的值恒大于等于子节点的值，此堆称为\u003cstrong\u003e最大堆（max heap）\u003c/strong\u003e。在堆中最顶端的那一个节点，称作 \u003cstrong\u003e根节点（root node）\u003c/strong\u003e，根节点本身没有 \u003cstrong\u003e父节点（parent node）\u003c/strong\u003e。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\u003c/p\u003e","title":"最小堆以及优先级队列的Golang实现"},{"content":"select 的缺陷 目前对于高并发的解决方案是 一个线程处理所有连接，在这一点上 select 和 epoll 是一样的。但 当大量的并发连接存在、但短时间内只有少数活跃的连接时，select 的表现就显得捉襟见肘了。\n首先，select 用在有活跃连接时，所以，在高并发的场景下 select 会被非常频繁地调用。当监听的连接以数万计的时候，每次返回的只是其中几百个活跃的连接，这本身就是一种性能的损失。所以内核中直接限定死了 select 可监听的文件句柄数：\n// include/uapi/linux/posix_types.h #define __FD_SETSIZE 1024 其次，内核中实现 select 的方式是 轮询，即每次检测都会遍历所有的 fd_set 中的句柄，时间复杂度为 O(n)，与 fd_set 的长度呈线性关系，select 要检测的句柄数越多就会越费时。\npoll 和 select 的实现机制没有太大差异，相比 select，poll 只是取消了最大监控文件描述符的限制，并没有从根本上解决 select 的缺陷。\n下面这张图中所表达的信息中，当并发连接较小时，select 和 epoll 差距非常小，当并发数逐渐变大时，select 性能就显得非常乏力：\n需要注意的是，这个前提是 保持大量连接，但是只有少数活跃连接，如果活跃连接也特别多，那 epoll 也会有性能问题。\nepoll 相关的数据结构与方法 与 epoll 相关的系统调用有以下三个：\n这三个方法可以在 Linux 系统的机器上通过 man 2 xxx 的方式查看具体用法\n/* 返回 epoll 实例的文件句柄，size 没有实际用途，传入一个大于 0 的数即可。 */ int epoll_create(int size); /* 让 epoll(epfd)实例 对 目标文件(fd) 执行 `ADD | DEL | MOD` 操作，并指定”关心“的事件类型 */ int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); /* 阻塞等待所”关心“的事件发生 */ int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 与 select 相比，epoll 分清了 频繁调用 和 不频繁调用 的操作。例如，epoll_ctl 是不太频繁调用的，而 epoll_wait 是非常频繁调用的。\n这是 epoll 最常见的 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; int main(void) { int epfd,nfds; struct epoll_event ev; // ev用于注册事件，表示自己关心的事哪些事件 struct epoll_event events[5]; // events 用于接收从内核返回的就绪事件 epfd = epoll_create(1); // 创建一个 epoll 实例 ev.data.fd = STDIN_FILENO; // 我们关心的是命令行输入 ev.events = EPOLLIN|EPOLLET; //监听读状态同时设置ET模式(这个后面会讲，可以简单理解成：文件内容发生变化时才会触发对应的事件) epoll_ctl(epfd, EPOLL_CTL_ADD, STDIN_FILENO, \u0026amp;ev); // 注册epoll事件 for(;;) { nfds = epoll_wait(epfd, events, 5, -1); // 进入死循环，最后的 -1 表示无限期阻塞，直到有事件发生 // epoll_wait 返回，表示有对应的事件发生，事件的信息存储在 events 数组中。nfds 表示数组的长度。接下来逐个处理事件 for(int i = 0; i \u0026lt; nfds; i++) { if(events[i].data.fd==STDIN_FILENO) printf(\u0026#34;welcome to epoll\u0026#39;s word!\\n\u0026#34;); } } } 接下来我们看看 epoll 相关的数据结构。\neventpoll /* * This structure is stored inside the \u0026#34;private_data\u0026#34; member of the file * structure and represents the main data structure for the eventpoll * interface. */ struct eventpoll { // 保护 rbr(红黑树) 和 rdllist(等待队列) struct mutex mtx; // 等待队列，用来保存对一个 epoll 实例调用 epoll_wait() 的所有进程。 // 当调用 epoll_wait 的进程发现没有就绪的事件需要处理时，就将当前进程添加到此队列中，然后进程睡眠；后续事件发生，就唤醒这个队列中的所有进程(也就是出现了惊群效应) wait_queue_head_t wq; // 当被监视的文件是一个 epoll 类型时，需要用这个等待队列来处理递归唤醒。 // epoll 也是一种文件类型，因此一个 epoll 类型的 fd 也是可以被其他 epoll 实例监视的。 // 而 epoll 类型的 fd 只会有“读就绪”的事件。当 epoll 所监视的非 epoll 类型文件有“读就绪”事件时，当前 epoll 也会进入“读就绪”状态。 // 因此如果一个 epoll 实例监视了另一个 epoll 就会出现递归。如 e2 监视了e1，e1 上有读就绪事件发生，e1 就会加入 e2 的 poll_wait 队列中。 wait_queue_head_t poll_wait; // 就绪列表(双链表)，产生了用户注册的 fd读写事件的 epi 链表。 struct list_head rdllist; // 保护 rdllist 和 ovflist 。 rwlock_t lock; /* RB tree root used to store monitored fd structs */ // 红黑树根结点，管理所有\u0026#34;关心\u0026#34;的 fd struct rb_root_cached rbr; // 单链表，当 rdllist 被锁定遍历向用户空间发送数据时，rdllist 不允许被修改，新触发的就绪 epitem 被 ovflist 串联起来， // 等待 rdllist 被处理完了，重新将 ovflist 数据写入 rdllist struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ // 创建 eventpoll 的用户结构信息。 struct user_struct *user; // eventpoll 对应的文件结构，Linux 中一切皆文件，epoll 也是一个文件。 struct file *file; /* used to optimize loop detection check */ u64 gen; struct hlist_head refs; }; 如上面 demo 中所示，\nepitem // 红黑树用于管理所有的要监视的文件描述符 fd。当我们向系统中添加一个 fd 时，就会对应地创建一个 epitem 结构体。 // epitem 可以添加到红黑树，也可以串联成就绪列表或其它列表。 struct epitem { union { /* RB tree node links this structure to the eventpoll RB tree */ // 所在的红黑树 struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; }; /* List header used to link this structure to the eventpoll ready list */ // 所在的 eventpoll 的就绪列表 struct list_head rdllink; /* Works together \u0026#34;struct eventpoll\u0026#34;-\u0026gt;ovflist in keeping the single linked chain of items. */ // 关联的 eventpoll 中的 ovflist struct epitem *next; /* The file descriptor information this item refers to */ // 为最开始的 fd 创建 epitem 时的文件描述符信息 struct epoll_filefd ffd; /* List containing poll wait queues */ // poll 等待队列 struct eppoll_entry *pwqlist; /* The \u0026#34;container\u0026#34; of this item */ // 所在的 eventpoll struct eventpoll *ep; /* List header used to link this item to the \u0026#34;struct file\u0026#34; items list */ struct hlist_node fllink; /* wakeup_source used when EPOLLWAKEUP is set */ struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ struct epoll_event event; }; epoll 工作流程 epoll 是有状态的, 内核中维护了一个数据结构用来管理所要监视的 fd，这个数据结构是 eventpoll；\n在 eventpoll 中有一颗红黑树, 用来快速的查找和修改要监视的 fd，每个节点被封装成 epitem 结构；\n在 eventpoll 中有一个列表, 用来收集已经发生事件的 epitem , 这个 list 叫 ready list(rdllist)。\n通过 epoll_ctl 函数添加进来的事件都会被放在红黑树的某个节点内，所以，重复添加是没有用的。当把事件添加进来的时候会完成关键的一步——该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数，该回调函数在内核中被称为：ep_poll_callback。这个回调函数其实就所把这个事件添加到rdllist这个双向链表中——一旦有事件发生，epoll就会将该事件添加到双向链表中。那么当我们调用 epoll_wait 时，epoll_wait 只需要检查 rdlist 双向链表中是否有存在注册的事件，有则返回，效率非常可观。\nepoll_create 细节 // 创建一个 eventpoll 对象，并且关联文件资源 static int do_epoll_create(int flags) { int error, fd; struct eventpoll *ep = NULL; struct file *file; // ... // 创建并初始化核心结构 eventpoll，赋值给 ep error = ep_alloc(\u0026amp;ep); if (error \u0026lt; 0) return error; // 创建一个文件(文件句柄 fd 和 file结构) fd = get_unused_fd_flags(O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (fd \u0026lt; 0) { error = fd; goto out_free_ep; } // 注意，在这里将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象 file = anon_inode_getfile(\u0026#34;[eventpoll]\u0026#34;, \u0026amp;eventpoll_fops, ep, O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (IS_ERR(file)) { error = PTR_ERR(file); goto out_free_fd; } // 绑定 fd 和 file，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程。 ep-\u0026gt;file = file; fd_install(fd, file); return fd; // ... } 这个函数很简单，主要做以下几件事：\n创建并初始化核心结构 eventpoll，赋值给变量 ep； 创建一个 文件句柄fd 和 文件 file结构体，并绑定 fd 和 file、绑定 file 和 eventpoll(将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象)，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程，这也间接说明 epoll 也是一种文件。 关于绑定 fd 和 file，参考：彻底理解 Linux 中的 文件描述符(fd)\nepoll_ctl 细节 // epoll_ctl 的详细实现 int do_epoll_ctl( int epfd/*epoll 文件描述符*/, int op /*操作类型*/, int fd /*要监控的目标文件描述符*/, struct epoll_event *epds/*要监视的事件类型*/, bool nonblock, ) { int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct eventpoll *tep = NULL; // epoll 对应的文件 f = fdget(epfd); // fd 对应的文件 tf = fdget(fd); /* The target file descriptor must support poll */ // epoll 并不能监控所有的文件描述符，只能监视支持 poll 方法的文件描述符 // 其实是检查对应的 file 中的 file_operations 中是否有 poll 方法，即当前文件类型是否实现了 poll 方法(普通文件没有实现，socket 或者 epoll 类型等都实现了，所以可以被 epoll 监控) if (!file_can_poll(tf.file)) goto error_tgt_fput; /* Check if EPOLLWAKEUP is allowed */ // 检查是否允许 EPOLLWAKEUP if (ep_op_has_event(op)) ep_take_care_of_epollwakeup(epds); // epoll 监视的不是自己 error = -EINVAL; if (f.file == tf.file || !is_file_epoll(f.file)) goto error_tgt_fput; // 在 do_epoll_create 实现里 anon_inode_getfile 已经将 private_data 与 eventpoll 关联。 ep = f.file-\u0026gt;private_data; // 当我们添加进来的 file 是一个 epoll 类型的文件时，有可能造成循环引用的死循环。在这里提前检查避免这种情况 error = epoll_mutex_lock(\u0026amp;ep-\u0026gt;mtx, 0, nonblock); if (error) goto error_tgt_fput; if (op == EPOLL_CTL_ADD) { if (READ_ONCE(f.file-\u0026gt;f_ep) || ep-\u0026gt;gen == loop_check_gen || is_file_epoll(tf.file)) { // ... } } // 查找 要添加的 fd 是否已经在红黑树上了，如果是，返回对应的 epitem 结构，否则返回 NULL epi = ep_find(ep, tf.file, fd); error = -EINVAL; switch (op) { case EPOLL_CTL_ADD: // 增加fd if (!epi) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; // fd 不在红黑树上，就将此 fd 添加到红黑树上管理。默认关注的事件是 EPOLLERR | EPOLLHUP error = ep_insert(ep, epds, tf.file, fd, full_check); } else error = -EEXIST; break; case EPOLL_CTL_DEL: // 删除fd if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: // 修改fd事件类型 if (epi) { if (!(epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE)) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; error = ep_modify(ep, epi, epds); } } else error = -ENOENT; break; } mutex_unlock(\u0026amp;ep-\u0026gt;mtx); // ... } 在 do_epoll_ctl() 的参数中，操作类型有三种：\nEPOLL_CTL_ADD： 往事件表中注册fd上的事件； EPOLL_CTL_DEL：删除fd上的注册事件； EPOLL_CTL_MOD：修改fd上的注册事件。 而 struct epoll_event 结构表示事件类型，常见的有：\n// eventpoll.h #define EPOLLIN (__force __poll_t)0x00000001 // 有可读数据到来 #define EPOLLPRI (__force __poll_t)0x00000002 // 有紧急数据可读：1. TCP socket 上有外带数据；2. 分布式环境下状态发生改变；3. cgroup.events类型的文件被修改 #define EPOLLOUT (__force __poll_t)0x00000004 // 有数据要写 #define EPOLLERR (__force __poll_t)0x00000008 // 文件描述符上发生错误(不管有没有设置这个 flag，epoll_wait 总是会检测并返回这样的错误) #define EPOLLHUP (__force __poll_t)0x00000010 // 该文件描述符被挂断。常见 socket 被关闭（read == 0） #define EPOLLRDHUP (__force __poll_t)0x00002000 // 对端已关闭链接，或者用 shutdown 关闭了写链 /* Set the Edge Triggered behaviour for the target file descriptor */ #define EPOLLET ((__force __poll_t)(1U \u0026lt;\u0026lt; 31)) // ET 工作模式 /* Set the One Shot behaviour for the target file descriptor */ /* 一般情况下，ET 模式只会触发一次，但有可能出现多个线程同时处理 epoll，此标志规定操作系统最多触发其上注册的一个可读或者可写或者异常事件，且只触发一次，如此无论线程再多，只能有一个线程或进程处理同一个描述符 */ #define EPOLLONESHOT ((__force __poll_t)(1U \u0026lt;\u0026lt; 30)) /* Set exclusive wakeup mode for the target file descriptor */ /* 唯一唤醒事件，主要为了解决 epoll_wait 惊群问题。多线程下多个 epoll_wait 同时等待，只唤醒一个 epoll_wait 执行。 该事件只支持 epoll_ctl 添加操作 EPOLL_CTL_ADD */ #define EPOLLEXCLUSIVE ((__force __poll_t)(1U \u0026lt;\u0026lt; 28)) 关于什么是 “ET(边缘触发)” 和 “LT(水平触发)”，后面会详细说。\nep_insert static int ep_insert(struct eventpoll *ep, const struct epoll_event *event, struct file *tfile, int fd, int full_check) { // ep_insert(ep, epds, tf.file, fd, full_check); // tf 表示 fd 对应的 file 结构 int error, pwake = 0; __poll_t revents; long user_watches; // epoll 文件对象中所监视的 fd 数量 struct epitem *epi; struct ep_pqueue epq; struct eventpoll *tep = NULL; // 当 fd 类型是 epoll 时，tep 用来保存 fd 对应的 eventpoll 结构 // 要监视的文件也是 epoll 类型，用 tep 保存对应的 eventepoll 结构 if (is_file_epoll(tfile)) tep = tfile-\u0026gt;private_data; lockdep_assert_irqs_enabled(); // 判断 epoll 监视的文件个数是否超出系统限制 user_watches = atomic_long_read(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); if (unlikely(user_watches \u0026gt;= max_user_watches)) return -ENOSPC; if (!(epi = kmem_cache_zalloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ // 创建一个双链表，头和尾都是它自己 INIT_LIST_HEAD(\u0026amp;epi-\u0026gt;rdllink); epi-\u0026gt;ep = ep; ep_set_ffd(\u0026amp;epi-\u0026gt;ffd, tfile, fd); // epitem 与 fd 绑定 epi-\u0026gt;event = *event; epi-\u0026gt;next = EP_UNACTIVE_PTR; // 目标文件是 epoll 类型 if (tep) mutex_lock_nested(\u0026amp;tep-\u0026gt;mtx, 1); /* Add the current item to the list of active epoll hook for this file */ if (unlikely(attach_epitem(tfile, epi) \u0026lt; 0)) { kmem_cache_free(epi_cache, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); return -ENOMEM; } if (full_check \u0026amp;\u0026amp; !tep) list_file(tfile); // 当前进程的用户的 epoll_watches 加一 atomic_long_inc(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); // 将初始化后的 epitem 添加到红黑树中 ep_rbtree_insert(ep, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); // 不允许递归监视太多的 epoll if (unlikely(full_check \u0026amp;\u0026amp; reverse_path_check())) { ep_remove(ep, epi); return -EINVAL; } if (epi-\u0026gt;event.events \u0026amp; EPOLLWAKEUP) { error = ep_create_wakeup_source(epi); if (error) { ep_remove(ep, epi); return error; } } /* Initialize the poll table using the queue callback */ epq.epi = epi; // 注册回调函数，作用：add our wait queue to the target file wakeup lists. 在tcp_sock-\u0026gt;sk_sleep中插入一个等待者 // 不同的系统实现 poll 的方式不同，如socket的话, 那么这个接口就是 tcp_poll() init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc); // 可能此时已经有事件存在了, revents返回这个事件 revents = ep_item_poll(epi, \u0026amp;epq.pt, 1); // ... // 如果此时就有关注的事件发生，我们将其放到就绪队列中 if (revents \u0026amp;\u0026amp; !ep_is_linked(epi)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); // 唤醒等待的线程，告诉他们有活干了 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) wake_up(\u0026amp;ep-\u0026gt;wq); if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; } // ... } ep_insert 先申请一个 epitem 对象 epi，并初始化 epitem 的两个 list 的头指针：rdllink(指向 eventpoll 的 rdllist)、pwqlist(指向包含此 epitem 的所有 poll wait queue)，通过 fs 将 epitem、fd 和 file 绑定，通过 epitem.ep 将此 epitem 和 传入的 eventpoll 对象绑定，通过传入的 event 对 epitem.events 赋值，紧接着，将这个 epitem 加入到 eventpoll 的 红黑树中。整个过程结束后，epitem 本身就完成了和 eventpoll 以及 被监视文件fd 的关联。但还要做一件事：将 epitem 加入目标文件的 poll 等待队列并注册对应的回调函数。\n在 ep_insert() 中有一行是 init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc);，这其实是注册了一个回调函数——将文件的 poll() 方法与此方法绑定，当文件就绪，就会调用此方法。\n关于 等待队列 的实现，参考：理解 Linux 等待队列\n我们知道，当一个进程加入等待队列之后，需要将设置对应的唤醒函数，当资源就绪的时候调用这个设置好的唤醒函数：\n// 链表中的一个结点 struct wait_queue_entry { unsigned int flags; // 标志，如 WQ_FLAG_EXCLUSIVE，表示等待的进程应该独占资源（解决惊群现象） void *private; // 等待进程相关信息，如 task_struct wait_queue_func_t func; // 唤醒函数 struct list_head entry; // 前后结点 }; 我们再来看下 init_waitqueue_func_entry 这个方法：\nstatic inline void init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func) { wq_entry-\u0026gt;flags = 0; wq_entry-\u0026gt;private = NULL; wq_entry-\u0026gt;func = func; } 正是将等待队列中的结点的唤醒函数设置为 ep_ptable_queue_proc ！\n我们来详细看看 ep_ptable_queue_proc 的实现：\n/* // 当该文件描述符对应的文件有事件到达后，回调用这个函数 // 首先根据pt拿到对应的epi。然后通过pwq将三者关联。 // @file: 要监听的文件 // @whead: 该fd对应的设备等待队列，每个设备的驱动都会带 // @pt: 调用文件的poll传入的东西。 */ static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct ep_pqueue *epq = container_of(pt, struct ep_pqueue, pt); struct epitem *epi = epq-\u0026gt;epi; struct eppoll_entry *pwq; // epitem 的私有项，为每一个 fd 保存内核的 poll。 // 这个结构体主要完成 epitem 和 epitem事件发生时 callback 函数的关联，将唤醒回调函数设置为 ep_poll_callback，然后加入设备等待队列 // ... // 将pwq的等待队列和回调函数ep_poll_callback关联 // ep_poll_callback 才是真正意义上的 poll() 醒来时的回调函数，当设备就绪，就会唤醒设备的等待队列中的进程，此时 ep_poll_callback 会被调用 init_waitqueue_func_entry(\u0026amp;pwq-\u0026gt;wait, ep_poll_callback); pwq-\u0026gt;whead = whead; pwq-\u0026gt;base = epi; // 将 进程对应的等待双链表结点 放入等待队列whead // 将eppoll_entry挂在到fd的设备等待队列上。也就是注册epoll的回调函数 ep_poll_callback if (epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, \u0026amp;pwq-\u0026gt;wait); else add_wait_queue(whead, \u0026amp;pwq-\u0026gt;wait); pwq-\u0026gt;next = epi-\u0026gt;pwqlist; epi-\u0026gt;pwqlist = pwq; } 我们来看看 ep_poll_callback 干了什么：\n/* * This is the callback that is passed to the wait queue wakeup * mechanism. It is called by the stored file descriptors when they * have events to report. * * This callback takes a read lock in order not to contend with concurrent * events from another file descriptor, thus all modifications to -\u0026gt;rdllist * or -\u0026gt;ovflist are lockless. Read lock is paired with the write lock from * ep_scan_ready_list(), which stops all list modifications and guarantees * that lists state is seen correctly. */ static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key) { int pwake = 0; struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-\u0026gt;ep; __poll_t pollflags = key_to_poll(key); unsigned long flags; int ewake = 0; // ... /* * If we are transferring events to userspace, we can hold no locks * (because we\u0026#39;re accessing user memory, and because of linux f_op-\u0026gt;poll() * semantics). All the events that happen during that period of time are * chained in ep-\u0026gt;ovflist and requeued later on. */ // 因为要访问用户空间，所以此时对 rdllist 的访问不应该加锁。如果恰巧这个时候有对应的 // 事件发生，应该将其放到 ovflist 中之后再调度。 if (READ_ONCE(ep-\u0026gt;ovflist) != EP_UNACTIVE_PTR) { if (chain_epi_lockless(epi)) ep_pm_stay_awake_rcu(epi); } else if (!ep_is_linked(epi)) { // 将当前的 epitem 添加到 eventpool 的就绪队列中 /* In the usual case, add event to ready list. */ if (list_add_tail_lockless(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist)) ep_pm_stay_awake_rcu(epi); } /* * Wake up ( if active ) both the eventpoll wait list and the -\u0026gt;poll() * wait list. */ // 同时唤醒 eventpool 和 poll 的等待的进程 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) { if ((epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) \u0026amp;\u0026amp; !(pollflags \u0026amp; POLLFREE)) { switch (pollflags \u0026amp; EPOLLINOUT_BITS) { case EPOLLIN: if (epi-\u0026gt;event.events \u0026amp; EPOLLIN) ewake = 1; break; case EPOLLOUT: if (epi-\u0026gt;event.events \u0026amp; EPOLLOUT) ewake = 1; break; case 0: ewake = 1; break; } } wake_up(\u0026amp;ep-\u0026gt;wq); } if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; // ... return ewake; } ep_wait 细节 入口在\nSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { struct timespec64 to; return do_epoll_wait(epfd, events, maxevents, ep_timeout_to_timespec(\u0026amp;to, timeout)); } 实际调用的是 do_epoll_wait：\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). * * @epfd: 对应的 eventpoll 文件描述符 * @events: 用于接收已经就绪的事件 * @maxevents：所监听的最大事件个数 * @to：超时事件(-1表示无限制等待) */ // epoll_wait 的具体实现 static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, struct timespec64 *to) { int error; struct fd f; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents \u0026lt;= 0 || maxevents \u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ // 确保用户传进来的地址空间是可写的 if (!access_ok(events, maxevents * sizeof(struct epoll_event))) return -EFAULT; /* Get the \u0026#34;struct file *\u0026#34; for the eventpoll file */ // 获取 epoll 实例 f = fdget(epfd); if (!f.file) return -EBADF; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; // 确保传进来的 epfd 是 epoll 类型 if (!is_file_epoll(f.file)) goto error_fput; /* * At this point it is safe to assume that the \u0026#34;private_data\u0026#34; contains * our own data structure. */ ep = f.file-\u0026gt;private_data; /* Time to fish for events ... */ // 执行具体的 poll，如果有事件产生，返回的 error 就是对应的事件个数，对应的事件也会同时从 eventpoll 对应的 rdllist(就绪队列) 中写入到传进来的 events 数组中 error = ep_poll(ep, events, maxevents, to); error_fput: fdput(f); return error; } 我们看下 ep_poll 的实现细节：\n/** * ep_poll - 检索已经就绪的事件，并将其从内核空间传送到用户空间传进来的events 列表中 * * @ep: eventpoll 实例指针 * @events: 存放就绪事件的用户空间的数组的指针 * @maxevents: events 数组的长度 * @timeout: 获取就绪事件操作的最大超时时间。如果是 0，表示不阻塞；如果是负数，表示一直阻塞 * * Return: 成功收到的事件的个数，或者失败时对应的错误码。 */ static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 设置超时 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { // 有具体的超时时长 slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. */ // 用户设置不阻塞。 timed_out = 1; } // 检查 ep.rdllist 或 ep.ovflist 中是否有就绪的事件，如果有返回就绪事件的个数。否则返回 0 eavail = ep_events_available(ep); while (1) { if (eavail) { // rdllist 中已经有事件了，将其传送到用户空间。 // 如果没有对应的事件并且也没到超时时间，就再等等，直到超时 res = ep_send_events(ep, events, maxevents); if (res) return res; } // 走到这一步，说明没有就绪事件 // 用户设置不阻塞，直接返回 if (timed_out) return 0; // always false eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查当前进程是否有信号处理，返回不为0表示有信号需要处理。 if (signal_pending(current)) return -EINTR; init_wait(\u0026amp;wait); write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有就绪事件，如果没有，让当前进程睡眠(然后进程就阻塞在这里了...) eavail = ep_events_available(ep); if (!eavail) __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 重新计算超时时间 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 进程被唤醒了，说明有事件发生！ __set_current_state(TASK_RUNNING); /* * We were woken up, thus go and try to harvest some events. * If timed out and still on the wait queue, recheck eavail * carefully under lock, below. */ eavail = 1; if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); /* * If the thread timed out and is not on the wait queue, * it means that the thread was woken up after its * timeout expired before it could reacquire the lock. * Thus, when wait.entry is empty, it needs to harvest * events. */ if (timed_out) // list_empty 检查 list 是否为空 eavail = list_empty(\u0026amp;wait.entry); // 将 wait 从 ep 的等待队列中删除 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 我们再来看 ep_send_events的实现：\nstatic int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) { struct epitem *epi, *tmp; LIST_HEAD(txlist); poll_table pt; int res = 0; if (fatal_signal_pending(current)) return -EINTR; init_poll_funcptr(\u0026amp;pt, NULL); mutex_lock(\u0026amp;ep-\u0026gt;mtx); // 将 rdllist 中的元素全部添加到 txlist 中，并清空 ep.rdllist ep_start_scan(ep, \u0026amp;txlist); // 迭代器，逐个处理从 ep-\u0026gt;rdllist 中取出后放在 txlist 中的 epitem // epi 表示正在处理的对象(cursor) list_for_each_entry_safe(epi, tmp, \u0026amp;txlist, rdllink) { struct wakeup_source *ws; __poll_t revents; if (res \u0026gt;= maxevents) break; ws = ep_wakeup_source(epi); if (ws) { if (ws-\u0026gt;active) __pm_stay_awake(ep-\u0026gt;ws); __pm_relax(ws); } // 重置 epitem 中的 rdllink list_del_init(\u0026amp;epi-\u0026gt;rdllink); // 检查就绪事件的 flag 是否是调用方需要的 revents = ep_item_poll(epi, \u0026amp;pt, 1); if (!revents) continue; // 内核向用户态复制数据 if (__put_user(revents, \u0026amp;events-\u0026gt;events) || __put_user(epi-\u0026gt;event.data, \u0026amp;events-\u0026gt;data)) { list_add(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;txlist); ep_pm_stay_awake(epi); if (!res) res = -EFAULT; break; } res++; events++; // 处理水平触发和边缘触发的场景 if (epi-\u0026gt;event.events \u0026amp; EPOLLONESHOT) epi-\u0026gt;event.events \u0026amp;= EP_PRIVATE_BITS; else if (!(epi-\u0026gt;event.events \u0026amp; EPOLLET)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); } } ep_done_scan(ep, \u0026amp;txlist); mutex_unlock(\u0026amp;ep-\u0026gt;mtx); return res; } 而其中的 ep_item_poll，不同的驱动程序，都会有自己的 poll 方法，如果是 TCP套接字，这个poll方法就是 tcp_poll。在 TCP 中，会周期性的调用这个方法调用频率取决于协议栈中断频率的设置。一旦有事件到达后，对应的 tcp_poll 方法被调用，tcp_poll 方法会回调用 sock_poll_wait()，该方法会调用这里注册的 ep_ptable_queue_proc 方法。epoll 其实就是通过此机制实现将自己的回调函数加入到文件的 waitqueue 中的。这也是 ep_ptable_queue_proc 的目的。\nstatic __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt, int depth) { struct file *file = epi-\u0026gt;ffd.file; __poll_t res; pt-\u0026gt;_key = epi-\u0026gt;event.events; if (!is_file_epoll(file)) // 非 epoll 类型的 fd，检查 socket 的就绪事件，fd 关联回调函数 ep_poll_callback。最终执行的 poll 是 tcp_poll res = vfs_poll(file, pt); else res = __ep_eventpoll_poll(file, pt, depth); return res \u0026amp; epi-\u0026gt;event.events; } 再谈 epoll 和 select 从更高的角度看，epoll 和 select 都是 I/O 多路复用，当我们在调用这类函数时，我们传入的是 关心的socket，接收到的返回是 就绪的 socket。那为何会有性能差距呢？我们尝试找出他们的不同点：\n对比 select epoll 连接数限制 1024 理论上无限制 内在处理机制 现行轮训 callback TODO TODO TODO 再回头看看 select 的 demo:\nint main(){ int fds[] = ...; // 关心的 socket 数组 fd_set source_fds; // 将我们关心的 socket 保存到 fd_set 中 fd_set temp_fds; // 临时变量，作为 select 的返回值 // 初始化 source_fds FD_ZERO(\u0026amp;source_fds); for (int i=0; i\u0026lt;fds.length; i++) { FD_SET(fds[i], \u0026amp;source_fds); } while(1) { // select 将一个 fd_set 作为入参，将就绪的 socket 又填充如这个入参中作为出参返回 // 因此，为了快速重置，设置一个临时变量，避免每次都要进行 source_fds 的重置 temp_fds = source_fds; // select 会阻塞，直到关心的 socket 上有事件发生 int n = select(..., \u0026amp;temp_fds, ...); // 在用户态遍历 socket，检查是否有我们关心的事件发生 for (int i=0; i \u0026lt; fds.length; i++) { if (FD_ISSET(fds[i], \u0026amp;temp_fds)) { // ... 进行对应的逻辑处理 FD_CLR(fds[i], \u0026amp;temp_fds); } } } return 0; } select 主要有两点限制：\n所能关注的 socket 太少，只能有 1024 个，对于一些大型 web 应用来说有点捉襟见肘； 尽管 FD_SET 是 O(1) 的操作，但返回后还要在用户态遍历一次整个 fd_set，这是一个线性操作 再回过头来看 epoll:\nint main() { int fds[] = ...; // 关心的 socket 数组 int epfd = epoll_create(...); // 创建 epoll 实例 // 将关心的 socket 添加到 epoll 中(红黑树等) for (int i=0; i \u0026lt; fds.length; i++){ epoll_ctl(epfd,EPOLL_CTL_ADD, fds[i], ...); } // 定义一个结构，用来接收就绪的事件 struct epoll_event events[MAX_EVENTS]; while(1){ // 如果无事件发生，那么进程将阻塞在这里 // 如果有事件发生，则返回就绪的事件个数，同时事件被存储在 events 中 int n = epoll_wait(epfd, \u0026amp;events,...); for (int i=0; i \u0026lt; n; i++) { // 通过下标取到返回的就绪事件，进行对应的逻辑处理 new_event = events[i]; } } return 0; } 每次epoll_wait 返回的都是活跃的 socket，根本不用全部遍历一遍 epoll 底层使用到了 红黑树 来存储所关心的 socket，查找效率有保证；注册的对应的事件通知是通过回调的方式执行的，这种解耦、相互协作的方式更有利于操作系统的调度。 ","permalink":"http://localhost:1313/posts/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/","summary":"\u003ch2 id=\"select-的缺陷\"\u003eselect 的缺陷\u003c/h2\u003e\n\u003cp\u003e目前对于高并发的解决方案是 \u003cstrong\u003e一个线程处理所有连接\u003c/strong\u003e，在这一点上 \u003ccode\u003eselect\u003c/code\u003e 和 \u003ccode\u003eepoll\u003c/code\u003e 是一样的。但 \u003cstrong\u003e当大量的并发连接存在、但短时间内只有少数活跃的连接时，\u003ccode\u003eselect\u003c/code\u003e 的表现就显得捉襟见肘了。\u003c/strong\u003e\u003c/p\u003e","title":"I/O多路复用之 epoll"},{"content":"看 select 源码，fd_set 这个结构体实际上是一个 long 型的数组，但是数组的长度依赖于系统中 typedef long int __fd_mask 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\n本文旨在抛开 select 相关的功能，彻底搞明白 fd_set 的存储原理、FD_SET() 等函数到底实现了什么效果。\n本次调试机器：\n$ uname -a Linux localhost 4.15.0-52-generic #56-Ubuntu SMP Tue Jun 4 22:49:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux fd_set 的源码中有非常多的预编译指令：\n// /usr/include/x86_64-linux-gnu/sys/select.h /* The fd_set member is required to be an array of longs. */ typedef long int __fd_mask; /* Some versions of \u0026lt;linux/posix_types.h\u0026gt; define this macros. */ #undef __NFDBITS /* It\u0026#39;s easier to assume 8-bit bytes than to get CHAR_BIT. */ #define __NFDBITS (8 * (int) sizeof (__fd_mask)) #define __FD_MASK(d) ((__fd_mask) (1UL \u0026lt;\u0026lt; ((d) % __NFDBITS))) /* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 我简单整理一下，去掉和本系统无关的，结果如下：\ntypedef long int __fd_mask; // 8 #define __NFDBITS (8 * (int) sizeof (__fd_mask) // 64 #define __FD_SETSIZE 1024 typedef struct { __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; // 长度为 1024/64=16，类型为 long } fd_set; 接着，我们看一个 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; void print_set1(fd_set *fdset); void print_set2(fd_set *fdset); int main() { fd_set fdset; FD_ZERO(\u0026amp;fdset); printf(\u0026#34;sizeof long int: %ld\\n\u0026#34;, sizeof(long int)); // 8 printf(\u0026#34;sizeof int: %ld\\n\u0026#34;, sizeof(int)); // 4 printf(\u0026#34;sizeof short: %ld\\n\u0026#34;, sizeof(short)); // 2 FD_SET(1, \u0026amp;fdset); FD_SET(2, \u0026amp;fdset); FD_SET(3, \u0026amp;fdset); FD_SET(7, \u0026amp;fdset); print_set1(\u0026amp;fdset); // 10001110 -\u0026gt; 第 1 2 3 7 位分别设置成了 1 FD_SET(15, \u0026amp;fdset); FD_SET(16, \u0026amp;fdset); FD_SET(31, \u0026amp;fdset); // 10000000000000011000000010001110 -\u0026gt; 长度为 32 FD_SET(32, \u0026amp;fdset); FD_SET(33, \u0026amp;fdset); FD_SET(62, \u0026amp;fdset); // 100000000000000000000000000001110000000000000011000000010001110 0-\u0026gt;长度为 63 print_set2(\u0026amp;fdset); FD_SET(63, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 0 -\u0026gt; 长度为 64 print_set2(\u0026amp;fdset); FD_SET(64, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 -\u0026gt; 长度还是 64，但产生了进位 print_set2(\u0026amp;fdset); FD_SET(128, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 1-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(129, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 3-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(1023, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1024, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1025, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 print_set2(\u0026amp;fdset); int isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 1，代表第 7 位被设置 FD_CLR(7, \u0026amp;fdset); print_set2(\u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000000001110 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 -\u0026gt; 第 7 位的 1 变成了 0 isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 0，代表第 7 位没有被设置 return 0; } void print_set2(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%llu \u0026#34;, (unsigned long long)fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } void print_set1(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%ld \u0026#34;,fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } print_set() 函数是我自己添加的，用于打印出 fd_set 中的 __fds_bits 数组中的内容。需要注意两点：\n数组长度是 16，是如何确定的？答：在处理过预编译指令之后，__FD_SETSIZE 的值是 1024，__NFDBITS 的值是 64，计算得到数组长度为 16；\n类型的长度如何确定？答：在最开始使用了 typedef long int __fd_mask，long int 其实就是 long，即 long signed integer type。熟悉 C语言的同学都知道，当我们描述 short、int 和 long 的长度时，只有对 short 的长度是肯定的，而对后两者都使用了 可能 的说法：可能长度为 8。这是因为 C语言 没有对其做出严格的规定，只做了宽泛的限制：short 占 2字节；int 建议为机器字长，64 位机器下占4字节；2 ≤ short ≤ int ≤ long，如上述代码中打印结果所示，在我测试的这台机器上，long 占 8字节 即 64位。\n接下来我们看 main() 中的代码：\n在调用 FD_SET() 设置 1 2 3 7 后，我们调用print_set1()打印结果，输出：142 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，数组第一位竟然是 142？！哪来的？但我们将 142 转成二进制就一下子了然了：10001110， 总共占 8 位，从右往左从 0 开始数，只有第 1 2 3 7 位被设置成了 1， 这个二进制对应的数就是 142，因为 142 完全在一个 long 的范围(64位)内，所以正常表示了。那如果我们对一个超过 long 范围的数调用 FD_SET()，会是什么效果？\n代码继续走到 FD_SET(62, \u0026amp;fdset)，我们调用 print_set1()，输出 4611686033459871886 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，4611686033459871886 转成二进制为 100000000000000000000000000001110000000000000011000000010001110，字符串长度为 63，可以看到，依旧在 long 的范围之内；执行到 FD_SET(63,\u0026amp;fdset) 呢，调用 print_set1()，输出 -4611686003394903922 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，出现了负数。我们想一下原因。只执行FD_SET(62,\u0026amp;fdset) 会将第 63 位处设置为 1，对应的二进制为 100000000000000000000000000000000000000000000000000000000000000(长度为 63)；根据 FD_SET() 的功能，我们可以猜测，FD_SET(63,\u0026amp;fdset) 会将第 64 位设置为 1，其对应的二进制应该是 1000000000000000000000000000000000000000000000000000000000000000(长度为 64)。\n在这里我们补充一个知识：参考这里 Wiki-无符号数，在计算机底层，有符号数可以表示特定范围内的整数(包括负数)，无符号数只能表示非负数(0 以及正数)，有符号数能够表示负数的原因是，最高位被用来当做符号位，1 表示负数，0 表示正数，代价就是所表示的数的范围少了一半，举个例子，8 位可以表示无符号数 [0,255](最小00000000；最大11111111，对应的十进制就是 255)，对应的有符号数范围就是 [-127,127]。\n再回头看 1000000000000000000000000000000000000000000000000000000000000000，__fd_mask 的类型是 long，是一个有符号数，最高位的 1 表示负数，后面的才是真正的值，于是这个二进制转成有符号十进制的结果就是 0，而且还是个 -0。为了验证我们的想法，我们将 print_set1() 换成 print_set2()，这两个函数唯一的不同是，将数组中的每一位的类型强转成了无符号数，这下结果就成了 9223372036854775808，符合我们的预期。 所以后面的调试，我们都使用 print_set2() 这个函数。\n刚才的 FD_SET(63,\u0026amp;fdset) 已经到达一个 long 的最大可 表示范围了，如果再多一位，会发生什么？我们看下 FD_SET(64, \u0026amp;fdset)，输出 13835058070314647694 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0，13835058070314647694 转换成二进制后为 1100000000000000000000000000001110000000000000011000000010001110(长度为 64)，和 设置 63 时的一样，但数组的第二位变成了 1。按照前面的推测，单独执行 FD_SET(64, \u0026amp;fdset)，应该将第 65 位设置成 1，长度为 65，但是 65 显然超过了 long 的可表示的长度(64位)，于是，产生了“进位”，这个进位的基本单位就是 64位，即 __NFDBITS 的值。于是，可以用如下 python 代码表示(python 对大数处理非常好，一般不会出现溢出)：\n#!/usr/local/env python3 # coding:utf-8 # get_fd_set_bin 返回 fd_set 表示的真实二进制(从右往左方向) # every_fd_bits 表示数组中每个元素代表多少位 # set_array 表示 fd_set 的 long 数组 def get_fd_set_bin(every_fd_bits, set_array): int_value = 0 for idx in range(len(set_array)): int_value = int_value | (set_array[idx] \u0026lt;\u0026lt; every_fd_bits * idx) return bin(int_value)[2:] # 输出 \u0026#34;0bxxxxxx\u0026#34;，为了方便展示，去掉前缀 # print_bin 将二进制按照 step 为一组打印 def print_bin(output, step=64): le = len(output) m = le % step padding = step - m if m != 0 else 0 output = output.zfill(le + padding) print(\u0026#39; \u0026#39;.join(\u0026#39;\u0026#39;.join(output[idx * step:(idx + 1) * step]) for idx in range((le + padding) // step))) 在我们当前的例子中，every_fd_bits = 64, set_array 的长度为 16。测试一下我们的代码：\n# 输入(相当于设置了 1 2 3 7) get_fd_set_bin(64, [142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000010001110 # 输入(相当于设置了 1 2 3 7 64) get_fd_set_bin(64, [142,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000000000001 0000000000000000000000000000000000000000000000000000000010001110 我用 Golang 做了简单实现：\npackage main import ( \u0026#34;math/big\u0026#34; \u0026#34;strings\u0026#34; ) type FdSet interface { FD_CLR(fd int) error FD_ISSET(fd int) (bool, error) FD_SET(fd int) error FD_ZERO() error FdSetString() string } type fdType uint64 const ( maxFdSetSize = 1024 fdMask = 8 // sizeof long int in c fdBits = 8 * fdMask ) type FdSetGolang struct { data [maxFdSetSize / fdBits]fdType } func NewGdSetGolang() *FdSetGolang { return \u0026amp;FdSetGolang{data: [maxFdSetSize / fdBits]fdType{}} } func (fs *FdSetGolang) FD_CLR(fd int) error { fs.clear(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ISSET(fd int) (bool, error) { return fs.isSet(fs.getMask(fd)), nil } func (fs *FdSetGolang) FD_SET(fd int) error { fs.set(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ZERO() error { for i := range fs.data { fs.data[i] = 0 } return nil } func (fs *FdSetGolang) FdSetString() string { tmp := make([]string, 0, len(fs.data)) for i := len(fs.data) - 1; i \u0026gt;= 0; i-- { if v := fs.uintBin(uint64(fs.data[i])); v != \u0026#34;\u0026#34; { tmp = append(tmp, v) } } // 最左边的那个，可以将前面的 0 全部去掉 if len(tmp) \u0026gt; 0 { t := tmp[0] if t != \u0026#34;\u0026#34; { for i := 0; i \u0026lt; len(t); i++ { if t[i] != \u0026#39;0\u0026#39; { tmp[0] = t[i:] break } } } } return \u0026#34;--\u0026gt;\u0026#34; + strings.Join(tmp, \u0026#34; \u0026#34;) + \u0026#34;\u0026lt;--\u0026#34; } func (fs *FdSetGolang) getMask(fd int) (idx int, n int) { return fd / fdBits, fd % fdBits } // set 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 1 func (fs *FdSetGolang) set(idx int, n int) { old := fs.data[idx] fs.data[idx] = 1\u0026lt;\u0026lt;n | old } // clear 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 0 func (fs *FdSetGolang) clear(idx int, n int) { if fs.isSet(idx, n) { fs.data[idx] ^= 1 \u0026lt;\u0026lt; n } } func (fs *FdSetGolang) isSet(idx, n int) bool { old := fs.data[idx] this := 1 \u0026lt;\u0026lt; n if int(old)\u0026amp;this == this { return true } return false } // uintBin 输出 n 的二进制表示 func (fs *FdSetGolang) uintBin(n uint64) string { if n == 0 { return \u0026#34;\u0026#34; } s := big.NewInt(0).SetUint64(n).Text(2) return strings.Repeat(\u0026#34;0\u0026#34;, fdBits-len(s)) + s } ","permalink":"http://localhost:1313/posts/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3linux-select%E4%B8%AD%E7%9A%84fd_set/","summary":"\u003cp\u003e看 \u003ccode\u003eselect\u003c/code\u003e 源码，\u003ccode\u003efd_set\u003c/code\u003e 这个结构体实际上是一个 \u003ccode\u003elong\u003c/code\u003e 型的数组，但是数组的长度依赖于系统中 \u003ccode\u003etypedef long int __fd_mask\u003c/code\u003e 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\u003c/p\u003e","title":"彻底理解Linux Select中的FD_SET"},{"content":"关于事务 事务的特性 原子性(Atomic, A)：要么全部执行，要么全部不执行； 一致性(Consistent, C)：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态； 隔离性(Isolation, I)：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务； 持久性(Durability, D)：事务提交后，其结果永久保存在数据库中。 事务ACID特性的实现思想\n原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 并发操作带来的问题 脏读(Dirty Reads)：一个事务在处理的过程中读取到了另一个未提交事务中的事务； 不可重复读(Non-Reapeatable Reads)：一个事务在读取某些数据后的某个时间再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了； 幻读(Phantom Reads)：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据。 不可重复读 和 幻读 区别是什么？\n不可重复读 的重点是 修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）\n幻读 的重点是 新增/删除：在同一事务中，同样的条件，第一次和第二次读出来的 记录数不一样。（因为中间有其他事务提交了插入/删除）\n事务的隔离级别 读未提交(Read UnCommitted)：所有的事务都可以看到其他事务未提交的修改(很少用到业务中)。(脏读：Y，不可重复读：Y，幻读：Y，) 读已提交(Read Committed)：只能看到其他已经提交的事务。(脏读：N，不可重复读：Y，幻读：Y) 可重复读(Reapeatable Read)：确保同一个事务在并发读取时数据一致(MySQL 默认的事务级别)。(脏读：N，不可重复读：N，幻读：Y) 可串行化(Serializable)：串行化读取数据(最高隔离级别，锁竞争激烈)。(脏读：N，不可重复读：N，幻读：N) 不同的数据库支持的隔离级别不同。在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据库中，只支持 Serializable (串行化)级别和 Read committed (读已提交)这两种级别，其中默认的为 Read committed 级别。\nMySQL 中有哪几种锁？ 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 什么是 MVCC？ 多版本并发控制(MultiVersion Concurrency Control) 是一种并发控制的方法，一般用在数据库管理系统中，实现对数据库的并发访问。\n为什么需要 MVCC？ 主要实现对数据的隔离，解决读写之间的阻塞问题，提高读写并发度。\n最原生的锁，锁住一个资源之后禁止其他任何线程访问。但是很多应用的场景都是 读多写少，很多数据的读取次数远远大于修改的次数，而这种读数据的操作之间进行排斥就显得很没必要； 所以出现了 读写锁，读锁与读锁不互斥，而写锁与写锁、写锁与读锁之间互斥，这样已经很大地提升了系统的并发能力。 后来人们发现并发读还是不够，又提出了一种让读写之间也不冲突的方法：快照读。就是读取数据的时候通过一种类似于 “快照” 的方式将第一眼看到的数据保存下来，这样读锁和写锁就不冲突了，不同的事务会看到自己特定版本的数据。当然，“快照”是一种概念模型，不同的数据库实现方式可能不太一样。 所以我们可以看到这样的“提高并发”的演进思路：\n普通锁，串行执行 \u0026ndash;\u0026gt; 读写锁，实现读读并发 \u0026ndash;\u0026gt; MVCC，实现读写并发。\nMVCC 解决了哪些问题？ 读写之间的阻塞问题：可以实现并发读写； 降低了死锁的概率：MySQL 的 InnoDB 的 MVCC 使用了乐观锁，读数据时并不需要加锁；对于写操作，也只锁定必要的行； 解决一致性读的问题：一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。 MVCC 只在 可重复读(REPEATABLE READ) 和 提交读(READ COMMITTED) 两个隔离级别下工作。其他两个隔离级别都和 MVCC 不兼容，因为 未提交读 总是读取最新的数据行，而不是符合当前事务版本的数据行。而 可串行化则会对所有读取的行都加锁。\nMVCC 如何实现的？ Innodb 中使用 B+树 作为索引的数据结构，并且主键所在的索引称为 聚簇索引(ClusterIndex)，聚簇索引的叶子结点保存了完整的一条数据。一张表只能有一个主键，所以也只能有一个聚簇索引，如果没有定义主键，InnoDB 将使用一个隐藏列作为聚簇索引。除了 聚簇索引，还有 二级索引(SecondaryIndex)，它的叶子结点中保存的是主键。\nInnoDB 的叶子段中保存了数据页，数据页中保存了行记录，而在行记录中有三个个重要的隐藏记录：\nDB_ROW_ID(隐藏行 ID)：隐藏的行 ID，用来生成默认的聚簇索引。如果我们创建表时没有指定聚簇索引，那么 InnoDB 会使用这个隐藏 ID来创建聚簇索引。 DB_TRX_ID(行的事务ID)：操作这行数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。新增一个事务时事务ID会增加，DB_TRX_ID 能够表示事务开始的先后顺序。 DB_ROLL_PT(行的回滚指针)：回滚指针，指向这行记录的 Undo Segment 中的 undo log。 MVCC 在 MySQL 中的实现依赖的是 undo log 和 ReadView。\nundo log：\n除了记录 redo log 之外，当进行数据修改时还会记录 undo log。undo log 用于数据的撤回操作，它记录修改的反向操作，比如插入对应删除，修改对应修改为原来的数据。undo log 分为两种：Insert 和 Update，Delete 可以看做是一种特殊的 Update，即在记录上修改删除标记。而 Insert undo log 在事务提交之后可以删除，因为用不到。所以我们可以理解为：update undo log记录了数据之前的数据信息，通过这些信息可以还原到之前版本的状态。\nReadView：\n也称为 一致性读视图。它并不实际存在，只是一个概念，通过 undo log 和版本计算出来，用以决定当前事务能看到哪些数据。\n对于 READ UNCOMMITTED 隔离级别，所有事务直接读取数据库的最新值即可；SERIALIZABLE 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 ReadView 的版本控制。\n所以我们才说 MVCC 只支持 Read Committed 以及 Repeated Read 隔离级别的实现，而核心逻辑就是依赖 undo log 以及版本控制。针对这个问题 InnoDB 在设计上增加了ReadView 的设计，ReadView 中主要包含当前聚簇索引对应的、当前系统中还有哪些活跃的读写事务，把它们的 事务ID 放到一个列表中，我们把这个列表命名为为 m_ids。对于查询时版本数据能否被看到的判断依据是：\n如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问； 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问； 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 先说结论：Read Committed 和 Repeatable Read 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同：\n在 Read Committed 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态； 在 Repeatable Read 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证 可重复读(Repeatale Read)。 腾讯面试：MySQL事务与MVCC如何实现的隔离级别？ 中有一个例子特别好，以截图方式展示：\nRead Committed 下的 ReadView：\nRepeatable Read 下的 ReadView：\nMySQL 中哪些存储引擎支持事务？ MySQL 服务器层不管理事务，事务是由下层的存储引擎实现的。支持事务的存储引擎有InnoDB 和 NDB Cluster。\n什么是自动提交？ MySQL 默认使用 InnoDB 引擎，并且默认采用 自动提交(AUTOCOMMITTED) 模式。也就是说，如果不是显式地开启一个事务，则每一个查询都被当成一个事务执行提交操作。\nMySQL 支持的存储引擎 我们主要关注三个：InnoDB、MyISAM 和 Memory。\nInnoDB MySQL 的默认事务型引擎，支持事务和外键。在你增删改查时匹配的条件字段带有索引时，InnoDB 使用 行级锁；在你增删改查时匹配的条件字段不带有索引时。InnoDB 使用的将是 表级锁。\nMyISAM 旧版本MySQL 的默认存储引擎。主要特点是快，不支持事务，也不支持外键。\nMemory 使用内存空间来创建表。Memory 类型的表访问非常快，因为它的数据是放在内存中的，并且默认使用 Hash 索引，但是一旦服务关闭，表中的数据就会丢失掉。\n关于索引 按照数据结构分：哈希索引、B+树索引 和 全文索引。\n按物理存储方式分：聚簇索引 和 二级索引。\nInnoDB到底支不支持哈希索引？\nInnoDB 用户无法手动创建哈希索引，这一层上说，InnoDB 确实不支持哈希索引; InnoDB 会 自调优(self-tuning)，如果判定建立 自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB 自己会建立相关哈希索引，这一层上说，InnoDB 又是支持哈希索引的。 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 B+树索引 所有的数据都在叶子节点，非叶子结点只存储叶子结点的索引，且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序的链表，这样就可以实现范围查询。优势：\nB+Tree 它的非叶子节点不存储数据，只存储索引，而数据会存放在叶子节点中。非叶子结点存储的索引越多，叶子结点能表示的数据就越多，同样数量情况下，树的高度越小，查找数据时进行的 IO 次数就越少。 全文索引 只支持英文，实现方式为 倒排索引：先分词，再建立对应的B+树索引。\nInnoDB 中的索引策略 覆盖索引 最左前缀原则 索引下推 索引下推优化是 MySQL 5.6 引入的，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 InnoDB 中创建索引有什么原则 最左前缀匹配原则 频繁作为查询条件的字段才去创建索引 频繁更新的字段不适合创建索引 索引列不能参与计算，不能有函数操作 优先考虑扩展索引，而不是新建索引，避免不必要的索引 在order by或者group by子句中，创建索引需要注意顺序 区分度低的数据列不适合做索引列(如性别） 定义有外键的数据列一定要建立索引。 对于定义为text、image数据类型的列不要建立索引。 删除不再使用或者很少使用的索引 MySQL 分库分表 分库分表方案 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。 分库分表可能遇到的问题 事务问题：需要用分布式事务啦 跨节点Join的问题：解决这一问题可以分两次查询实现 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。 数据迁移，容量规划，扩容等问题 ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID 跨分片的排序分页问题（后台加大pagesize处理？） MySQL InnoDB 索引为什么使用 B+树？ 可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？\n为什么不是一般二叉树？ 如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。\n为什么不是平衡二叉树呢？ 我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。\n那为什么不是B树而是B+树呢？ B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。 B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。 ","permalink":"http://localhost:1313/posts/mysql%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch3 id=\"关于事务\"\u003e关于事务\u003c/h3\u003e\n\u003ch4 id=\"事务的特性\"\u003e事务的特性\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e原子性(Atomic, A)\u003c/code\u003e：要么全部执行，要么全部不执行；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e一致性(Consistent, C)\u003c/code\u003e：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e隔离性(Isolation, I)\u003c/code\u003e：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e持久性(Durability, D)\u003c/code\u003e：事务提交后，其结果永久保存在数据库中。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e事务ACID特性的实现思想\u003c/p\u003e","title":"MySQL面试汇总"},{"content":"当我们谈论 Redis 时，应该谈论什么？ Redis 基本数据类型有哪些？以及他们各自的使用场景是什么？ 常见的有五种：字符串、哈希、列表、集合、有序集合。5.0 版本中新添加了 Stream 类型。\n字符串 String: 就是常规的 GET/SET 操作。是 Redis 最基本的数据类型，一个键最大能存储 512MB(底层数据结构：SDS)； 哈希 Hash：可以理解成一个键值对的集合，十分适合存储结构化数据。比如 MySQL 中有一条记录：id=1, name=demo, age=18，那么可以使用 hash 将其存到 Redis 中：HSET user:1 name demo age 18(数据结构：ZipList 或 HashTable)； 列表 List：就是简单的字符串列表，按照插入顺序排序。比较常见的场景是当做队列或者栈使用(数据结构：QuickList，是 ZipList 和 双向链表 的组合)。 集合 Set：存放的是一堆不重复值的集合，通常用来做去重，同时还提供了不同 Set 之间求交集、并集、合集等功能，业务上也能使用的到。它底层也是通过哈希表去实现的，可以做到增删改查都是 O(1) 的复杂度(数据结构：HashTable)。 有序集合 Sorted Set：跟 Set 一样，也是一堆不重复值的集合，不同的是每一个元素都会关联一个 float64 类型的分数，而 Redis 正是基于这个分数为集合中的成员进行排序的。比较常见的使用场景是存排行榜数据，去 Top N 会非常方便(数据结构：跳表SkipList)。 流式数据 Stream：这是 V5.0 版本引入的新的数据类型，用来弥补 Pub/Sub 的不足，工作模式类似于 kafka，可以使用 XADD 往一个 stream 中发送消息，而消费者可以是单个，也可以是消费者集群，并且任意一个消费者消费之后，必须手动调用 XACK 才会完全标志这条消息被处理，特别适合做消息队列。 Redis 使用场景 热数据存储：当成缓存中间件来使用，以缓解 DB 的压力。 做消息队列：我们可以使用它的 List 或 Stream 或 Pub/Sub 来实现一个消息队列，完成业务逻辑上的数据解耦； 排行榜：利用 Redis Sorted Set 实现； 限流器：利用单线程、原子递增等特性，可以记录某个用户在某段时间内的访问量，结合业务逻辑做到限流效果； 分布式锁：setnx 命令，设置成功表示拿到锁，不成功表示没拿到锁。 Redis 是单线程还是多线程？为什么这么快？ 4.0 以前，不管是主业务逻辑还是持久化，都是单线程； 4.0 版本，引入了多线程处理 AOF 等不太核心的操作，但主 Reactor 模型依旧使用单线程。主要是体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等; 6.0 版本，主 Reactor 真正引入多线程处理用户逻辑。 既然是单线程，为什么还这么快？\n官方的 QA 里说过，Redis 是基于内存的操作，CPU 并不是 Redis 的瓶颈，最大的瓶颈可能来自于机器内存大小以及网络带宽。快的原因：\n基于内存操作，并且有许多非常优秀的的数据结构为数据存储和处理做支撑； 单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能损失； 基于 I/O 多路复用 实现了自己类似于 Reactor 模型的事件库，大大提高网络处理能力。 Redis 是如何实现分布式锁的？ 主要利用 Redis 的 SETNX 命令实现：SETNX k v，当 k 不存在时，k v 设置成功并返回成功，表示拿到锁；k 已经存在则返回失败，加锁失败。操作结束后，可以使用 del k 删除，表示释放锁；也可以在加锁的同时，给这个锁一个过期时间，避免锁没有被显式释放而造成永久锁住。\n但上述方式也存在一些问题：\nSETNX 和 EXPIRE 并不是原子性操作，如果我 SET 之后因为网络原因没有 EXPIRE，锁因为没有设置超时时间而永远无法释放。很多开源的解决方案是 通过 lua 脚本同时设置过期时间，也可以 使用原生的 SET 命令，加上 nx 选项以及对应的过期时间，都可以解决没有 没有expire造成的锁不释放 问题。 使用了 expire，但有可能出现新的问题：就是加锁的一方的执行时间超过了 expire，此时锁自动过期释放，另一个线程获得锁，此时两个线程并发运行，就会出问题，而且如果当前线程处理完后调用 expire 也会将另一个线程的锁解除；而且这个锁也不是可重入锁。 针对这个问题，Redis 作者提出了在基于分布式环境下提出了更高级的分布式锁的实现：RedLock。(不过也并不是完美的，而且实际使用时也不会给你 5 个独立的 redis master)\n结论：Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。\n缓存雪崩、缓存穿透、缓存击穿等问题 缓存雪崩 现象：大量的热 key 设置了相同的过期时间，在该时刻这些热 key 全部失效，所有的请求铺天盖地都打到了 DB。\n解决方案：不要设置相同的过期时间，可以在一个 baseDuration 上加减一个随机数。\n缓存穿透 现象：一般的逻辑都是在 redis 中找不到，就会去 DB 查，然后将结果缓存到 Redis。但是如果某些 Key 在 DB 中也不存在(如小于 0 的用户 ID)，这类 Key 每次都会进行两次无用的查询。\n解决方案：\n加强非法参数的逻辑校验，提前返回失败； 将不存在的 Key 也缓存下来； 使用布隆过滤器，可以帮助识别：哪些数据一定不存在和可能存在，提前过滤一定不存在的数据。 缓存击穿 现象：某一个热点 key 扛着非常大的并发，某一时刻这个热点 key 失效，所有请求全部打到 DB 上，像是在墙上穿了一个洞。\n解决方案：1. 设置这个热点 key 永不过期；2. 如果非要更新，那么在这个热点 key 为空的时候，设置一个锁(比如 SETNX)，只让一个请求去数据库拉取数据，取完之后释放锁，恢复正常缓存逻辑。\nRedis 持久化方式以及实现细节 Redis 是在内存中处理数据的，但断电后内存数据会消失，因此需要将内存数据通过某种方式存储到磁盘上，以便服务器重启后能够恢复原有数据，这就是 Redis 的持久化。有三种方式：\nAOF日志(Append Only File)：文件追加方式，并且以文本的形式追加到文件中； RDB快照(Redis DataBase)：将某一时刻的内存数据，以二进制的形式全部存到磁盘中； 混合持久方式：v4.0 增加了混合持久化方式，集成了 RDB 和 AOF 的优点。 AOF AOF 采用的是写后日志的方式，现将数据写入内存，再记录到日志文件中。AOF 记录的是实际的操作命令和数据，即我们在终端输入的命令。等到重启恢复时，只需要将 AOF 文件中的命令重复执行一遍(涉及到 AOF 重写)。\n命令同步到 AOF 需要经历三个阶段：\n命令追加：Redis 将执行完的命令、命令的参数等信息“传播” AOF 程序中： 缓存追加：AOF 程序根据接收到的命令数据，将命令编码为自己的网络通信协议，然后将内容追加到服务器的 AOF 缓存中(redisServer 中有一个字段叫 sds aof_buf)； 文件写入和保存：缓存数据到一定条件，在事件处理器之后，会调 flushAppendOnlyFile 函数，这个函数会执行两个操作： WRITE：将 aof_buf 中的数据缓存写入 AOF 文件中； SAVE：调用 fsync 或者 fdataasync函数，将AOF 文件保存到磁盘中； 而 AOF 的文件保存模式有三种：\n不保存：WRITE 会被执行，SAVE 只会在服务关闭等常见会被执行一次，平常会被略过。这个时候，这两个操作都是由主线程来完成的，会阻塞主线程； 每秒保存一次：WRITE 每次都被执行，SAVE 启动子线程每秒执行一次。WRITE 操作由主进程执行，阻塞主进程；SAVE 操作由子线程执行，不直接阻塞主进程，但 SAVE 完成的快慢会影响 WRITE 的阻塞时长。 每执行一个命令保存一次：每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。这两个动作都由主线程执行，会阻塞主线程。 文件重写(bgrewriteaof):\n当开启的AOF时，随着时间推移，AOF文件会越来越大,当然redis也对AOF文件进行了优化，即触发AOF文件重写条件（后续会说明）时候，redis将使用bgrewriteaof对AOF文件进行重写。这样的好处在于减少AOF文件大小，同时有利于数据的恢复。常见的重写策略：\n重复或无效的命令不写入文件； 过期的数据不再写入文件； 多条命令合并写入。 RDB 按照指定时间间隔对你的数据集生成的时间点快照。它是 Redis 数据库中数据的内存快照，它是一个二进制文件（默认名称为：dump.rdb，可修改），存储了文件生成时 Redis 数据库中所有的数据内容。在 Redis Server 重启时可以通过加载 RDB 文件来还原数据库状态。 可用于 Redis 的数据备份、转移与恢复。\nrdbSave 负责将内存中的数据以 RDB 的格式保存到磁盘中，如果 RDB 文件已经存在，那么旧的文件会被新的文件替换。\n而 SAVE 和 BGSAVE 都会调用 rdbSave 函数，但他们的执行方式不同：\nSAVE 直接调用 rdbSave，阻塞 Redis 主进程，直到保存完为止。在主进程阻塞期间，服务器不能处理任何客户端请求； BGSAVE 则会 folk 出一个子进程，子进程调用 rdbSave，并在结束后向主进程发送信号通知。因为 rdbSave 是在子进程运行的，所以并不会阻塞主进程，在此期间服务器仍旧可以继续处理客户端的请求。 其他需要注意的：\n为了避免产生竞争条件， BGSAVE 执行时， SAVE 命令不能执行。 调用 rdbLoad 函数载入 RDB 文件时，不能进行任何和数据库相关的操作，不过订阅与发布方面的命令可以正常执行，因为它们和数据库不相关联。 AOF 文件的保存频率通常要高于 RDB 文件保存的频率， 所以一般来说， AOF 文件中的数据会比 RDB 文件中的数据要新。因此， 如果服务器在启动时， 打开了 AOF 功能， 那么程序优先使用 AOF 文件来还原数据。 只有在 AOF 功能未打开的情况下，Redis 才会使用 RDB 文件来还原数据。 混合持久化 混合持久化就是 同时结合 RDB 持久化以及 AOF 持久化混合写入 AOF文件。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据，缺点是 AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性差，并且 4.0 之前的版本并不识别；\n混合持久化同样也是通过 bgrewriteaof 完成的，不同的是当开启混合持久化时，fork 出的子进程先将共享的内存副本全量的以 RDB 方式写入 AOF文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有 RDB 格式和 AOF 格式的 AOF文件 替换旧的的 AOF文件。\n总结 RDB 优点：\n是一个非常紧凑的问题，特别适合文件备份以及灾难恢复； 节省性能。开启子进程不影响主进程功能。 RDB 缺点：\nRDB 是某一时刻的快照，无法保存全部数据，在请求较大时，丢失的数据会更多。 AOF 优点：\n数据更完整，秒级数据丢失(取决于设置fsync策略)； 文件内容可读性高，方便 debug。 AOF 缺点：\n文件体积更大，且恢复速度慢于 RDB。 Redis 如何实现高可用 Redis 实现高可用主要有三种方式：主从复制、哨兵模式，以及 Redis 集群。\n主从复制 在 主从复制 中，Redis server 分为两类：主库 master 和 从库 slave。主库可以进行读写操作，当写操作导致数据变化时会自动同步到从库。而从库一般是只读的，并接受来自主库的数据，一个主库可拥有多个从库，而一个从库只能有一个主库。\n哨兵模式 哨兵(sentinel) 是官方推荐的的 高可用(HA) 解决方案。Redis 的主从高可用解决方案，这种方案的缺点在于当 master 故障时候，需要手动进行故障恢复，而 sentinel 是一个独立运行的进程，它能监控一个或多个主从集群，并能在 master 故障时候自动进行故障转移，更为理想的是 sentinel 本身是一个分布式系统，其分布式设计思想有点类似于 zookeeper，当某个时候 Master 故障后，sentinel集群 采用一致性算法来选取Leader，故障转移由 Leader 完成。而对于客户端来说，操作 Redis 的主节点，我们只需要询问 sentinel，sentinel 返回当前可用的 master，这样一来客户端不需要关注的切换而引发的客户端配置变更。\nRedis 集群 从最开始的 一主N从，到 读写分离，再到 Sentinel 哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。为什么还需要 Redis 集群？这是因为某些场景下，单实例会存在一下几个问题：\n写并发：读操作可以通过负载均衡由诸多从节点分担，但所有的写操作只能由主节点完成，在海量数据高并发场景下，主节点压力也会飙升； 海量数据的存储压力：单实例本质上是只有一台主节点作为存储，其他从结点都是复制主节点的数据，也就是说，Redis 服务的存储能力取决于主节点所能承载的上线。 为了扩展写能力和存储能力，Redis引入集群模式。\nRedis3.0 加入了 集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的 master 节点上面，从而解决了海量数据的存储问题。\n同时 Redis集群 采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。\nRedis 也内置了高可用机制，支持 N 个 master节点 ，每个 master节点 都可以挂载多个slave节点，当 master节点 挂掉时，集群会提升它的某个slave节点 作为新的master节点。\nRedis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点(其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用)。\n问：集群中那么多 master节点，集群在存储的时候如何确定选择哪个节点呢？\n采用 类一致性哈希算法 实现节点选择。\n首先，集群将自己分成 16384 个 slot(槽位)，然后让每个节点分别负责一部分槽位(范围固定)。当某个 key 到来时，某个集群的 master 会先计算这个 key 应该被分配到哪个槽位(CRC16后的哈希值与 16384 取模的结果就是应该放入的槽位号)，如果这个槽位刚好是自己负责，那么开始处理并返回；如果不属于当前节点负责的范围，那么会返回一个 moved error，并告诉你应该去哪个节点指定这个写入命令。\n问：那集群如何实现扩容？\n通过 reshard(重新分片)来实现。它可以将已经分配给某个节点的任意数量的 slot 迁移给另一个节点，同时将对应 slot 的数据也全部迁移值新的节点。\nRedis 的过期策略以及内存淘汰机制 过期策略 定期随机检测删除：Redis 默认每隔 xxx ms就随机抽取设置了过期时间的 key，检测这些 key 是否过期，如果过期就删除。\n惰性删除：不再是 Redis主动去删除，而是在客户端获取某个 key 时，先检查是否过期，没过期则正常返回，如果过期则删除并且返回 nil。\n内存淘汰机制 惰性删除可以解决一些过期了，但没被定期删除随机抽取到的 key。但有些过期的 key 既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以 Redis 提供了内存淘汰机制来解决这个问题。\nRedis 在使用内存达到某个阈值(通过 maxmemory 配置)的时候，就会触发内存淘汰机制，选取一些 key 来删除。当内存不足以容纳新写入的数据时，内存淘汰有以下几种策略：\nnoeviction：报错。默认策略。 allkeys-lru：在所有的 key 中，删除最近最少使用的 key； allkeys-random：在所有的 key 中，随机移除某个 key； volatile-lru：在所有设置了过期时间的 key中，删除最近最少使用的 key； volatile-random：在所有设置了过期时间的 key中，随机移除某个 key； volatile-ttl：在所有设置了过期时间的 key中，有更早过期时间的 key 优先移除。 Redis 中 大key 和 热key 问题 大Key 问题 现象：\n什么是大 Key：\n单个简单的 key 存储的 value 很大：会导致网络拥塞，内存使用不均(集群模式下)； hash、set、zset 以及 list 结构中存储过多的元素：单个命令耗时太长容易阻塞其他命令，严重会引起集群发生故障切换，循环故障从而整个集群宕机。 如何发现：\nRedis 监控对超多 xxx 的 kv 报警； 定时脚本不断去 scan 拿到结果进而报警然后处理优化； 利用 redis-cli --bigkeys 命令行工具分析； 使用 redis-rdb-tools 工具对 RDB 文件进行分析 如何解决：\n删除：4.0 以后有 lazy delete，不会阻塞主线程。但这只是临时方案； hash： 使用 hscan + hdel set ： 使用 sscan + srem zset ： 使用 zremrangebyrank list ： 使用 scan + ltrim 拆分，然后使用 multiGet 获取; 热Key 问题 现象：\n突然有非常大的请求去访问 Redis 上的某个特定的key，流量过于集中，甚至达到物理网卡的上限，导致这台 Redis 服务器宕机。此时，这台Redis上的其他读写请求都变得不可用；热 key 会落到同一个 Redis 实例上，无法通过扩容解决；所有的请求都打在 DB 上，Redis 都扛不住，DB 大概率会挂掉。\n如何发现：\n业务经验预估 对用户行为数据分析，如点击、加购行为都会有打点数据 如果是集群，可以利用集群 proxy 统计分析 Redis v4.3 的 redis-cli 有一个 --hotkeys 选项，可以在命令行直接获取当前 namespace 中的热点 key(实现上是通过 scan + object freq 完成的)。 利用 redis-cli monitor 抓取数据，利用现有开源工具如 redis-faina 进行分析，统计出热 key。 怎么解决：\n增加 Redis 副本数量，将读请求的压力分配到不同的副本节点上； 业务上缓存(本地缓存)：比如使用一个大小限定的 map，每次去 Redis 查询前先检查内存中是否存在，如果存在就直接返回了。 集群条件下热key 备份：在集群条件下，一个 key 会被放入指定的实例的 slot，增加集群的节点数是没有用的。为了将针对某一个 key 的请求打散到不同的实例上，可以给对应的 key 增加前缀或者后缀，这样就可以实现将热key的流量让整个集群来分担，而不是某个节点。不过整个方案需要进行一定的业务开发，比如 key 前后缀的生成方式。 Redis 通信协议简单介绍 简称 RESP(Redis Serilization Protocol)，是 Redis 自定义的用于服务端和客户端之间的通信协议。特点是：实现简单、可读性强、快速解析。\n间隔符号，在 类Unix 下是 \\r\\n，在 Windows 是 \\n。\n+：简单字符串：\u0026quot;+OK\\r\\n\u0026quot; -：错误信息：\u0026quot;-Error unknow command 'foobar'\\r\\n\u0026quot; :：整数：\u0026quot;:1000\\r\\n\u0026quot; $：批量字符串：\u0026quot;$6\\r\\nfoobar\\r\\n\u0026quot;，前面的数组表示字符串长度 *：数组：\u0026quot;\\*2\\\\r\\\\n$2\\\\r\\\\nfoo\\\\r\\\\n$3\\\\r\\\\nbar\\\\r\\\\n\u0026quot;，数组包含2个元素，分别是字符串foo和bar。 ","permalink":"http://localhost:1313/posts/redis-%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch2 id=\"当我们谈论-redis-时应该谈论什么\"\u003e当我们谈论 Redis 时，应该谈论什么？\u003c/h2\u003e\n\u003ch3 id=\"redis-基本数据类型有哪些以及他们各自的使用场景是什么\"\u003eRedis 基本数据类型有哪些？以及他们各自的使用场景是什么？\u003c/h3\u003e\n\u003cp\u003e常见的有五种：\u003ccode\u003e字符串\u003c/code\u003e、\u003ccode\u003e哈希\u003c/code\u003e、\u003ccode\u003e列表\u003c/code\u003e、\u003ccode\u003e集合\u003c/code\u003e、\u003ccode\u003e有序集合\u003c/code\u003e。\u003ccode\u003e5.0\u003c/code\u003e 版本中新添加了 \u003ccode\u003eStream\u003c/code\u003e 类型。\u003c/p\u003e","title":"Redis 面试汇总"},{"content":"一、原理 0. 简介 channel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 容量capacity。\n在 runtime 中是通过 hchan 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\ntype hchan struct { qcount uint // 环形队列中已经有的元素个数 dataqsiz uint // 环形队列容量，就是用户创建时指定的 capacity buf unsafe.Pointer // 环形队列所在的地址 elemsize uint16 // channal 中元素类型的大小 closed uint32 // channel 是否关闭 elemtype *_type // channel 元素类型 sendx uint // 环形队列中已经发送的 index recvx uint // 环形队列中已经接受的 index recvq waitq // 等待接受 channel 中消息的 goroutine 队列 sendq waitq // 等待向 channel 中发送消息的 goroutine 队列 lock mutex } 1. 用法以及常见问题汇总 已经关闭的 channel，再次关闭会 panic 向已经关闭的 channel 发送数据会造成 panic 如果从 channel 中取出元素的方式是 for-range，则在 channel 关闭时会自动退出循环 func main() { ch := make(chan int, 10) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } // 注意这里的 close，如果没有，将会出现死锁 panic close(ch) }() for j := range ch { fmt.Println(j) } } close 一个 channel 时，如果还有 sender goroutine 挂在 channel 的发送队列中，则会引起 panic。首先 close 会唤醒所有在此 channel 等待队列中的 goroutine，使其状态变为 Grunable，再看下文 3 中的 sendchan 源码就知道，当 goroutine 被唤醒之后，还会去检查 channel 是否已经被关闭，如果被关闭则会 panic。\n从已经 close 的 channel 中取值(说明已经正常关闭，channel 是空的)，会返回 channel 元素的零值。区分零值还是真实值，可以使用 comma, ok 的语法：\nx, ok := \u0026lt;- ch if !ok{ // channel 已经被关闭 // ..... } If the receiving goroutine queue of the channel is not empty, in which case the value buffer of the channel must be empty, all the goroutines in the receiving goroutine queue of the channel will be unshifted one by one, each of them will receive a zero value of the element type of the channel and be resumed to running state.\n没有通过 make 来初始化的 channel 被称为 nil channel，关闭一个 nil channel 会直接 panic 2. 创建 channel // 初始化 channel func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // 如果 hchan 中的元素不包含指针，那么也就不需要 GC var c *hchan switch { case mem == 0: /* channel 中缓冲区大小是 0(ch := make(chan int, 0)) 或者 元素类型的大小是 0(ch := make(chan struct{})) 此时所需的空间只有 hchan 这一个元素的 */ // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: /* channel 中元素的类型不是指针。 此时所需要的空间除了 hchan 的，还有对应元素的：uintptr(size)*elem.size + hchanSize 因为不是指针，GC 也不会对channel中的元素进行 scan */ // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: /* channel 中的元素包含指针。 注意，这里进行了两次空间分配，一次是给 hchan，第二次是给 channel 中的元素 */ // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } 3. 向 channel 发送 // select {case \u0026lt;-xxx} 的入口 func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } // entry point for c \u0026lt;- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } // 向一个 channel 发送数据的具体实现 // c 就是 channel 实体，ep 表示要发送的数据，block 表示是否阻塞(正常业务逻辑中是 true，如果是 select 则是 false) func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { /* 应用层的 channel 是空的，如 var ch chan int ch \u0026lt;- 1 如果非阻塞，则直接返回； 如果阻塞，也就是向一个 nil channel 发送数据，那么将永久阻塞下去 需要注意的是，空的channel 和 已经关闭的channel是不同的。向空 channel 发送将永久阻塞，向 closed channel 发送将 panic。 */ if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 数据竞争相关的检测，后面专门说明 if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread\u0026#39;s view of c.closed and full(). /* 这里的 FastPath 其实是对 非阻塞channel(select) 操作判断的一种优化：已经要求不要在 channel 上发生阻塞， 那么这里迅速做一个判断，“能失败则立刻失败”——如果 非阻塞 \u0026amp;\u0026amp; 未关闭 \u0026amp;\u0026amp; 已经满了，那就不往后面走了。 // 检查 channel 是否已经满了 func full(c *hchan) bool { // 无缓冲的 channel if c.dataqsiz == 0 { // 如果等待队列中有 goroutine 等待，那么就返回 channel 未满，可以进行后续的处理 return c.recvq.first == nil } // 有缓冲的 channel，看环形链表中的元素数量是否已经到达容量 return c.qcount == c.dataqsiz } 如何理解这个 full？ 答：For a zero-capacity (unbuffered) channel, it is always in both full and empty status. */ if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 向一个已经关闭的 channel 发送数据，会造成 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). /* 这里也是一个 FastPath： 通常情况下往一个 channel 中发送数据，会先将数据复制到环形链表中，然后 等待接受的 goroutine 来取，再讲数据从唤醒链表中拷贝到 goroutine 中。 但是考虑一种情况，等待接收的 goroutine 早就在等了(等待队列不为空)， 这个时候发送过来一个数据，就没必要再先放进 buffer、再拷贝给等待 goroutine 了， 直接将数据从发送 goroutine 的栈拷贝到接受者 goroutine 的栈中，节省资源。 */ send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. /* 如果是有缓冲的 channel 并且 buffer 中空间足够，那么就将数据拷贝到 buffer 中。 同时更新 */ qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将数据从发送 goroutine 拷贝到 buffer 中 typedmemmove(c.elemtype, qp, ep) // 发送 index++ c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } // buffer 中 已有元素数量++ c.qcount++ unlock(\u0026amp;c.lock) return true } // 如果是非阻塞的 channel(select)，发送的工作已经走完了，可以返回了，后面的都是阻塞 channel 要做的事 if !block { unlock(\u0026amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. // 在 channel 上阻塞，receiver 会帮我们完成后续的工作 // 将当前的发送 goroutine 打包成一个 sudog 结构 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 将打包好的 sudog 入队到 channel 的 sendq(发送队列)中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 将这个发送 g 的状态改变：Grunning -\u0026gt; Gwaiting，之后进入休眠 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren\u0026#39;t considered as roots of the // stack tracer. KeepAlive(ep) // 后面的是当前 goroutine 被唤醒后的逻辑 // 醒来后检查一下状态，才会返回成功 // someone woke us up. if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 醒来后发现 channel 已经被关闭了，直接 panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } 4. 从 channel 中接收 func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } // entry points for \u0026lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller\u0026#39;s stack. // 从 hchan 中接收数据，并将数据拷贝到 ep 对应的空间中。ep 可以是 nil，这种情况下数据会被丢弃； // 如果 ep 不为 nil，那么必须指向 堆 或者 调用者g的栈地址 // 这里的返回值 selected 表示是否被 select 到，received 表示是否成功接收到数据 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 从一个阻塞的 nil channel 中接收数据，则会永久阻塞 if c == nil { if !block { return } // 这种情况其实就是 goroutine 泄露 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // FastPath: 如果不阻塞并且没有内容可接收，直接返回 false false if !block \u0026amp;\u0026amp; empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026#34;open and empty\u0026#34;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026amp;c.closed) == 0 { // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. // 走到这里，说明 channel 是非阻塞的，并且已经关闭了，而且 channel 中没有数据留下，此时会返回对应值的零值 if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 当前 channel 中没有数据可读，直接返回 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { // 将 ep 设置成对应元素的零值 typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). /* 这里也是一个 FastPath：如果我们去接收的时候，发现 buffer 是空的，但是 发送等待队列不为空，那么直接从这个等待的 goroutine 中拷贝数据。 如果 buffer 不为空，那么需要先从 buffer 中拿，然后将等待队列中的元素再放到 buffer 中 */ recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } if c.qcount \u0026gt; 0 { // Receive directly from queue // 如果 buffer 中有数据可取，直接从 buffer 中拿 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 将 buffer 中的数据拷贝到目标地址 if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 清空 buffer 中取出的元素的内容 typedmemclr(c.elemtype, qp) // 接收 index++ c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // buffer 中 总数-- c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 如果非阻塞，返回 false if !block { unlock(\u0026amp;c.lock) return false, false } // no sender available: block on this channel. // 如果是阻塞的 channel，那么接收的 goroutine 将阻塞在这里 // 将等待的 goroutine 打包成 sudog，并将其放到等待队列中，之后休眠 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // 被唤醒 // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 如果 channel 没有被关闭，那就是真的 receive 到数据了 return true, success } 5. 关闭 channel func closechan(c *hchan) { // close 一个 nil channel 将 panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) // close 一个已经 closed 的 channel，将 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } // 明确关闭 channel c.closed = 1 var glist gList // release all readers /* 将所有的接收等待队列中的 goroutine 全部弹出， 每一个 goroutine 将会收到 channel 中元素类型的零值， 并且恢复到 Grunning 状态 */ for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { // 这一步设置零值 typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) /* 将所有发送队列中的 goroutine 全部弹出，并恢复到 Grunning 状态。 恢复到后将继续进行“往 channel buffer 中发送数据”操作 但这个方法中已经将 closed 设置成 1，恢复运行后会检查，如果已经 closed，则会直接 panic */ for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 二、使用 如何正确关闭 channel 不同的场景介绍几种建议方案，尤其是生产-消费模型相关的。\n1. M receivers, one sender, the sender says \u0026ldquo;no more sends\u0026rdquo; by closing the data channel 一个生产者、多个消费者，由 producer 来关闭 channel，通知数据已经发送完毕。\nfunc main(){ consumerCnt := 10 // 这里可以是缓冲的，也可以是非缓冲的 taskChan := make(chan int, consumerCnt) wg := \u0026amp;sync.WaitGroup{} go func() { for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for data := range taskChan { fmt.Printf(\u0026#34;consumer %d received: %d\\n\u0026#34;, idx, data) } }(i) } }() for i := 0; i \u0026lt; consumerCnt * 2; i++ { taskChan \u0026lt;- i } close(taskChan) wg.Wait() } 2. One receiver, N senders, the only receiver says \u0026ldquo;please stop sending more\u0026rdquo; by closing an additional signal channel 一个 consumer、多个 producer 场景，多添加一个用于 通知 的 channel，由其中一个消费者告诉生产者“已经够了，不要再发了”。\nfunc main(){ rand.Seed(time.Now().UnixNano()) producerCnt := 10 taskChan := make(chan int) wg := \u0026amp;sync.WaitGroup{} // 用于信号通知 stopChan := make(chan struct{}) // 多个 producer 一直在生产消息，直到收到停止的信号 for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { // 这是一个 try-receive 操作，尝试能否快速退出 select { case \u0026lt;-stopChan: return default: } // 即使上面刚进行了判断没有退出，但到这一步的过程中 stopChan 可能就有数据 或者 被close了 select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- rand.Intn(1000): } } }(i) } // 一个消费者 wg.Add(1) go func() { defer wg.Done() for value := range taskChan { // 在这里确定要退出的逻辑 if value%7 == 0 { fmt.Println(value) fmt.Printf(\u0026#34;%d is times of 7, bye \\n\u0026#34;, value) // 在这里使用 close(stopChan) 和 stopChan \u0026lt;- struct{}{} 都能达到同样的效果 close(stopChan) // stopChan \u0026lt;- struct{}{} return } fmt.Println(value) } }() wg.Wait() } 3. M receivers, N senders, any one of them says \u0026ldquo;let\u0026rsquo;s end the game\u0026rdquo; by notifying a moderator to close an additional signal channel 多个 producer、多个 consumer 的场景下，当其中任何一个发生异常时，全部退出。这种场景下，不能让任何一个 producer 或者 consumer 来关闭 taskChan，也不能让任何一个 consumer 来关闭 stopChan 进而通知所有的 goroutine 退出。这个时候，我们可以再添加一个类似于主持人角色的 channel，让它来做 close stopChan 这个操作。\nfunc main(){ rand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int, consumerCnt) stopChan := make(chan struct{}) // 这里必须使用有缓冲的 buffer，主要是为了避免 moderator 还没启动时就已经有一个 toStop 消息到达导致它没收到 toStop := make(chan string, 1) var stoppedBy string // moderator go func() { stoppedBy = \u0026lt;-toStop close(stopChan) }() // producer for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { value := rand.Intn(10000) if value == 0 { // 达到退出的条件 /* 注意这里的用法，直接换成 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) 是否可行？ 答案是不行，会造成死锁。 */ select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx): default: } return } // 剩下的逻辑和前一个 demo 一样 select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- value: } } }(i) } wg := \u0026amp;sync.WaitGroup{} // consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case value := \u0026lt;-taskChan: // 达到 consumer 的退出条件 if value%7 == 0 { select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, value): default: } return } fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;exit by\u0026#34;, stoppedBy) } 注意当 producer 或者 consumer 达到退出的条件时，往 toStop channel 发送数据的方式。因为 toStop 的容量只有 1，直接使用 toStop \u0026lt;- fmt.Sprintf(\u0026quot;consumer-%d\u0026quot;, value) ，当 toStop 满了塞不下了，那么所有的往里面塞的 goroutine 都将被阻塞挂起，而这些 goroutine 还在等 stopChan 通知退出，而 moderator 的实现里，只接收一个，这就造成了死锁。所以正确做法是，通过 select 尝试往 toStop 中发送，成功还好，不成功(说明已经有其他的 goroutine 通知了)直接 return。\n也可以不使用“通过 select 尝试发送”的方式，那就是让 toStop 的容量变成容纳所有可能发送的 goroutine 的数量，这个时候就可以放心直接往 toStop 里灌数据了：\n// ... toStop := make(chan string, producerCnt + consumerCnt) // ... // producer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) // ... // consumer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, idx) 4. A variant of the \u0026ldquo;N sender\u0026rdquo; situation: the data channel must be closed to tell receivers that data sending is over 上面三个 demo 中，我们都没有对 tashChan 进行明确的 close，close 操作交给了 GC。但是有些场景下，会要求没数据时一定要关闭 taskChan，然后通知调用consumer明确告知“数据已经发送完了”。但是当有多个 producer 时，直接关闭肯定行不通。再这样的场景下，可以引入一个 middle channel ，producer 的数据不再直接发给 consumer，而是先发给middle channel，这个 middle channel 只有一个 sender，可以做到 close taskChan 了。\nrand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int) middleChan := make(chan int) closing := make(chan string) done := make(chan struct{}) var stoppedBy string stop := func(by string) { select { case closing \u0026lt;- by: \u0026lt;-done case \u0026lt;-done: } } // 多个 producer，将数据发送给 middle channel for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { select { case \u0026lt;-done: return default: } value := rand.Intn(10000) if value%7 == 0 { fmt.Println(value, \u0026#34; will stop\u0026#34;) stop(\u0026#34;producer-\u0026#34; + strconv.Itoa(idx)) return } select { case \u0026lt;-done: return case middleChan \u0026lt;- value: } } }(i) } // middle channel go func() { exit := func(v int, needSend bool) { close(done) if needSend { taskChan \u0026lt;- v } close(taskChan) } for { select { case stoppedBy = \u0026lt;-closing: exit(0, false) return case v := \u0026lt;-middleChan: select { case stoppedBy = \u0026lt;-closing: exit(v, true) return case taskChan \u0026lt;- v: } } } }() wg := \u0026amp;sync.WaitGroup{} // 多个 consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-done: return default: } for value := range taskChan { fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;stopped by\u0026#34;, stoppedBy) ","permalink":"http://localhost:1313/posts/golang-channel%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一原理\"\u003e一、原理\u003c/h2\u003e\n\u003ch3 id=\"0-简介\"\u003e0. 简介\u003c/h3\u003e\n\u003cp\u003echannel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 \u003ccode\u003e容量capacity\u003c/code\u003e。\u003cbr /\u003e\n在 \u003ccode\u003eruntime\u003c/code\u003e 中是通过 \u003ccode\u003ehchan\u003c/code\u003e 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\u003cbr /\u003e\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\u003cbr /\u003e\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\u003c/p\u003e","title":"Golang Channel详解"},{"content":" Redis 设计与实现\u0026ndash;事件 中有很清晰的说明。\nredis 要处理的事件有两种类型：\n文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发； 时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。 一、时间事件 时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\n每个时间事件主要由三个属性组成：\nwhen ：以毫秒格式的 UNIX 时间戳为单位，记录了应该在什么时间点执行事件处理函数。 timeProc ：事件处理函数。 next 指向下一个时间事件，形成链表。 根据 timeProc 函数的返回值，可以将时间事件划分为两类：\n如果事件处理函数返回 ae.h/AE_NOMORE ，那么这个事件为单次执行事件：该事件会在指定的时间被处理一次，之后该事件就会被删除，不再执行。 如果事件处理函数返回一个非 AE_NOMORE 的整数值，那么这个事件为循环执行事件：该事件会在指定的时间被处理，之后它会按照事件处理函数的返回值，更新事件的 when 属性，让这个事件在之后的某个时间点再次运行，并以这种方式一直更新并运行下去。 这些常规操作主要包括：\n更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 对不合理的数据库进行大小调整。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主节点的话，对附属节点进行定期同步。 如果处于集群模式的话，对集群进行定期同步和连接测试。 二、文件事件 Redis 服务器通过在多个客户端之间进行多路复用， 从而实现高效的命令请求处理： 多个客户端通过套接字连接到 Redis 服务器中， 但只有在套接字可以无阻塞地进行读或者写时， 服务器才会和这些客户端进行交互。\nRedis 将这类因为对套接字进行多路复用而产生的事件称为文件事件（file event）， 文件事件可以分为读事件和写事件两类。\n1. 读\u0026ndash;标志着客户端命令请求的发送状态 当一个新的客户端连接到服务器时， 服务器会给为该客户端绑定读事件， 直到客户端断开连接之后， 这个读事件才会被移除。\n有两种状态：\n等待：客户端只是连接到服务器，并没有发送命令； 就绪：客户端给服务端发送命令请求、并且请求已经到达(相应的套接字可以无阻塞地执行读操作)时，读事件状态更新为“就绪”。 当一个新的客户端连接到服务器\n2. 写\u0026ndash;标志着客户端对命令结果的接受状态 服务器只会在有命令结果要传回给客户端时， 才会为客户端关联写事件， 并且在命令结果传送完毕之后， 客户端和写事件的关联就会被移除。\n也只有两种状态：\n等待：有结果返回，但客户端还未能执行无阻塞写时； 就绪：有结果返回，并且能无阻塞写时。 当客户端向服务器发送命令请求， 并且请求被接受并执行之后， 服务器就需要将保存在缓存内的命令执行结果返回给客户端， 这时服务器就会为客户端关联写事件。\n3.读 和 写的关系 读事件只有在客户端断开和服务器的连接时，才会被移除。这也就是说，当客户端关联写事件的时候，实际上它在同时关联读/写两种事件。因为在同一次文件事件处理器的调用中， 单个客户端只能执行其中一种事件（要么读，要么写，但不能又读又写）， 当出现读事件和写事件同时就绪的情况时，事件处理器优先处理读事件————也就是说， 当服务器有命令结果要返回客户端， 而客户端又有新命令请求进入时， 服务器先处理新命令请求。\n4. 常见的文件事件 为Server端的接口（TCP Socket，Unix Socket，管道）客户端连接的可读事件（在server.c的initServer()函数中） 为各个客户端连接的Socket添加读/写事件（在networking.c中） AOF的管道（Pipe）添加读/写事件（在aof.c中） Cluster集群连接的读/写事件（在cluster.c中） 主从复制连接的读/写事件（在replication.c中） Redis哨兵模式连接的读/写事件（在sentinel.c中） ","permalink":"http://localhost:1313/posts/redis%E4%BA%8C-%E4%BB%80%E4%B9%88%E6%98%AF-redis-%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://redisbook.readthedocs.io/en/latest/internal/ae.html\"\u003eRedis 设计与实现\u0026ndash;事件\u003c/a\u003e 中有很清晰的说明。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eredis 要处理的事件有两种类型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发；\u003c/li\u003e\n\u003cli\u003e时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"一时间事件\"\u003e一、时间事件\u003c/h3\u003e\n\u003cp\u003e时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\u003cbr /\u003e\n每个时间事件主要由三个属性组成：\u003c/p\u003e","title":"Redis(二): 什么是 Redis 中的事件"},{"content":"一、前言 在关注 redis 单线程/多线程 时，有几个重要的时间节点：\nBefore Redis v4.0，真正的单线程； Redis v4.0，引入多线程处理 AOF 等任务，但核心的网络模型中依旧使用单线程； Redis v6.0，正式在网络模型中实现 I/O多线程。 从 Redis v1.0 到 Redis v6.0以前，Redis 的核心网络模型一直都是一个典型的 单Reactor模型，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 单Reactor模型 的所有运作细节，为以后更好地理解新的 Multi-Reactors/Master-Workers 模型做准备。\n注：本文基于 Redis v5.0.0 版本分析。\n二、概览 Reactor 模式本质上指的是使用 I/O多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O) 的模式。传统的 单Reactor 模型中有三种角色：\nReactor：主线程，模型核心，通过事件循环不断处理事件，如果是新的连接事件，则交给 Acceptor，如果是已经连接的 I/O 事件，则交给 Handler； Acceptor：负责 server 和 client 的连接。Reactor 模式一条最重要的原则就是：I/O 操作不能阻塞主线程循环，所以对于阻塞的网络 I/O，一般都是通过 I/O 多路复用实现的，如 Linux 上的epoll，这样可以最大程度地满足“一个线程非阻塞地监听多个 I/O 事件”。当有新的连接到来是，Acceptor 创建一个新的 socket，并将这个 socket添加到 epoll 的监听队列中，指定事件类型(读事件 或 写事件)，指定对应事件发生时的回调函数，这样当此客户端的请求到来时，epoll 会调用设定好的回调函数(可以理解成 Handler)； Handler：真正的业务处理逻辑。已经建立连接的客户端请求到来后，触发 epoll 的读事件，调用 Handler 执行具体的业务逻辑。 Redis v6.0 之前的网络模型就是一个典型的 单Reactor 模型：\n我们先逐一认识一下对应的角色概念：\naeEventLoop：这是 Redis 自己实现的一个高性能事件库，里面封装了适配各个系统的 I/O多路复用(I/O multiplexing)，除了 socket 上面的事件以外，还要处理一些定时任务。服务启动时就一直循环，调用 aeProcessEvent 处理事件； client ：代表一个客户端连接。Redis 是典型的 CS 架构（Client \u0026lt;---\u0026gt; Server），客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。Redis 使用结构体 client 存储客户端的所有相关信息，包括但不限于封装的套接字连接 \u0026ndash; *conn，当前选择的数据库指针 \u0026ndash;*db，读入缓冲区 \u0026ndash; querybuf，写出缓冲区 \u0026ndash; buf，写出数据链表 \u0026ndash; reply等； acceptTcpHandler：角色 Acceptor 的实现，当有新的客户端连接时会调用这个方法，它会调用系统 accept 创建一个 socket 对象，同时创建 client 对象，并将 socket 添加到 EventLoop 的监听列表中，并注册当对应的读事件发生时的回调函数 readQueryFromClient，即绑定 Handler，这样当该客户端发起请求时，就会调用对应的回调函数处理请求； readQueryFromClient：角色 Handler 的实现，主要负责解析并执行客户端的命令请求，并将结果写到对应的 client-\u0026gt;buf 或者 client-\u0026gt;reply 中； beforeSleep：事件循环之前的操作，主要执行一些常规任务，比如将 client 中的数据写会给客户端、进行一些持久化任务等。 有了这写概念，我们可以试着描绘一下 客户端client 与 Redis server 建立连接、发起请求到接收到返回的整个过程：\nRedis 服务器启动，开启主线程事件循环 aeMain，注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来； 客户端和服务端建立网络连接，acceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上作为对应事件发生时的回调函数，并初始化一个 client 绑定这个客户端连接； 客户端发送请求命令，触发读就绪事件，主线程调用 readQueryFromClient 通过 socket 读取客户端发送过来的命令存入 client-\u0026gt;querybuf 读入缓冲区； 接着调用 processInputBuffer，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 根据 Redis 协议解析命令，最后调用 processCommand 执行命令； 根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族的一系列函数将响应数据写入到对应 client 的写出缓冲区：client-\u0026gt;buf 或者 client-\u0026gt;reply ，client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client 添加进一个 LIFO 队列 clients_pending_write； 在事件循环 aeMain 中，主线程执行 beforeSleep --\u0026gt; handleClientsWithPendingWrites，遍历 clients_pending_write 队列，调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 sendReplyToClient 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。 三、事件库 aeEventLoop 实现细节 先来看核心数据结构：\n/* State of an event based program */ typedef struct aeEventLoop { int maxfd; // 当前已经注册在此的最大文件描述符 int setsize; // 可“关心”的文件描述符数量 long long timeEventNextId; // 下一个 timer 的id time_t lastTime; // 上一轮事件循环时的系统事件，用来诊断系统时间偏差 aeFileEvent *events; // 注册的文件事件 aeTimeEvent *timeEventHead; // 注册的时间事件 aeFiredEvent *fired; // 就绪的事件 int stop; // 事件轮询是否停止 void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; // 下一次事件轮训之前的钩子函数 aeBeforeSleepProc *aftersleep; // 事件轮询结束后的钩子函数 } aeEventLoop; /* File event structure */ typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE) */ aeFileProc *rfileProc; // 读事件就绪时的回调函数 aeFileProc *wfileProc; // 写事件就绪时的回调函数 void *clientData; // fd 对应的 client 实例 } aeFileEvent; /* Time event structure */ typedef struct aeTimeEvent { long long id; /* time event identifier. */ long when_sec; /* seconds */ long when_ms; /* milliseconds */ aeTimeProc *timeProc; aeEventFinalizerProc *finalizerProc; void *clientData; struct aeTimeEvent *next; } aeTimeEvent; /* A fired event */ typedef struct aeFiredEvent { int fd; int mask; } aeFiredEvent; 关于 时间事件 和 文件事件，可参考：redis 中的事件(时间事件和文件事件)到底是什么？\naeEventLoop 的 Prototypes 有很多，我们关注几个重要的：\n1. aeEventLoop *aeCreateEventLoop(int setsize) 创建一个 aeEventLoop 实例 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; int i; if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;lastTime = time(NULL); eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; if (aeApiCreate(eventLoop) == -1) goto err; /* Events with mask == AE_NONE are not set. So let\u0026#39;s initialize the * vector with it. */ for (i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } 这个方法的实现很简单，就是一些成员变量的初始化。需要注意的是 aeApiCreate，在 src/ae.c 的最开始，有下面的代码：\n/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \u0026#34;ae_evport.c\u0026#34; #else #ifdef HAVE_EPOLL #include \u0026#34;ae_epoll.c\u0026#34; #else #ifdef HAVE_KQUEUE #include \u0026#34;ae_kqueue.c\u0026#34; #else #include \u0026#34;ae_select.c\u0026#34; #endif #endif #endif 这段代码的意思是，根据当前的系统类型，选择性能最好的 I/O多路复用 库，比如当前系统是 Linux，那么应该使用 ae_epoll，Mac 下使用 ae_kqueue等，ae_select 是保底方案。而 ae_xxx 是对不同系统下的 I/O多路复用 的封装，将底层的不同系统调用都通过统一的 API接口 和 数据结构 aeApiStates 暴露出去，供上层调用。我们看下 Linux 系统中 aeApiCreate 的实现：\ntypedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } // 创建 epoll 实例 state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 而 Mac 下的实现又是这样的：\ntypedef struct aeApiState { int kqfd; struct kevent *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct kevent)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;kqfd = kqueue(); if (state-\u0026gt;kqfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 2. aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) 监听文件事件 int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) { if (fd \u0026gt;= eventLoop-\u0026gt;setsize) { errno = ERANGE; return AE_ERR; } aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; if (aeApiAddEvent(eventLoop, fd, mask) == -1) return AE_ERR; fe-\u0026gt;mask |= mask; if (mask \u0026amp; AE_READABLE) fe-\u0026gt;rfileProc = proc; if (mask \u0026amp; AE_WRITABLE) fe-\u0026gt;wfileProc = proc; fe-\u0026gt;clientData = clientData; if (fd \u0026gt; eventLoop-\u0026gt;maxfd) eventLoop-\u0026gt;maxfd = fd; return AE_OK; } 同样，aeApiAddEvent 在不同系统下有不同的实现，在 Linux 系统中，会调用 epoll_ctl ，将 fd 添加到 epoll 实例的监听列表中，同时指定对应事件触发时的回调函数为 *proc。\n3. aeProcessEvents(aeEventLoop *eventLoop, int flags) 事件轮训处理的核心逻辑 /* The function returns the number of events processed. */ int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; // 只处理时间事件和文件事件 if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; // 先处理文件事件 if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { // 计算下一次时间事件到来之前应该阻塞等待的时长 // 调用底层的 poll 函数，获取已经就绪的事件 numevents = aeApiPoll(eventLoop, tvp); // 如果设置了 aftersleep 钩子函数，那应该在 poll 之后调用 if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); // 调用对应事件的回调函数 for (j = 0; j \u0026lt; numevents; j++) { aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[eventLoop-\u0026gt;fired[j].fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fd = eventLoop-\u0026gt;fired[j].fd; int rfired = 0; // 读事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { rfired = 1; fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } // 写事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!rfired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } processed++; } } // 最后再处理时间事件 if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; /* return the number of processed file/time events */ } 四、Redis 单线程流程详解 在这个 section，我们将通过源码的角度，看看 section 1 中的 Redis 的 单Reactor 网络模型中的实现细节，我们对照这张图开始：\n1. server 启动，创建 EventLoop 在 src/server.c 中的 main 方法中，当服务器启动时，会调用 initServer方法，在这个方法中，Redis 会创建全局唯一的 aeEventLoop 实例，并注册 Server socket 到对应的多路复用组件上，同时指定回调函数为 acceptTcpHandler，意思是服务器接收到新的连接时，应该调用 acceptTcpHandler 这个回调函数。\nvoid initServer(void) { ... // 创建全局唯一的 EventLoop 实例 server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } ... /* Create an event handler for accepting new connections in TCP and Unix * domain sockets. */ // ipfd 表示服务启动是监听的 socket 对应的 fd，epoll 监听此 fd，有读事件发生(新连接到来)时调用回调函数 acceptTcpHandler for (j = 0; j \u0026lt; server.ipfd_count; j++) { if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL) == AE_ERR) { serverPanic( \u0026#34;Unrecoverable error creating server.ipfd file event.\u0026#34;); } } } .... 2. 新连接到来时创建连接以及 client 实例 在前面我们将 server 对应的 socket 添加到 epoll 的监听队列，当有新的连接到来时，会触发读事件就绪，此时回调函数 acceptTcpHandler 就会被调用：\nvoid acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 创建 connect fd，代表 Redis Server 和客户端的一个连接(socket) cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), \u0026amp;cport); if (cfd == ANET_ERR) { if (errno != EWOULDBLOCK) serverLog(LL_WARNING, \u0026#34;Accepting client connection: %s\u0026#34;, server.neterr); return; } serverLog(LL_VERBOSE, \u0026#34;Accepted %s:%d\u0026#34;, cip, cport); acceptCommonHandler(cfd, 0, cip); } static void acceptCommonHandler(int fd, int flags, char *ip) { client *c; // 1. 为 connect fd 创建一个 Client 对象 if ((c = createClient(fd)) == NULL) { serverLog(LL_WARNING, \u0026#34;Error registering fd event for the new client: %s (fd=%d)\u0026#34;, strerror(errno), fd); close(fd); /* May be already closed, just ignore errors */ return; } // 2. 检查是否超过了最大连接数 if (listLength(server.clients) \u0026gt; server.maxclients) { char *err = \u0026#34;-ERR max number of clients reached\\r\\n\u0026#34;; /* That\u0026#39;s a best effort error message, don\u0026#39;t check write errors */ if (write(c-\u0026gt;fd, err, strlen(err)) == -1) { /* Nothing to do, Just to avoid the warning... */ } server.stat_rejected_conn++; freeClient(c); return; } // 3. 检查 protect mode 是否开启，如果开启，不允许远程登录 if (server.protected_mode \u0026amp;\u0026amp; server.bindaddr_count == 0 \u0026amp;\u0026amp; server.requirepass == NULL \u0026amp;\u0026amp; !(flags \u0026amp; CLIENT_UNIX_SOCKET) \u0026amp;\u0026amp; ip != NULL) { ... } server.stat_numconnections++; c-\u0026gt;flags |= flags; } client *createClient(int fd) { client *c = zmalloc(sizeof(client)); ... // 1. 标记 fd 为非阻塞 anetNonBlock(NULL, fd); // 2. 设置不开启 Nagle 算法 anetEnableTcpNoDelay(NULL, fd); // 3. 设置 KeepAlive if (server.tcpkeepalive) anetKeepAlive(NULL, fd, server.tcpkeepalive); // 4. 为 fd 创建对应的文件事件监听对应 socket 的读事件，并指定对应事件发生之后的回调函数为 readQueryFromClient if (aeCreateFileEvent(server.el, fd, AE_READABLE, readQueryFromClient, c) == AE_ERR) { close(fd); zfree(c); return NULL; } // 5. 默认使用 0 号 db selectDb(c, 0); uint64_t client_id; // 6. 设置 client 其他默认属性 atomicGetIncr(server.next_client_id, client_id, 1); c-\u0026gt;id = client_id; c-\u0026gt;fd = fd; ... return c; } 在这个方法中，主要做了以下几件事：\n为新连接创建一个 socket，并将这个 socket 添加到 epoll 的监听队列中，注册读事件，并指定对应读事件触发后的回调函数为 readQueryFromClient； 创建一个 client 对象，将 client、socket 等互相绑定，建立联系。 3. 客户端请求到来，执行具体的 handler 在 createClient 中我们知道对应客户端的 socket 上有事件发生时，回调函数是 readQueryFromClient。这个方法主要做一件事：将客户端的请求读取到 client 对象的 querybuf 中。之后再调用 processInputBufferAndReplicate 进一步处理请求。\nvoid readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 调用 read 从 socket 中读取客户端请求数据到 client-\u0026gt;querybuf c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); nread = read(fd, c-\u0026gt;querybuf+qblen, readlen); ... // 如果 client-\u0026gt;querybuf 的大小超过 client_max_querybuf_len，直接返回错误，并关闭连接 if (sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClient(c); return; } // 处理客户端请求 processInputBufferAndReplicate(c); } 再来看 processInputBufferAndReplicate 的实现，它其实是 processInputBuffer 的封装，多加了一层判断：如果是普通的 server，则直接调用 processInputBuffer ；如果是主从客户端，还需要将命令同步到自己的从服务器中。\nvoid processInputBufferAndReplicate(client *c) { if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) { processInputBuffer(c); } else { size_t prev_offset = c-\u0026gt;reploff; processInputBuffer(c); size_t applied = c-\u0026gt;reploff - prev_offset; if (applied) { replicationFeedSlavesFromMasterStream(server.slaves, c-\u0026gt;pending_querybuf, applied); sdsrange(c-\u0026gt;pending_querybuf,applied,-1); } } } processInputBuffer 会试着先从缓冲区中解析命令类型，判断类型，之后调用 processCommand 执行：\nvoid processInputBuffer(client *c) { // 设置 server 的当前处理 client 为c，可以理解为获得了 server 这把锁 server.current_client = c; // 不断从 querybuf 中取出数据解析成成对的命令，直到 querybuf 为空 while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { // 进行一些 flags 的判断 ... // 根据命令类型判断是 单条指令 还是 多条指令一起执行 if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); } // 参数个数为 0 时重置客户端，可以接收下一个命令 if (c-\u0026gt;argc == 0) { resetClient(c); } else { // 执行命令 if (processCommand(c) == C_OK) { // 集群信息同步 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MULTI)) { /* Update the applied replication offset of our master. */ c-\u0026gt;reploff = c-\u0026gt;read_reploff - sdslen(c-\u0026gt;querybuf) + c-\u0026gt;qb_pos; } // 如果不是阻塞状态，则重置client，可以接受下一个命令 if (!(c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) || c-\u0026gt;btype != BLOCKED_MODULE) resetClient(c); } // 释放“锁” if (server.current_client == NULL) break; } } // 重置 querybuf if (c-\u0026gt;qb_pos) { sdsrange(c-\u0026gt;querybuf,c-\u0026gt;qb_pos,-1); c-\u0026gt;qb_pos = 0; } server.current_client = NULL; } 我们再来看 processCommand，在真正执行命令之前，会进行非常多的校验，校验通过后才会真正执行对应的命令。\nint processCommand(client *c) { // 1. 如果命令是 quit，则直接退出 if (!strcasecmp(c-\u0026gt;argv[0]-\u0026gt;ptr, \u0026#34;quit\u0026#34;)) { addReply(c, shared.ok); c-\u0026gt;flags |= CLIENT_CLOSE_AFTER_REPLY; return C_ERR; } // 2. 在 command table 寻找对应命令的处理函数， c-\u0026gt;cmd = c-\u0026gt;lastcmd = lookupCommand(c-\u0026gt;argv[0]-\u0026gt;ptr); ... // 3. 用户权限校验 if (server.requirepass \u0026amp;\u0026amp; !c-\u0026gt;authenticated \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand) { flagTransaction(c); addReply(c, shared.noautherr); return C_OK; } // 4. 如果是集群模式，还需要处理集群 node 重定向 if (server.cluster_enabled \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_LUA \u0026amp;\u0026amp; server.lua_caller-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;getkeys_proc == NULL \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;firstkey == 0 \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand)) { ... } // 5. 处理 maxmemory 情形 if (server.maxmemory \u0026amp;\u0026amp; !server.lua_timedout) { ... } // 6. 非 master 或者 磁盘有问题是，不要进行 AOF 等持久化操作 int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE \u0026amp;\u0026amp; server.masterhost == NULL \u0026amp;\u0026amp; (c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE || c-\u0026gt;cmd-\u0026gt;proc == pingCommand)) { flagTransaction(c); if (deny_write_type == DISK_ERROR_TYPE_RDB) addReply(c, shared.bgsaveerr); else addReplySds(c, sdscatprintf(sdsempty(), \u0026#34;-MISCONF Errors writing to the AOF file: %s\\r\\n\u0026#34;, strerror(server.aof_last_write_errno))); return C_OK; } // 7. 当此服务器时master时：如果配置了 repl_min_slaves_to_write，当slave数目小于时，禁止执行写命令 if (server.masterhost == NULL \u0026amp;\u0026amp; server.repl_min_slaves_to_write \u0026amp;\u0026amp; server.repl_min_slaves_max_lag \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE \u0026amp;\u0026amp; server.repl_good_slaves_count \u0026lt; server.repl_min_slaves_to_write) { flagTransaction(c); addReply(c, shared.noreplicaserr); return C_OK; } // 8. 当只读时，除了 master 的命令，不执行任何其他指令 if (server.masterhost \u0026amp;\u0026amp; server.repl_slave_ro \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE) { addReply(c, shared.roslaveerr); return C_OK; } // 9. 当客户端处于 Pub/Sub 时，只处理部分命令 if (c-\u0026gt;flags \u0026amp; CLIENT_PUBSUB \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != pingCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != subscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != unsubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != psubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != punsubscribeCommand) { addReplyError(c, \u0026#34;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\u0026#34;); return C_OK; } // 10. 服务器为slave，但是没有连接 master 时，只会执行带有 CMD_STALE 标志的命令，如 info 等 if (server.masterhost \u0026amp;\u0026amp; server.repl_state != REPL_STATE_CONNECTED \u0026amp;\u0026amp; server.repl_serve_stale_data == 0 \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_STALE)) { flagTransaction(c); addReply(c, shared.masterdownerr); return C_OK; } // 11. 正在加载数据库时，只会执行带有 CMD_LOADING 标志的命令，其余都会被拒绝 if (server.loading \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_LOADING)) { addReply(c, shared.loadingerr); return C_OK; } // 12. 当服务器因为执行lua脚本阻塞时，只会执行部分命令，其余都会拒绝 if (server.lua_timedout \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != replconfCommand \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == shutdownCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;n\u0026#39;) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == scriptCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;k\u0026#39;)) { flagTransaction(c); addReply(c, shared.slowscripterr); return C_OK; } // 13. 真正执行命令 if (c-\u0026gt;flags \u0026amp; CLIENT_MULTI \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != discardCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != multiCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != watchCommand) { // 如果是事务命令，则开启事务，命令进入等待队列 queueMultiCommand(c); addReply(c, shared.queued); } else { // 否则调用 call 直接执行 call(c, CMD_CALL_FULL); c-\u0026gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); } return C_OK; } 最后就是 call 函数，这是 Redis 执行命令的核心函数，它会处理通用的执行命令的前置和后续操作：\n如果有监视器 monitor，则需要将命令发送给监视器； 调用 redisCommand 的 proc 方法，执行对应具体的命令逻辑； 如果开启了 CMD_CALL_SLOWLOG，则需要记录慢查询日志； 如果开启了 CMD_CALL_STATS，则需要记录一些统计信息； 如果开启了 CMD_CALL_PROPAGATE，则当 dirty 大于0时，需要调用 propagate 方法来进行命令传播(命令传播就是将命令写入 repl-backlog-buffer 缓冲中，并发送给各个从服务器中。)。 void call(client *c, int flags) { .... start = ustime(); c-\u0026gt;cmd-\u0026gt;proc(c); duration = ustime() - start; .... } 经过上面的过程，命令执行结束，对应的结果已经写在了 client-\u0026gt;buf缓冲区 或者 client-\u0026gt;reply链表中：client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client添加进一个 LIFO 队列 server.clients_pending_write。\n4. 在下一次事件循环之前，将写缓冲区中的数据发送给客户端 这个过程在主事件循环之前的钩子函数 beforeSleep 中，这个函数在 main 中指定，在 aeMain 中执行：\nint main(int argc, char **argv) { ... aeSetBeforeSleepProc(server.el, beforeSleep); aeSetAfterSleepProc(server.el, afterSleep); aeMain(server.el); // 启动单线程网络模型 .... } void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; // 这是一个死循环，一直到 redis-server 停止 while (!eventLoop-\u0026gt;stop) { if (eventLoop-\u0026gt;beforesleep != NULL) eventLoop-\u0026gt;beforesleep(eventLoop); aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP); // 处理三个事件：time file call_after_sleep } } 再具体的实现中，我们只关注如何将写缓冲区的数据写回给客户端：\nvoid beforeSleep(struct aeEventLoop *eventLoop) { ... /* Handle writes with pending output buffers. */ handleClientsWithPendingWrites(); .... } int handleClientsWithPendingWrites(void) { listIter li; listNode *ln; int processed = listLength(server.clients_pending_write); // clients_pending_write 是一个 client 队列，listRewind 获取一个用于迭代的游标 listRewind(server.clients_pending_write,\u0026amp;li); // 当队列不为空时，持续进行下面的逻辑处理 while((ln = listNext(\u0026amp;li))) { client *c = listNodeValue(ln); c-\u0026gt;flags \u0026amp;= ~CLIENT_PENDING_WRITE; // 将遍历过 client 从队列中删除 listDelNode(server.clients_pending_write,ln); /* If a client is protected, don\u0026#39;t do anything, * that may trigger write error or recreate handler. */ if (c-\u0026gt;flags \u0026amp; CLIENT_PROTECTED) continue; // 将 client 的数据写回 client 对应的s ocket if (writeToClient(c-\u0026gt;fd,c,0) == C_ERR) continue; // 这次一次性没发完，那就给对应 socket 创建额外的写事件 if (clientHasPendingReplies(c)) { int ae_flags = AE_WRITABLE; /* For the fsync=always policy, we want that a given FD is never * served for reading and writing in the same event loop iteration, * so that in the middle of receiving the query, and serving it * to the client, we\u0026#39;ll call beforeSleep() that will do the * actual fsync of AOF to disk. AE_BARRIER ensures that. */ if (server.aof_state == AOF_ON \u0026amp;\u0026amp; server.aof_fsync == AOF_FSYNC_ALWAYS) { ae_flags |= AE_BARRIER; } if (aeCreateFileEvent(server.el, c-\u0026gt;fd, ae_flags, sendReplyToClient, c) == AE_ERR) { freeClientAsync(c); } } } return processed; } 对 client-\u0026gt;buf 和 client-\u0026gt;reply 的处理在 writeToClient 方法中：\n/* Write data in output buffers to client. Return C_OK if the client * is still valid after the call, C_ERR if it was freed. */ int writeToClient(int fd, client *c, int handler_installed) { ssize_t nwritten = 0, totwritten = 0; size_t objlen; clientReplyBlock *o; while(clientHasPendingReplies(c)) { // 优先处理 buf，先发送一批。在执行之前会判断如果 client-\u0026gt;buf 中有数据，则发送 client-\u0026gt;buf 中的 if (c-\u0026gt;bufpos \u0026gt; 0) { nwritten = write(fd,c-\u0026gt;buf+c-\u0026gt;sentlen,c-\u0026gt;bufpos-c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If the buffer was sent, set bufpos to zero to continue with * the remainder of the reply. */ if ((int)c-\u0026gt;sentlen == c-\u0026gt;bufpos) { c-\u0026gt;bufpos = 0; c-\u0026gt;sentlen = 0; } } else { // client-\u0026gt;buf 中没数据了，则处理 client-\u0026gt;reply 链表中剩下的 o = listNodeValue(listFirst(c-\u0026gt;reply)); objlen = o-\u0026gt;used; if (objlen == 0) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); continue; } nwritten = write(fd, o-\u0026gt;buf + c-\u0026gt;sentlen, objlen - c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If we fully sent the object on head go to the next one */ if (c-\u0026gt;sentlen == objlen) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); c-\u0026gt;sentlen = 0; /* If there are no longer objects in the list, we expect * the count of reply bytes to be exactly zero. */ if (listLength(c-\u0026gt;reply) == 0) serverAssert(c-\u0026gt;reply_bytes == 0); } } if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } server.stat_net_output_bytes += totwritten; if (nwritten == -1) { if (errno == EAGAIN) { nwritten = 0; } else { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, strerror(errno)); freeClient(c); return C_ERR; } } if (totwritten \u0026gt; 0) { /* For clients representing masters we don\u0026#39;t count sending data * as an interaction, since we always send REPLCONF ACK commands * that take some time to just fill the socket output buffer. * We just rely on data / pings received for timeout detection. */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } // 数据全部发送完毕了，那么前一步因为没发完而创建的文件监听事件可以从 EventLoop 中删除了 if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; if (handler_installed) aeDeleteFileEvent(server.el,c-\u0026gt;fd,AE_WRITABLE); /* Close connection after entire reply has been sent. */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClient(c); return C_ERR; } } return C_OK; } ","permalink":"http://localhost:1313/posts/redis%E4%B8%80-redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e在关注 \u003cstrong\u003eredis 单线程/多线程\u003c/strong\u003e 时，有几个重要的时间节点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBefore \u003ccode\u003eRedis v4.0\u003c/code\u003e，真正的单线程；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v4.0\u003c/code\u003e，引入多线程处理 \u003ccode\u003eAOF\u003c/code\u003e 等任务，但\u003cstrong\u003e核心的网络模型中依旧使用单线程\u003c/strong\u003e；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v6.0\u003c/code\u003e，正式在网络模型中实现 \u003ccode\u003eI/O多线程\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e从 \u003ccode\u003eRedis v1.0\u003c/code\u003e 到 \u003ccode\u003eRedis v6.0以前\u003c/code\u003e，Redis 的核心网络模型一直都是一个典型的 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e 的所有运作细节，为以后更好地理解新的 \u003cstrong\u003eMulti-Reactors/Master-Workers\u003c/strong\u003e 模型做准备。\u003c/p\u003e","title":"Redis系列(一): Redis 单线程事件循环"},{"content":"题目描述 使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\n1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z 思路 使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\n代码参考 func printEach() { letter, number := make(chan bool), make(chan bool) wait := sync.WaitGroup{} go func() { i := 1 for { select { case \u0026lt;-number: fmt.Print(i) i++ letter \u0026lt;- true } } }() wait.Add(1) go func(wait *sync.WaitGroup) { str := \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34; i := 0 for { select { case \u0026lt;-letter: if i \u0026gt;= len(str) { wait.Done() return } fmt.Print(str[i : i+1]) i++ if i \u0026gt;= len(str) { wait.Done() return } number \u0026lt;- true } } }(\u0026amp;wait) // 让数字先开始打印 number \u0026lt;- true // 等待循环结束，表示整个打印可以结束了 wait.Wait() // 最后关闭 channel，防止内存泄露 close(letter) close(number) } 代码解释：\nletter 用于通知打印字母，number 用于通知打印数字。\nsync.Waitgroup{} 用于阻塞主线程等待整个打印过程结束。\n倒数第 4 行中的 number \u0026lt;- true 表示让数字先开始打印。\n结束后记得关闭 channel，防止内存泄露\n扩展 有三个函数，分别可以打印 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo;，要求每个函数都起一个 goroutine，并按照 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo; 的顺序打印在屏幕上，5 次。\nfunc printCatDogFish(){ cat, dog, fish := make(chan struct{}), make(chan struct{}), make(chan struct{}) wg := \u0026amp;sync.WaitGroup{} target := 100 go func() { // cat for { select { case \u0026lt;-cat: fmt.Println(\u0026#34;cat\u0026#34;) dog \u0026lt;- struct{}{} } } }() go func() { // dog for { select { case \u0026lt;-dog: fmt.Println(\u0026#34;dog\u0026#34;) fish \u0026lt;- struct{}{} } } }() wg.Add(1) go func(w *sync.WaitGroup) { // fish defer w.Done() i := 0 for { select { case \u0026lt;-fish: fmt.Println(\u0026#34;fish\u0026#34;) i++ if i \u0026gt;= target { return } cat \u0026lt;- struct{}{} } } }(wg) cat \u0026lt;- struct{}{} wg.Wait() close(cat) close(dog) close(fish) } ","permalink":"http://localhost:1313/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003ch3 id=\"题目描述\"\u003e题目描述\u003c/h3\u003e\n\u003cp\u003e使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"思路\"\u003e思路\u003c/h3\u003e\n\u003cp\u003e使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\u003c/p\u003e","title":"面试题:交替打印数字和字符串"},{"content":" 本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\n一、介绍 当我们谈论加解密方式时，通常有两种情形：对称加密 和 非对称加密。\n对于 对称加密，加密和解密使用同一份秘钥，加密者必须将加密方式告知使用者，否则使用者无法解密，这就面临着 “秘钥配送问题”。\n而在 非对称加密 中，有公钥和私钥加密使用公钥，解密使用私钥；公钥是公开的，任何人都可以获得，私钥则是保密的。只有持有私钥的人才能解开被对应公钥加密的数据。因此非对称加密算法，也称公钥加密算法。\n如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。\n1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做 RSA算法。从那时直到现在，RSA 算法一直是最广为使用的\u0026quot;非对称加密算法\u0026quot;。毫不夸张地说，只要有计算机网络的地方，就有 RSA 算法。\n这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA 密钥是 768 个二进制位。也就是说，长度超过 768 位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024 位的 RSA 密钥 基本安全，2048 位的密钥极其安全。\n二、使用 Golang 的标准库中已经对 RSA 相关的加密算法进行了实现，这里展示基本用法 以及 使用自定义密码 的场景。\n对 RSA 的使用大致分为三个步骤：\nRSAGenKey 生成公钥和私钥； RSAEncrypt 加密数据，传入 待加密数据 和 公钥，返回 加密后的数据； RSADecrypt 解密数据，传入 被加密的数据 和 私钥，返回 解密后的数据。 1. RSA 加密的基本用法 // RSAGenKey 生成公私钥 func RSAGenKey(bits int) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥（bits=1024基本安全，2048 极其安全） privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 4、通过pem将设置的数据进行编码，并写入磁盘文件 // fPrivate, err := os.Create(\u0026#34;privateKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPrivate.Close() // err = pem.Encode(fPrivate, block1) // if err != nil { // return err // } // 4. 有两种方式，一种是将秘钥写入文件，一种是当成返回值返回，由使用者自行决定 prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } // fPublic, err := os.Create(\u0026#34;publicKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPublic.Close() // pem.Encode(fPublic, \u0026amp;block2) // 同样，可以将公钥写入文件，也可以直接返回 pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // RSAEncrypt 对数据进行加密操作 func RSAEncrypt(src []byte, pubKey []byte) (res []byte, err error) { block, _ := pem.Decode(pubKey) // 使用X509将解码之后的数据 解析出来 keyInit, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return } publicKey := keyInit.(*rsa.PublicKey) // 使用公钥加密数据 res, err = rsa.EncryptPKCS1v15(rand.Reader, publicKey, src) return } // 对数据进行解密操作 func RSADecrypt(src []byte, prvKey []byte) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo:\nfunc main() { sourceData := \u0026#34;我的头发长，天下我为王\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKey(2048) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecrypt(encryptData, prvKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 我的头发长，天下我为王 after encrypt: [153 1 185 195 ...(很长的字节数组)] after decrypt: 我的头发长，天下我为王 equal? true 2. 使用自定义密码的 RSA 算法 有时候我们想在随机生成的基础上加上自定义的密码，可以使用下面的方式：\n// RSAGenKeyWithPwd generate rsa pair key with specified password func RSAGenKeyWithPwd(bits int, pwd string) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥 privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 通过自定义密码加密 if pwd != \u0026#34;\u0026#34; { block1, err = x509.EncryptPEMBlock(rand.Reader, block1.Type, block1.Bytes, []byte(pwd), x509.PEMCipherAES256) if err != nil { return nil, nil, err } } prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // 加密方式与 RSAEncrypt 没有区别，可以共用 // RSADecryptWithPwd decrypt src with private key and password func RSADecryptWithPwd(src []byte, prvKey []byte, pwd string) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes if pwd != \u0026#34;\u0026#34; { blockBytes, err = x509.DecryptPEMBlock(block, []byte(pwd)) if err != nil { return nil, err } } privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo：\nfunc main() { sourceData := \u0026#34;好的代码本身就是最好的说明文档\u0026#34; pwd := \u0026#34;123456\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKeyWithPwd(2048, pwd) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecryptWithPwd(encryptData, prvKey, pwd) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 好的代码本身就是最好的说明文档 after encrypt: [136 134 26 233 ...(很长的字节数组)] after decrypt: 好的代码本身就是最好的说明文档 equal? true 参考文章： golang 使用 RSA 生成公私钥，加密，解密，并使用 SHA256 进行签名，验证 GO 语言 RSA 加密解密 go - 如何在 golang 中使用密码创建 rsa 私钥 RSA 算法原理（一） ","permalink":"http://localhost:1313/posts/golang%E4%B8%AD%E4%BD%BF%E7%94%A8rsa%E8%BF%9B%E8%A1%8C%E5%8A%A0%E8%A7%A3%E5%AF%86/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003e本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\u003c/p\u003e\n\u003ch2 id=\"一介绍\"\u003e一、介绍\u003c/h2\u003e\n\u003cp\u003e当我们谈论加解密方式时，通常有两种情形：\u003cstrong\u003e对称加密\u003c/strong\u003e 和 \u003cstrong\u003e非对称加密\u003c/strong\u003e。\u003c/p\u003e","title":"Golang中使用RSA进行加解密"},{"content":"介绍 boltdb 是一个使用 Go 编写的键值对数据库，它的目标是 简单、快速和稳定的轻型数据库，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\n使用 1. 安装 go get github.com/boltdb/bolt/... 2. 打开(Open)一个数据库文件连接 func main() { dbPath := \u0026#34;./data.db\u0026#34; // 指定你的数据库文件要存储的地方 db, err := bolt.Open(dbPath, os.ModePerm, nil) if err != nil { panic(err) } ... } bolt 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 Open 操作添加超时：\ndb, err := bolt.Open(dbPath, os.ModePerm, \u0026amp;bolt.Options{Timeout: time.Second * 5}) 运行如上代码，如果 5 秒内未能成功打开文件，会返回一个 timeout 错误。\n3. 事务(Transaction) 在某一时刻， bolt 只允许有一个读写事务 或者 允许多个只读事务。其事务的隔离级别对应 MySQL 中的 可重复读，即每一个事务在 commit 之前，多次读库多看到的信息视图是一致的。\n3.1 读写事务(Read-write Transactions) 启动一个 读写事务，可以通过下面的方式：\nerr := db.Update(func(tx *bolt.Tx) error { ... return nil }) if err != nil { log.Fatal(err) } 或者：\n// open a Read-write transaction with the first argument `true` tx,err := db.Begin(true) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } Update 中的函数就是一个 可重复读 的事务，在这个函数里面可以进行任何的数据库操作。最后需要通过 return nil 来提交修改；如果提交一个 error，那么整个修改会进行 Rollback，回到最初的状态，不会产生任何改变。注意，在 Update 中手动进行 Rollback，会造成 panic。\n3.2 只读事务(Read-only Transactions) 通过下面的方式打开一个只读事务：\nerr := db.View(func(tx *bolt.Tx) error { ... return nil }) 或者：\n// open a Read-only transaction with the first argument `false` tx,err := db.Begin(false) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } 需要注意的是，在 View 只读事务中，无法做一些“写入”操作，能做的可以是：读一个 bucket，读对应 bucket 中的值，或者复制整个 db。注意，在 View 中手动进行 Rollback，会造成 panic。\n3.3 批量读写事务(Batch read-write transactions) 通过以下方式使用 Batch：\nerr := db.Batch(func(tx *bolt.Tx) error { b := tx.Bucket(bucketName) for i := 0; i \u0026lt; 100; i++ { if err := b.Put([]byte(fmt.Sprintf(\u0026#34;name-%d\u0026#34;, i+1)), []byte(fmt.Sprintf(\u0026#34;%d\u0026#34;, rand.Int31n(math.MaxInt32)))); err != nil { return err } } return nil }) Batch 和 Update 相似，以下情形除外：\nBatch 中的操作可以被合并成一个 transaction； 传给 Batch 的函数可能被执行多次，不管返回的 error 是否为 nil 这也就意味着，Batch 里面的操作必须是幂等的，这似乎会带来一些额外的工作，因此之建议在 多个 goroutine 同时调用的时候使用。\n创建一个 DB 对象是线程安全的，但一个事务里面的操作并不是线程安全的。另外，读写事务 和 只读事务 不应该相互依赖，或者不应该同时在同一个 goroutine 中被长时间打开，因为 读写事务 需要周期性地 re-map 数据，但是当 只读事务 打开时，这个操作会造成死锁。\n4. bolt 的读与写 首先，不管是读还是写，都需要先指定一个 bucket，这个概念类似于关系型数据库中的 table。对于 bucket 的操作，有以下几种：\nCreateBucket 创建一个 bucket ，但当 bucket 已经存在时，会返回错误 bucket already exists；如果成功，会返回一个 Bucket对象： bucketName := \u0026#34;my-bucket\u0026#34; _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，当 bucket 已经存在时，会返回错误 b, err := tx.CreateBucket([]byte(bucketName)) if err != nil { return err } // ... do some thing return nil }) CreateBucketIfNotExists 创建一个 bucket，创建成功 或 bucket已经存在时，返回 Bucket 对象： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // ... return nil }) Bucket 选择一个已经存在的 bucket，bucket 不存在时不会报错，但返回的 Bucket 对象为 nil，后续所有对 b 的操作都会造成空指针错误： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式选择一个已经存在的 bucket b, err := tx.Bucket([]byte(bucketName)) if err != nil { return err } fmt.Println(b == nil) // 如果 bucket 不存在，则 b 为 nil，后面所有对 b 的操作都会造成空指针错误 return nil }) DeleteBucket 删除一个已经存在的 bucket，如果 bucket 不存在会返回 bucket not found 错误。 _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式删除一个已经存在的 bucket，如果 bucket 不存在会返回 `bucket not found` 错误 err := tx.DeleteBucket([]byte(bucketName)) if err != nil { return err } return nil }) 4.1 写 或 修改 只有一种方式：使用 Put(k,v []byte) 方法。\n_ = db.Update(func (tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // set name = Jemmy err = b.Put([]byte(\u0026#34;name\u0026#34;),[]byte(\u0026#34;Jemmy\u0026#34;)) if err != nil { return err } }) Value 不一定是一个字符串，你可以存储整个序列化后的对象：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket111\u0026#34; err = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } u := \u0026amp;User{ ID: 1, Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) err = b.Put([]byte(key), data) if err != nil { return err } fmt.Printf(\u0026#34;%s\\n\u0026#34;, b.Get([]byte(key))) return nil }) if err != nil { log.Fatal(err) } } 输出：\n{\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 比较有用的一个技巧：可以使用 NextSequence() 得到一个递增的 unique identifier，你可以把它理解成 MySQL 中的递增主键：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket222\u0026#34; err = db.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } for i:=0;i\u0026lt;5;i++ { u := \u0026amp;User{ Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } // 获取一个主键值。只有当 Tx被关闭 或者 b不可写 时，才会返回错误。在 Update() 函数中不可能发生 id, err := b.NextSequence() if err != nil { return err } u.ID = id // 将 user 序列化成 []byte data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) // 使用 Put 保存 err = b.Put([]byte(key), data) if err != nil { return err } } return nil }) if err != nil { log.Fatal(err) } _ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) } 输出：\nkey=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 4.2 读取 正如上面代码所示，你可以使用 func (b *Bucket) Get(key []byte) []byte 。下面介绍一些更高阶的用法：\n遍历整个 bucket: bolt 通过 byte-sorted 的顺序在 bucket 中存储键值对，这个设计使得对 key 的迭代遍历非常方便也非常快：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 使用 游标 cursor 可以非常方便地移动，类似的函数还有：\nFirst() Move to the first key. Last() Move to the last key. Seek() Move to a specific key. Next() Move to the next key. Prev() Move to the previous key. 所以你可以使用下面的方式进行倒序遍历：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.Last(); k != nil; k, v = c.Prev() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 当然，如果你明确知道你要遍历整个 bucket，并且是正序输出，也可以通过 ForEach：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) err := b.ForEach(func(k, v []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) return nil }) if err != nil { return err } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 前缀匹配搜索，可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() prefix := []byte(\u0026#34;1\u0026#34;) for k, v := c.Seek(prefix); k != nil \u0026amp;\u0026amp; bytes.HasPrefix(k, prefix); k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 范围搜索，也可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() min := []byte(\u0026#34;1\u0026#34;) max := []byte(\u0026#34;3\u0026#34;) for k, v := c.Seek(min); k != nil \u0026amp;\u0026amp; bytes.Compare(k, max) \u0026lt;= 0; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} ","permalink":"http://localhost:1313/posts/boltdb%E4%BD%BF%E7%94%A8%E4%B8%80%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/boltdb/bolt\"\u003eboltdb\u003c/a\u003e 是一个使用 Go 编写的键值对数据库，它的目标是 \u003cstrong\u003e简单、快速和稳定的轻型数据库\u003c/strong\u003e，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\u003c/p\u003e\n\u003ch2 id=\"使用\"\u003e使用\u003c/h2\u003e\n\u003ch3 id=\"1-安装\"\u003e1. 安装\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ego get github.com/boltdb/bolt/...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-打开open一个数据库文件连接\"\u003e2. 打开(Open)一个数据库文件连接\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;./data.db\u0026#34;\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 指定你的数据库文件要存储的地方\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edb\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebolt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eOpen\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eos\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eModePerm\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tpanic(\u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003ebolt\u003c/code\u003e 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 \u003ccode\u003eOpen\u003c/code\u003e 操作添加超时：\u003c/p\u003e","title":"Boltdb使用(一)基本用法"},{"content":" 实验机器：MacBook Pro (Retina, 15-inch, Mid 2015)\nGolang 版本：go version go1.14.6 darwin/amd64\n一、前言 网卡 也称 网络适配器，是电脑与局域网进行相互连接的设备，在 OSI 七层模型中，工作在 物理层 和 数据链路层，其作用可以简单描述为：\n将本机的数据封装成帧，通过网线发送到网络上去； 接收网络上其他设别传过来的帧，将其重新组合成数据，向上层传输到本机的应用程序中。 这里的网卡指的是真实的网卡，是一个真实的物理设备。今天我们要了解的是一个叫 虚拟网卡 的东西。\n在当前的云计算时代，虚拟机和容器的盛行离不开网络管理设备，即 虚拟网络设备，或者说是 虚拟网卡。虚拟网卡有以下好处：\n对用户来说，虚拟网卡和真实网卡几乎没有区别。我们对虚拟网卡的操作不会影响到真实的网卡，不会影响到本机网络； 虚拟网卡的数据可以直接从用户态读取和写入，这样方便我们在用户态进行一些额外的操作(比如截包、修改后再发送出去) Linux 系统中有众多的虚拟网络设备，如 TUN/TAP 设备、VETH 设备、Bridge 设备、Bond 设备、VLAN 设备、MACVTAP 设备 等。这里我们只关注 TUN/TAP 设备。\ntap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。\n二、理解 tun/tap 数据传输过程 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备(OSI 模型的第三层：网络层，即IP 层),也就是说，通过它可以处理来自网络层的数据，更通俗一点的说，通过它，通过它我们可以处理 IP 数据包。\n先看一下正常情况下的物理设备是如何工作的：\n这里的 ethx 表示的就是一台主机的真实的网卡接口，一般一台主机只会有一块网卡，像一些特殊的设备，比如路由器，有多少个口就有多少块网卡。\n我们先看一下 ifconfig 命令的输出：\n$ ifconfig ... en0: flags=8863\u0026lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST\u0026gt; mtu 1500 options=400\u0026lt;CHANNEL_IO\u0026gt; ether ac:bc:32:96:86:01 inet6 fe80::456:7cb8:3dc5:2722%en0 prefixlen 64 secured scopeid 0x4 inet 10.0.0.176 netmask 0xffffff00 broadcast 10.0.0.255 nd6 options=201\u0026lt;PERFORMNUD,DAD\u0026gt; media: autoselect status: active ... 可以看到 etho 这个网卡接口分配到的 IP 地址是 10.0.0.176，这是一块物理网卡，它的两端分别是 内核协议栈 和 外面的网络，从物理层收到的数据，会被转发给内核进而通过某种接口被应用层的用户程序读到；应用程序要想和网络中的另一个进程进行数据通信，会先将数据发送给内核，然后被网卡发送出去。\n接下来我们看一看 tun/tap 设备的工作方式：\n上图中应用层有两个应用程序，而 网络协议栈 和 网络设备(eth0 和 tun0) 都位于内核层，对于 socket，可以这么理解：socket 就像是一组 接口(interface)，它将更复杂的 TCP/IP 协议簇隐藏在 socket 接口后面，只对用户暴露更简单的接口，就像操作系统隐藏了底层的硬件操作细节而只对用户程序暴露接口一样，它是 应用层 与 TCP/IP协议簇 通信的中间软件抽象层。\ntun0 就是一个 tun/tap 虚拟设备，从上图中就可以看出它和物理设备 eth0 的区别：虽然它们的一端都是连着网络协议栈，但是 eth0 另一端连接的是物理网络，而 tun0 另一端连接的是一个 应用层程序，这样协议栈发送给 tun0 的数据包就可以被这个应用程序读取到，此时这个应用程序可以对数据包进行一些自定义的修改(比如封装成 UDP)，然后又通过网络协议栈发送出去——这就是目前大多数 代理 的工作原理。\n假如 eth0 的 IP 地址是 10.0.0.176，而 tun0 配的 IP 为 192.168.1.2。上图是一个典型的使用 tun/tap 进行 VPN 工作的原理，发送给 192.168.1.0/24 的数据通过 应用程序 B 这个 隧道 处理(隐藏一些信息)之后，利用真实的物理设备 10.0.0.176 转发给目的地址(假如为 49.233.198.76)，从而实现 VPN。我们看下每一个流程：\nApplication A 是一个普通的应用程序，通过 Socket A 发送了一个数据包，这个数据包的目的地址是 192.168.1.2； Socket A 将这个数据包丢给网络协议栈； 协议栈根据数据包的目的地址，匹配本地路由规则，得知这个数据包应该由 tun0 出去，于是将数据包丢给了 tun0； tun0 收到数据包之后，发现另一端被 Application B 打开，于是又将数据包丢给了 Application B； Application B 收到数据包之后，解包，做一些特殊的处理，然后构造一个新的数据包，将原来的数据嵌入新的数据包中，最后通过 Socket B 将数据包转发出去，这个时候新数据包的源地址就变成了 eth0 的地址，而目的地址就变成了真正想发送的主机的地址，比如 49.233.198.76； Socket B 将这个数据包丢给网络协议栈； 协议栈根据本地路由得知，这个数据包应该从 eth0 发送出去，于是将数据包丢给 eth0； eth0 通过物理网络将这个数据包发送出去 简单来说，tun/tap 设备的用处是将协议栈中的部分数据包转发给用户空间的特殊应用程序，给用户空间的程序一个处理数据包的机会，比较常用的场景是 数据压缩、加密等，比如 VPN。\n三、使用 Golang 实现一个简易 VPN 先看客户端的实现：\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; \u0026#34;github.com/songgao/water\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; ) /* * @CreateTime: 2020/11/16 11:08 * @Author: hujiaming * @Description: 数据传输过程： 用户数据，如ping --\u0026gt; 协议栈conn --\u0026gt; IfaceWrite --\u0026gt; IfaceRead --\u0026gt; 协议栈conn --\u0026gt; 网线 */ var ( serviceAddress = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;10.0.0.245:9621\u0026#34;, \u0026#34;service address\u0026#34;) tunName = flag.String(\u0026#34;dev\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;local tun device name\u0026#34;) ) func main() { flag.Parse() // create tun/tap interface iface, err := water.New(water.Config{ DeviceType: water.TUN, PlatformSpecificParams: water.PlatformSpecificParams{ Name: *tunName, }, }) if err != nil { color.Red(\u0026#34;create tun device failed,error: %v\u0026#34;, err) return } // connect to server conn, err := net.Dial(\u0026#34;tcp\u0026#34;, *serviceAddress) if err != nil { color.Red(\u0026#34;connect to server failed,error: %v\u0026#34;, err) return } // go IfaceRead(iface, conn) go IfaceWrite(iface, conn) sig := make(chan os.Signal, 3) signal.Notify(sig, syscall.SIGINT, syscall.SIGABRT, syscall.SIGHUP) \u0026lt;-sig } /* IfaceRead 从 tun 设备读取数据 */ func IfaceRead(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 在这里你可以对拿到的数据包做一些数据，比如加密。这里只对其进行简单的打印 color.Cyan(\u0026#34;get data from tun: %v\u0026#34;, packet[:n]) // 通过物理连接，将处理后的数据包发送给目的服务器 err = forwardServer(conn, packet[:n]) if err != nil { color.Red(\u0026#34;forward to server failed\u0026#34;) } } } /* IfaceWrite 从物理连接中读取数据，然后通过 tun 将数据发送给 IfaceRead */ func IfaceWrite(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 从物理请求中读取数据 nr, err := conn.Read(packet) if err != nil { color.Red(\u0026#34;WRITE: read from tun failed\u0026#34;) break } // 将处理后的数据通过 tun 发送给 IfaceRead _, err = iface.Write(packet[4:nr]) if err != nil { color.Red(\u0026#34;WRITE: write to tun failed\u0026#34;) } } } // forwardServer 通过物理连接发送一个包 func forwardServer(conn net.Conn, buff []byte) (err error) { output := make([]byte, 0) bsize := make([]byte, 4) binary.BigEndian.PutUint32(bsize, uint32(len(buff))) output = append(output, bsize...) output = append(output, buff...) left := len(output) for left \u0026gt; 0 { nw, er := conn.Write(output) if er != nil { err = er } left -= nw } return err } 再看服务端的实现：\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; ) /* * @CreateTime: 2020/11/16 11:39 * @Author: hujiaming * @Description: */ var clients = make([]net.Conn, 0) func main() { listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:9621\u0026#34;) if err != nil { color.Red(\u0026#34;listen failed,error: %v\u0026#34;, err) return } color.Cyan(\u0026#34;server start...\u0026#34;) for { // 对客户端的每一个连接，都起一个 go 协程去处理 conn, err := listener.Accept() if err != nil { color.Red(\u0026#34;tcp accept failed,error: %v\u0026#34;, err) break } clients = append(clients, conn) color.Cyan(\u0026#34;accept tun client\u0026#34;) go handleClient(conn) } } func handleClient(conn net.Conn) { defer conn.Close() buff := make([]byte, 65536) for { n, err := conn.Read(buff) if err != nil { if err != io.EOF { color.Red(\u0026#34;read from client failed\u0026#34;) } break } // broadcast data to all clients for _, c := range clients { if c.RemoteAddr().String() != conn.RemoteAddr().String() { c.Write(buff[:n]) } } } } 在这里，我们把 网络协议栈 抽象成了一个黑盒。在接下来的步骤中，我们将逐渐抽丝剥茧，一步步了解网络协议栈的工作原理，以及用 Golang 去实现它。\n四、参考 原创 详解云计算网络底层技术——虚拟网络设备 tap/tun 原理解析 TUN/TAP概述及操作 TUN/TAP设备浅析 https://github.com/ICKelin/article/issues/9 ","permalink":"http://localhost:1313/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tuntap/","summary":"\u003cblockquote\u003e\n\u003cp\u003e实验机器：\u003ccode\u003eMacBook Pro (Retina, 15-inch, Mid 2015)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eGolang 版本：\u003ccode\u003ego version go1.14.6 darwin/amd64\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e网卡\u003c/strong\u003e 也称 \u003cstrong\u003e网络适配器\u003c/strong\u003e，是电脑与局域网进行相互连接的设备，在 \u003ccode\u003eOSI\u003c/code\u003e 七层模型中，工作在 \u003cstrong\u003e物理层\u003c/strong\u003e 和 \u003cstrong\u003e数据链路层\u003c/strong\u003e，其作用可以简单描述为：\u003c/p\u003e","title":"虚拟网络设备tuntap"},{"content":"一、前言 公司后端服务已经全部微服务化，想要调试某个服务可以使用 grpcui，但要对某个接口进行压测，grpcui 还做不到。诸多努力之后找到本次主角：https://github.com/bojand/ghz，官网：ghz.sh。\n推荐理由：简洁！可以一次性解决掉 proto 文件相互之间引用的烦心事！\n二、使用 这里只介绍在 Mac 环境下的用法，其他环境请参阅官网。\n另：我们仍旧使用 GOPATH 方式来管理包，我的： export GOPATH=/Users/hujiaming/go ，本次测试目录为：/Users/hujiaming/go/src/hujm.net。\n1. 安装 直接使用 brew 来安装：\nbrew install ghz 如果不成功，可以直接去 https://github.com/bojand/ghz/releases 下载二进制，下载后放在 PATH 中即可。\n注：还需要有 protoc 工具。\n2. 生成 protoset 文件 如果你的 proto 文件中还引用了其他文件，强烈建议使用 protoset 方式。\n假如我在如下的 proto 中定义一个 GRPC服务：\n/** * @filename: api.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/offer.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/association.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; service ApiService { rpc CreateSKUAssociations(CreateSKUAssociationsReq) returns (CreateSKUAssociationsReply) {}; } message CreateSKUAssociationsReq { repeated Association associations = 1 [ (validator.field) = {repeated_count_min : 1} ]; } message CreateSKUAssociationsReply {} 而 Association 是定义在 \u0026quot;xxx/cm/fulfillment/offermanager/offerpb/association.proto” 文件中的：\n/** * @filename: association.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; message Association { int64 offer_id = 1 [ (validator.field) = {int_gt : 1000000000} ]; string sku_code = 2 [ (validator.field) = {string_not_empty : true} ]; string author = 3 [ (validator.field) = {string_not_empty : true} ]; } 如果采用非 protoset 方式，可能要先生成 association.pb.go，再生成 api.pb.go 文件。这里我们采用 protoset 方式，一步到位：\nprotoc \\ --include_imports \\ -I. -I/usr/local/include \\ -I/usr/local/go \\ -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \\ -I$GOPATH/src \\ --proto_path=. \\ --descriptor_set_out=api.bundle.protoset \\ api.proto 需要注意的点如下：\n如果你的 proto 文件中有引用，上述命令中一定要有 include_imports 参数； 在后面运行时如果出现 no descriptor found for \u0026quot;xxxxxx\u0026quot;，可能是某个文件没有通过 -I 引用进来，记得加上重新执行。 不出意外，会在当前目录下生成 api.bundle.protoset 文件。\n3. 执行压测任务 可以看一下 ghz 的用法：\n$ ghz --help usage: ghz [\u0026lt;flags\u0026gt;] [\u0026lt;host\u0026gt;] Flags: -h, --help Show context-sensitive help (also try --help-long and --help-man). --config= Path to the JSON or TOML config file that specifies all the test run settings. --proto= The Protocol Buffer .proto file. --protoset= The compiled protoset file. Alternative to proto. -proto takes precedence. --call= A fully-qualified method name in \u0026#39;package.Service/method\u0026#39; or \u0026#39;package.Service.Method\u0026#39; format. -i, --import-paths= Comma separated list of proto import paths. The current working directory and the directory of the protocol buffer file are automatically added to the import list. --cacert= File containing trusted root certificates for verifying the server. --cert= File containing client certificate (public key), to present to the server. Must also provide -key option. --key= File containing client private key, to present to the server. Must also provide -cert option. --cname= Server name override when validating TLS certificate - useful for self signed certs. --skipTLS Skip TLS client verification of the server\u0026#39;s certificate chain and host name. --skipFirst=0 Skip the first X requests when doing the results tally. --insecure Use plaintext and insecure connection. --authority= Value to be used as the :authority pseudo-header. Only works if -insecure is used. -c, --concurrency=50 Number of requests to run concurrently. Total number of requests cannot be smaller than the concurrency level. Default is 50. -n, --total=200 Number of requests to run. Default is 200. -q, --qps=0 Rate limit, in queries per second (QPS). Default is no rate limit. -t, --timeout=20s Timeout for each request. Default is 20s, use 0 for infinite. -z, --duration=0 Duration of application to send requests. When duration is reached, application stops and exits. If duration is specified, n is ignored. Examples: -z 10s -z 3m. -x, --max-duration=0 Maximum duration of application to send requests with n setting respected. If duration is reached before n requests are completed, application stops and exits. Examples: -x 10s -x 3m. --duration-stop=\u0026#34;close\u0026#34; Specifies how duration stop is reported. Options are close, wait or ignore. -d, --data= The call data as stringified JSON. If the value is \u0026#39;@\u0026#39; then the request contents are read from stdin. -D, --data-file= File path for call data JSON file. Examples: /home/user/file.json or ./file.json. -b, --binary The call data comes as serialized binary message or multiple count-prefixed messages read from stdin. -B, --binary-file= File path for the call data as serialized binary message or multiple count-prefixed messages. -m, --metadata= Request metadata as stringified JSON. -M, --metadata-file= File path for call metadata JSON file. Examples: /home/user/metadata.json or ./metadata.json. --stream-interval=0 Interval for stream requests between message sends. --reflect-metadata= Reflect metadata as stringified JSON used only for reflection request. -o, --output= Output path. If none provided stdout is used. -O, --format= Output format. One of: summary, csv, json, pretty, html, influx-summary, influx-details. Default is summary. --connections=1 Number of connections to use. Concurrency is distributed evenly among all the connections. Default is 1. --connect-timeout=10s Connection timeout for the initial connection dial. Default is 10s. --keepalive=0 Keepalive time duration. Only used if present and above 0. --name= User specified name for the test. --tags= JSON representation of user-defined string tags. --cpus=8 Number of cpu cores to use. --debug= The path to debug log file. -e, --enable-compression Enable Gzip compression on requests. -v, --version Show application version. Args: [\u0026lt;host\u0026gt;] Host and port to test. 需要关注的几个参数：\n--skipTLS --insecure：如果服务不支持 HTTPS 的话，可以使用此参数跳过 TLS 验证；\n--protoset：指定本次运行的 protoset 文件路径，即上面生成的 api.bundle.protoset；\n--call：需要调用的方法名，格式为：包名.服务名.方法名。比如我要调用 offerpb 包下的 ApiService 服务的 CreateSKUAssociations 方法，那么 call 参数应该是： --call offerpb.ApiService.CreateSKUAssociations；\n--data：本次请求的参数，通过 jsonString 的格式传入；\n--data-file：本次请求的参数，只不过通过文件的形式传入，文件中是标准的通过 json 序列化后的数据；\n--metadata：metadata 参数，通过 jsonString 的格式传入；\n-c：并发数，默认 50(这里有坑，具体参照官网解释：-c。虽然会其多个 goroutine，但是所有的 goroutine 会公用一个连接)；\n-n：请求数，默认 200。n 不能小于 c。\n假设 ApiService服务的地址是：localhost:58784。我们执行下面的命令，发起一次压测任务：\n$ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data \u0026#39;{\u0026#34;associations\u0026#34;:[{\u0026#34;sku_code\u0026#34;: \u0026#34;test:6985079117562211244\u0026#34;,\u0026#34;offer_id\u0026#34;: 8629237865019910744,\u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34;}]}\u0026#39; \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 当你的请求参数比较多时，将他们放在一个文件中、然后使用 --data-file 参数是更好的选择：\n$ cat test_data.json { \u0026#34;associations\u0026#34;: [ { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6237052533738512496\u0026#34;, \u0026#34;offer_id\u0026#34;: 5655307241153104444, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:2156276639623439583\u0026#34;, \u0026#34;offer_id\u0026#34;: 6360134836979240095, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:8361104385030719827\u0026#34;, \u0026#34;offer_id\u0026#34;: 3705044490439993926, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6023087259299523902\u0026#34;, \u0026#34;offer_id\u0026#34;: 3776027093787512475, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:9196748606623463644\u0026#34;, \u0026#34;offer_id\u0026#34;: 1506864634761125694, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; } ] } $ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data-file /Users/hujiaming/go/src/hujm.net/test_data.json \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 看下输出：\nSummary: Count:\t1000 Total:\t743.17 ms Slowest:\t194.74 ms Fastest:\t37.67 ms Average:\t69.32 ms Requests/sec:\t1345.59 Response time histogram: 37.670 [1]\t| 53.377 [384]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 69.084 [349]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 84.791 [138]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 100.498 [26]\t|∎∎∎ 116.205 [2]\t| 131.912 [0]\t| 147.619 [16]\t|∎∎ 163.326 [33]\t|∎∎∎ 179.033 [17]\t|∎∎ 194.739 [34]\t|∎∎∎∎ Latency distribution: 10 % in 46.59 ms 25 % in 49.94 ms 50 % in 57.28 ms 75 % in 69.51 ms 90 % in 102.33 ms 95 % in 163.38 ms 99 % in 183.99 ms Status code distribution: [OK] 1000 responses Summary 的参数：\nCount：完成的请求总数，包括成功的和失败的； Total：本次请求所用的总时长，从 ghz 启动一直到结束； Slowest：最慢的某次请求的时间； Fastest：最快的某个请求的时间； Average：(所有请求的响应时间) / Count。 Requests/sec：RTS，Count / Total 的值。 三、参考资料 https://github.com/bojand/ghz Simple gRPC benchmarking and load testing tool ","permalink":"http://localhost:1313/posts/%E4%BD%BF%E7%94%A8ghz%E5%8E%8B%E6%B5%8Bgrpc%E6%8E%A5%E5%8F%A3/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e公司后端服务已经全部微服务化，想要调试某个服务可以使用 \u003ca href=\"https://github.com/fullstorydev/grpcui\"\u003e\u003ccode\u003egrpcui\u003c/code\u003e\u003c/a\u003e，但要对某个接口进行压测，\u003ccode\u003egrpcui\u003c/code\u003e 还做不到。诸多努力之后找到本次主角：\u003ca href=\"https://github.com/bojand/ghz\"\u003ehttps://github.com/bojand/ghz\u003c/a\u003e，官网：\u003ca href=\"https://ghz.sh\"\u003eghz.sh\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e推荐理由：简洁！可以一次性解决掉 \u003ccode\u003eproto\u003c/code\u003e 文件相互之间引用的烦心事！\u003c/p\u003e","title":"使用ghz压测GRPC接口"},{"content":"一、简介 默克尔树是一种典型的二叉树结构，由一个根节点、一组中间节点 和 一组叶节点 组成。默克尔树最早由 Merkle Ralf 在 1980 年提出，曾广泛用于 文件系统 和 P2P 系统中，比如 Git、区块链、IPFS 等大名鼎鼎的项目或技术。\n他又被称为 哈希树，即存储哈希值的树。树的叶子结点是 数据块(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\n最下面的叶节点包含存储数据或其哈希值。 非叶子节点（包括中间节点和根节点）都是它的两个孩子节点内容的哈希值。 如果是奇数个叶子结点，那么其父节点保存的哈希值就是它本身或者复制一份自己凑成对再进行哈希的结果(具体实现取决于实际情况) 当然，默克尔树可以推广到多叉树的情形，此时非叶子节点的内容为它所有的孩子节点的内容的哈希值。\n二、原理与用途 最开始，我们有一组已经准备好的数据块(比如文件)，他们根据某个标准有序(比如根据文件名字典排序)，而每一个文件都有唯一的哈希值与之对应。这是最底层的情况，当我们向上走的时候，每两个当前层的节点(左右孩子结点)的哈希值可以重新组合，形成一个新的节点(父节点)，这个新的结点中不存储数据，其哈希值为左右孩子结点组合后再次使用预设的哈希函数求哈希值。如此以往，直到生成树根，这个树根我们称为 Merkel Root。有一个特殊情况需要注意，有可能某一层的节点数是奇数，这样就会剩下最后一个结点，再没有结点与其组队生成父节点，这种情况下有两种解决方案：一种是复制一份自己；另一种是不复制，让其父节点只有它一个子节点，而且是左孩子结点。\n目前，默克尔树的典型应用场景包括如下几种。\n快速比较大量数据 对每组数据排序后构建默克尔树结构。当两个默克尔树根相同时，则意味着所代表的两组数据必然相同。否则，必然不同。\n由于 Hash 计算的过程可以十分快速，预处理可以在短时间内完成。利用默克尔树结构能带来巨大的比较性能优势。\n快速定位修改 假如我们基于文件 D0~D3 构建如上的默克尔树，如果 D2 被修改，那么会影响到结点 N2、N2 和 Root。此时我们可根据发生变化的节点，沿着 Root -\u0026gt; N5 -\u0026gt; N2， 通过 O(logN) 的时间复杂度快速定位到哪个结点发生了变化。\n零知识证明 它指的是证明者能够在不向验证者提供任何有用的信息的情况下(没有泄露信息)，使验证者相信某个论断是正确的。有一个很简单的例子：A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法：\nA 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。\nB 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。\n后面的第二种方法属于零知识证明。它的好处在于，在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。\n在默克尔树中，我们仍旧以上图为例，如何向他人证明我拥有 D0 这个数据，而不用暴露更多系统的信息呢？模仿上面的例子，验证者随机提供数据 D1、D2 和 D3，证明者构造如图的默克尔树，并公布 N1 、N5 和 Root。验证者自行计算 Root 值，看是否一致，从而检验 D0 是否存在，因为如果存在，N0 一定相同，那么 N4(N0-N1) 也一定相同、Root(N4-N5)也一定相同。整个过程中验证着没有得到任何除了 D0 外的敏感信息(其他的 D)。\n三、Golang 实现 首先，我们定义需要的结构：\n// Node 表示默克尔树中的 叶结点、非叶结点 或者 Root type Node struct { Tree *MerkleTree // 所在的 Merkle Tree Parent *Node // 父节点 Left *Node // 左孩子 Right *Node // 右孩子 leaf bool // 是否叶子结点 Hash []byte // 如果是叶子结点，则为叶子结点数据的哈希值；如果是非叶子结点，则为左右孩子哈希值组合后的哈希值 C Content // 叶子结点存储的数据块 } // Content 代表一个数据块 type Content interface { CalculateHash() ([]byte, error) Equals(other Content) (bool, error) } // MerkleTree 默克尔树 type MerkleTree struct { Root *Node // Merkle Root 树根 merkleRoot []byte // 树根的哈希值 Leafs []*Node // 所有的叶子结点 hashStrategy func() hash.Hash // 计算哈希的方法 } 需要注意的是，hashStrategy 是一个函数，其返回 type hash.Hash interface，目前最常见的实现是 sha256.New 等，这里为了说明清楚原理，我们自己实现一个，计算 hash 时，只是简单将其转化为 []byte 即可：\ntype myHash struct { hash []byte data []byte blockSize int } func newMyHash() hash.Hash { h := \u0026amp;myHash{ data: make([]byte, 0), blockSize: 64, } return h } // Write 将 p 中的数据更新进 m func (m *myHash) Write(p []byte) (n int, err error) { nn := 0 if len(m.data) == 0 { m.data = p nn = len(p) } else { m.data = append(m.data, 38) m.data = append(m.data, p...) nn = len(m.data) + 1 + len(p) } return nn, nil } // Sum 后面追加 func (m *myHash) Sum(b []byte) []byte { m.data = append(m.data, b...) return m.data } func (m *myHash) Reset() { m.data = make([]byte, 0) m.blockSize = 64 } func (m *myHash) Size() int { return len(m.data) } func (m *myHash) BlockSize() int { return m.blockSize } func newMyHashFunc() hash.Hash { return newMyHash() } 另外，对于 type Content interface，我们也简单实现一个：\ntype myContent string func newMyContent(s string) myContent { return myContent(s) } func (c myContent) CalculateHash() ([]byte, error) { //hash := md5.New() //hash.Write(c.ToBytes()) //return hash.Sum(nil), nil return []byte(c), nil } func (c myContent) Equals(other merkletree.Content) (bool, error) { return reflect.DeepEqual(c, other), nil } 创建 接下来我们提供一个构造方法：\n//NewTree creates a new Merkle Tree using the content cs. func NewTree(cs []Content) (*MerkleTree, error) { var defaultHashStrategy = sha256.New // 默认使用 sha256.New 进行哈希 t := \u0026amp;MerkleTree{ hashStrategy: defaultHashStrategy, } root, leafs, err := buildWithContent(cs, t) // 逐层构建结点 if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } // NewTreeWithHashStrategy 效果同 NewTree，不过使用自定义的哈希函数 func NewTreeWithHashStrategy(cs []Content, hashStrategy func() hash.Hash) (*MerkleTree, error) { t := \u0026amp;MerkleTree{ hashStrategy: hashStrategy, } root, leafs, err := buildWithContent(cs, t) if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } 接着我们来看 buildWithContent 做了什么：\n// buildWithContent 主要将 Content 转变成 Node，为下一步的逐层构建做好准备 func buildWithContent(cs []Content, t *MerkleTree) (*Node, []*Node, error) { if len(cs) == 0 { return nil, nil, errors.New(\u0026#34;error: cannot construct tree with no content\u0026#34;) } var leaves []*Node // 将当前的所有 Content 转化成 Node，放在数组 leaves 中 for _, c := range cs { hash, err := c.CalculateHash() if err != nil { return nil, nil, err } leaves = append(leaves, \u0026amp;Node{ Hash: hash, C: c, leaf: true, Tree: t, }) } root, err := buildIntermediate(leaves, t) // 逐层构建默克尔树，最后返回树根 if err != nil { return nil, nil, err } return root, leaves, nil } 再看 buildIntermediate 如何逐层构建：\nfunc buildIntermediate(nl []*Node, t *MerkleTree) (*Node, error) { var nodes []*Node // 如果是单数，不复制自己以凑成对，而是使自己的父节点只有一个左孩子结点(自己)，没有右孩子结点 for i := 0; i \u0026lt; len(nl); i += 2 { h := t.hashStrategy() left, right := i, i+1 var chash []byte if right == len(nl) { // 单数个，父节点计算哈希时只计算左孩子的 chash = nl[left].Hash } else { // 双数个，父节点从左右子孩子的哈希计算得到自己的哈希 chash = append(nl[left].Hash, nl[right].Hash...) } if _, err := h.Write(chash); err != nil { return nil, err } // 生成父节点 node := \u0026amp;Node{ Left: nl[left], Hash: h.Sum(nil), Tree: t, } if right \u0026lt; len(nl) { node.Right = nl[right] } nodes = append(nodes, node) if right \u0026lt; len(nl) { node.Right.Parent = node } nl[left].Parent = node // 如果只有两个，说明当前构造的 node 就是根节点，结束递归 if len(nl) == 2 { return node, nil } } // 递归调用 return buildIntermediate(nodes, t) } 打印 为了方便调试，我们先实现反序列化默克尔树——逐层遍历二叉树。逐层遍历二叉树是数据结构课程中的基础操作，需要用到一个队列，我们先实现一个简单的队列：\ntype queue struct { data []*Node } func newQueue() queue { q := queue{data: make([]*Node, 0)} return q } // 入队 func (q *queue) enqueue(c *Node) { q.data = append(q.data, c) } // 出队 func (q *queue) dequeue() *Node { if len(q.data) == 0 { return nil } data := q.data[0] q.data = q.data[1:] return data } // 是否为空 func (q *queue) isEmpty() bool { return len(q.data) == 0 } // 队列中元素个数 func (q *queue) len() int { return len(q.data) } 借助队列实现默克尔树的打印：\n// Print 打印默克尔树 func (m *MerkleTree) Print() { if len(m.Leafs) == 0 { fmt.Println(\u0026#34;empty tree\u0026#34;) return } q := newQueue() q.enqueue(m.Root) for !q.isEmpty() { size := q.len() for i := 0; i \u0026lt; size; i++ { tmp := q.dequeue() if tmp == nil { break } if !tmp.leaf { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } else { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } if tmp.Left != nil { q.enqueue(tmp.Left) } if tmp.Right != nil { q.enqueue(tmp.Right) } } fmt.Print(\u0026#34;\\n\u0026#34;) } } 查找 先看实现：\n// 查找 content 对应的从上到下的路径，index 表示是否为左孩子 func (m *MerkleTree) GetMerklePath(content Content) ([][]byte, []int64, error) { for _, current := range m.Leafs { ok, err := current.C.Equals(content) if err != nil { return nil, nil, err } if ok { currentParent := current.Parent var merklePath [][]byte var index []int64 for currentParent != nil { // 当前节点是父节点的右孩子 if bytes.Equal(currentParent.Right.Hash, current.Hash) { merklePath = append(merklePath, currentParent.Right.Hash) index = append(index, 1) } else { merklePath = append(merklePath, currentParent.Left.Hash) index = append(index, 0) } current = currentParent currentParent = currentParent.Parent } // 添加 root if len(merklePath) \u0026gt; 0 { if bytes.Equal(m.Root.Left.Hash, merklePath[0]) { index = append(index, 0) } else { index = append(index, 1) } merklePath = append(merklePath, m.Root.Hash) } return merklePath, index, nil } } return nil, nil, nil } 验证(证明) 首先验证一棵默克尔树是否是有效的：\nfunc (m *MerkleTree) VerifyTree() (bool, error) { calculatedMerkleRoot, err := m.Root.verifyNode() if err != nil { return false, err } // 重新根据各个结点构建一棵默克尔树，并得到其 root，看是否与已存在的相同 if bytes.Compare(m.merkleRoot, calculatedMerkleRoot) == 0 { return true, nil } return false, nil } func (n *Node) verifyNode() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } var ( rightBytes []byte leftBytes []byte err error ) // 递归处理 if n.Right != nil { rightBytes, err = n.Right.verifyNode() if err != nil { return nil, err } } if n.Left != nil { leftBytes, err = n.Left.verifyNode() if err != nil { return nil, err } } h := n.Tree.hashStrategy() if _, err := h.Write(append(leftBytes, rightBytes...)); err != nil { return nil, err } return h.Sum(nil), nil } 再次验证某个 Content 是否属于这棵树(零知识证明)：\nfunc (m *MerkleTree) VerifyContent(content Content) (bool, error) { for _, l := range m.Leafs { ok, err := l.C.Equals(content) if err != nil { return false, err } // 存在于已知的节点中 if ok { // 逐层计算 hash，并比较 currentParent := l.Parent for currentParent != nil { h := m.hashStrategy() var allBytes []byte leftBytes, err := currentParent.Left.calculateNodeHash() if err != nil { return false, err } allBytes = leftBytes if currentParent.Right != nil { rightBytes, err := currentParent.Right.calculateNodeHash() if err != nil { return false, err } allBytes = append(allBytes, rightBytes...) } if _, err := h.Write(allBytes); err != nil { return false, err } if bytes.Compare(h.Sum(nil), currentParent.Hash) != 0 { return false, nil } currentParent = currentParent.Parent } return true, nil } } return false, nil } // calculateNodeHash 计算当前 node 的哈希(左右孩子哈希值组合后，再求哈希) func (n *Node) calculateNodeHash() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } h := n.Tree.hashStrategy() var allBytes []byte allBytes = n.Left.Hash if n.Right != nil { allBytes = append(allBytes, n.Right.Hash...) } if _, err := h.Write(allBytes); err != nil { return nil, err } return h.Sum(nil), nil } 重建 // RebuildTree 根据保存的文件块(leaves)重新构建默克尔树 func (m *MerkleTree) RebuildTree() error { var cs []Content for _, c := range m.Leafs { cs = append(cs, c.C) } root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 也可以根据提供的 []Content 重新构建：\n// RebuildTreeWith 根据提供的 content 完全重建一棵树 func (m *MerkleTree) RebuildTreeWith(cs []Content) error { root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 四、参考文档 Merkle 树结构 Merkle Tree（默克尔树）算法解析 go 语言实现的 merkle 树 我修改了部分实现 ","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%BB%98%E5%85%8B%E5%B0%94%E6%A0%91/","summary":"\u003ch2 id=\"一简介\"\u003e一、简介\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Merkle_tree\"\u003e默克尔树\u003c/a\u003e是一种典型的二叉树结构，由\u003cstrong\u003e一个根节点\u003c/strong\u003e、\u003cstrong\u003e一组中间节点\u003c/strong\u003e 和 \u003cstrong\u003e一组叶节点\u003c/strong\u003e 组成。默克尔树最早由 \u003ccode\u003eMerkle Ralf \u003c/code\u003e在 1980 年提出，曾广泛用于 \u003cstrong\u003e文件系统\u003c/strong\u003e 和 \u003cstrong\u003eP2P\u003c/strong\u003e 系统中，比如 \u003ccode\u003eGit\u003c/code\u003e、区块链、\u003ccode\u003eIPFS\u003c/code\u003e 等大名鼎鼎的项目或技术。\u003c/p\u003e\n\u003cp\u003e他又被称为 \u003cstrong\u003e哈希树\u003c/strong\u003e，即存储哈希值的树。树的叶子结点是 \u003cstrong\u003e数据块\u003c/strong\u003e(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\u003c/p\u003e","title":"优秀数据结构--默克尔树"},{"content":"一、前言 前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\n有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\n这道题本质上是解决 判断数据是否存在于一个大集合中。我当时的回答大致是：前面设置一个 布隆过滤器，可以判断哪些 key 一定不存在、哪些可能存在；通过布隆过滤器的检测之后，后面再设置 n 个 redis 数据库(桶)，通过一个 hash 函数进行分桶操作，之后在某个桶中判断某个 key 是否存在就是 O(1) 的时间复杂度。\n需要注意的是，在计算机中，判断一个元素是不是在一个集合中，通常是用 hash 来解决，这在数据量不大的时候是可以的，但是当数据量很大的时候存储空间就会爆炸。\n当时面试官并没有表示满意或者不满意，毕竟这和其他众多更加底层的面试题比起来，只是冰山一角。最后的面试结果是通过，但因为薪资没有达到我的期望，因此也就没有后续了。\n正好国庆假期有时间，系统总结一下 布隆过滤器 的原理，介绍现有的 Redis 实现，并希望通过 Golang 简单实现，算是学习与总结。\n二、原理 布隆过滤器(Bloom Filter) 由 布隆 于 1970 年提出，在这里可以看到原论文：Space/time Trade-offs in Hash Coding with Allowable Errors。从论文标题可以看出，布隆过滤器在时空复杂度方面有着非常大的优势，同时使用到了哈希，但是存在误算率。实际上，布隆过滤器由 一个很长的二进制数组 和 一系列哈希函数 组成，它的作用是 可以检索一个元素是否存在于一个集合中，优点是 插入与查询的时空效率都远超一般的算法，缺点是 存在一定的误识别率 和 删除困难。\n下面我们看一下布隆过滤器的工作流程：\n布隆过滤器本质上是由长度为 m 的 位向量 或者 位列表 (仅包含 0 或者 1 的列表)组成，并且列表的所有元素被初始化为 0：\n当然还会有一系列哈希函数：\n当我们插入一个 key 时，先通过几个哈希函数得到各自的哈希值，然后将位列表对应位设置为 1：\n再插入元素时，继续将对应位设置为 1 即可，而不用担心之前的值是否为 1：\n当我们查询 another_key 是否在上面的位列表中时，还是经过同样的哈希函数，得到各个列表索引值，进而得到位列表处的值，之后进行判断：如果全为 1，则表示可能存在，如果出现一个为 0，则表明一定不存在。\n为什么说当 结果全为 1 时可能存在，而不是 一定存在？假设我们要查一个单词 test 是否存在，其计算的哈希索引值分别为 [2, 5, 14]，位列表中对应的值也全是 1，但是三个 1 是由 hu 和 Jemmy 两个单词插入的结果，原来并没有 test，这种情况下就会出现误判。\n你可以在这个在线网站 Bloom Filters 上自己体会一下这个过程。\n我们假设位列表的长度为 m，有 k 个哈希函数，那么其误判率大概为：\n对于给定的 m 和 n，当\n的时候，误差率取得最小值。具体的推导过程可参考这篇文章：布隆过滤器的误判率该如何计算？ - Xdims 的回答 - 知乎。我们只需要记住结论即可：\n不要让实际元素数量远大于初始化数量； 如果实际元素数量超过初始化数量，则应该选择更大的 m 重建布隆过滤器，将之前的元素进行批量 add。 三、在 Redis 中使用 在低版本需要安装插件并且重新启动：\n下载插件并安装 cd ~/Documents \u0026amp;\u0026amp; git clone https://github.com/RedisBloom/RedisBloom \u0026amp;\u0026amp; cd RedisBloom \u0026amp;\u0026amp; make # 会得到一个 redisbloom.so 文件 重启 redis-server： # 在redis-cli中关闭服务器，其他方法比如 命令行下 kill -9 (redis-server的pid)是没用的 shutdown # 之后退出 # 重启 redis-server /usr/local/etc/redis.conf --loadmodule ~/Documents/RedisBloom/redisbloom.so \u0026amp; 重新进入 redis-cli 即可。 常用命令如下：\nbf.add name key ：往名为 name 的布隆过滤器中添加一个 key bf.madd name key1 key2 ... keyn: 往名为 name 的布隆过滤器中批量添加多个 key bf.exists name key：检查 key 是否存在于名为 name 的布隆过滤器中 bf.mexists name key1 key2 ... keyn：查询多个 key 是否存在于布隆过滤器中。 五、使用 Golang 实现 package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;github.com/spaolacci/murmur3\u0026#34; \u0026#34;hash\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;unsafe\u0026#34; ) /* * @CreateTime: 2020/10/7 17:28 * @Author: Jemmy(hujm20151021@gmail.com) * @Description: 布隆过滤器 实现 */ // BloomFilter 布隆过滤器的struct type BloomFilter struct { m uint8 // 位数组长度为 2^m n uint64 // 已有元素 k uint32 // 哈希函数的个数 hashFunc []hash.Hash64 // 哈希函数，使用 murmur3 算法，性能好实现简单，但是易于遭受DDoS攻击 data []byte sync.RWMutex // 读写锁 } // NewBloomFilter 初始化一个布隆过滤器 // m 表示位数组长度为 2的m次方 // k 表示哈希函数的个数 func NewBloomFilter(m uint8, k int) *BloomFilter { if k \u0026lt;= 0 { panic(\u0026#34;invalid number k for hashFunc num \u0026#34;) } hashFunc := make([]hash.Hash64, k) // 初始化哈希函数 for i := 0; i \u0026lt; k; i++ { hashFunc[i] = murmur3.New64WithSeed(uint32(i)) } filter := \u0026amp;BloomFilter{ m: m, n: 0, k: uint32(k), hashFunc: hashFunc, data: make([]byte, 1\u0026lt;\u0026lt;m), } // 防止创建数组越界 if len(filter.data) == 0 { panic(\u0026#34;m is too big to make slice\u0026#34;) } return filter } // exists 检查元素是否存在于集合中 // true: 可能存在 // false: 一定不存在 func (b *BloomFilter) exists(data []byte) bool { b.RLock() defer b.RUnlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) f.Reset() if b.data[position] == 0 { return false } } return true } func (b *BloomFilter) add(data []byte) { b.Lock() defer b.Unlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) b.data[position] = 1 f.Reset() } b.n++ } // Reset 清空布隆过滤器中的所有元素 func (b *BloomFilter) Reset() { b.Lock() defer b.Unlock() b.data = make([]byte, 1\u0026lt;\u0026lt;b.m) b.n = 0 } // Number 返回过滤器中的元素个数 func (b *BloomFilter) Number() uint64 { b.RLock() defer b.RUnlock() return b.n } // AddString 向布隆过滤器中添加字符串对象 func (b *BloomFilter) AddString(s string) { b.add(stringToBytes(s)) } // ExistsString 检查s是否存在于集合中 func (b *BloomFilter) ExistsString(s string) bool { return b.exists(stringToBytes(s)) } // AddNumber 添加数字m func (b *BloomFilter) AddNumber(m uint64) { b.add(uint64ToBytes(m)) } // ExistsNumber 检查数字m是否存在于集合中 func (b *BloomFilter) ExistsNumber(m uint64) bool { return b.exists(uint64ToBytes(m)) } // AddBytes 添加 序列化后的对象 func (b *BloomFilter) AddBytes(data []byte) { b.add(data) } // ExistsBytes 检查对象data是否存在 func (b *BloomFilter) ExistsBytes(data []byte) bool { return b.exists(data) } /* ********************************************* 辅助函数 ***************************************************** */ // stringToBytes 将string转换成byte数组，零拷贝 func stringToBytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } // bytesToString byte数组转换成string，零拷贝 func bytesToString(b []byte) string { return *(*string)(unsafe.Pointer(\u0026amp;b)) } // uint64ToBytes 将uint64转为byte数组 func uint64ToBytes(num uint64) []byte { data := make([]byte, 8) binary.LittleEndian.PutUint64(data, num) return data } 写一个测试一下：\nfunc main() { filter := NewBloomFilter(10, 3) filter.AddNumber(1) filter.AddNumber(2) filter.AddNumber(3) filter.AddNumber(4) filter.AddNumber(5) filter.AddNumber(7) filter.AddString(\u0026#34;hu\u0026#34;) filter.AddString(\u0026#34;Jemmy\u0026#34;) fmt.Println(filter.Number()) // 8 fmt.Println(filter.ExistsNumber(3)) fmt.Println(filter.ExistsNumber(5)) fmt.Println(filter.ExistsNumber(6)) fmt.Println(filter.ExistsString(\u0026#34;Jemmy\u0026#34;)) fmt.Println(filter.ExistsString(\u0026#34;jemmy\u0026#34;)) } // 输出 8 true true false true false 【参考资料】\n布隆过滤器论文\n维基百科 布隆过滤器\n在线演示\n","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E7%BB%84%E4%BB%B6-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\u003c/p\u003e","title":"优秀组件-布隆过滤器"},{"content":"一、前言 大家应该对 二分查找算法 不陌生，二分查找之所以能达到 O(logN) 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 随机访问数据 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\n事实上，对于一个有序的链表，我们可以通过建索引的方式，做到类似二分查找的效果。\n假设我们有一个已经排好序的链表(其实是一个双链表，这里为了方便，看待成单链表)：\n如果要对这个链表进行查找，那将是 O(n) 的时间复杂度，我们做一些额外的工作：先对链表中每两个结点建一个索引构成一级索引，再对一级索引进行同样的操作得到二级索引：\n当我们要查找元素 20 时，从最高层开始查，则查找路线应该是 1(向右)-\u0026gt;8(向右)-\u0026gt;14(向下)-\u0026gt;14(向右)-\u0026gt;20，经过了 5 个结点；如果直接在原始链表中查找，需要经过 11 个结点，速度有很明显的提升。不过你也发现了，这是典型的 空间换时间 ，虽然查找速度提升了，但是需要花费空间去存储每一层的索引，占用了更大的空间。\n这种带多级索引的链表结构，就是我们今天要详细学习的 跳表。许多开源软件中都有使用到 跳表 这种数据结构，比如 Redis 中的 zset ，我也是最近看 redis 源码才发现对 skiplist 了解甚少，才决定专门学习一遍。\n二、跳表的性质 跳表 可以视为一个 水平排列(Level)、垂直排列(Tower) 的位置(position，对具体结点 Entry 访问的抽象) 的二维集合。跳表具有如下性质：\n由多层(Level)组成，最底层为第 1 层，向上一层为第 2 层，以此类推。层数不会超过规定的一个最大值 LMAX；\n每一层都是一个拥有头结点的有序列表，第 1 层的链表包含所有的元素；\n如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。 这也是 “第 k 层是第 k-1 层的索引” 描述的体现。\n为了节省空间，第一层之上都不存储实际数据，只有指针，包含同层下一个元素的指针 和 同列下一个元素的指针。\n当查找元素时，会从最顶层链表的头节点开始遍历。以升序跳表为例，如果当前节点的下一个节点包含的值比目标元素值小，则继续向右查找。如果下一个节点的值比目标值大，就转到当前层的下一层去查找。重复向右和向下的操作，直到找到与目标值相等的元素为止。以下为找到元素 20 的路径：\n三、跳表的 Golang 实现 跳表首先由 William Pugh 在其 1990 年的论文《Skip lists: A probabilistic alternative to balanced trees》中提出。由该论文的题目可以知道两点：\n跳表是概率型数据结构。 跳表是用来替代平衡树的数据结构。准确来说，是用来替代自平衡二叉查找树（self-balancing BST）的结构。 在这里我们用 Golang 具体实现一遍。\n首先定义需要的结构体：\ntype Node struct { Value int // 某个结点的值，为了方便理解，这里暂时使用 int forward []*Node // 存储该节点所有层的下一个节点的信息，纵向观察，数组的长度是固定的，为 maxLevel。 curLevel int // 本节点最高层 } type SkipList struct { head *Node // 当前结点 length int // (最后一层)总结点长度 maxLevel int // 跳表的最大层 } 这里最让人疑惑的是 forward []*Node 这个属性，它用来存储该结点所有层的下一个节点。怎么理解呢？看上图，对于结点 8 来说，第一层该结点的下一个节点是 9，第二层该结点的下一个节点是 10，第三层该结点的下一个节点是 14，当 maxLevel = 3(代表forward数组长度为 3) 时，结点 8 的 forward 的应该是 [9, 10, 14]。\n当我们要定位一个元素时，从最顶层 先行后列、从上到下 进行对比。怎么个先行后列？从最顶层开始，如上图，这就选定了第一个元素 1，如果当前的元素比要定位的元素小并且后面的元素不为空时，将当前的位置水平向右移动(p = p.forward[i])，否则，向下移动。重复这个动作，直到找到合适的位置。\n接下来我们还要有一个初始化 SkipList 的操作：\n// CreateSkipList 初始化一个 SkipList func CreateSkipList(base,maxLevel int) *SkipList { s := new(SkipList) s.head = new(Node) s.maxLevel = maxlevel // 第一列默认全都为 base ，并且不计算在 length 中 s.head.curLevel = maxlevel - 1 // 计算层数的时候，为了和 forward 数组保持一致，从第 0 层开始计数 s.head.forward = make([]*Node, maxlevel) s.head.Value = base s.length = 0 return s } 我们先看插入一个元素：\n1. 插入新元素 第一步，确定这个元素的位置；第二步，确定这个元素应该有的层数。\n参考之前的性质：如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。这个概率我们可以通过一个函数来解决：\n// func (s *SkipList) getNodeLevel() int { var level int = 0 // 根据性质 第1层包含所有的元素，所以第一层肯定包含这个新元素，所以默认在第一层 rand.Seed(time.Now().UnixNano()) for { // 第 k 层 有 1/2 的概率成为 k-1 层的索引，并且不会超过最大层 if rand.Intn(2) == 1 || level \u0026gt;= s.maxLevel-1 { break } level++ } return level } 接下来我们看插入的过程：\nfunc (s *SkipList) Insert(value int) (bool, error) { v, err := checkSkipListValid(s) if v == false { return false, err } p := s.head newNode := new(Node) newNode.Value = value newNode.forward = make([]*Node, s.maxLevel) level := s.getNodeLevel() // 当前节点所包含的层数 // forward []*Node 存储该节点所有层的下一个节点的信息 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从最高层开始，向下移动 for { // 找到应该插入的位置 if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; value { p = p.forward[i] // 不为空且插入的值比当前值大，向右移动 } else { // 当前值的当前行的后继为空或者大于插入值，应该向下走，即 i-1 break } } //find the last Node which match user defined IsLess() condition in i level //insert new Node after the node // 在第i层找到应该插入的最佳位置，然后在该位置插入新的节点 // level层以下都有这个节点 if i \u0026lt;= level { // 相当于链表的插入操作，新节点在当前层的下一个节点就是当前节点的后一个节点 newNode.forward[i] = p.forward[i] p.forward[i] = newNode // 当前节点的后一个节点就是新节点 } } newNode.curLevel = level s.length++ // 更新节点长度加一 return true, nil } 我们通过一组图来说明这个情况：\n加入我们设定 maxLevel = 5、插入节点 10 时得到的 level = 1，那么效果如下：\n当我们继续 插入元素 20 时，假如计算得到 level = 2，从上述代码第 15 行开始进去循环，从节点 p = base 开始遍历，在第二个 for 循环，也就是第 17 行里面，base 的 forward = [10, 10, nil, nil, nil] ，第 4 层和第 3 层都直接跳过。\n当 i = 2 也就是第 2 层时，base.forward[2] = nil，所以不会走到第 20 行，但是此时 i \u0026lt;= level，于是有 newNode.forward[2] = p.forward[2] = base.forward[2] = nil，也就是第 2 层的下一个结点，p.forward[2] = base.forward[2] = newNode(结点 20)：\n当 i = 1 也就是第 1 层时，在第 19 行处，base.forward[1] = 10 != nil，并且 10 \u0026lt; 20，因此会走到底 20 行，p = p.forward[i] = base.forward[1] = 10，之后跳出内层循环，来到第 30 行，同样执行赋值操作：\n同样，当 i = 0 即最底下一层时，操作步骤和 i=1 时一样，最终效果为：\n再比如我们 插入元素 15。假如得到的 level = 0，即只出现在最底层。i \u0026gt;= 1 这个过程和插入 20 时没多大区别：\n当 i = 0 时，第 19 行代码中，base.forward[0] = 10 != nil，并且 ·10 \u0026lt; 15，因此 p = p.forward[0] = 10，继续内层循环，此时发现虽然 p.forward[0] = 结点10.forward[0] = 20 != nil，但是 20 \u0026gt; 15，因此跳出内层循环，在下面第 30 行，将 结点 15 插在了结点 10 和结点 20 的中间，效果如下：\n2. 查找元素 查找元素 value 是否在跳表中，如果存在返回对应的 Node，否则返回 nil。\n还是固定的遍历策略，先看代码：\n//try to find the first node which not match the user defined IsLess() condition func (s *SkipList) Search(value int) *Node { p := s.head // 从最高层开始 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从左往右 for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i] \u0026lt; value { p = p.forward[i] // 当前节点的 next 不空，且当前值小于待查找值，则向右移动 } else { break } } } // 假如我们需要查找 value=14，此时已经定位到第一层的10 p = p.forward[0] // 还是要再判断一下p的 value，比如我们要查找14，那 p=15 就不符合，应该返回 nil if p.Value != value { return nil } return p } 3. 删除元素 假设我们已经有了如下的跳表：\n代码如下：\nfunc (s *SkipList) RemoveNode(obj int) bool { var update []*Node = make([]*Node, s.maxLevel) // 用来存储被删除结点每一层的前缀 p := s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; obj { p = p.forward[i] } else { break } } update[i] = p } p = p.forward[0] // 删除的节点不存在 if p == nil || p.Value \u0026lt; obj || obj \u0026lt; p.Value { return false } for i := p.curLevel; i \u0026gt;= 0; i-- { // 将被删除结点的前缀，指向删除结点的 next update[i].forward[i] = p.forward[i] } s.length-- return true } 现在我们想 删除结点 20。运行到第 16 行时，update = [15, 10, base, base, base]。p = p.forward[0] = 20，即此时 p 指向被删除的节点。在第 23 行，从 结点 20 的最高层开始，逐层替换掉被删除结点的前缀结点的后缀结点。\n4. 逐层打印跳表 直接看代码：\nfunc (s *SkipList) Traverse() { var p *Node = s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p != nil { fmt.Print(\u0026#34;%d\u0026#34;,p.Value) if p.forward[i] != nil { fmt.Print(\u0026#34;--\u0026gt;\u0026#34;) } p = p.forward[i] } else { break } } fmt.Println() p = s.head } } 四、时空复杂度分析 都是 O(logn)。具体证明方法请阅读 【参考文献】中 2 跟 3 。\n五、总结 跳表 是一个非常优秀的数据结构，在 Redis 中被用来作为 zset 的底层实现，但是 Redis 的实现比上述设计要复杂的多，比如其引入了 span 表示当前节点到下一个 forward 跨过了几个元素，用来快速计算排名等。\n不过有一点，二叉平衡树也能用来做排序查找，为什么 Redis 不采用树形结构呢？其实 Redis 的作者已经在 这里 说出了原因：\nThere are a few reasons:\nThey are not very memory intensive. It\u0026rsquo;s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.\nA sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.\nThey are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.\n大致意思就是：\n跳表更加节省内存，并且计算随机层数的函数，可以由自己随意更改来获得更多或者更少的索引；\nzset 经常用来实现整体遍历操作，这一点上二者相差无几；\n跳表在调试的时候更容易操作一些。\n【参考文献】\n1. Golang 跳表的实现 https://github.com/GrassInWind2019/skipList/blob/master/src/skipList/skipList.go 2. 跳表时空复杂度分析 https://lotabout.me/2018/skip-list/ 3. 一文彻底搞懂跳表的各种时间复杂度、适用场景以及实现原理 ","permalink":"http://localhost:1313/posts/%E8%B7%B3%E8%A1%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e大家应该对 \u003cstrong\u003e二分查找算法\u003c/strong\u003e 不陌生，二分查找之所以能达到 \u003ccode\u003eO(logN)\u003c/code\u003e 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 \u003cstrong\u003e随机访问数据\u003c/strong\u003e 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\u003c/p\u003e","title":"跳表原理以及Golang实现"},{"content":"首先明确，Redis 是一个使用 C 语言编写的键值对存储系统。Redis 是众所周知的 “快”，一方面，它是一个内存数据库，所有的操作都是在内存中完成的，内存的访问速度本身就很快；另一方面，得益于它底层的数据结构。Redis 的常见类型可在这个网页找到：Redis 命令参考简体中文版，其使用到的底层数据结构有如下六种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和 整数数组。本篇文章，将具体了解这些底层数据结构的实现。\n本文所涉及源码位于：https://github.com/redis/redis，所选版本为 6.0.8。\n绘图工具为 draw.io\n涉及到内存操作的函数：\nvoid *zmalloc(size_t size); // 调用zmalloc函数，申请size大小的空间 void *zcalloc(size_t size); // 调用系统函数calloc申请内存空间 void *zrealloc(void *ptr, size_t size); // 原内存重新调整为size空间的大小 void zfree(void *ptr); // 调用zfree释放内存空间 char *zstrdup(const char *s); // 字符串复制方法 size_t zmalloc_used_memory(void); // 获取当前以及占用的内存空间大小 void zmalloc_enable_thread_safeness(void); // 是否设置线程安全模式 void zmalloc_set_oom_handler(void (*oom_handler)(size_t)); // 可自定义设置内存溢出的处理方法 float zmalloc_get_fragmentation_ratio(size_t rss); // 获取所给内存和已使用内存的大小之比 size_t zmalloc_get_rss(void); // 获取RSS信息(Resident Set Size) size_t zmalloc_get_private_dirty(void); // 获得实际内存大小 size_t zmalloc_get_smap_bytes_by_field(char *field); // 获取/proc/self/smaps字段的字节数 size_t zmalloc_get_memory_size(void); // 获取物理内存大小 void zlibc_free(void *ptr); // 原始系统free释放方法 一、底层数据结构 1. 简单动态字符串 源码文件：sds.h\n1.1 数据结构 SDS（Simple Dynamic Strings, 简单动态字符串）是 Redis 的一种基本数据结构，主要是用于存储字符串和整数。 在 Redis 3.2 版本以前，SDS 的实现如下：\nstruct sdshdr { // 记录 buf 数组中已使用字节的数量，等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; 比如，字符串 Redis6.0 的结构如下：\nSDS 遵循 C 字符串以空字符结尾的惯例， 但保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面， 并且为空字符分配额外的 1 字节空间， 以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的， 所以这个空字符对于 SDS 的使用者来说是完全透明的——这样做的好处是，SDS 可以直接使用 C 库中的有关字符串的函数。\n但是在 Redis 3.2 以后，为了提高效率以及更加节省内存，Redis 将 SDS 划分成一下五种类型：\nsdshdr5 sdshdr8 sdshdr16 sdshdr32 sdshdr64 先看 sdshdr5，增加了一个 flags 字段来标识类型，用一个字节(8 位)来存储：\n// Note: sdshdr5 is never used, we just access the flags byte directly. struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 前 3 位表示类型, 后 5 为表示长度 */ char buf[]; }; 对于 sdshdr5 ，因为其可存储长度最大为 2^5 - 1 = 31，当字符串长度超过 31 时，仅靠 flag 的后 5 为表示长度是不够的，这时需要使用其他的四个结构来保存：\nstruct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; // 已使用长度 1字节 uint8_t alloc; // 总长度 1字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; // 已使用长度 2字节 uint16_t alloc; // 总长度 2字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; // 已使用长度 4字节 uint32_t alloc; // 总长度 4字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; // 已使用长度 8字节 uint64_t alloc; // 总长度 8字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; C/C++ 中 __packed 的作用：\n假设有以下结构体：\nstruct { char a; // 1 字节 int b; // 4 字节 char c[2]; // 2 字节 double d; // 8 字节 }Struct_A; 在计算机内存中，结构体变量的存储通常是按字长对齐的，比如在 8 位机上，就按照 1 字节(8 位)对齐，上述结构体占用 1+4+2+8=15​ 字节的内存；在 16 位机上，按照 2 字节对齐，则该结构体占用 2+4+2+8=16​ 字节。也就是说，在更高位的机器中，如果按照默认的机器字长做内存对齐的标准，那总会有一些空间是浪费的，比如上面 16 位时，为了对齐，使用了 2 字节来存储一个char类型的变量。为什么要对齐？这是因为对内存操作按照整字存取会有更高的效率，是 “以空间换时间” 的思想体现。当然，在空间更优先的情况下，也可以不使用默认的机器字长做内存对齐，这个时候，使用 __packed___关键字，可以强制使编译器将结构体成员按照 1 字节进行内存对齐，可以得到非对齐的紧凑型结构体。\n1.2 API 创建 SDS /* Create a new sds string starting from a null terminated C string. */ sds sdsnew(const char *init) { size_t initlen = (init == NULL) ? 0 : strlen(init); // 拿到要创建的字符串的长度 return sdsnewlen(init, initlen); // 传入字符串、字符串长度，调用 sdsnewlen 动态分配内存 } sds sdsnewlen(const void *init, size_t initlen) { void *sh; sds s; char type = sdsReqType(initlen); // 根据字符串长度得到合适的类型 // 一般情况下，创建一个空字符串的目的都是为了后面的append操作，因此，空字符串的情况下，直接创建SDS_TYPE_8，减少后面的扩容操作 if (type == SDS_TYPE_5 \u0026amp;\u0026amp; initlen == 0) type = SDS_TYPE_8; // 计算类型对应的结构体头部长度(len alloc flags的长度) int hdrlen = sdsHdrSize(type); // 指向flag的指针 unsigned char *fp; // 申请内存，内存大小为 结构体头部长度+字符串长度(buf)+1，这里+1是因为要考虑 \u0026#39;\\0\u0026#39; 字符 sh = s_malloc(hdrlen+initlen+1); if (sh == NULL) return NULL; if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); // 将s指向buf s = (char*)sh+hdrlen; // 将 s-1 指向flag fp = ((unsigned char*)s)-1; // 对sds结构体变量进行赋值 switch(type) { case SDS_TYPE_5: { *fp = type | (initlen \u0026lt;\u0026lt; SDS_TYPE_BITS); break; } case SDS_TYPE_8: { SDS_HDR_VAR(8,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = initlen; *fp = type; break; } ... } if (initlen \u0026amp;\u0026amp; init) memcpy(s, init, initlen); // 在s的最后添加\u0026#39;\\0\u0026#39; s[initlen] = \u0026#39;\\0\u0026#39;; // 返回指向 buf 数组的指针s return s; } 注意，创建 SDS 时返回给上层的是指向 buf 数组的指针 s，而不是结构体的指针，那如何找到结构体中的其他元素呢？上面提到了 __packed__ 关键字，使用 1 字节进行内存对齐，那么知道了 buf 的地址，将其减去对应类型的长度(偏移量)，就能得到结构体中其他类型的地址。\n清空 SDS 清空一个 SDS 有两个途径：\n第一种是直接调用 s_free() 函数：\n/* Free an sds string. No operation is performed if \u0026#39;s\u0026#39; is NULL. */ void sdsfree(sds s) { if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1])); } 另一种方式是 重置 len 为 0 的方式，这种情况下 buf 所占用的空间并没有被清除掉，新的数据会直接覆盖 buf 中的原有数据而无需再申请新的内存空间：\n/* Modify an sds string in-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */ void sdsclear(sds s) { sdssetlen(s, 0); s[0] = \u0026#39;\\0\u0026#39;; } 拼接 SDS 拼接使用的是 sds sdscatsds(sds s, sds t)，但最终调用的还是 sdscatlen：\n// 将 t 拼接到 s 后面。调用此方法之后，sds底层的buf可能经过了扩容迁移了原来的位置，注意更新原来变量中对应的指针 sds sdscatsds(sds s, const sds t) { return sdscatlen(s, t, sdslen(t)); } sds sdscatlen(sds s, const void *t, size_t len) { size_t curlen = sdslen(s); // 计算当前s的长度 s = sdsMakeRoomFor(s,len); // 空间不够的话扩容，确保s的剩余空间足够放得下t if (s == NULL) return NULL; // 扩容失败 memcpy(s+curlen, t, len); // 拼接 sdssetlen(s, curlen+len); // 更新s的属性len s[curlen+len] = \u0026#39;\\0\u0026#39;; // 给s最后加上 \u0026#39;\\0\u0026#39; return s; } 接下来我们详细看一下扩容规则，在函数 sdsMakeRoomFor 中：\n// 将sds s的 buf 的可用空间扩大，使得调用此函数之后的s能够再多存储 addlen 长度的字符串。 // 注意：此方法并未改变 sds 的len属性，仅仅改变的是 sds 的 buf 数组的空间。 sds sdsMakeRoomFor(sds s, size_t addlen) { void *sh, *newsh; size_t avail = sdsavail(s); // 当前的可用空间长度：s.alloc - s.len size_t len, newlen; char type, oldtype = s[-1] \u0026amp; SDS_TYPE_MASK; int hdrlen; // 情况1：剩余长度大于所需要长度，没必要扩容，直接返回 if (avail \u0026gt;= addlen) return s; len = sdslen(s); // 当前字符串长度 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 新字符串长度 // 情况2：扩容 // 情况2.1： 如果 新长度 \u0026lt; 1MB，则按 新长度的2倍 扩容 // 否则，就按 新长度+1MB 扩容 if (newlen \u0026lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; // 计算新长度的类型 type = sdsReqType(newlen); // 还是为了后续使用减少扩容次数的原因，将 sdshdr5 变为 sdshdr8 if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) { // 如果新长度对应的类型没变，则直接调用 s_realloc 扩大动态数组即可 newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; } else { /* Since the header size changes, need to move the string forward, * and can\u0026#39;t use realloc */ // 类型发生了改变，意味着sds结构体头部的三个属性的类型也要跟着变化，此时直接重新申请一块内存 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; // 原s的数据拷贝到新的内存上 memcpy((char*)newsh+hdrlen, s, len+1); // 释放掉原来的s的空间，并将其更新为刚才新申请的 s_free(sh); s = (char*)newsh+hdrlen; // 更新 flag s[-1] = type; // 更新 len sdssetlen(s, len); } // 更新 alloc sdssetalloc(s, newlen); return s; } 代码中注释已经很清楚了，这里再总结一下扩容策略：如果 剩余长度 avail \u0026gt;= 新增长度 addlen ，则无需扩容；否则，如果 avail + addlen \u0026lt; 1MB，按照 2 * (avail + addlen)扩容，否则按照 avail + addlen + 1MB 扩容。\n1.3 总结 创建 SDS 时返回的是指向 buf 数组的指针，而不是 SDS 类型的对象，这样的好处是兼容了已有的 C 语言中的相关函数； 读取内容时，先通过类对应类型计算偏移量，再通过 len 属性来限制读取的长度，杜绝了缓冲区溢出，二进制安全； 根据字符串的长度，定义了五种不同的类型，节省了空间； 进行字符串拼接时，会通过 sdsMakeRoomFor 函数来决定是否有底层 buf 数组的扩容操作。 2. 双端链表 源码文件：adlist.h\n2.1 数据结构 当我们使用 lpush 或者 rpush 的时候，其实底层对应的数据结构就是一个双端链表。\n首先我们来了解结点 listNode：\ntypedef struct listNode { struct listNode *prev; // 头指针 struct listNode *next; // 尾指针 void *value; // 具体的值，因为值的类型不确定，此处使用万能指针 } listNode; 虽然使用多个 listNode就已经足够表示一个双端链表，但是为了更方便，Redis 还有如下结构：\ntypedef struct list { listNode *head; // 头指针 listNode *tail; // 尾指针 void *(*dup)(void *ptr); // 拷贝结点函数 void (*free)(void *ptr); // 释放结点值函数 int (*match)(void *ptr, void *key); // 判断两个结点是否相等的函数 unsigned long len; // 链表长度 } list; 他们的关系可用如下图表示：\n2.2 API 创建 list 对象 创建的是一个 list 对象，首先会尝试申请分配空间，失败返回 NULL ：\n// 创建的只是一个 list 对象，这个对象可以被 AlFreeList() 释放掉，但是仅仅释放的是这个 list 对象，其上面的 listNode 对象还需要另外手动释放 list *listCreate(void) { struct list *list; // 申请分配内存，失败返回 NULL if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 给其他属性赋值 list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; list-\u0026gt;dup = NULL; list-\u0026gt;free = NULL; list-\u0026gt;match = NULL; // 最终返回 list 对象 return list; } 添加元素 listNode 到 list 给一个带头的双向链表添加元素，有三种添加方法：头插入 、 尾插入 和 指定位置，分别对应的操作为 lpush 、rpush 和 linsert。对于 lpush 和 rpush 的实现如下，本质上就是对双端链表的基础操作：\nlist *listAddNodeHead(list *list, void *value) { listNode *node; // 申请分配内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; // 将 listNode 插入到 list 的元素中 if (list-\u0026gt;len == 0) { // 如果之前 list 没有元素，那么 list 的 head 和 tail 均指向当前的 listNode list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { // 链表的头插入 node-\u0026gt;prev = NULL; node-\u0026gt;next = list-\u0026gt;head; list-\u0026gt;head-\u0026gt;prev = node; list-\u0026gt;head = node; } // 更新 len list-\u0026gt;len++; // 返回的是传进来的 list ，失败返回的是 NULL return list; } // 尾插入，过程和头插入类似 list *listAddNodeTail(list *list, void *value) { listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (list-\u0026gt;len == 0) { list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { node-\u0026gt;prev = list-\u0026gt;tail; node-\u0026gt;next = NULL; list-\u0026gt;tail-\u0026gt;next = node; list-\u0026gt;tail = node; } list-\u0026gt;len++; return list; } 关于 linsert ，其用法如下：\nLINSERT key BEFORE|AFTER pivot value\n将值value插入到列表key当中，位于值pivot之前或之后。\n当pivot不存在于列表key时，不执行任何操作。\n当key不存在时，key被视为空列表，不执行任何操作。\n如果key不是列表类型，返回一个错误。\n在 Redis 底层，对应的方法为 listInsertNode，当然，为了找到 old_node，前面还需要遍历 list，这个操作的时间复杂度是 O(n)，我们这里只关注如何插入元素：\n// 在 list 的 old_node 的前或后(after\u0026lt;0,在前面增加；after\u0026gt;0，在后面增加)新增值为 value 的新listNode list *listInsertNode(list *list, listNode *old_node, void *value, int after) { listNode *node; // 为新增的 listNode 申请内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (after) { // after\u0026gt;0，在后面插入 node-\u0026gt;prev = old_node; node-\u0026gt;next = old_node-\u0026gt;next; if (list-\u0026gt;tail == old_node) { list-\u0026gt;tail = node; } } else { // after\u0026lt;0，在前面插入 node-\u0026gt;next = old_node; node-\u0026gt;prev = old_node-\u0026gt;prev; if (list-\u0026gt;head == old_node) { list-\u0026gt;head = node; } } if (node-\u0026gt;prev != NULL) { node-\u0026gt;prev-\u0026gt;next = node; } if (node-\u0026gt;next != NULL) { node-\u0026gt;next-\u0026gt;prev = node; } // 更新 len list-\u0026gt;len++; // 成功 返回传进来的 list return list; } 删除元素 删除元素的情况有以下几种：清空整个 list ，删除某个 listNode。\n我们先看清空整个 list ，它只是释放掉了这个 list 上连的所有的 listNode ，而 list 对象并没有被销毁：\n/* Remove all the elements from the list without destroying the list itself. */ void listEmpty(list *list) { unsigned long len; listNode *current, *next; current = list-\u0026gt;head; len = list-\u0026gt;len; // 遍历整个链表，逐个释放空间，直到为空 while(len--) { next = current-\u0026gt;next; if (list-\u0026gt;free) list-\u0026gt;free(current-\u0026gt;value); zfree(current); current = next; } list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; } 而下面这个 listRelease 方法，会释放所有：\n/* Free the whole list. * * This function can\u0026#39;t fail. */ void listRelease(list *list) { listEmpty(list); // 先清空所有的 listNode zfree(list);\t// 再释放 list } 然后看删除某个具体的 listNode：\nvoid listDelNode(list *list, listNode *node) { // 是否是 list 中的第一个元素 if (node-\u0026gt;prev) node-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; else list-\u0026gt;head = node-\u0026gt;next; // 是否是 list 中的最后一个元素 if (node-\u0026gt;next) node-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; else list-\u0026gt;tail = node-\u0026gt;prev; // 释放当前节点的值 if (list-\u0026gt;free) list-\u0026gt;free(node-\u0026gt;value); // 释放内存 zfree(node); // 更新 len list-\u0026gt;len--; } 2.3 总结 Redis 基于双端链表，可以提供各种功能：列表键、发布订阅功能、监视器等；\n因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表；\n仔细看过源代码后会发现，这是一个典型的双端链表，其底层实现与我在《数据结构》中遇到的如出一辙，这也从侧面说明了熟悉基本的数据结构的重要性。\n3. 字典 字典，由一个个键值对构成，首先想一下，一个字典应该提供什么样的功能？键值对用来存储数据，之后还要能插入数据、修改数据、删除数据、遍历(读取)数据，字典最大的特点就是上面这些所有的操作都可以在 O(1) 的时间复杂度里完成。\n比如在 redis-cli 中，我输入如下命令：\nredis\u0026gt; set name Jemmy 这条命令在 redis 的内存中生成了一个键值对(key-value)，其中 key 是 name，value 是 Jemmy的字符串对象，\nRedis 的字典采用 哈希表 来实现。一个哈希表，你可以简单把它想成一个数组，数组中的每个元素称为一个桶，这也就对应上我们经常所说，一个哈希表由多个桶组成，每个桶中保存了键值对的数据(哈希桶中保存的值其实并不是值本身，而是一个指向实际值的指针)。\n提到哈希，首先要关注的是哈希算法以及解决哈希冲突的方式。哈希算法的具体实现我们暂时不关心，只需要知道 Redis 使用的是 MurmurHash2，“这个算法的优点在于：即使输入的键是有规律的，算法仍能够给出一个很好的随机分布性，计算速度也很快”；对于解决哈希冲突的方法，最常见的是 开放地址法 和 拉链法。二者实现原理在 Golang-map 详解 中已经说过，这里不再细讲，目前只需要知道，Redis 采用拉链法解决哈希冲突。\n在 Redis 中，有以下几个概念：哈希表、哈希表结点和字典，他们的关系大致可以描述为：字典是一个全局的字典，一个字典中包含两个哈希表，一个正在使用，另一个用作扩容用；哈希表中包含多个哈希表结点。接下来我们详细看下每个结构的具体实现：\n源码文件：dict.h\n3.1 数据结构 哈希表结点 哈希表节点使用 dictEntry 结构表示， 每个 dictEntry 结构都保存着一个键值对：\ntypedef struct dictEntry { // key void *key; // value，可以是指针 uint64_t int64_t double中的某一个 union { void *val; uint64_t u64; int64_t s64; double d; } v; // 指向另一个哈希表结点的指针，连接哈希值相同的键值对，用来解决哈希冲突 struct dictEntry *next; } dictEntry; 哈希表 typedef struct dictht { dictEntry **table; // dictEntry数组，dictEntry代表一个键值对 unsigned long size; // 哈希表大小(容量) unsigned long sizemask; // 值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 unsigned long used; // 哈希表已有结点的数量 } dictht; 下图可以表示 哈希表 dictht 和 哈希表结点 dictEntry 之间的关系：\n字典 typedef struct dict { dictType *type; // 类型对应的特定函数 void *privdata; // 私有数据 dictht ht[2]; // 两个哈希表，一个正常使用，另一个用于扩容 long rehashidx; // rehash 索引值，扩容时使用，正常时为-1 unsigned long iterators; // 正在运行的迭代器的数量 } dict; 这里的 type 是一个指向 dictType 结构体的指针，而每一个 dictType 结构体保存了 一组用于操作特定类型键值对的函数，不同的类型有不同的操作函数，privdata 保存了需要传递给特定类型函数的可选参数：\ntypedef struct dictType { // 计算哈希值的函数 uint64_t (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键是否相同的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj); } dictType; ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。\n除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。\n下图展示了一个普通状态(没有进行 rehash )的字典：\n3.2 哈希冲突的解决方式 当两个以上的键经过哈希函数计算之后，落在了哈希表数组的同一个索引上面，我们就称这些键发生了 哈希冲突(hash collision)。\nRedis 的哈希表使用 链接法来解决键冲突： 每个哈希表节点(dictEntry)都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。写入时，因为没有直接指向链的最后一个元素的指针，因此为了更少的时间复杂度， Redis 采用的是在链表头部插入；读取时，先定位到链头，之后逐个比较值是否与所求相同，直到遍历完整个链。\n比如上图中，在 dictht.table 的 3 号桶中已经存在一个键值对 k1-v1，此时又新加入一个键值对 k2-v2，经过哈希计算后正好也落在 3 号桶中，经过插入后结果如下：\n3.4 rehash 细节 当哈希表的键值对数量太多或者太少时，需要根据实际情况对哈希表的大小进行扩大或者缩小，这个过程通过 rehash(重新散列) 来完成。 而判断是否进行 rehash ，是在向哈希表插入一个键值对的时候，接下来我们通过分析源代码的方式，详细了解 rehash 的细节。\n首先，添加一个新键值对，用到的是 dictAdd 方法：\n/* Add an element to the target hash table */ int dictAdd(dict *d, void *key, void *val) { dictEntry *entry = dictAddRaw(d,key,NULL); // 将键值对封装成dictEntry if (!entry) return DICT_ERR; // 如果创建dictEntry，返回失败 dictSetVal(d, entry, val); // 键不存在，则设置dictEntry结点的值 return DICT_OK; } 我们接着看 dictAddRaw，这一步主要将键值对封装成一个 dictEntry 并返回 ：\n// 将 key 插入哈希表中 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing) { long index; dictEntry *entry; dictht *ht; // 如果哈希表正在rehash，则向前 rehash一步(渐进式rehash的体现) // 是否正在进行 rehash，是通过 dict.rehashidx == -1 来判断的 if (dictIsRehashing(d)) _dictRehashStep(d); // 调用_dictKeyIndex() 检查键是否存在，如果存在则返回NULL if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; // 获取当前正在使用的ht，如果正在 rehash，使用 ht[1]，否则使用 ht[0] ht = dictIsRehashing(d) ? \u0026amp;d-\u0026gt;ht[1] : \u0026amp;d-\u0026gt;ht[0]; // 为新增的节点分配内存 entry = zmalloc(sizeof(*entry)); // 将结点插入链表头部 entry-\u0026gt;next = ht-\u0026gt;table[index]; ht-\u0026gt;table[index] = entry; // 更新结点数量 ht-\u0026gt;used++; // 设置新节点的键，使用的是 type 属性中的 keyDup 函数 dictSetKey(d, entry, key); return entry; } 我们再看 _dictKeyIndex 这个方法，作用是计算某个 key 应该存储在哪个空的 bucket ，即需要返回这个 key 应该存储在 dictEntry 数组的 index，如果已经存在，返回 -1。需要注意的是，当哈希表正在 rehash 时，返回的 index 应该是要搬迁的 ht：\n// 传进来的 existing 是 NULL, hash是通过 type 中的哈希函数计算的 static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing) { unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; // 检查是否需要扩展哈希表，如果需要则进行扩展 if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table \u0026lt;= 1; table++) { idx = hash \u0026amp; d-\u0026gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-\u0026gt;ht[table].table[idx]; while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (existing) *existing = he; return -1; } he = he-\u0026gt;next; } if (!dictIsRehashing(d)) break; } return idx; } 最后，我们关注 检查是否需要 rehash，需要则启动 的 _dictExpandIfNeeded：\nstatic int _dictExpandIfNeeded(dict *d) { // 如果正在 rehash，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果哈希表中是空的，则将其收缩为初始化大小 DICT_HT_INITIAL_SIZE=4 if (d-\u0026gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // 在 (ht[0].used/ht[0].size)\u0026gt;=1前提下，如果 系统允许扩容 或者 ht[0].used/t[0].size\u0026gt;5 时，容量扩展为原来的2倍 if (d-\u0026gt;ht[0].used \u0026gt;= d-\u0026gt;ht[0].size \u0026amp;\u0026amp; (dict_can_resize || d-\u0026gt;ht[0].used / d-\u0026gt;ht[0].size \u0026gt; dict_force_resize_ratio)) { return dictExpand(d, d-\u0026gt;ht[0].used * 2); // 扩容至原来容量的2倍 } return DICT_OK; } 仔细看看 dictExpand 是如何扩展哈希表容量的，这个函数中，判断是否需要扩容，如果需要，则新申请一个 dictht ，赋值给 ht[0]，然后将字典的状态设置为 正在 rehash(rehashidx \u0026gt; -1)，需要注意的是，这个方法中并没有实际进行键值对的搬迁：\n// 扩容 或者 新建一个 dictht int dictExpand(dict *d, unsigned long size) { /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 如果正在 reahsh 或者 传进来的size不合适(size比当前已有的容量小，正常情况下这是不可能的)，直接返回错误 if (dictIsRehashing(d) || d-\u0026gt;ht[0].used \u0026gt; size) return DICT_ERR; dictht n; // 新哈希表 // 计算 扩展或缩放新哈希表容量 的大小，必须是2的倍数 unsigned long realsize = _dictNextPower(size); // 如果计算扩容后的新哈希表的容量，和原来的相同，就没必要扩容，直接返回错误 if (realsize == d-\u0026gt;ht[0].size) return DICT_ERR; // 为新哈希表申请内存，并将所有的指针初始化为NULL n.size = realsize; n.sizemask = realsize - 1; n.table = zcalloc(realsize * sizeof(dictEntry *)); n.used = 0; /* Is this the first initialization? If so it\u0026#39;s not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果原来的哈希表是空的，意味着这是在新建一个哈希表，将新申请的 dictht 赋值给 ht[0]，直接返回创建成功 if (d-\u0026gt;ht[0].table == NULL) { d-\u0026gt;ht[0] = n; return DICT_OK; } // 如果不是新建哈希表，那就是需要实打实的扩容，此时将刚才新申请的 哈希表 赋值给 ht[1]，并将当前字典状态设置为\u0026#34;正在rehash\u0026#34;(rehashidx \u0026gt; -1) d-\u0026gt;ht[1] = n; d-\u0026gt;rehashidx = 0; return DICT_OK; } // 哈希表的容量必须是 2的倍数 static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size \u0026gt;= LONG_MAX) return LONG_MAX + 1LU; while (1) { if (i \u0026gt;= size) return i; i *= 2; } } 什么时候进行 桶 的搬迁呢？这里涉及到一个名词：渐进式扩容。我们知道，扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面，如果哈希表中的键值对数量少，那么一次性转移过去不是问题；但是键值对的数量很大，几百万几千万甚至上亿，那么一次性搬完的计算量+单线程很有可能使 redis 服务停止一段时间。因此，为了避免 rehash 对服务造成影响，服务不是一次性 rehash 完成的，而是 分多次、渐进式地将 ht[0] 中的键值对搬迁到 ht[1] 中。\n源码中真正执行搬迁的函数是 _dictRehashStep：\n// _dictRehashStep 让 rehash 的动作向前走一步(搬迁一个桶)，前提是当前字典没有被遍历，即iterators==0，iterators表示当前正在遍历此字典的迭代器数目 static void _dictRehashStep(dict *d) { if (d-\u0026gt;iterators == 0) dictRehash(d, 1); } 再看 dictRehash ：\n// dictRehash 向前 rehash n步。如果还没有搬迁完，返回 1，搬迁完成返回0 int dictRehash(dict *d, int n) { // 当dictRehash时，rehashidx指向当前正在被搬迁的bucket，如果这个bucket中一个可搬迁的dictEntry都没有，说明就没有可搬迁的数据。 // 这个时候会继续向后遍历 ht[0].table 数组，直到找到下一个存有数据的bucket位置，如果一直找不到，则最多向前走 empty_visits 步，本次搬迁任务结束。 int empty_visits = n * 10; // 整个dict的 rehash 完成了，返回0 if (!dictIsRehashing(d)) return 0; // 外层大循环，确保本次最多向前走n步 以及 ht[0].table中还有值 while (n-- \u0026amp;\u0026amp; d-\u0026gt;ht[0].used != 0) { dictEntry *de, *nextde; // 确保 rehashidx 不会超过 ht[0].table 的长度，因为 rehashidx 指向当前正在被搬迁的bucket，其实就是 ht[0].table 数组的下标，这里保证数组下标访问不会越界 assert(d-\u0026gt;ht[0].size \u0026gt; (unsigned long)d-\u0026gt;rehashidx); // 当前的bucket搬迁完了，继续寻找下一个bucket，知道全部为空 或者 向前走的步数超过了限定值 while (d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] == NULL) { d-\u0026gt;rehashidx++; if (--empty_visits == 0) return 1; } // 终于找到了可搬迁的某个bucket中的 dictEntry de = d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx]; // 将这个 bucket 中的所有 dictEntry 包括链表上的，前部搬迁到新的 ht[1] 中 while (de) { uint64_t h; nextde = de-\u0026gt;next; // 获取当前键值对在新的哈希表中的桶的序号，这里进行取模的是 ht[1]的sizemask，所以 h 很大概率会与在 ht[0] 中的不一样 h = dictHashKey(d, de-\u0026gt;key) \u0026amp; d-\u0026gt;ht[1].sizemask; // 更新 新桶与旧桶 中的属性 de-\u0026gt;next = d-\u0026gt;ht[1].table[h]; d-\u0026gt;ht[1].table[h] = de; d-\u0026gt;ht[0].used--; d-\u0026gt;ht[1].used++; de = nextde; } // 搬迁完成，将原来的ht[0]中的bucket置空 d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] = NULL; // rehashidx 自增，表示又搬完了一个桶 d-\u0026gt;rehashidx++; } // 检查是否搬完了整张表 if (d-\u0026gt;ht[0].used == 0) { // 全部完成搬迁，则释放掉ht[0]的内存，将ht[1]的内容放到ht[0]中，重置ht[1]，并标志rehash完成(rehashidx=-1) zfree(d-\u0026gt;ht[0].table); d-\u0026gt;ht[0] = d-\u0026gt;ht[1]; _dictReset(\u0026amp;d-\u0026gt;ht[1]); d-\u0026gt;rehashidx = -1; return 0; } // 否则后面的动作还要继续搬迁 return 1; } 那什么时候会进行渐进式rehash呢？在源码中搜索 _dictRehashStep：有以下几处出现了：\ndictAddRaw ：向字典增加一个键值对时； dictGenericDelete：查找并移除某个键值对时； dictFind ：根据 key 查找对应的 dictEntry 时； dictGetRandomKey：返回一个随机的 dictEntry 时； dictGetSomeKeys：随机返回指定 count 个 dictEntry 时，会进行 count 次 _dictRehashStep 总结一下：\n为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。\n3.5 API 添加键值对 dictAdd 在上面讲 rehash 时，使用的例子，就是 添加键值对，这里不再赘述。\n删除键值对 dictDelete 其底层调用的是 dictGenericDelete：\n// 找到key对应的键值对，并移除它。此处dictDelete 调用时传入 nofree=0 static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) { uint64_t h, idx; dictEntry *he, *prevHe; int table; // 如果字典中键值对数量为0，返回 未找到 if (d-\u0026gt;ht[0].used == 0 \u0026amp;\u0026amp; d-\u0026gt;ht[1].used == 0) return NULL; // 如果当前处于 rehash 阶段，则往前进行一步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table \u0026lt;= 1; table++) { // 获取桶的索引 idx = h \u0026amp; d-\u0026gt;ht[table].sizemask; // 获取桶中的第一个 dictEntry he = d-\u0026gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表，找到之后将其从链表中删除 while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (prevHe) prevHe-\u0026gt;next = he-\u0026gt;next; else d-\u0026gt;ht[table].table[idx] = he-\u0026gt;next; if (!nofree) { dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } d-\u0026gt;ht[table].used--; return he; } prevHe = he; he = he-\u0026gt;next; } // 如果没有再 rehash，就没必要再去 ht[1] 中寻找了 if (!dictIsRehashing(d)) break; } return NULL; // 没找到，返回 NULL } 查找键值对 dictFind 过程跟 dictGenericDelete 一模一样， dictGenericDelete 还多了一个删除操作。\n4. 跳表 会有专门的一篇文章来讲。看这里：跳表原理以及 Golang 实现\n5. 整数集合 当一个集合中只包含整数，并且元素的个数不是很多的话，redis 会用整数集合作为底层存储，它的一个优点就是可以节省很多内存，虽然字典结构的效率很高，但是它的实现结构相对复杂并且会分配较多的内存空间。当然，当整数集合中的 元素太多(redis.conf 中 set-max-intset-entries=512) 或者 添加别的类型的元素是，整个整数集合会被转化成 字典。\n源码文件：intset.h\n5.1 数据结构 整数集合（intset） 是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。\ntypedef struct intset { // 编码方式 uint32_t encoding; // 集合中包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; } intset; contents 数组中的元素按照从小到大的顺序排列，并且保证没有重复值；length 表示整数集合中包含的元素数量，即 contents 数组的长度。虽然 contents 数组的类型是 int8_t，但实际上并不保存 int8_t 类型的值，而是会根据实际 encoding 的值做出判断，比如 encoding = INTSET_ENC_INT16，那么数组的底层类型均为 int16_t ，整个数组中的元素类型都是 int16_t：\n/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 \u0026lt; INTSET_ENC_INT32 \u0026lt; INTSET_ENC_INT64. */ #define INTSET_ENC_INT16 (sizeof(int16_t)) // int16 16位 #define INTSET_ENC_INT32 (sizeof(int32_t)) // int32 32位 #define INTSET_ENC_INT64 (sizeof(int64_t)) // int64 64位 // 返回 v 对应的 encoding 值 static uint8_t _intsetValueEncoding(int64_t v) { if (v \u0026lt; INT32_MIN || v \u0026gt; INT32_MAX) return INTSET_ENC_INT64; else if (v \u0026lt; INT16_MIN || v \u0026gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16; } 下面是一个使用 INTSET_ENC_INT16 编码的、长度为 6 的整数集合：\n5.2 API 初始化 intset // 创建一个空的 intset intset *intsetNew(void) { // 为 intset 对象申请空间 intset *is = zmalloc(sizeof(intset)); // 默认使用 INTSET_ENC_INT16 作为存储大小 is-\u0026gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 数组长度为0，因为没有初始化的操作 is-\u0026gt;length = 0; return is; } 这里有一点需要注意，创建 intset 的时候并没有初始化 contents 数组，应为没必要。在常规情况下，访问数组是根据数组第一个元素地址加上类型大小作为偏移值读取，但是 intset 的数据类型依赖于 encoding，读取的时候通过 memcpy 按照 encoding 的值重新计算偏移量暴力读取的，属于 非常规操作数据，因此，刚开始没必要申请数组的空间，等添加一个元素时，动态扩容该元素的大小的内存即可。\n添加元素 我们先看代码：\n// 在 intset 中添加一个整数 intset *intsetAdd(intset *is, int64_t value, uint8_t *success) { uint8_t valenc = _intsetValueEncoding(value); // 根据要插入的 value 的类型 获取对应的 encoding uint32_t pos; if (success) *success = 1; // success = NULL if (valenc \u0026gt; intrev32ifbe(is-\u0026gt;encoding)) { // 插入元素的 encoding 值大于 intset 当前的，升级 return intsetUpgradeAndAdd(is,value); } else { // 插入元素的 encoding 值小于等于当前 intset 的，则找到这个 value 应该插入的位置，赋值给 pos，已经存在的话直接返回 if (intsetSearch(is,value,\u0026amp;pos)) { if (success) *success = 0; return is; } // 动态扩容 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 将 pos 位置后面的元素整体向后挪一位，给 pos 腾位置 if (pos \u0026lt; intrev32ifbe(is-\u0026gt;length)) intsetMoveTail(is,pos,pos+1); } // 将 pos 位置设置为 value _intsetSet(is,pos,value); // 更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } // 动态扩容，即将原来数组的容量 (is.length*encoding) 调整为 ((is.length+1)*encoding) static intset *intsetResize(intset *is, uint32_t len) { uint32_t size = len*intrev32ifbe(is-\u0026gt;encoding); is = zrealloc(is,sizeof(intset)+size); return is; } // 暴力迁移pos位置之后的数据，为pos位置挪出位置 static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) { // from = pos, to = pos+1 // src 表示 pos 相对于数组头部的迁移量 // dst 表示 pos下一个元素相对于数组头部的偏移量 void *src, *dst; // pos位置 距离数组末尾的元素个数，bytes*类型大小 即是pos后面的所有元素的总长度 uint32_t bytes = intrev32ifbe(is-\u0026gt;length)-from; // encoding uint32_t encoding = intrev32ifbe(is-\u0026gt;encoding); if (encoding == INTSET_ENC_INT64) { src = (int64_t*)is-\u0026gt;contents+from; dst = (int64_t*)is-\u0026gt;contents+to; bytes *= sizeof(int64_t); } else if (encoding == INTSET_ENC_INT32) { src = (int32_t*)is-\u0026gt;contents+from; dst = (int32_t*)is-\u0026gt;contents+to; bytes *= sizeof(int32_t); } else { src = (int16_t*)is-\u0026gt;contents+from; dst = (int16_t*)is-\u0026gt;contents+to; bytes *= sizeof(int16_t); } // 从 src 复制 bytes 个字符到 dst memmove(dst,src,bytes); } 整个过程可以简单总结为：先判断当前插入值的 encoding 是否超过了 intset 的，如果超过了，进行升级，升级 操作我们待会儿再看。没超过的话，需要找到当前元素应该插入的位置 pos ，查找 操作我们还是待会儿再看。之后是动态扩容，动态扩容的过程有：先将数组容量增加，之后将 pos 后面的元素整体移一位，最后将 value 值写入 pos 处。特别需要注意的是，将 pos 后面的元素整体后移一位 这一步，没有逐个移动元素，而是计算好 src 和 dst，直接调用 memmove 将 src 处的 bytes 个字符复制到 dst 处，这正是利用了 intset 数组非常规读取数组的特点。下面通过一个例子看一下插入的过程：\n升级 当插入的元素的类型比集合中现有所有元素的类型都要长时，需要先将数组整个升级之后，才能继续插入元素。升级 指的是 将数组类型变成和插入值类型相同的过程。\n升级过程大致可分为三个步骤：\n根据新元素类型，扩展底层数组的大小，并为新元素分配空间； 将底层数组的所有元素都转化成与新元素相同，并将转换后的元素放在合适的位置上，并且在防止的过程中，需要维持底层数组中数组顺序不变； 将新元素添加到新数组中 下面我们直接看代码：\nstatic intset *intsetUpgradeAndAdd(intset *is, int64_t value) { uint8_t curenc = intrev32ifbe(is-\u0026gt;encoding); // 当前 encoding uint8_t newenc = _intsetValueEncoding(value); // 插入元素的 encoding int length = intrev32ifbe(is-\u0026gt;length); // 插入到 数组最左边 还是 数组最右边。为什么会是最值？因为要升级，所以插入值肯定超出了现有 encoding 对应类型的最值，要么是负数越界，要么是正数越界 int prepend = value \u0026lt; 0 ? 1 : 0; // 首先，设置 intset 的 encoding 为插入元素的 encoding(更大的那个) is-\u0026gt;encoding = intrev32ifbe(newenc); // 根据新元素类型 扩展数组大小 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 从数组最后一个元素开始遍历，将其放入合适的位置。prepend 的作用就是确保我们能给待插入值留下最左边的位置 或 最右边的位置 while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); // 在数组头部或者数组尾部插入 value if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-\u0026gt;length),value); // 最后更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } 通过一个例子说明升级的过程：\n注意：整数集合没有降级操作！一旦对数组进行了升级， 编码就会一直保持升级后的状态。\n查找 在 intset 中查找 value 是否存在，如果存在，返回 1，同时将 pos 值设置为数组的索引值；如果不存在，返回 0，同时将 pos 设置成应该存放的位置的索引值：\nstatic uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) { int min = 0, max = intrev32ifbe(is-\u0026gt;length)-1, mid = -1; int64_t cur = -1; // 当 intset 中没有元素时，直接返回 if (intrev32ifbe(is-\u0026gt;length) == 0) { if (pos) *pos = 0; return 0; } else { // 大于当前数组中最大值 或 小于最小值，也是直接返回 if (value \u0026gt; _intsetGet(is,max)) { if (pos) *pos = intrev32ifbe(is-\u0026gt;length); return 0; } else if (value \u0026lt; _intsetGet(is,0)) { if (pos) *pos = 0; return 0; } } // 因为数组有序，所以采用二分法查找位置是一个非常正确的选择 while(max \u0026gt;= min) { mid = ((unsigned int)min + (unsigned int)max) \u0026gt;\u0026gt; 1; cur = _intsetGet(is,mid); if (value \u0026gt; cur) { min = mid+1; } else if (value \u0026lt; cur) { max = mid-1; } else { break; } } if (value == cur) { // value 已经存在 if (pos) *pos = mid; return 1; } else { // value 不存在 if (pos) *pos = min; return 0; } } 5.3 总结 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 整数集合中的元素不能太对，当超过配置值后，会被转化成字典。 6. 压缩列表 压缩列表 是 Redis 自己实现的一个数据存储结构，有点类似数组，通过一片连续的空间存储数据，只不过数组的每个元素大小都相同，压缩列表允许每个元素有自己的大小。其核心思想，就是在一个连续的内存上，模拟出一个链表的结构。\n在源代码中有这么一段描述：\nThe ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist.\n大致意思是：ziplist 是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist 可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以 O(1) 的时间复杂度在表的两端提供 push 和 pop 操作。但由于每次操作都需要重新分配 ziplist 使用的内存，所以实际的复杂度与 ziplist 使用的内存量有关。\n源码文件：ziplist.h\n6.1 数据结构 ziplist 并没有实际的 struct 表示，但在 ziplist.c 中有如下描述：\nThe general layout of the ziplist is as follows:\n\u0026lt;zlbytes\u0026gt; \u0026lt;zltail\u0026gt; \u0026lt;zllen\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;entry\u0026gt; \u0026hellip; \u0026lt;entry\u0026gt; \u0026lt;zlend\u0026gt;\nzlbytes：本身占用 4 字节，整个压缩列表占用的总字节数(包括他自己) zltail：本身占用 4 字节，起始位置到最后一个结点的偏移量，用来快速定位最后一个元素，在反向输出压缩列表时会有用 zllen：本身占用 2 字节，压缩列表包含的元素个数 entry：元素内容。用数组存储，内存上紧挨着 zlend：本身占用 1 字节，压缩列表结束的标志位，一般为常量 0xFF 接下来看 entry 这个结构：\n\u0026lt;prevlen\u0026gt; \u0026lt;encoding\u0026gt; \u0026lt;entry-data\u0026gt;\nprevlen：1 字节或者 5 字节，表示前一个 entry 长度，在反向遍历的时候会有用 encoding：1、2 或 5 字节，表示当前 entry 的编码方式，表示当前 entry 的类型，integer 或 string entry-data：实际所需的字节数，结点真正的值，可以是 integer 或 string。它的类型和长度由 encoding 来决定 接下来我们详细关注这三个参数：\nprevlen 以字节为单位，记录前一个 entry 的长度。prevlen 的长度可以是 1 字节 或者 5 字节：\n当前一个结点的长度小于 254 字节时，prevlen 的长度为 1 字节，前一个 entry 的长度就保存在这一个字节中； 当前一个结点的长度大于等于 254 字节时，prevlen 的长度为 5 字节，其中第一个字节会被设置成 0xFE(十进制的 254)，表示这是一个 5 字节长 的 prevlen，后面的四个字节则保存前一个 entry 的长度。 prevlen 的作用是：在反向遍历压缩数组时，可以通过当前元素的指针，减去 prevlen ，就能得到前一个元素的地址。\nencoding 节点的 encoding 属性记录了节点的 entry-data 属性所保存 数据的类型 以及 长度：\n一字节、两字节或者五字节长， 值的最高位为 00 、 01 或者 10 的是字节数组编码： 这种编码表示节点的 content 属性保存着 字符串(字节数组)， 数组的长度由编码除去最高两位之后的其他位记录： 编码 编码长度 content 中保存的值 00bbbbbb 1 字节 长度小于等于 63 字节的字节数组(6 位分辨位，2^6 = 64，除去全 0 的) 01bbbbbb | xxxxxxxx 2 字节 长度小于等于 16383 字节的字节数组(14 位分辨位，2^14 = 16384，除去全 0 的) 10000000 | xxxx…xxxx(32 位) 5 字节 长度小于等于 4294967295 字节的字节数组(32 位分辨位，2^32 = 4294967296) 一字节长， 值的最高位以 11 开头的是整数编码： 这种编码表示节点的 entry-data 属性保存着整数值， 整数值的类型和长度由编码除去最高两位之后的其他位记录: 编码 编码长度 entry-data 中保存的值 11000000 1 字节 int16_t 类型整数 11010000 1 字节 int32_t 类型整数 11100000 1 字节 int64_t 类型整数 11110000 1 字节 24 位有符号整数 11111110 1 字节 8 位有符号整数 1111xxxx 1 字节 使用这一编码的节点没有相应的 entry-data 属性， 因为编码本身的 xxxx 四个位已经保存了一个介于 0 和 12 之间的值， 所以它无须 entry-data 属性。 entry-data 节点的 entry-data 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。\n6.2 API 创建ziplist 返回一个只包含 \u0026lt;zlbytes\u0026gt;\u0026lt;zltail\u0026gt;\u0026lt;zllen\u0026gt;\u0026lt;zlend\u0026gt; 的 ziplist：\nunsigned char *ziplistNew(void) { unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; // 头部的 4+4+2 和 尾部的1 总共 11 字节 unsigned char *zl = zmalloc(bytes); // 这里的ziplist类型是一个 char 数组，而不是某个具体的结构体 ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); // 设置 zlbytes 为 初始分配的值，即 bytes ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); // 设置 zltail 为 header 结束的地方 ZIPLIST_LENGTH(zl) = 0; // 设置 zllen 为 0 zl[bytes-1] = ZIP_END; // 最后一个字节存储常量 255 ，表示 ziplist 结束 return zl; } 插入ziplistInsert 这个函数的作用是 在 ziplist 的任意数据项前面插入一个新的数据项：\nunsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { return __ziplistInsert(zl,p,s,slen); } // 在 p 处 插入 s，s 的长度为 slen；插入后s占据p的位置，p及其后面的数据整体后移。其中 p 指向 ziplist 中某一个 entry 的起始位置，或者 zlend(当向尾部插入时) unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { // reqlen 表示 将 s 变成一个 entry 所需要的总字节数，即 prevlen,encoding,entry-data 的总长度 size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; // 随便使用一个一眼就能看出来的值表示当前变量未被逻辑初始化，避免 warning zlentry tail; if (p[0] != ZIP_END) { // 如果不是插入尾部，则根据p获取 p所在的 entry 的前一个 entry 的 prevlen，需要保存 prevlen的字节数保存在 prevlensize(1字节或者5字节，前面有介绍) ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); } else { // p 指向的是 尾部标志 unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) { // 获取 ziplist 最后一个 entry 的长度，保存在 prevlen 中 prevlen = zipRawEntryLength(ptail); } } // 尝试能否转化成整数 if (zipTryEncoding(s,slen,\u0026amp;value,\u0026amp;encoding)) { // 可以转化成 int，则 reqlen 即为存储此 int 所需的字节数，即 entry-data 的长度 reqlen = zipIntSize(encoding); } else { // 无法转换成 int，那就是字节数组，reqlen 就是要存入的字符串的长度，即 entry-data 的长度 reqlen = slen; } // reqlen reqlen += zipStorePrevEntryLength(NULL,prevlen); // 再加上 prevlen 的长度 reqlen += zipStoreEntryEncoding(NULL,encoding,slen); // 再加上 encoding 的长度 // 当不是向尾部插入时，我们必须确保下一个 entry 的 prevlen 等于当前 entry 的长度 int forcelarge = 0; // 【1】nextdiff 存储的是p的prevlen的变化值(新元素长度reqlen - p之前entry的prelen)，具体解释看代码后面【1】处的解释 nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 \u0026amp;\u0026amp; reqlen \u0026lt; 4) { nextdiff = 0; forcelarge = 1; // 这种情况下意味着，本来可以用 1 字节的，却使用了 5 个字节 } /* Store offset because a realloc may change the address of zl. */ // 存储 p 相对于 ziplist 的偏移量，因为 resize 可能改变 ziplist 的起始地址 offset = p-zl; // 到这一步已经能确定 ziplist 需要的总的容量了，调用 resize 调整 ziplist 的大小 zl = ziplistResize(zl,curlen+reqlen+nextdiff); // 重新定位 p p = zl+offset; // 将 p 以及其后面的数据移动为 s 挪地方，别忘了更新 zltail 的值 if (p[0] != ZIP_END) { // 在p前面腾出reqlen字节给新entry使用（将p move到p+reqlen，考虑了prelen缩减或增加） memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); // 更新 s 的后一个 entry（p+reqlen即p的新地址）的prevlen； if (forcelarge) // 【2】强制使用 5 字节存储，避免连锁更新时的大量重新分配空间操作，不进行缩容 zipStorePrevEntryLengthLarge(p+reqlen,reqlen); else // 计算 reqlen 进而判断使用 1 字节 还是 5 字节 zipStorePrevEntryLength(p+reqlen,reqlen); // 更新 zltail ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); // 更新zltail zipEntry(p+reqlen, \u0026amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); } } else { // 如果是在尾部插入，则直接修改 zltail 为 s ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); } // 如果 nexydiff 不等于0，整个 s 后面的 ziplist 的 prevlen 都可能发生变化，这里尝试进行维护 if (nextdiff != 0) { offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; // 改变的只是 p 后面的，前面的没变，因此 s 插入的位置没变 } // 存入 s 这个 entry p += zipStorePrevEntryLength(p,prevlen); p += zipStoreEntryEncoding(p,encoding,slen); if (ZIP_IS_STR(encoding)) { memcpy(p,s,slen); } else { zipSaveInteger(p,value,encoding); } // ziplist 的长度加 1 ZIPLIST_INCR_LENGTH(zl,1); return zl; } // 将 ziplist 的长度变成 len unsigned char *ziplistResize(unsigned char *zl, unsigned int len) { zl = zrealloc(zl,len); ZIPLIST_BYTES(zl) = intrev32ifbe(len); zl[len-1] = ZIP_END; return zl; } 解释【1】：这种情况发生在 插入的位置不是尾部 的情况，我们假设 p 的前一个元素为 p0，此时 p 的 prevlen 存储的是 p0 的长度。但是由于要将 s 插入到 p 之前，那么 p 的 prevlen 的值就应该变成 s 的长度，这样 p 本身的长度也就发生了变化，有可能变大也有可能变小。这个变化了多少的值就是 nextdiff，如果变大了，nextdiff 是正数，否则是负数。如果是负数，只有一种情况，那就是 p0 的长度大于 254，用 5 个字节存；而 s 的长度小于 254，用 1 个字节存就够了。\n解释【2】：关于 forcelarge，这是一个已经被修改后的 bug，大致意思是，这种操作发生在 连锁更新(90 行) 的时候，为了防止大量的重新分配空间的动作，如果一个 entry 的长度只需要 1 个字节就能够保存,但是连锁更新时如果原先已经为 prevlen 分配了 5 个字节,则不会进行缩容操作。关于为何，可以参考这篇文章：Redis 的一个历史 bug 及其后续改进，作者对这个 bug 进行了复现，以及提到了 Redis 对此作出的更新(提出了更优化的结构 listpack)。\n我们接着说 连锁更新。回忆一个 entry 的结构，其中 prevlen 表示前一个 entry 的长度：如果前一个结点长度小于 254，则 prevlen 占用 1 字节，否则占用 5 字节。现在， 考虑这样一种情况： 在一个压缩列表中， 有多个连续的、长度介于 250 字节到 253 字节之间的节点 e1 至 eN 。因为 e1 至 eN 的所有节点的长度都小于 254 字节， 所以记录这些节点的长度只需要 1 字节长的 prevlen 属性， 换句话说， e1 至 eN 的所有节点的 prevlen 属性都是 1 字节长的。此时，如果我们在 e1 前面插入一个长度大于 254 的元素 m，因为 e1 的 prevlen 仅为 1 字节，无法保存大于 254 的数，因此，我们还要对 ziplist 进行空间重分配操作，使得 e1 能够保存 m 的长度，即将 ziplist 的大小再增加 4 字节，让 e1 的 prevlen 大小由 1 字节变为 5 字节，这种操作我们称为 m 对 e1 发生了 扩展。回到刚才的情况，现在麻烦来了，e1 大小发生了变化，肯定超过了原来的 254，此时 e1 需要对 e2 进行扩展，又到后面，e2 需要对 e3 进行扩展……程序需要不断地对压缩列表执行空间重分配操作， 直到 eN 为止。\nRedis 将这种在特殊情况下产生的连续多次空间扩展操作称之为 “连锁更新”（cascade update）。我们看看 连锁更新 的具体实现：\n// p 指向第一个不需要更新的 entry unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) { size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; // 当 p 是 ziplist 的”尾巴“时停止更新 while (p[0] != ZIP_END) { zipEntry(p, \u0026amp;cur); // 【1】将 entry 解码称为一个易于操作的 entry 结构体，细节见代码后解释 rawlen = cur.headersize + cur.len; // 当前节点的长度 rawlensize = zipStorePrevEntryLength(NULL,rawlen); // 存储当前节点所需要的 prevlen 大小 // 没有下一个节点，直接返回 if (p[rawlen] == ZIP_END) break; // 获取 p 的下一个节点 zipEntry(p+rawlen, \u0026amp;next); // 如果下一个节点的 prevlen 等于当前节点的 长度，则没必要更新，直接退出循环 if (next.prevrawlen == rawlen) break; // 下一个节点的 prevlen 小于当前节点的长度(当前节点长度为 5 字节，next 的 prevlen 为1 字节) if (next.prevrawlensize \u0026lt; rawlensize) { // ziplist的地址可能发生改变，先记录 p 相对于zl起始位置的偏移量 offset = p-zl; // 额外需要申请的空间 5 - 1 = 4 extra = rawlensize-next.prevrawlensize; // 改变 ziplist 的容量 zl = ziplistResize(zl,curlen+extra); // 重新计算 p 的位置 p = zl+offset; /* Current pointer and offset for next element. */ np = p+rawlen; // next 的新地址 noffset = np-zl; // next新地址相对于 ziplist 头部的偏移量 // 更新 zltail if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra); } // 扩展 next 的 prevlen，并将数据拷贝 memmove(np+rawlensize, np+next.prevrawlensize, curlen-noffset-next.prevrawlensize-1); // 在扩展后的 next 的 prevlen 中重新记录 p 的长度 zipStorePrevEntryLength(np,rawlen); /* Advance the cursor */ // 更新 p 为下一个 entry p += rawlen; // 更新 p 的长度(需要加上扩展的 prevlen 的 extra 个字节) curlen += extra; } else { // 这种情况下，next 的 prevlen 足够表示 当前 p 的长度 if (next.prevrawlensize \u0026gt; rawlensize) { // next 的 prevlen \u0026gt; p 的长度(next.prevlen = 5 结点，p的长度小于 5 个结点)，此时应该 缩容，但出于性能以及操作的方便性(减少后续连锁更新的可能性)，我们通常不进行缩容，这个时候，直接将 next 的 prevlen 设置为 5 个结点 zipStorePrevEntryLengthLarge(p+rawlen,rawlen); } else { // 相等 zipStorePrevEntryLength(p+rawlen,rawlen); } // next 的长度并没有发生变化(没有缩容)，终止循环 break; } } return zl; } 解释【1】：“辅助结构体” zlentry，这个结构体与 ziplist 中的一个实际 entry 相对应，其作用是为了更加方便地操作一个 实际的 entry：\ntypedef struct zlentry { unsigned int prevrawlensize; // 存储 prevrawlen 所需要的字节数，同样也有 1字节 和 5字节之分 unsigned int prevrawlen; // 对应 prevlen unsigned int lensize; // 存储 len 所需要的字节数 unsigned int len; // 当前 entry 的长度 unsigned int headersize; // ziplist头部大小: prevrawlensize + lensize unsigned char encoding; // 编码方式 unsigned char *p; // 指向某个实际 entry 的地址 } zlentry; 其他的一些操作，比如删除、查找，过程与插入类似，无非就是各个 entry 地址的计算，删除时还有可能涉及到连锁更新。 这里不再描述，想了解的可以根据上面的思路自己研究源代码。\n6.3 总结 ziplist是 redis 为了节省内存，提升存储效率自定义的一种紧凑的数据结构，每一个 entry 都保存这上一个 entry 的长度，可以很方便地进行反向遍历； 添加和删除节点可能会引发连锁更新，极端情况下会更新整个ziplist，但是概率很小； 在 Redis 中，当元素个数较少时，哈希表(hset 等操作) 和 列表(lpush 等操作) 的底层结构都是 ziplist。 7. 紧凑列表 源码文件：listpack.h\n实现文档：Listpack specification\n紧凑列表是 压缩列表 的升级版，目的是在未来代替 ziplist。\n有时间再完善。\n二、 Redis 对象对应的数据结构 前面大致介绍了 简单动态字符串 sds、双端链表 adlist、字典 dict、跳表 skiplist、整数集合 intset 和 压缩列表 ziplist 等基础数据结构，同时我们知道 Redis 中有 字符串对象(string)、列表对象(list)、哈希对象(hash)、集合对象(set) 和 有序集合对象(zset) 等五种对象，他们都至少用了上面一种基础数据结构来实现。在 Redis 中，客户端的一条命令以及参数会被解释成一个 robj 结构体：\n源码文件： server.h\ntypedef struct redisObject { unsigned type : 4; // 类型 unsigned encoding : 4;\t// 编码 unsigned lru : LRU_BITS; // 对象最后被访问的时间，我们暂时不关注 LRU int refcount;\t// 引用次数 void *ptr;\t// 指向实现对象的数据结构 } robj; /* Object types */ #define OBJ_STRING 0 /* String object. */ #define OBJ_LIST 1 /* List object. */ #define OBJ_SET 2 /* Set object. */ #define OBJ_ZSET 3 /* Sorted set object. */ #define OBJ_HASH 4 /* Hash object. */ /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The \u0026#39;encoding\u0026#39; field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 // 简单动态字符串 sds #define OBJ_ENCODING_INT 1 // long 类型 #define OBJ_ENCODING_HT 2 // 字典 dict #define OBJ_ENCODING_ZIPMAP 3 // zipmap(弃用) #define OBJ_ENCODING_LINKEDLIST 4 // 双端链表 adlist #define OBJ_ENCODING_ZIPLIST 5 // 压缩列表 ziplist #define OBJ_ENCODING_INTSET 6 // 整数集合 intset #define OBJ_ENCODING_SKIPLIST 7 // 跳表 skiplist #define OBJ_ENCODING_EMBSTR 8 // 采用embstr编码的sds #define OBJ_ENCODING_QUICKLIST 9 // qunicklist，用于列表 #define OBJ_ENCODING_STREAM 10 // 紧凑列表 listpack #define LRU_BITS 24 obj 的作用大致为：\n为多种数据类型提供一种统一的表示方式。 允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。 支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。 说到底， robj 所表示的就是 五种 Object types 和 11 中 Object encoding 之间的对应方式，起到一个桥梁作用。这种对应关系可用如下的图来表示：\n","permalink":"http://localhost:1313/posts/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-1-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","summary":"\u003cp\u003e首先明确，\u003ccode\u003eRedis\u003c/code\u003e 是一个\u003cstrong\u003e使用 C 语言编写的键值对存储系统\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 是众所周知的 “\u003cstrong\u003e快\u003c/strong\u003e”，一方面，它是一个内存数据库，所有的操作都是在\u003cstrong\u003e内存\u003c/strong\u003e中完成的，内存的访问速度本身就很快；另一方面，得益于它\u003cstrong\u003e底层的数据结构\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 的常见类型可在这个网页找到：\u003ca href=\"https://redis.readthedocs.io/en/2.4/index.html\"\u003eRedis 命令参考简体中文版\u003c/a\u003e，其使用到的底层数据结构有如下六种：\u003cstrong\u003e简单动态字符串\u003c/strong\u003e、\u003cstrong\u003e双向链表\u003c/strong\u003e、\u003cstrong\u003e压缩列表\u003c/strong\u003e、\u003cstrong\u003e哈希表\u003c/strong\u003e、\u003cstrong\u003e跳表\u003c/strong\u003e和 \u003cstrong\u003e整数数组\u003c/strong\u003e。本篇文章，将具体了解这些底层数据结构的实现。\u003c/p\u003e","title":"Redis源码阅读--1.基础数据结构与对象"},{"content":"一、常见的索引类型 1. 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 创建自定义的哈希索引：\n通过一个实例来说明：\n提出问题：假如我们要存储大量的URL，同时还有通过 URL 查询该条记录的需求，应该如何建立索引？ 调研：如果直接在 URL 上建立索引，那么索引会很长，并且很大 解决方案：删除原来 URL 上的索引，新增一个被索引的 url_crc 列，存储 URL 列被 CRC32 之后的值，之后的查询可通过这个索引来查。缺点是还要花时间维护这个索引列。 # 建表 CREATE TABLE url_demo ( id int unsigned NOT NULL auto_increment, url varchar(255) NOT NULL, url_crc int unsigned NOT NULL DEFAULT 0, PRIMARY KEY(id) ); # 为了减少维护工作，可以创建一个触发器 DELIMITER // CREATE TRIGGER url_demo_crc_ins BEFORE INSERT ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; CREATE TRIGGER url_demo_crc_upd BEFORE UPDATE ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; // DELIMITER ; # 之后可验证增删改查 INSERT INTO url_deml(url) VALUES(\u0026#34;https://www.baidu.com\u0026#34;); SELECT * FROM url_demo; +----+-----------------------+------------+ | id | url | url_crc | +----+-----------------------+------------+ | 1 | https://www.baidu.com | 3010065587 | +----+-----------------------+------------+ UPDATE url_demo SET url=\u0026#34;https://www.google.com\u0026#34; WHERE id=1; SELECT * FROM url_demo; +----+------------------------+-----------+ | id | url | url_crc | +----+------------------------+-----------+ | 1 | https://www.google.com | 857627499 | +----+------------------------+-----------+ # 查询某个具体的URL时，必须使用下面的查询方法： SELECT * FROM url_demo WHERE url_crc=CRC32(\u0026#34;https://www.google.com\u0026#34;) AND url=\u0026#34;https://www.google.com\u0026#34;; 2. B-Tree 索引 当人们谈论索引时，如果没有特别指明类型，那多半说的是 B-Tree 索引。它使用 B 树(部分引擎使用 B+树)作为底层的数据结构，这通常意味着被索引的值都是按顺序存储的(首先是个 二叉排序树)，并且每一个叶子节点到根节点的举例相同(变形的 多叉排序树)。树的深度和表的大小直接相关。\n假如我们有如下数据表：\nCREATE TABLE people ( last_name varchar(64) NOT NULL, first_name varchar(64) NOT NULL, dob date NOT NULL, gender enum(\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;) NOT NULL, key(last_name, first_name, dob) ); 下图显示了该索引时如何组织数据的：\n以下情况，索引(key(last_name, first_name, bob))是有效的：\n全值匹配：指查询的列和索引中的列完全匹配(字段以及对应的字段顺序)，例如 SELECT * FROM people WHERE last_name= ‘Allen’ AND first_name = 'Cuba' AND bob = '1960-01-01'； 最左前缀匹配：索引的顺序非常重要： 可以匹配所有last_name = ‘Allen’的人，因为 last_name 是索引列中最左边的； 可以只匹配某一列的值得开头部分，如 last_name 全部以 K 开头，即 last_name like 'K%’，注意，这里也是针对最左边的列； 可以匹配 last_name 在 Allen 和 Barrymore 之间的人，即 last_name \u0026gt; ‘Allen’ AND last_name \u0026lt; 'Barrymore’，这里也是针对最左边列； 精准访问某一列并范围匹配另一列：例如第一列last_name全匹配，第二列first_nbame 范围匹配；或者last_name和first_name全匹配，第三列bob范围匹配。 只访问索引的查询：即 覆盖索引。即select的字段就属于索引列，而不用通过“回表”再拿一次。关于覆盖索引，后面会详细介绍。 以下情况，索引会失效（即不会使用之前创建的索引 key(last_name, first_name, bob)）：\n单独列非最左列，索引失效，即 如果不是按照索引的最左列开始查找，无法使用索引。例如：无法查找 WHERE first_name = ‘Bill’；例如 WHERE bob = '1960-01-01’；例如 WHERE first_name like 'K%'。因为查询的列都不是该索引的最左列。同理，WHERE last_name like '%L’也会失效。 跳过某一列，索引失效。即 WHERE last_name='Allen' AND bob='1960-01-01’也不会使用该索引，因为跳过了列first_name。 某列范围查询，右边所有列无法使用索引优化查询。如 WHERE last_name='Allen' AND first_name like ‘J%’ AND bob='1960-01-01’，那么 bob 列无法使用索引优化查询，因为中间的first_name LIKE是一个范围条件。 如果使用B-Tree，创建多列索引时，列的顺序非常重要！\n二、高性能的索引策略 正确地创建和使用索引是实现高性能查询的基础。下面介绍如何正确地运用索引。\n1. 查询时，索引列单独放在比较符号的一侧 如果查询中的列不是独立的，则 MySQL 不会使用索引。 独立的列 是指索引列不能是表达式的一部分，也不能是函数的参数。\n下面这个查询就无法使用score列的索引：\nSELECT * FROM student WHRER score + 1 = 90; 我们都知道上述查询中表达式的值是 89，但是MySQL 无法解析这个方程式。我们应该养成简化 MySQLWHERE条件的习惯，始终将索引列单独放在比较符号的一侧。\n2. 前缀索引和索引选择性 索引选择性是指 不重复的索引数(I) 和 数据表的记录总数(S) 的比值，即 $I/S$，根据其计算方式可知，$I/S \u0026lt;= 1$，并且索引选择性越高，查询性能越高，因为索引选择性高的索引可以让 MySQL 在查询的时候 过滤掉更多行。单一列的索引的选择性是 1，是最好的。\n既然单一列的索引选择性是最好的，我们为什么还要讨论这个问题？想一下要对 某一些很长的列建立索引，这时索引会变的非常大，有可能出现索引文件远大于数据文件的情况。这个时候对整个字段建立索引就显得不太明智，此时索引选择性可以作为一个辅助工具，帮助我们 选择足够长的前缀以保持较高的选择性，同时又不能太长。\n如何选择合适的前缀长度？方法是 计算完整列的选择性，然后逐个计算前缀的选择性，选择最接近完整列的那一个。\n假如完整列的选择性为 0.0312，而不同前缀长度对应的选择性结果为：\n当长度大于 7 时，再增加前缀长度，性能提升的幅度就已经很小了。于是建立索引：\nALTER TABLE demo ADD KEY(city(7)); 优点：使索引又快又小的这种方法；\n缺点：无法使用前缀索引进行 GROUP BY 和 ORDER BY，也无法进行覆盖扫描(覆盖索引)。\n3. 多列索引 我们经常会听到有人说“把 WHERE 条件里面的列都建上索引”这种模糊的建议，但事实上，如果不从实际出发，大多数情况下，在多个列上简历单独的索引并不能提高 MySQL 的查询性能。\nMySQL 5.0 之后引入了一种叫 索引合并(Index Merge) 的策略，一定程度上可以提高多个单列索引查询时的性能。\n关于 索引合并 ，看这篇文章：索引合并\n在以下情况下，建议使用多列索引而不是在每个单独列上建立索引：\n当出现对多个索引做相交操作时(通常是多个 AND 操作)，这通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引； 当出现对多个索引做联合操作时(通常是多个 OR 操作)，通常需要耗费大量的 CPU 和内存用以对结果的缓存、归并和排序上，特别是某些索引的选择性不高时，需要合并扫描大量的数据。 4. 选择合适的列顺序 当使用 B-Tree 索引时，由于其“最左匹配”的性质，索引列的顺序往往意味着索引首先按照最左列进行排序，然后是第二列。对于如何选择多列索引的顺序，有一个经验法则： 将选择性最高的列放在索引最前列。\n5. 聚簇索引 MySQL 的 InnoDB 索引数据结构是 B+树，主键索引叶子节点的值存储的就是 MySQL 的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提。\n首先，用一句话解释什么是聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引。所以主键就是聚簇索引。\n对应地，什么是非聚簇索引？也称二级索引，索引的存储和数据的存储是分离的，在 InnoDB 引擎中，二级索引中存储的是主键值，先通过查找二级索引得到对应的主键值，再通过主键值回表查询需要的字段。\n二级索引使用主键值当做行的指针，会让二级索引占用更多的空间，换来的好处是，InnoDB 在移动行时无需更新索引中的这个指针——这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。\n在 InnoDB 中，主键一定是聚簇索引，InnoDB 一定有主键(如果没有手动设定，InnoDB 会默认创建一个)，并且一张表只允许有一个聚簇索引。\n建议：InnoDB 中应该尽可能按照主键的顺序去插入数据，一般使用一个递增的 bigint 类型 作为主键。最差的情况是使用值完全随机的列如 UUID 作为主键！\n6. 覆盖索引 前面提到过，InnoDB 中，非聚簇索引所存储的值为主键值，要想获得其他列的值，还要进行一个被称为 “回表” 的操作——也就是说，使用非聚簇索引查询更多列，要进行两次查询。但是想一想，如果我们差的刚好就是主键 id，如 SELECT id FROM student WHERE name='Tom';，此时我们需要的列就在二级索引中，不需要再执行“回表”操作，这个操作，可以极大地提高性能。\n如果一个索引包含(或者说 覆盖) 所有查询的字段的值，我们就称为**“覆盖索引”**。\n为什么覆盖索引能提高性能？因为减少了“回表”的操作，减少了很多次随机 IO。\n7. 学会使用 EXPLAIN 在需要执行的 SQL 语句前面加上EXPLAIN，可以查询和分析这条 SQL 语句的执行记录，对我们优化查询效率有很大的帮助。\n先看一个EXPLAIN的示例：\nmysq\u0026gt; explain select * from city\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: city partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 366 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 其他的几个列暂时不考虑，只对 type 和 EXTRA 做记录：\ntype 关联类型，或访问类型——MySQL 如何查找表中的行。以下按照从最差到最优的方式介绍：\nALL： 全表扫描。 index：按照索引次序扫描。跟全表扫描一样，只不过扫描时按照索引顺序进行而不是按照每一行。它的优点是：避免了排序操作。缺点是：要承担按索引次序读取整个表的开销(如果是非聚簇索引，那么索引次序是有序的，但存储的主键不一定是有序的，回表的时候进行的就是随机 IO，此时开销会更大，还不如 ALL)。如果在EXTRA列中看到“Using index”，说明 MySQL 正在使用覆盖索引。 range：范围扫描，即带有WHERE或BETWEEN或\u0026lt;等比较符号的查询语句。比全表扫描好一些，因为不需要遍历全部索引，只需要从满足条件的行开始计算。开销与index相同。 ref：非主键 非唯一索引 等值查找。 eq_ref：主键索引 或 非空唯一索引 进行等值查找。 cost：常量连接，表最多只有一行匹配，通常用于 主键 或者 唯一索引 进行等值比较。 system：系统表，少量数据，往往不需要进行磁盘 IO (可以当成 cost 连接的特例) extra extra 表示 MySQL 如何解析这条查询，参数更多地显示一些关于索引的信息。它的最常用的选值如下：\nusing index：表示本次查询将使用 覆盖索引，避免了 回表 的操作，即 where 筛选条件是索引的前导列 并且 select 选择的列被索引覆盖，没有 回表 操作。 using where：限制了哪一行，也就是说，读取结束之后使用了 Table Filter 进行了过滤。不管查询条件有没有覆盖索引，只要筛选条件没有使用索引，就会有 using where。 using where; using index：查询的列被索引覆盖，但是 筛选条件不是前导列 或者 筛选条件是前导列但是使用了范围查询。 NULL：查询的列未被索引覆盖，但是筛选条件使用了索引的前导列。这种情况意味着用到了索引，但是 select 的字段没有被索引覆盖，因此还要进行 回表 操作，“不是纯粹地使用索引，也没有完全用到索引”，所以为 NULL(没有信息)。 using index condition：查询的列没有被索引全部覆盖，筛选条件使用了索引的前导列的范围查询 或者 查询条件使用到了索引但还有一些别的条件。 上面的这些情形可用如下的表格总结：\n","permalink":"http://localhost:1313/posts/mysql%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95/","summary":"\u003ch2 id=\"一常见的索引类型\"\u003e一、常见的索引类型\u003c/h2\u003e\n\u003ch3 id=\"1-哈希索引\"\u003e1. 哈希索引\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e哈希索引(Hash Index)\u003c/strong\u003e 基于哈希表实现，\u003cstrong\u003e只适合精确匹配，不适合范围查找\u003c/strong\u003e。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算\u003ccode\u003e哈希code\u003c/code\u003e，通过 \u003cstrong\u003eK-V\u003c/strong\u003e 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\u003c/p\u003e","title":"MySQL关于索引"},{"content":"1. 堆排序 堆 是一种数据结构，它具有如下特征：\n是一棵完全二叉树 父节点的值 \u0026gt; 子节点的值 1.1 完全二叉树 若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是 完全二叉树。\n完全二叉树有一个很重要的特点，它的元素可以全部放在一个数组中，这个数组中的元素排列非常紧密，不会出现零值的情况。比如下面这棵树，对应的数组为： [25, 14, 13, 4, 2, 10]。\n如果我们从上到下、从左到右的顺序去遍历这棵树，会发现，元素顺序与数组中完全对应。于是会有下面的公式：\n设数组中父节点的 index 值为i，则左孩子的 index 值为 2*i+1，右孩子的 index 值为 2*i+2。这样数组和数的关系就对应上了。这是堆排序的基础。\n1.2 heapify 我们称 将一棵树变成堆的过程 称为 heapify。具体来说是将 parent、left 和 right这三个结点，通过交换，使得 parent 为最大(left和right哪个大没关系)，因为数的定义是递归的，所以上面这个交换过程也是递归的。此时需要决定的是从下到上，还是从上到下。答案是如果是大根堆，从下到上进行 heapify 过程，因为从上到下的，处理完父节点，还不确定这个父节点是不是就是整个堆中的最大，而从下到上可以看成是一个不断往上 “喂” 最大值的过程。可以写出代码：\n// heapify 从数组的第i个元素为父节点，使其符合大根堆的特性。前提，左右子树均已经是大根堆了 func heapify(arr []int, n int, i int) { if i \u0026gt;= n { return } // 第i个结点的左右孩子分别为 left := 2*i + 1 right := 2*i + 2 // 求得父节点、左孩子、右孩子之间的最大值 maxIndex := i if left \u0026lt; n \u0026amp;\u0026amp; arr[left] \u0026gt; arr[maxIndex] { maxIndex = left } if right \u0026lt; n \u0026amp;\u0026amp; arr[right] \u0026gt; arr[maxIndex] { maxIndex = right } // 如果发生了交换，需要递归去处理对应的子树 if maxIndex != i { // 交换 使得parent为最大的那个 arr[i], arr[maxIndex] = arr[maxIndex], arr[i] //fmt.Println(arr[maxIndex], arr[left], arr[right]) // 此时，修改了原来的结构，为了保证交换后的子树也继续是大根堆，这里递归调用调整子树 heapify(arr, n, maxIndex) } } 1.3 build heap 当我们从下到上构建一个大根堆的时候，没必要从最后一个元素开始，需要从最后一个有孩子的父节点开始，所以第一步是先找到 最后一个有孩子的父节点。方法很简单，找到最后一个孩子，再根据他们之间的关系很容易就能求得其父节点的索引值。之后遍历所有的有孩子的节点，即剩下的 13 , 14, 25，这三个元素刚好按照数组索引的顺序递减，因此可以写出代码：\n// buildHeap 从底向上构建大根堆 func buildHeap(arr []int) { n := len(arr) parent := (n - 1 - 1) / 2 // n-1为数组最后一个元素的index，其父节点为 ((n-1) - 1) / 2 for i := parent; i \u0026gt;= 0; i-- { // 从这个父节点开始，一直到第一个元素，从下到上构建不断heapify heapify(arr, n, i) } } 1.4 heap sort 构建出大根堆之后，堆顶(也就是数组index=0)的元素就是最大值。此时，我们将数组第一个元素和最后一个元素交换位置，之后缩小数组长度再次从头到尾进行 heapify ，之后再交换，最后的结果就是 数组从尾巴到头的元素一次递减。\nfunc heapSort(arr []int) { buildHeap(arr) // 构建大根堆 // 最后一个元素 与 第一个元素(最大)交换，之后再次heapify，再交换，结果就是从尾到头数值依次减小 for i := len(arr) - 1; i \u0026gt;= 0; i-- { arr[0], arr[i] = arr[i], arr[0] heapify(arr, i, 0) } } 2. 插入排序 它的工作原理是构建有序序列，对于未排序的数据，在已经排好序的序列中从后向前扫描，放入合适的位置。\n优点是：对近乎有序的一组数排序，其时间复杂度可以接近线性。 这个特性非常重要！谨记！！\n步骤：\n第一步，将第一个元素看成有序序列，第二个元素到最后一个元素看成未排序的序列； 从头到尾扫描未排序的序列，将这个元素插入到前面的有序序列的合适位置。为了 稳定性 的目的，如果某个元素和有序序列中的某个元素相同，应该将这个元素放在有序序列元素的后面。 // insertionSort 插入排序 func insertionSort(arr []int) { sortedIndex := 0 // 有序序列的最后一个元素 // 遍历所有的未排序元素 for i := sortedIndex + 1; i \u0026lt; len(arr); i++ { // 从当前元素开始向前遍历有序序列 for j := i; j \u0026gt; 0; j-- { // 当前值大于等于前面的，终止循环 if arr[j-1] \u0026lt;= arr[j] { break } // 如果当前值比前一个小，交换，之后循环再不断交换 arr[j-1], arr[j] = arr[j], arr[j-1] } } } 3. 希尔排序 是插入排序的改进版本，更高效一些，但是它是不稳定的。具体步骤如下：\n以 gap 为间隔分组 分好的组内内部排好序 降低 gap，重复上述步骤，直到 gap 变成 1，此时变成对整个数组进行排序 有一个问题，组内排序，采用什么方法？答案是 插入排序法，原因就是，在 gap 不断减小的过程中，数组主键接近有序，此时借助插入排序的优点：对近乎有序的一组数排序，其时间复杂度可以接近线性。是一个不错的选择。\nfunc shellSort(arr []int) { gap := 1 // 计算gap，简单点，可以让gap变成数组长度的一半 for gap \u0026lt; len(arr)/3 { gap = gap*3 + 1 } for gap \u0026gt; 0 { for i := gap; i \u0026lt; len(arr); i++ { tmp := arr[i] j := i - gap // 每次之和当前组内前面的元素比较交换 for j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp { arr[j+gap] = arr[j] j -= gap } arr[j+gap] = tmp } gap /= 3 // 更新gap } } 4. 快速排序 采用的是“分而治之”的思想。步骤如下：\n第一步，挑出基准元素(一般取第一个元素) 对数组进行排序，使得所有小于基准的排在前面，大于基准的排在基准后面。最后返回分区的位置。这个操作我们称之为 partition。 递归地 把小于基准值元素的子数列和大于基准值元素的子数列排序 func quickSort(arr []int) []int { return _QuickSort(arr, 0, len(arr)-1) } func _QuickSort(arr []int, left, right int) []int { if left \u0026lt; right { partitionIndex := partition(arr, left, right) _QuickSort(arr, left, partitionIndex-1) _QuickSort(arr, partitionIndex+1, right) } return arr } func partition(arr []int, startIndex, endIndex int) int { var ( pivot = arr[startIndex] // 基准 left = startIndex right = endIndex ) for left != right { // right指向倒数第一个小于基准的数 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026lt; arr[right] { right-- } // left指向顺数第一个大于基准的 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026gt;= arr[left] { left++ } // 交换left和right处的值 if left \u0026lt; right { arr[left], arr[right] = arr[right], arr[left] } } // 此时left=right，将left与pivot处的值交换即可 arr[startIndex], arr[left] = arr[left], arr[startIndex] return left } ","permalink":"http://localhost:1313/posts/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","summary":"\u003ch2 id=\"1-堆排序\"\u003e1. 堆排序\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e堆\u003c/strong\u003e 是一种数据结构，它具有如下特征：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e是一棵完全二叉树\u003c/li\u003e\n\u003cli\u003e父节点的值 \u0026gt; 子节点的值\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"11-完全二叉树\"\u003e1.1 完全二叉树\u003c/h3\u003e\n\u003cp\u003e若设二叉树的深度为\u003ccode\u003eh\u003c/code\u003e，除第 \u003ccode\u003eh\u003c/code\u003e 层外，其它各层 \u003ccode\u003e(1～h-1)\u003c/code\u003e 的结点数都达到最大个数，第 \u003ccode\u003eh\u003c/code\u003e 层所有的结点都连续集中在最左边，这就是 \u003cstrong\u003e完全二叉树\u003c/strong\u003e。\u003c/p\u003e","title":"排序算法"},{"content":"位运算 位运算讲究技巧，需要多积累经验。\n一、背景知识 Go 语言支持的 位运算符 如下：\n运算符 描述 规则 \u0026amp; 按位 与 二者同为 1 时结果才为 1，否则为 0 | 按位 或 二者同为 0 时结果才为 0，否则是 1 ^ 按位 异或 相同为 0，相异为 1 \u0026laquo; 左移 n 位，相当于乘以 2 的 n 次方 后面补 0 \u0026raquo; 右移一位，相当于除以 2 的 n 次方 截掉最后一位 1. 与 将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的对应位同为 1 时，该位才为 1，否则为 0。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a \u0026amp; b) // 0001 0100 上述例子中，我们从最后一位开始，逐位运算。可以看到只有 倒数第3位 和 倒数第5位 都是 1，结果中也只有倒数第 3 位和倒数第 5 位是 1。\n规律：\n任何数 \u0026amp; 0 = 0； 任何数 \u0026amp; 任何数 = 任何数； 2.或 将参与运算的两个数 各对应的二进制位 相或。只有当二者对应位全部是 0 时，该位结果才是 0，其他情况结果全为 1。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0011 1111 规律：\n任何数 | 0 = 任何数 任何数 | 任何数 = 任何数 3. 异或 逐位异或，对应位相同，结果为 0，否则为 1——可以理解为 “抵消 1” 效果。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0010 1011 规律：\n任何数 ^ 任何数 = 0 任何数 ^ 0 = 任何数 任何数 ^ 1 = ~任何数(按位取反) 二、经典题目 1. 二进制中 1 的个数 LeetCode 题目： 191. 位 1 的个数 1.1 题目描述 请实现一个函数，输入一个整数，输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n举例：\n输入：00000000000000000000000000001011 输出：3 解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 \u0026#39;1\u0026#39;。 1.2 思路 思路 1 最后一位通过和 1 进行 与运算，可以判断最后一位是否为 1；然后将要计算的数字向右移动 1 位，再计算是否最后一位是否为 1。逐渐循环，知道直到要计算的数变成 0。\nfunc hammingWeight(num uint32) int { result := 0 // 保存1出现的次数 for num \u0026gt; 0 { if num\u0026amp;1 == 1 { result++ // 最后一位是 1 } num \u0026gt;\u0026gt;= 1 // 将原数右移一位 } return result } 思路 2 某一位通过和 1 进行 与运算，可以判断该位是是否为 1。题目指定了 32 位无符号整数，那么循环 32 次，从最后一位开始逐位判断，如何向前移动？左移一位即可。\nfunc hammingWeight(num uint32) int { result := 0 base := uint32(1) for i := 0; i \u0026lt; 32; i++ { if base\u0026amp;num != 0 { result++ } base \u0026lt;\u0026lt;= 1 } return result } 思路 3 出发点：n \u0026amp; (n-1)，会消除 n 最后一个 1。因此，n \u0026amp; (n-1) 总是能把 n中最低位的 1 变成 0 ，并保持其他位不变。具体什么原因，暂时不做深究。\nfunc hammingWeight(num uint32) int { result := 0 for num \u0026gt; 0 { result++ num \u0026amp;= num - 1 } return result } 2. 判断一个数是否为 2 的幂 LeetCode 题目：231. 2 的幂 2.1 题目描述 给定一个整数，编写一个函数来判断它是否是 2 的幂次方。\n示例：\n输入: 1 输出: true 解释: 20 = 1 2.2 解题思路 如果将 2 的所有次幂的二进制写出来，你会发现这些数的规律：最高位都是 1，其余位全是 0。也就是说，如果一个数为 2 的次幂，那么它只有一个 1，而且是在最高位，同时也是最后一个 1。再回想一下上一题中的思路三，n \u0026amp; (n-1) 会消除最后一个 1，于是乎：\nfunc isPowerOfTwo(n int) bool { return n \u0026gt; 0 \u0026amp;\u0026amp; n\u0026amp;(n-1) == 0 } 3. 使用位运算求和 LeetCode 题目：剑指 Offer 65. 不用加减乘除做加法 3.1 题目描述 写一个函数，求两个整数之和，要求在函数体内不得使用 “+”、“-”、“*”、“/” 四则运算符号。\n举例：\n输入: a = 1, b = 1 输出: 2 提示：\na, b 均可能是负数或 0 结果不会溢出 32 位整数 3.2 解题思路 我们用 n 表示无进位和，c 表示进位，那么 sum = a + b = n + c，而位运算可以分别计算出 n 和 c。以两个 1 位的二进制数求和为例：\na b 无进位和 n 进位 c 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 10 从上表中可以看出，n = a ^ b，c = (a\u0026amp;b) \u0026lt;\u0026lt; 1。借用 leetcode 上大神的一张图：\n但是在 sum = n + c 中还是使用了加法，而这种情况我们依旧可以使用上面的规律。这里可以使用一个循环来解决，需要存储n 和 c，循环直到c = 0 时停止，而此时n 即为结果。\nfunc add(a,b int) int { /* * 循环解法 for b != 0 { b, a = (a\u0026amp;b) \u0026lt;\u0026lt; 1, a ^ b } return a */ /* * 递归解法，比上面的循环解法更清晰 if b == 0 { return a } return add(a ^ b, (a \u0026amp; b) \u0026lt;\u0026lt; 1) */ } 4. 数组中出现的次数 LeetCode 题目：136. 只出现一次的数字 4.1 题目描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,1] 输出: 1 4.2 解题思路 回想前面背景知识中的 异或 的特性：任何数 ^ 任何数 = 0，并且 任何数 ^ 0 = 任何数。所以思路很明显，全部进行 异或 操作，出现两次的都会被“抵消”，最后剩下那个“没人要的”，就是我们要找的。\nfunc singleNumber(nums []int) int { if len(nums) == 0 { return 0 } // 整体异或运算 for i:=1;i\u0026lt;len(nums);i++ { nums[0] ^= nums[i] // 使用已有数组的第0个位置，节省空间 } return nums[0] } 4.3 进阶——只出现一次的数字 II LeetCode 题目：137. 只出现一次的数字 II 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,3,2] 输出: 3 使用一个 map 的解法这里没必要说了，因为使用了额外空间。\n思路 1 使用数学规律法——原数组去重、再乘以 3 得到的值，刚好就是要找的元素的 2 倍。Go 中没有 set 的这种数据结构，这里提供 Python 解法：\ndef singleNumber(nums){ return int((sum(set(nums))*3 - sum(nums))/2) } 思路 2 回想之前的 异或，发现有两个 1，该位结果是 0；二进制加法中，两个 1 相加，产生了进位，抛弃进位，其结果也是 0——这个过程，可以看成是对应位上 1 的个数对 2 取模的结果。如果是三个数呢？是不是三个数的对应位都是 1 的时候，该位结果才是 0，否则就是 1——对应位上的 1 的个数对 3 取模即可。\nfunc singleNumber(nums []int) int { result := 0 for i := 0; i \u0026lt; 64; i++ { // int至少32位，一般都是64位 // 初始化每一位1的个数为0 number := 0 for _, k := range nums { // 通过右移i位的方式，计算每一位1的个数 number += (k \u0026gt;\u0026gt; i) \u0026amp; 1 } // 对3取模后 最终将抵消后剩余的1放到对应的位数上 res |= (number) % 3 \u0026lt;\u0026lt; i } return res } 再如果 除 1 个元素外，每个元素出现了 4 次呢？原理一样，对 4 取模即可。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%BD%8D%E8%BF%90%E7%AE%97/","summary":"\u003ch1 id=\"位运算\"\u003e位运算\u003c/h1\u003e\n\u003cp\u003e位运算讲究技巧，需要多积累经验。\u003c/p\u003e\n\u003ch2 id=\"一背景知识\"\u003e一、背景知识\u003c/h2\u003e\n\u003cp\u003eGo 语言支持的 \u003cstrong\u003e位运算符\u003c/strong\u003e 如下：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e运算符\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e描述\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e规则\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026amp;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e与\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 1 时结果才为 1，否则为 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e|\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 0 时结果才为 0，否则是 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e^\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e异或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e相同为 0，相异为 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026laquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e左移 n 位，相当于乘以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e后面补 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026raquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e右移一位，相当于除以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e截掉最后一位\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"1-与\"\u003e1. 与\u003c/h3\u003e\n\u003cp\u003e将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的\u003cstrong\u003e对应位同为 1 时，该位才为 1，否则为 0\u003c/strong\u003e。\u003c/p\u003e","title":"LeetCode-位运算"},{"content":"leetcode 上 三数之和 问题：\n15. 三数之和 259. 较小的三数之和 16. 最接近的三数之和 1. 题目描述 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素a，b，c ，使得 a + b + c = 0？请你找出所有满足条件且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例：\n给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 2. 解题思路 直接跳过暴力解法，说说此题的思路。\n首先，对这个数字排一下序；\n之后，采取固定一个数，同时用双指针来查找另外两个数的方式求解：\n比如，先固定第一个元素，下一个元素设置为 left 指针，最后一个元素设置为 right 指针； 计算这三个数之和是否为 0，如果是，这就是一组满足条件的三元组；如果不是，看结果与 0 的关系，如果小于 0，则 left 向右移动，再比较，如果大于 0，则 right 向左移动一位，再比较。 当然，如果当 固定元素+left \u0026gt; 0 或者 固定元素+right \u0026lt; 0 时，就没必要再去比较了。 以下是代码实现：\nfunc threeSum(nums []int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { // 最外层循环为 固定指针 pin = i left = i + 1 // left 为固定指针的下一个元素 right = l - 1 // right 为最后一个元素 // 如果最小的大于0，不用再循环了 if nums[pin] \u0026gt; 0 { break } // 跳过 pin 相同的 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 找到一个三元组 if nums[pin]+nums[left]+nums[right] == 0 { result = append(result, []int{nums[pin], nums[left], nums[right]}) // 跳过left相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } // 跳过 right 相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1] { right-- } // 找到之后，同时改变 left++ right-- } else if nums[pin]+nums[left]+nums[right] \u0026lt; 0 { // 左指针向右移动 left++ } else { right-- } } } return result } 3. 进阶 1——较小的三数之和 给定一个长度为 n 的整数数组和一个目标值 target，寻找能够使条件 nums[i] + nums[j] + nums[k] \u0026lt; target 成立的三元组 i, j, k 个数（0 \u0026lt;= i \u0026lt; j \u0026lt; k \u0026lt; n）。\n示例：\n输入: nums = [-2,0,1,3], target = 2 输出: 2 解释: 因为一共有两个三元组满足累加和小于 2: [-2,0,1] [-2,0,3] 直接上代码：\nfunc threeSumSmaller(nums []int, target int) int { result := 0 // 满足条件的三元组数目 sort.Ints(nums) // 先排序 var pin, left, right int // 固定、左、右 指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { pin = i // 固定指针 left = i + 1 // 左指针指向固定指针的下一个 right = l - 1 // 右指针指向最后一个元素 for left \u0026lt; right { if nums[pin]+nums[left]+nums[right] \u0026gt;= target { // 说明这个 right 不能出现在三元组中, right 左移一位 right-- } else { // 从 left 到 right 之间的那几对都符合条件， left 右移一位 result += right - left left++ } } } return result } 4. 进阶 2——最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1 输出：2 解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 代码如下：\nfunc threeSumClosest(nums []int, target int) int { result := math.MaxInt32 // 结果 sort.Ints(nums) // 先排序 var pin, left, right int // 固定指针 左指针 右指针 l := len(nums) // 数组长度 // 求绝对值 abs := func(a int) int { if a \u0026lt; 0 { return -1 * a } return a } // 更新 result updateFunc := func(sum int) { if abs(sum-target) \u0026lt; abs(result-target) { result = sum } } for i := 0; i \u0026lt; l-2; i++ { pin = i left = i + 1 right = l - 1 // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 如果 right 左移一位，结果离得更远了，说明需要left向右移 //result = min(result, nums[pin]+nums[left]+nums[right]) sum := nums[right] + nums[left] + nums[pin] if sum == target { return target } updateFunc(sum) if sum \u0026gt; target { // 此时需要向左移动 right，并且移动到下一个不相等的 tmp := right - 1 for left \u0026lt; tmp \u0026amp;\u0026amp; nums[tmp] == nums[right] { tmp-- } right = tmp } else { // 向右移动left tmp := left + 1 for tmp \u0026lt; right \u0026amp;\u0026amp; nums[tmp] == nums[left] { tmp++ } left = tmp } } } return result } 5. 总结 解决此类问题，一般都是 升序后，外层循环 + 内层双指针 思路。其中最关键的是 左右指针移动的条件，一般都是和 target 比大小，大于 target 就向左移动右指针，小于 target 就向右移动左指针。\n由此延伸到 四数之和 问题，解决思路与之类似，设置两个固定指针，即外层两个循环，剩下的处理逻辑与 三数之和 一样。\n看一下 四数之和：\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n注意：\n答案中不可以包含重复的四元组。\n示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin1, pin2, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-3; i++ { pin1 = i // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] { continue } for j := i + 1; j \u0026lt; l-2; j++ { pin2 = j left = j + 1 right = l - 1 // 不要重复 if j \u0026gt; i+1 \u0026amp;\u0026amp; nums[j] == nums[j-1] { continue } for left \u0026lt; right { // 相等 if nums[pin1]+nums[pin2]+nums[left]+nums[right] == target { result = append(result, []int{nums[pin1], nums[pin2], nums[left], nums[right]}) for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } for left \u0026lt; right \u0026amp;\u0026amp; nums[right-1] == nums[right] { right-- } left++ right-- } else if nums[pin1]+nums[pin2]+nums[left]+nums[right] \u0026gt; target { right-- } else { left++ } } } } return result } ","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003e三数之和\u003c/code\u003e 问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum/\"\u003e15. 三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-smaller/\"\u003e259. 较小的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-closest/\"\u003e16. 最接近的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-题目描述\"\u003e1. 题目描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给你一个包含 \u003ccode\u003en\u003c/code\u003e 个整数的数组 \u003ccode\u003enums\u003c/code\u003e，判断 \u003ccode\u003enums\u003c/code\u003e 中是否存在三个元素\u003ccode\u003ea，b，c\u003c/code\u003e ，使得 \u003ccode\u003ea + b + c = 0\u003c/code\u003e？请你找出所有满足条件\u003cstrong\u003e且不重复\u003c/strong\u003e的三元组。\u003c/p\u003e","title":"LeetCode-三数之和问题"},{"content":"leetcode 上 twoSum 相关的问题：\n1. 两数之和 167. 两数之和 II - 输入有序数组 170. 两数之和 III .数据结构设计 1. 问题描述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 2. 解决思路 一般情况下，使用的是暴力穷举法，但是这种情况下时间复杂度为 $O(n^2)$，爆炸，不考虑。\n这里采用 空间换时间 的思路：\n设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的 索引i和 map[target-j] 即为所需要的。\n下面通过代码实现：\nfunc twoSum(nums []int, target int) []int { result := make([]int,0) m := make(map[int],int) for i,j := range nums { if v, ok := m[target-j]; ok { result = append(result, v) result = append(result, i) } m[j] = i } return result } 3. 进阶 设计并实现一个 TwoSum 的类，使该类需要支持 add 和 find 的操作。\nadd 操作 - 对内部数据结构增加一个数。\nfind 操作 - 寻找内部数据结构中是否存在一对整数，使得两数之和与给定的数相等。\n示例 1:\nadd(1); add(3); add(5); find(4) -\u0026gt; true find(7) -\u0026gt; false 示例 2:\nadd(3); add(1); add(2); find(3) -\u0026gt; true find(6) -\u0026gt; false 实现如下：\ntype TwoSum struct { M map[int]int } /** Initialize your data structure here. */ func Constructor() TwoSum { return TwoSum{M: make(map[int]int)} } /** Add the number to an internal data structure.. */ func (this *TwoSum) Add(number int) { this.M[number]++ // 这里的map中，key保存number，value保存出现的次数 } /** Find if there exists any pair of numbers which sum is equal to the value. */ func (this *TwoSum) Find(value int) bool { for key := range this.M { other := value - key // 第一种情况，针对出现了两次的元素、value为其2倍的，比如 [3,3]，value为6 if other == key \u0026amp;\u0026amp; this.M[other] \u0026gt; 1 { return true } // 第二种情况，针对出现过一次的元素，比如 [2,6], value 为8 if other != key \u0026amp;\u0026amp; this.M[other] \u0026gt; 0 { return true } } return false } 4. 总结 对于题目 1 和题目 167： 设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的索引i和 map[target-j] 即为所需。\n对于题目 170： 设计数据结构时，map 的 key 为元素，value 为该元素出现的此时。查找时，考虑两种情况：一种是 [3,3]--\u0026gt;6 的情况，一种是 [2,5] --\u0026gt; 7 的情况。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003etwoSum\u003c/code\u003e 相关的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum/\"\u003e1. 两数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/\"\u003e167. 两数之和 II - 输入有序数组\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-iii-data-structure-design/\"\u003e170. 两数之和 III .数据结构设计\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-问题描述\"\u003e1. 问题描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\u003c/p\u003e","title":"LeetCode-两数之和问题"},{"content":"一、设计原理 哈希表(也就是我们说的map)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是O(1)，是典型的 以空间换时间 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：哈希函数 和 冲突解决方法。\n1. 哈希函数 可以将任意长度的数据 映射 到有限长度的域上。通俗解释：你可以把它抽象成一个黑盒(一个函数 f)，它的输入是任意数据 m，输出是另一段固定范围的数据 n，即f(m) = n，n 可以作为 m 的特征(指纹)。\n对任意两个输入m1和m2，如果他们的输出均不同，则称这个函数为 完美哈希函数。如果存在m1和m2，有 f(m1) = f(m2)，则称这个函数为 不均匀哈希函数，这个现象称为 哈希碰撞。\n完美哈希函数很难找到，比较实际的做法是 让哈希函数的结果尽可能地分布均匀，然后通过工程上的手段解决哈希碰撞的问题。但是哈希的结果一定要尽可能均匀，结果不均匀的哈希函数会造成更多的冲突并导致更差的读写性能。\n2. 解决哈希冲突的方法 在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多最终也会造成冲突。\n然而我们的哈希函数往往都是不完美的，输出的范围是有限的，所以一定会发生哈希碰撞，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。\n2.1 开放寻址法 这种方法的核心思想在于 线性探测，通常情况下，这种哈希表的底层数据结构就是数组。先计算index，判断数组的这个index处是否有值，如果没有，直接存入；否则从这个index向后遍历，直到找到一个为空的index。可以大致用下面的代码表示：\nfunc hash1(source string) int { arr := make([]string,10,10) index := hash(source) % len(arr) tmp := index for { if arr[index%len(arr)] == \u0026#34;\u0026#34; { return index }else { index++ } if index == tmp { return -1 // 没找到 } } } 查找的时候，还是先计算 index ，如果数组在该位置的数刚好是要找的，直接返回，否则需要向后逐步遍历比较。在某些情况下，当装载的元素太多时，哈希表的性能会急剧下降，最差的结果就是每次增加和查找，都需要遍历整个数组，此时整个哈希表完全失效。\n2.2 拉链法 与开放地址法相比，拉链法是哈希表中最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。\n拉链法使用链表作为底层数据结构，我们把这个链表称为桶。这种方法对哈希冲突的解决方法是：直接在相同哈希值的结点后面增加一个链表结点。查询的时候，先找到对应链表第一个结点，之后遍历链表寻找符合要求的那个。\n在一个性能比较好的哈希表中，每一个桶中都应该有 01 个元素，有时会有 23 个，很少会超过这个数量，计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：\n装载因子 := 元素数量/桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。\n二、用到的数据结构 我的 Go 版本：\ngo version go1.14.6 darwin/amd64 Go 语言中对哈希表的实现方案是：使用拉链法解决哈希冲突。同时使用了多个数据结构组合来标识哈希表。\n在源码中，表示map 的结构体是 hmap：\n// A header for a Go map. type hmap struct { count int // 当前哈希表中元素个数，调用len(m)时直接返回此值 flags uint8 // B uint8 // 当前哈希表持有的 buckets 数量的对数，即 buckets数量 = 2^B noverflow uint16 // overflow 的 buckets 的近似数(buckets\u0026lt;16时是准确的) hash0 uint32 // 哈希种子，在创建哈希表时确定的随机数，并在调用哈希函数的时候作为参数传入 buckets unsafe.Pointer // 指向 buckets 数组，大小为 2^B，如果元素个数为0则为nil oldbuckets unsafe.Pointer // 渐进式扩容时用于保存之前的 buckets，扩容的时候，buckets 长度会是 oldbuckets 的两倍 nevacuate uintptr // 指示扩容进度，表示即将迁移的旧桶编号 extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. 溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 目前已经使用的溢出桶的地址 oldoverflow *[]*bmap // 在扩容阶段存储旧桶用到的溢出桶的地址 nextOverflow *bmap // 指向下一个空闲溢出桶 } buckets 是一个指针，最终指向的是一个结构体：\n// A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 } bmap 结构体其实不止包含 tophash 字段，由于哈希表中可能存储不同类型的键值对并且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导，这些字段在运行时也都是通过计算内存地址的方式直接访问的，所以它的定义中就没有包含这些字段，实际上的 bmap 是这样的：\ntype bmap struct { topbits [8]uint8 // tophash数组 keys [8]keytype // key数组 values [8]valuetype // value数组 pad uintptr overflow uintptr // 当当前桶存满时，发现还有可用的溢出桶，就会用此指针链接一个溢出桶，溢出桶也是 bmap 结构 } 如上图所示，hmap的桶就是 bmap，每一个 bmap 最多能存储 8 个键值对，这些键值对之所以会落在同一个桶，是因为他们经过哈希计算之后，得到的哈希结果是 “一类的”。当单个桶中存储的数据过多而无法装满时，就会使用 extra.overflow 中的桶存储溢出的数据。上面两种桶在内存中是连续的，我们暂且称之为 常规桶 和 溢出桶。\n我们来看看 bmap 的内部组成：\n最开始是 8 个 tophash，每个 tophash 都是对应哈希值的高 8 位。需要注意的是，key 和 value 是各自放在一起的，这样的好处是为了padding 时节省空间。每一个桶被设计成最多只能存放 8 个键值对，如果有第 9 个键值对落入当前的桶，那就需要再构建一个桶(溢出桶)，然后用 overflow 指针连接起来。\n三、使用 1. 初始化 无论是通过字面量还是运行时，最终底层都会调用 makemap 方法：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // 计算哈希占用的内存是否溢出或者产出能分配的最大值 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } if h == nil { h = new(hmap) } // 获取随机的哈希种子 h.hash0 = fastrand() // 根据传入的hint计算需要的最少的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 创建用于保存桶的数组 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 需要注意的是 makeBucketArray 函数，这个函数会根据传入的 B 计算出的需要创建的桶的数量 在内存中分配一片连续的空间用于存储数据。当桶的数量小于 $2^4$ 时，由于数据较少，使用溢出桶的可能性比较低，这时会省略创建的过程以减少额外开销；当桶的数量多于 $2^4$ 时，就会额外创建 $2^{B-4}$ 个溢出桶。正常情况下，溢出桶和常规桶在内存中的存储空间是连续的，只不过被 hmap 的不同字段引用。\n另外注意makemap 的返回，是一个 *hmap ，指针类型，这个时候传给函数在函数中改变的就是原来的 map ，即 改变map类型的形参，是可以影响实参的。这一点和之前的 slice 不同，slice 返回的是一个 slice 结构体，虽底层共用数组，但是扩容后就与原来的数据脱钩了。\n举个例子，下面的代码：\nmap := make(map[string]string, 10) Go 源码中的负载因子是 6.5 ，在源码 /usr/local/go/src/runtime/map.go:70 可以找到：\n// Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 这里的map 的键值对个数是 10，根据 负载因子 = 键值对个数/桶个数，得到 需要的桶的个数为 2。此时不会创建更多的溢出桶。\n2. 写 源码中执行 写入 操作的是 mapassign 函数，该函数较长，我们分步来看(每一步我会在关键位置写上注释，也更容易理解过程)。\n首先，函数会根据传入的键计算哈希，确定所在的桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // a.调用key类型对应的哈希算法得到哈希 hash := t.hasher(key, uintptr(h.hash0)) // b.设置 写 标志位 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // c.根据 hash 计算位于哪个 bucket bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // d.如果 map 正在扩容，此操作确保此 bucket 已经从 hmap.oldbuckets 被搬运到 hmap.buckets growWork(t, h, bucket) } // e.取得 bucket 所在的内存地址 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) // f.计算此bucket中的tophash，方法是：取高8位 top := tophash(hash) // ... } 在 64 位机器上，步骤 a 计算得到的 hash 值共有 64 个 bit 位。之前提到过，hmap.B 表示桶的数量为 $2^{h.B}$。这里用得到的哈希值的最后 B 个 bit 位表示落在了哪个桶中，用哈希值的 高 8 位表示此 key 在 bucket 中的位置。\n还是以上面的map = make(map[string]int, 10)为例，计算可知 B=2，则应该用后 2 位用来选择桶，高 8 位用来表示 tophash。 某个 key 经过哈希之后得到的 hash=01100100 001011100001101110110010011011001000101111000111110010 01，后两位 01 代表 1 号桶。\n然后，会有两层循环，最外层循环 bucket 以及其链接的溢出桶(如果有的话)，内存逐个遍历所有的tophash： var inserti *uint8 // 目标元素在桶中的索引 var insertk unsafe.Pointer // 桶中键的相对地址 var elem unsafe.Pointer // 桶中值的相对地址 bucketloop: // 最外层是一个死循环，其实是当前 bucket 后面链接的溢出桶(overflow) for { // bucketCnt=8，因为一个bucket最多只能存储8个键值对 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 找到一个tophash不同的 if b.tophash[i] != top { // isEmpty判断当前tophash是否为正常tophash值而不是系统迁移标志 if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // 已经找到一个可以放置的位置了，为什么不直接break掉？是因为有可能K已经存在，需要找到对应位置然后更新掉 } // 如果余下位置都是空的，则不再需要往下找了 if b.tophash[i] == emptyRest { break bucketloop } continue } // tophash 相同后，还需要再比较实际的key是否相同 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // key已经在map中了，更新之 if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } // 外层循环接着遍历这个bucket后面链接的overflow ovf := b.overflow(t) if ovf == nil { break } b = ovf } 在上述代码中有出现isEmpty 以及 emptyRest 等标志位，这其实是 tophash 的状态值，在源码 /usr/local/go/src/runtime/map.go:92 中可以找到：\n// // Possible tophash values. We reserve a few possibilities for special marks. emptyRest = 0 // 这个 cell 是空的, 并且在当前bucket的更高的index 或者 overflow中，其他的都是空的 emptyOne = 1 // 这个 cell 是空的 evacuatedX = 2 // K-V 已经搬迁完毕，但是 key 在新的 bucket 的前半部分(扩容时会提到) evacuatedY = 3 // 同上，key 在新的 bucket 的后半部分 evacuatedEmpty = 4 // cell 是空的，并且已经被迁移到新的 bucket 上 minTopHash = 5 // 正常的 tophash 的最小值 由此也可知，正常的 tophash 是 大于 minTopHash 的。\n如果此时 (键值对数已经超过负载因子 或者 已经有太多的溢出桶) \u0026amp;\u0026amp; 当前没有处在扩容阶段，那么 开始扩容： // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } 具体的扩容过程后面再细说，这里暂不讨论。\n如果没有找到合适的 cell 来存放这个键值对(桶满了)，则 使用预先申请的保存在 hmap.extra.nextoverflow 指向的溢出桶 或者 创建新桶 来保存数据，之后将键值对插入到相应的位置： if inserti == nil { // all current buckets are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } // 将键值对移动到对应的空间 typedmemmove(t.key, insertk, key) *inserti = top h.count++ 而使用预分配的溢出桶还是申请新的桶，在 newoverflow 函数中：\nfunc (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap if h.extra != nil \u0026amp;\u0026amp; h.extra.nextOverflow != nil { // 如果有预分配的 bucket ovf = h.extra.nextOverflow if ovf.overflow(t) == nil { // 并且预分配的溢出桶还没有使用完，则使用这个溢出桶，并更新 h.extra.nextOverflow 指针 h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize))) } else { // 预分配的溢出桶已经用完了，则置空 h.extra.nextOverflow指针 ovf.setoverflow(t, nil) h.extra.nextOverflow = nil } } else { // 没有可用的溢出桶，则申请一个新桶 ovf = (*bmap)(newobject(t.bucket)) } // 更新h.noverflow(overflow的树木)，如果h.B \u0026lt; 16，则自增1，否则“看可能性”自增(没啥用，感兴趣可以自己研究一下) h.incrnoverflow() if t.bucket.ptrdata == 0 { h.createOverflow() *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) return ovf } 3. 读 我们再来说说 读 的过程。map 的读取有两种方式：带 comma 和 不带 comma 的。这两种方式，其实底层调用的分别是：\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer // v1 := m[key] func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) // v2, isExist := m[key] 这两个函数大同小异，我们只看 mapaccess1。我们还是采用分步的方式来从源码中探究细节：\n根据 key 计算得到 hash 值，同时确定在哪个 bucket 中寻找： // 这个函数永远不会返回 nil ，如果map是空的，则返回对应类型的 零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026amp;zeroVal[0]) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map read and map write\u0026#34;) } // 得到 hash 值 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // 本例中m=31 // 得到 bucket b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { // 正处在扩容阶段 // 如果不是等量扩容(后面会讲到) if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. // 非等量扩容，那就是渐进式扩容，在原来基础上增加了2倍，为了得到原来的，这里除以2 m \u0026gt;\u0026gt;= 1 // m=15 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 是否处于扩容阶段 if !evacuated(oldb) { b = oldb } } top := tophash(hash) 和前面 写 的过程类似，也是两个大循环，外层遍历 bucket 以及链接在后面的 溢出桶，内层遍历每个 bucket 中的 tophash，直至找到需要的 键值对： bucketloop: // 外层循环溢出桶 for ; b != nil; b = b.overflow(t) { // bucketCnt=8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { // 和当前index的tophash不相等，并且后面的cell都是空的，说明后面就没不要再去遍历了，直接退出循环，返回对应元素的零值 if b.tophash[i] == emptyRest { break bucketloop } continue } // 找到对应的 key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // tophash相同，还要判断完整的key是否相同 if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } // 根据偏移找到对应的value，直接返回 return e } } } // 没找到，返回对应类型的零值 return unsafe.Pointer(\u0026amp;zeroVal[0]) 另外，编译器还会根据 key 的类型，将具体的操作用更具体的函数替换，比如 string 对应的是 mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer，函数的参数直接就是具体的类型，这么做是因为提前知道了元素类型，而且由于 bmap 中 key 和 value 各自放在一起，内存布局非常清晰，这也是前面说的 “减少 padding 带来的浪费”的原因。\n4. 扩容 在前面介绍 写 过程时，我们跳过了有关扩容的内容，现在回过头来看一下：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } // ... } // 判断h是否正在扩容。 扩容结束之后，h.oldbuckets 会被置空 func (h *hmap) growing() bool { return h.oldbuckets != nil } // 判断map中的键值对数目与已有的buckets 是否超过负载因子 即 count/2^B 与 6.5的大小关系 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 是否有太多的bucket func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. if B \u0026gt; 15 { B = 15 } // 翻译一下这条语句： // 如果 B \u0026lt; 15， 即 bucket总数 \u0026lt; 2^15 时，overflow的bucket数目不超过 2^B // 如果 B \u0026gt;= 15，即 bucket总数 \u0026gt; 2^15 时，overflow的bucket数目不超过 2^15 // 即 noverflow \u0026gt;= 2^(min(B,15)) return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 从现实角度出发，会有以下两种情形：\n在没有溢出、且所有的桶都装满了的情况下，装载因子是 8，超过了 6.5，表明很多的 bucket 中都快装满了，读写效率都会降低，此时进行扩容是必要的； 当装载因子很小、但是 bucket 很多的时候，map 的读写效率也会很低。什么时候会出现 “键值对总数很小、但 bucket 很多”的情况呢？不停地插入、删除元素。当插入很多元素时，导致创建了更多的 bucket ，之后再删除，导致某个 bucket 中的键值对数量非常少。“这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。” 对于上述两种情况，Go 有着不同的策略：\n对于第一种情况，城中人多房少，直接将 B 加一，建更多的房子即可； 对第二种情况，新开辟一块同样大小的空间，然后将旧空间中的键值对全部搬运过去，然后重新组织。 扩容 最基础的一个操作是 将原有的键值对搬到新开辟的空间，如果键值对数量太多，将严重影响性能。因此对于情况一，Go 采取 渐进式扩容，并不会一次全部搬完，每次最多只搬迁 2 个 bucket；第二种情况，称之为 等量扩容 ，可以理解成“内存整理”。接下来我们通过源码来分析实际的过程：\n执行扩容的函数是 hashGrow ， hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数和 evacuate() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。\n我们来看看 hashGrow 函数：\nfunc hashGrow(t *maptype, h *hmap) { // If we\u0026#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026#34;grow\u0026#34; laterally. // 首先通过 是否超过负载因子 判断进行渐进式扩容还是等量扩容 bigger := uint8(1) // 默认等量扩容 if !overLoadFactor(h.count+1, h.B) { // 如果没有超过负载因子，则进行等量扩容 bigger = 0 h.flags |= sameSizeGrow } // 申请新的 bucket 空间，并将原来的 h.buckets 字段 转移到 h.oldbuckets oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) // 将以前原有的buckets的标志位也转移到新申请的buckets去 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 执行grow操作 (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 // h.nevacuate指示扩容进度，表示当前正在搬迁旧的第几个bucket h.noverflow = 0 // 将溢出桶个数置为零 // 将extra中的overflow扔到oldoverflow中去 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026#34;oldoverflow is not nil\u0026#34;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 第 17 行涉及到的 flag 如下：\n// flags iterator = 1 // 可能有迭代器使用 buckets oldIterator = 2 // 可能有迭代器使用 oldbuckets hashWriting = 4 // 有协程正在向 map 中写入 key sameSizeGrow = 8 // 等量扩容（对应第二种情况） 我们再来看看实际执行扩容的 growWork 和 evacuate：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 还没搬迁完成的话，再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) } } evacuate 函数非常长，我们还是逐步去深入：\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位到老的bucket b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() // 存放增长之前的bucket数，结果为 2^B if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. /* // evacDst表示搬迁的目的区域. type evacDst struct { b *bmap // 搬去的bucket i int // bucket中键值对的index k unsafe.Pointer // pointer to current key storage e unsafe.Pointer // pointer to current elem storage } */ // 这里设置两个目标桶，如果是等量扩容，则只会初始化其中一个； // xy 指向新空间的高低区间的起点 var xy [2]evacDst x := \u0026amp;xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 如果是翻倍扩容，则同时初始化，之后会将旧桶中的键值对“分流”到两个新的目标桶中 if !h.sameSizeGrow() { // Only calculate y pointers if we\u0026#39;re growing bigger. // Otherwise GC can see bad pointers. y := \u0026amp;xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell for i := 0; i \u0026lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 当前cell的tophash if isEmpty(top) { // 当前cell为空，即没有key，则标志其为 “搬迁过”，然后继续下一个 cell b.tophash[i] = evacuatedEmpty continue } // 正常情况下，tophash只能是 evacuatedEmpty 或者 正常的tophash(大于等于minTopHash) if top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // 计算如何分流(将这个键值对放到x中还是y中) // 计算方法与前面相同 hash := t.hasher(k2, uintptr(h.hash0)) // !t.key.equal(k2, k2)这种情况，只能是float的NaN了 // 没有协程正在使用map \u0026amp;\u0026amp; 不是float的NaN if h.flags\u0026amp;iterator != 0 \u0026amp;\u0026amp; !t.reflexivekey() \u0026amp;\u0026amp; !t.key.equal(k2, k2) { // 在这种情况下，我们使用 tophash 的低位来作为分流的标准 useY = top \u0026amp; 1 top = tophash(hash) } else { if hash\u0026amp;newbit != 0 { useY = 1 // 新的位置位于高区间 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\u0026#34;bad evacuatedN\u0026#34;) } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026amp;xy[useY] // 放到高位置还是低位置 // 是否要放到 overflow 中 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That\u0026#39;s ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.ptrdata != 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } // 最后会调用 advanceEvacuationMark 增加哈希的 nevacuate 计数器，在所有的旧桶都被分流后清空哈希的 oldbuckets 和 oldoverflow 字段 if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 简单总结一下分流规则：\n对于等量扩容，从旧的 bucket 到新的 bucket，数量不变，因此可以按照 bucket 一一对应，原来是 0 号，搬过去之后还是 0 号； 对于渐进式扩容，要重新计算 key 的 哈希，才能决定落在哪个 bucket 。原来只有 2^B 个bucket ，确定某个 key 位于哪个 bucket 需要使用最后B 位；现在 B 增加了 1，那就应该使用最后的 B+1 位，即向前看一位。比如原来的 B=3，key1和key2的哈希后四位分别是 0x0101 和 0x1101，因为二者的后三位相同，所以会落在同一个 bucket 中，现在进行渐进式扩容，需要多看一位，此时key1和key2的哈希后四位不相同，因为倒数第 4 位有 0 和 1 两种取值，这也就是我们源码中说的 X 和 Y，key1和key2也就会落入不同的 bucket 中——如果是 0，分配到X，如果是 1 ，分配到 Y。 还有一种情况是上面函数中第 64 行 !t.key.equal(k2, k2)，即相同的 key ，对它进行哈希计算，两次结果竟然不相同，这种情况来自于 math.NaN()，NaN 的意思是 Not a Number，在 Go 中是 float64 类型(打印出来直接显示 “NaN”)，当使用它作为某个 map 的 key 时，前后计算出来的哈希是不同的，这样的后果是，我们永远无法通过 GET 操作获取到这个键值对，即使用 map[math.NaN] 是取不到想要的结果的，只有在遍历整个 map 的时候才会出现。这种情况下，在决定分流到 X 还是 Y 中时，就只能 使用tophash的最低位来决定 这个策略了——如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。\n关于 NaN：In computing, NaN, standing for Not a Number, is a member of a numeric data type that can be interpreted as a value that is undefined or unrepresentable, especially in floating-point arithmetic.\n在计算机科学中，NaN 代表 Not a Number，是一个 能够被打印出来的 未定义或者不可预知的 数字类型。\n我们简单总结一下哈希表的扩容设计和原理，哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，整个扩容过程并不是原子的，而是通过 growWork增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流；除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 sameSizeGrow(等量扩容) 这一机制，在出现较多溢出桶时会对哈希进行『内存整理』减少对空间的占用。————Go 语言设计与实现 3.3 哈希表\n5. 删除 Go 语言中删除一个 map 中的 key，使用的是特定的关键字 delete(map, key)。在底层，实际调用的 /usr/local/go/src/runtime/map.go 中的 mapdelete。这个函数的执行过程和 写 过程类似，如果在删除期间当前操作的桶遇到了扩容，就会对该桶进行分流，分流之后找到同种的目标元素完成键值对的删除工作。\n6. 遍历 理论上map 的遍历比较简单——“遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。” 但实际情况是，当我们在遍历一个处在扩容阶段的 map 时，不仅要考虑到已经搬过去的位于 h.buckets 的，还要考虑还没有搬的位于 h.oldbuckets 中的。\n接下来我们还是通过源码的方式逐步探寻 map 遍历 的奥秘。\n与之相关的函数分别是 mapiterinit 和 mapiternext，前者会初始化一个迭代器，之后循环调用后者进行迭代。迭代器结构如下：\ntype hiter struct { key unsafe.Pointer // key的指针，必须放在第一位，nil表示迭代结束 elem unsafe.Pointer // value指针，必须放在第二位 t *maptype // map中key的类型 h *hmap // 指向map的指针 buckets unsafe.Pointer // 初始化时指向的 bucket bptr *bmap // 当前遍历到的 map overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // 起始迭代的 bucket 编号 offset uint8 // 遍历时的偏移量(可以理解成遍历开始的 cell 号) wrapped bool // 是否从头遍历 B uint8 // h.B i uint8 // 当前的 cell 编号 bucket uintptr // 当前的 bucket checkBucket uintptr // 因为扩容，需要检查的 bucket } mapiterinit 主要是对 hiter 的初始化，需要关注的是这几行：\nfunc mapiterinit(t *maptype, h *hmap, it *hiter) { // ... // decide where to start r := uintptr(fastrand()) // bucketCntBits=3 if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } // bucketMask 即 1\u0026lt;\u0026lt;h.B -1 it.startBucket = r \u0026amp; bucketMask(h.B) // bucketCnt=8 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // ... } r 是一个随机数，这里假设我们的 m = make(map[string]int)， h.B=2，即有 2^2=4 个桶，可以计算得到 bucketMask(h.B)=3，二进制表示为 0000 0011，将 r 与这个数相与，就能得到 0~3 的 bucket 序号；同样，第 12 行，7 的二进制表示为 0000 0111，将 r 右移两位之后，与 7 相与，可以得到 0~7 的一个 cell 序号。这就是 map 每次遍历的 key 都是无序的原因。\n之后，使用这个随机的 bucket ，在里面的随机的这个 cell 处开始遍历，取出其中的键值对，直到回到这个 bucket 。\n接下来我们看 mapiternext 的细节：\nfunc mapiternext(it *hiter) { h := it.h if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext)) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t bucket := it.bucket b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // 回到了最开始遍历的那个 bucket，说明遍历结束了，可以退出迭代了 it.key = nil it.elem = nil return } if h.growing() \u0026amp;\u0026amp; it.B == h.B { // 如果我们当前遍历的 bucket 对应的原来的老的 bucket 的状态位显示为 “未搬迁”，则不再遍历当前的 bucket 而去遍历老的 bucket oldbucket := bucket \u0026amp; it.h.oldbucketmask() b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) if !evacuated(b) { checkBucket = bucket } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // 当前 cell 是空的，继续下一个 cell if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() { // 正好遇上扩容但是扩容还没完成，如果我们当前遍历的 bucket 对应的老 bucket还没有进行迁移，那么需要去遍历未搬迁的老的 bucket，但是！并不是遍历对应的全部的老的 bucket，而是只遍历 分流后会落在当前 bucket 的那部分键值对 if t.reflexivekey() || t.key.equal(k, k) { // 对于老 bucket 中不会分流到这个 bucket 的键值对，直接跳过 hash := t.hasher(k, uintptr(h.hash0)) if hash\u0026amp;bucketMask(it.B) != checkBucket { continue } } else { // 处理 math.NaN 情况，还是一样，看最低位来决定是不是落在当前这个 bucket if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue } } } if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // 对于 math.NaN 情况，我们只能通过遍历找到，对它的增删改查都是不可能的(这也是比较幸运的一件事，最起码能访问到，否则那真就成了“幽灵”了——占用空间又无可奈何，而且还能同一个 key 无限制地添加) it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else { // 开始迭代的时候，已经完成了扩容。此时 math.NaN 已经被放置到了别的 bucket 中，这种情况下只需要处置已经被 更新、删除或者删除后重新插入的情况。需要注意的是那些在 equal() 函数中判断为真的但是实际上他们的 key 不相同的情况，比如 +0.0 vs -0.0 rk, re := mapaccessK(t, h, k) if rk == nil { continue // key 已经被删除 } it.key = rk it.elem = re } it.bucket = bucket if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b } it.i = i + 1 it.checkBucket = checkBucket return } b = b.overflow(t) i = 0 goto next } 在 码农桃花源 深度解密 Go 语言之 map 中 map 遍历 一节，作者举了一个非常通俗易懂的例子，非常推荐，建议去看一下加深理解。\n四、总结 这是我第一次非常深入地看源码，也领会到了一切疑难杂症都会在源码面前原形毕露。map 操作的核心，就在于如何在各种情况下定位到具体的 key，搞清楚了这一点，其他问题看源码会更清晰。\nGo 语言中，哈希表的实现采用的哈希查找表，使用拉链法解决哈希冲突。有空间换时间的思想体现(不同的 key 落到不同的 bucket，即定位bucket的过程)，也有 时间换空间 思想的体现(在一个 bucket 中，采用遍历的方式寻找 key 而不是再使用哈希)，同时渐进式扩容和等量扩容的思想也值得我们学习。\n","permalink":"http://localhost:1313/posts/golang-map%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一设计原理\"\u003e一、设计原理\u003c/h2\u003e\n\u003cp\u003e哈希表(也就是我们说的\u003ccode\u003emap\u003c/code\u003e)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是\u003ccode\u003eO(1)\u003c/code\u003e，是典型的 \u003cstrong\u003e以空间换时间\u003c/strong\u003e 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：\u003cstrong\u003e哈希函数\u003c/strong\u003e 和 \u003cstrong\u003e冲突解决方法\u003c/strong\u003e。\u003c/p\u003e","title":"Golang-map详解"},{"content":"一、概述 1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器 主要解决系统线程太重的问题：\n创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大； 系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。 goroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\ngoroutine 是用户态线程，其创建和切换等，都是在用户态完成而无需进入操作系统内核，其开销相比系统线程要小很多； goroutine 启动时默认栈大小只有 2k，可以根据实际情况进行自动伸缩。 2. Go scheduler Go 程序的执行由两部分组成：Go Program 和 runtime，即 用户代码 和 运行时。这里的 runtime 和 Java、Python 中的不一样，Java 的是虚拟机，而Go 的 runtime 和用户代码一起编译到一个可执行文件中。用户代码和 runtime 除了代码组织上有界限之外，运行的时候并没有明显的界限，用户代码中，一些常用的关键字(如 go, new 等)被编译成 runtime 包下的一些函数调用。用户程序进行的系统调用都会被 runtime 拦截，以此来帮助 runtime 进行调度方面以及垃圾回收其他方面的工作。\n一张关系图如下：\n为什么需要 scheduler 呢？runtime 维护所有的 goroutine，就是通过 scheduler 来进行调度。goroutine 和系统线程是独立的，但是 goroutine 需要依赖系统线程才能执行。\n可以用一句话概括 Go scheduler 的目标：\nFor scheduling goroutines onto kernel threads.\nGo scheduler 的核心思想是：\nreuser 系统线程，限制同时运行(不包括阻塞的)的线程数为 N，其中 N 为 CPU 的核心数； 线程使用私有的本地运行队列，并且为了更高地使用 CPU，某个线程可以从其他线程偷 goroutine 来帮助运行，也可以在 goroutine 阻塞的时候将其传递给其他线程。 3. M:N 模型 goroutine 建立在操作系统线程之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。M:N 是指 M 的 goroutine 运行在 N 的操作系统线程上，内核负责对这 N 的操作系统线程进行调度，而 Go runtime 则负责将这 M 个 goroutine 调度运用在这 N 个操作系统线程上。\n简单理解，对 goroutine 的调度，是指程序代码按照一定的算法，在适当的时候挑选出合适的 goroutine 然后放到真正的线程上去执行的过程。其实并没有一个调度器实体，它只是一段代码的抽象化表示，具体来说是 需要发生调度时由操作系统线程执行runtime.schedule方法进行的。\nGo runtime 负责 goroutine 的生老病死，从创建、切换、销毁都一手包办。runtime 在启动的时候，会创建 M 个操作系统线程(CPU 内核执行调度的基本单位)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行。在同一时刻，一个系统线程上只能执行一个 goroutine，当 goroutine 发生阻塞时，runtime 会将当前 goroutine 调走，让其他的 goroutine 继续执行。这样做的目的是尽量提升性能，尽量让所有的系统线程上面都有代码在执行。\n4. GPM 模型 我们观察调度过程的进化，从进程到线程再到协程，其实是一个不断共享、不断减少切换成本的过程。\n要理解调度，需要理解两个概念：运行和阻塞。这里提供两个角度：我们觉得自己就是线程或者协程，运行就是在低头不断做事，阻塞就是我们目前做的事需要等待别人，然后就一直等着，等其他人做完了，我们接着做，这里我们是站在线程或者协程的角度去看的；另一个角度是，我们站在 CPU 的角度看，我正在敲代码写需求(一个线程或者协程)，发现依赖别人的函数还没有提交，那就把敲代码这事放在一边，最小化 IDE 然后点开钉钉沟通下一个需求，等依赖的函数提交了，又打开 IDE 继续敲代码——在 Linux 中，线程对应的是一个叫做task_struct的结构体，从本质上来说，线程并不是一个实体，线程只是代表一个执行流和其状态。真正驱动流程的是 CPU，CPU 根据 PC 寄存器从程序中取指令和操作数，从 RAM 中取数据,，进行计算、 处理、 跳转、 驱动执行流往前。 CPU 并不关注处理的是线程还是协程,，只需要设置 PC 寄存器， 设置栈指针等(这些称为上下文),，那么 CPU 就可以运行这个线程或者协程了。\n所以，线程的运行，其实是被运行；线程的阻塞，其实是换出调度队列，不再去执行这个执行流。协程同理，协程也是一个类似于task_struct数据结构，其作用也是一个执行流或者状态，记录运行什么函数，运行到什么程度，也就是上下文。\nGo 在用户态实现调度，所以 Go 也需要有代表协程这种执行体的数据结构，也要有保存和恢复上下文的处理过程以及调度队列。\n在这些数据结果中，最主要的是一下几个(以下结构体均位于runtime包的runtime.go文件中)：\ng: 它保存了 goroutine 的所有信息，该结构体的每一个实例对象都代表了一个goroutine。调度器代码会通过 g 对象来对 goroutine 进行调度——当 goroutine 被调离系统线程时，调度器负责把 CPU 相关寄存器值等上下文信息保存在 g 对象的成员变量中；当 goroutine 被重新拉起运行时，调度器又负责把 g 对象成员变量中所保存的上下文信息恢复到相关寄存器，也就是恢复了执行上下文。 schedt：一方面保存调度器本身的状态信息，另一方面它拥有一个用来保存 goroutine 的运行队列。因为每个 Go 程序只有一个调度器，所以在每个 Go 程序中 schedt 结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的 goroutine 运行队列，我们称这个运行队列为全局运行队列(GRQ)。 p：表示执行所需要的资源，其最大数量同时也是 Go 代码的最大并行度。每一个运行着 go 代码的工作线程都会与一个 p 结构体的实例对象关联在一起。全局运行队列是每一个工作线程都可以读写的，因此为了并发安全，访问时需要加锁，但加锁势必耗费性能进而称为瓶颈。于是调度器为每一个工作线程引入了一个 私有的 goroutine 运行队列，我们称之为“局部队列(LRQ)”，工作线程优先使用局部队列的 goroutine，只有必要时才会去访问全局队列(后面还会了解到，当一个 p 的局部队列使用完时，还会去别的 p 偷几个 g 过来运行)，这大大减少了锁冲突，提高了工作线程的并发性。 m：代表实际工作线程，每一个工作线程都有唯一的m与之对应。m 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 p 结构体的实例对象之间的绑定关系。于是，通过 m 既可以找到与之对应的工作线程正在运行的 goroutine，又可以找到工作线程的局部运行队列等资源。 他们之间的关系，可以使用下图表示：\n另有一张图可能更清晰形象：\nGo scheduler 的职责就是将所有处于 可运行状态 的 goroutines 均匀分布到在 P 上运行的 M。\n当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。这被称为 Work-stealing，Go 从 1.1 开始实现。\nGo scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。\n实际上，Go scheduler 每一轮调度要做的工作就是找到处于 runnable 的 goroutines，并执行它。寻找的顺序如下：\nruntime.schedule() { // 检查全局队列，防止全局队列中的G被饿死 // if not found, 检查局部队列 // if not found, // 尝试从其他的P偷一些G过来 // if not found, 从全局队列中去一些 // if not found, poll network } 上述任何一步找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来一半的 G。\n这样做的好处是，有更多的 P 可以一起工作，加速执行完所有的 G。\n5. goroutine 的状态 如下图：\n6. Go scheduler 的调度时机 在以下四种情况下，scheduler 可能会发生调度——“可能”意味着，scheduler 只是有机会调度，但并不一定会发生。\n情形 说明 使用关键字 go 创建一个新的 goroutine，scheduler 会考虑调度 GC 肯定会发生调度，因为 GC 必须要在 M 上运行。 发生系统调用 当一个 goroutine 发生系统调用时，会阻塞 M，此时它会被调走，同时调用新的 goroutine 在 M 上运行 内存同步访问 atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 7. 同步/异步系统调用概览 当一个正在执行的 G(goroutine)需要进行系统调用时，根据调用类型，它所依附的 M 有两种情况：同步(系统调用等) 和 异步(网络请求等)。\n同步情况下，M1 会被阻塞，进而从 P 上调度下来，此时 G1 依然依附在 M1 上执行，之后会有一个新的 M2 被调用到 P 上，接着执行 P 的本地运行队列 LRQ 中的 G。一旦系统调用完成，G1 会再次加入 P 的 LRQ 等待被调度，而之前的 M1 则会被隐藏，等到需要的时候再次被使用。\n异步情况下，M1 不会被阻塞，G1 的异步请求会被另一个组件Network Poller接手，而 G1 本身也会被绑定到Network Poller上，等到系统调用结束，G1 会再次回到 P 上。由于 M 没有被阻塞，它可以继续执行当前被绑定的 P 的 LRQ 里面的 G。\n可以看到，在异步情况下，通过调度，Go scheduler 成功地将 IO 任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，极大地提高了效率。\n二、具体实现 有时间再细究。\n未完，待续…\n","permalink":"http://localhost:1313/posts/golang-gpm%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86/","summary":"\u003ch2 id=\"一概述\"\u003e一、概述\u003c/h2\u003e\n\u003ch3 id=\"1-为什么在内核的线程调度器之外go-还需要实现一个自己的调度器\"\u003e1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器\u003c/h3\u003e\n\u003cp\u003e主要解决\u003cstrong\u003e系统线程太重\u003c/strong\u003e的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大；\u003c/li\u003e\n\u003cli\u003e系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003egoroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\u003c/p\u003e","title":"Golang-GPM调度原理"},{"content":"1. Go语言指针的限制 go语言中也有指针，但相对C语言的指针来说，有了很多限制，但这也算是go的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\ngo中指针不能进行数学运算; func main() { num := 1 pNum := \u0026amp;num pNum++ // invalid operation: p++ (non-numeric type *int) } 不同类型的指针不能相互转换 func main() { var a int a = 10 var f *float32 f = \u0026amp;a // cannot use \u0026amp;a (type *int) as type *float32 in assignment } 不同类型的指针之间不能使用==或!=进行比较，也不能相互赋值 func main() { var a int var b float32 a = 1 b = 3.14 pa := \u0026amp;a pb := \u0026amp;b fmt.Println(pa == nil) fmt.Println(pa == pb) // invalid operation: pa == pb (mismatched types *int and *float32) pa = pb // cannot use pb (type *float32) as type *int in assignment } 只有在两个指针类型相同或者可以相互转换的情况下，才可以对两者进行比较。另外，指针可以通过 == 和 != 直接和 nil 作比较。\n2. unsafe包介绍 unsafe 包，“不安全”，为何不安全？是因为它可以使得用户绕过 go 的类型规范检查，能够对指针以及其指向的区域进行读写操作，即“允许程序无视 type 体系对任意类型内存进行读写”。因此使用时要格外小心。\nunsafe包中只有很简单的几个函数和定义:\npackage unsafe // 任意go表达式的类型。只是为了文档而声明的类型，实际上它并不是unsafe包的一部分 type ArbitraryType int // 任意类型代表的指针 type Pointer *ArbitraryType // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr // 返回x所在结构体的起始内存地址到x所对应属性两者距离，单位为byte，参数x的格式应该是structValue.field func Offsetof(x ArbitraryType) uintptr // 内存对齐时使用，这里暂时不研究 func Alignof(x ArbitraryType) uintptr 与此同时，unsafe包提供了两个很重要的功能：\n任何类型的指针 和 unsafe.Pointer 可以相互转换。 uintptr 类型和 unsafe.Pointer 可以相互转换。 即 任何数据类型的指针 \u0026lt;----\u0026gt; unsafe.Pointer \u0026lt;----\u0026gt; uintptr\n上述的功能有何用途？答： Pointer允许程序无视 type 体系对任意类型内存进行读写。\n如何理解这句话？因为unsafe.Pointer不能直接进行数学运算，但是我们可以将其转换成uintptr，对uintptr进行对应的数学运算(比如内存复制与内存偏移计算)，计算之后再转换成unsafe.Pointer类型。\n有了这个基础，我们可以干好多“见不得光”的事，比如 底层类型相同的数组之间的转换、使用 sync/atomic 包中的一些函数、访问并修改 Struct 的私有字段等场景。\n3. unsafe包的使用场景 场景一：访问并修改 struct 的私有属性 先从一个 demo 开始：\npackage main // unsafe修改struct私有属性 type user struct { name string age int company string } func main() { u := new(user) // A fmt.Println(*u) // { 0} uName := (*string)(unsafe.Pointer(u)) // B *uName = \u0026#34;Jemmy\u0026#34; fmt.Println(*u) // {Jemmy 0} uAge := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.age))) // C *uAge = 23 fmt.Println(*u) // {Jemmy 23} uCompany := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.company))) // D *uCompany = \u0026#34;吹牛逼技术有限公司\u0026#34; fmt.Println(*u) // {Jemmy 23 吹牛逼技术有限公司} } 在 A 处，我们新建一个user对象，使用new直接返回此类对象的指针。在这里要注意，在go中，对一个struct进行内存分配，实际上是分配的一块连续的空间，而new返回的指针，其实是struct中第一个元素的地址。\n通过上面的介绍我们知道，unsafe.Offsetof(x ArbitraryType) 返回 x 所在结构体的起始内存地址到 x 所对应属性两者距离，单位为 byte，参数 x 的格式应该是 structValue.field，那么unsafe.Offsetof(u.name)指的就是 u的起始地址，到属性name之间有多少个byte。\n在 C 处，因为unsafe.Pointer不能直接参与数学运算，所以我们先转换成uintptr类型，然后与unsafe.Offsetof(u.age)相加，就是u的属性age的地址，为uintptr类型，之后再转换为unsafe.Pointer，即可通过强制类型转换，直接去修改该属性的值。\n再来看 B 处，因为u的地址就是其第一个属性name的地址，可以直接获取到。其实我们可以改成和 C 处相似的结构：uName := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.name)))，效果一样。\n**注意!!!**上面 C 处的语句的加号两边的对象不能直接拆开去写，也就是说，不能写成:\ntmp := uintptr(unsafe.Pointer(u)) uAge := (*int)(unsafe.Pointer(tmp + unsafe.Offsetof(u.age))) 原因是，uintptr这个临时变量，本身就是一个很大的整数，而程序经过一些很大的计算之后，涉及到栈的扩容，扩容之后，原来的对象的内存位置发生了偏移，而 uintptr 所指的整数对应的地址也就发生了变化。这个时候再去使用，由于这个整数指的地址已经不是原来的地址了，会出现意想不到的 bug。\n场景二： 利用unsafe获取 slice 的长度 通过查看对应的源代码，我们知道slice header的结构体定义为：\ntype slice struct { array unsafe.Pointer // 元素指针 1字节 len int // 长度 1字节 cap int // 指针 1字节 } 当我们调用make函数创建一个新的slice后，底层调用的是makeslice，返回的是slice结构体:\nfunc makeslice(et *_type, len, cap int) slice 因此，我们可以通过unsafe.Pointer和uintptr进行转换，得到 slice 的字段值：\nfunc main() { s := make([]int, 10, 20) // slice结构体中，array类型为pointer，占1个字节8位，uintptr(unsafe.Pointer(\u0026amp;s))表示s的地址也是第一个属性array的地址，那么加上属性array的长度，就是下一个属性len的长度 var sLen = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(8))) fmt.Println(*sLen, len(s)) // 10 10 // 16的原因同上 var sCap = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(16))) fmt.Println(*sCap, cap(s)) // 20 20 } 场景三：实现string和[]byte 的零拷贝转换 一般的做法，都需要遍历字符串或 bytes 切片，再挨个赋值。\n在反射包src/reflect/value.go中，有下面的结构体定义：\ntype StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } 因此，只需共享底层的Data和Len即可：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } 4. unsafe.Sizeof(struct) 的本质 先看源码注释：\n// Sizeof takes an expression x of any type and returns the size in bytes // of a hypothetical variable v as if v was declared via var v = x. // The size does not include any memory possibly referenced by x. // For instance, if x is a slice, Sizeof returns the size of the slice // descriptor, not the size of the memory referenced by the slice. // The return value of Sizeof is a Go constant. // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr 这其中比较有意思的是 unsafe.Sizeof(a struct)的结果问题，即一个struct的 size 值为多少的问题。\n我们来观察一个有趣的事实：一个struct的 size 依赖于它内部的属性的排列顺序，即两个属性相同但排列顺序不同的struct的 size 值可能不同。\n比如，下面这个结构体 A 的 size 是 32：\ntype struct A{ a bool b string c bool } 而另一个和它有相同属性的结构体 B 的 size 是 24:\ntype struct B{ a bool c bool b string } 这都是 内存对齐在捣鬼。我们看一下 A 和 B 的内存位置：\n如上图所示，左边为struct A，右边为struct B。而Aligment可以使 1,2,4 或者 8。对 A 来说，a bool占一个 byte，而下一个属性是b string，占 16 个 byte(后面会说明为什么占 2 个字节)，因此无法进行内存对齐；而对 B 来说，a bool和c bool可以放在同一个 byte 中。\n在Golang中，各类型所占的 byte 如下\nbool,int8,uint8 \u0026ndash;\u0026gt; 1 byte int16,uint16 \u0026ndash;\u0026gt; 2 byte int32,uint32,float32 \u0026ndash;\u0026gt; 4 byte int,int64,uint64,float64,pointer \u0026ndash;\u0026gt; 8 byte string \u0026ndash;\u0026gt; 16 byte (两个字节) 任何 slice \u0026ndash;\u0026gt; 24 byte(3 个字节) 长度为 n 的 array \u0026ndash;\u0026gt; n*对应的 type 的长度 为什么string占到 2 个字节？因为 string 底层也是一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占 8 个字节；\n为什么任意类型的slice占到 3 个字节？同理，slice底层也是一个结构体，有三个域：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 1个字节 len int // 长度 8个byte 1个字节 cap int // 容量 8个byte 1个字节 } 说到这里，你也应该明白了，unsafe.Sizeof总是在编译期就进行求值，而不是在运行时，而且是根据类型来求值，而和具体的值无关。(这意味着，unsafe.Sizeof的返回值可以赋值给const即常量)\n可以通过下面的 demo 输出，判断你的掌握程度：\npackage main type user struct { name string // 2字节 age int // 1字节 company string // 2字节 } func main(){ fmt.Println(unsafe.Sizeof(user{})) // 输出40，5个字节，看 struct user 注释 fmt.Println(unsafe.Sizeof(10)) // 输出8，因为int占1字节 fmt.Println(unsafe.Sizeof([]bool{true, false})) // 输出24，任何slice都输出24 fmt.Println(unsafe.Sizeof([][]string{})) // 输出24，任何slice都输出24，即使是多维数组 } 5. 参考文献 码农桃花源—标准库\u0026ndash;unsafe sizeof-struct-in-go ","permalink":"http://localhost:1313/posts/golang-unsafe%E5%8C%85%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"1-go语言指针的限制\"\u003e1. \u003ccode\u003eGo\u003c/code\u003e语言指针的限制\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ego\u003c/code\u003e语言中也有指针，但相对\u003ccode\u003eC语言\u003c/code\u003e的指针来说，有了很多限制，但这也算是\u003ccode\u003ego\u003c/code\u003e的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\u003c/p\u003e","title":"Golang-unsafe包详解"},{"content":"在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\nGo 语言中数组、字符串和切片三者是密切相关的数据结构。这三种数据类型，在底层原始数据有着相同的内存结构，在上层，因为语法的限制而有着不同的行为表现。\n一、 数组(Array) 1. 概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存其中的元素，我们可以利用数组中元素的索引快速访问元素对应的存储地址。\n数组作为一种基本的数据类型，我们通常都会从两个维度描述数组：类型 和 大小(能够存储的最大元素个数)：\n// 源码位于 /usr/local/go/src/cmd/compile/internal/types/type.go // Array contains Type fields specific to array types. type Array struct { Elem *Type // element type 元素类型 Bound int64 // number of elements; \u0026lt;0 if unknown yet 最大元素个数，小于0表示未知 } // NewArray returns a new fixed-length array Type. func NewArray(elem *Type, bound int64) *Type { if bound \u0026lt; 0 { Fatalf(\u0026#34;NewArray: invalid bound %v\u0026#34;, bound) } t := New(TARRAY) t.Extra = \u0026amp;Array{Elem: elem, Bound: bound} t.SetNotInHeap(elem.NotInHeap()) return t } 从上述代码可以看出，类型Array包含两个属性，一个是数组类型Elem，另一个是数组大小Bound。另外需要注意的是：Go 语言中数组在初始化之后大小无法改变。\n2. 初始化 有两种初始化方式：\narray1 = [5]int{1, 2, 3, 4, 5} array2 = [...]int{1, 2, 3, 4, 5} 上述两种声明方式在运行期间得到的结果是完全相同的，后一种声明方式在编译期间就会被“转换”成为前一种，这也就是编译器对数组大小的推导。\n对第一种方式，那么变量的类型在编译进行到类型检查阶段就会被提取出来，随后会使用 NewArray函数创建包含数组大小的 Array 类型。\n对第二种方式，在第一步会创建一个Array{Elem: elem, Bound: -1}，即其大小会是-1，不过这里的-1只是一个占位符，编译器会在后面的 /usr/local/go/src/cmd/compile/internal/gc/typecheck.go 中对数组大小进行推导，并更新其 Bound 值：\n// The result of typecheckcomplit MUST be assigned back to n, e.g. // n.Left = typecheckcomplit(n.Left) func typecheckcomplit(n *Node) (res *Node) { ... // Need to handle [...]T arrays specially. if n.Right.Op == OTARRAY \u0026amp;\u0026amp; n.Right.Left != nil \u0026amp;\u0026amp; n.Right.Left.Op == ODDD { n.Right.Right = typecheck(n.Right.Right, ctxType) if n.Right.Right.Type == nil { n.Type = nil return n } elemType := n.Right.Right.Type // typecheckarraylit type-checks a sequence of slice/array literal elements. length := typecheckarraylit(elemType, -1, n.List.Slice(), \u0026#34;array literal\u0026#34;) n.Op = OARRAYLIT n.Type = types.NewArray(elemType, length) n.Right = nil return n } ... } 虽然在编译期这两种方式的实现方式不同，但在运行时这两中方式是完全等价的。事实上，[...]T 这种初始化方式也只是 Go 语言为我们提供的一种语法糖，当我们不想计算数组中的元素个数时可以偷个懒。\n另：变量初始化的位置：\n如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化；如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换之后代码才会继续进入 中间代码生成 和 机器码生成 两个阶段，最后生成可以执行的二进制文件。\n3. 赋值与访问 Go 语言中数组是值语义。一个数组变量即表示整个数组，它并不是隐式的指向第一个元素的指针（比如 C 语言的数组），而是一个完整的值。当一个数组变量被赋值或者被传递的时候，实际上会复制整个数组。如果数组较大的话，数组的赋值也会有较大的开销。为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。\nvar a = [...]int{1, 4, 3} // a 是一个数组 var b = \u0026amp;a // b 是指向数组的指针 fmt.Println(a[0], a[1]) // 打印数组的前2个元素 fmt.Println(b[0], b[1]) // 通过数组指针访问数组元素的方式和数组类似 for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v) } 我们可以用for循环来迭代数组。下面常见的几种方式都可以用来遍历数组：\nfmt.Println(\u0026#34;方式一：\u0026#34;) for i := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } fmt.Println(\u0026#34;方式二：\u0026#34;) for i, v := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, v) } fmt.Println(\u0026#34;方式三：\u0026#34;) for i := 0; i \u0026lt; len(a); i++ { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } // 输出 方式一： a[0]: 1 a[1]: 4 a[2]: 3 方式二： a[0]: 1 a[1]: 4 a[2]: 3 方式三： a[0]: 1 a[1]: 4 a[2]: 3 用for range方式迭代的性能可能会更好一些，因为这种迭代可以保证不会出现数组越界的情形，每轮迭代对数组元素的访问时可以省去对下标越界的判断。\n需要注意的是 长度为 0 的数组。长度为 0 的数组在内存中并不占用空间，有时候可以用于强调某种特有类型的操作时避免分配额外的内存空间，比如用于管道的同步操作：\nc1 := make(chan [0]int) go func() { fmt.Println(\u0026#34;c1\u0026#34;) c1 \u0026lt;- [0]int{} }() \u0026lt;-c1 在此场景下我们并不关心管道中的具体数据以及类型，我们需要的只是管道的接收和发送操作用于消息的同步，此时，空数组作为管道类型可以减少管道元素赋值时的开销。当然一般更倾向于用无类型的匿名结构体代替：\nc2 := make(chan struct{}) go func() { fmt.Println(\u0026#34;c2\u0026#34;) c2 \u0026lt;- struct{}{} // struct{}部分是类型, {}表示对应的结构体值 }() \u0026lt;-c2 注：本节参考自Go 语言高级编程 1.4\n二、切片(Slice) 切片和数组非常类似，可以用下标的方式访问，也会在访问越界时发生panic。但它比数组更加灵活，可以自动扩容。\n1. 内部实现 源代码位于： /usr/local/go/src/runtime/slice.go\ntype slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 长度(已经存放了多少个元素) cap int // 容量(底层数组的元素个数)，其中 cap\u0026gt;=len } 需要注意的是，底层的数组是可以被多个 slice 同时指向的，因此，对一个 slice 元素进行操作可能会影响其他指向对应数组的 slice。\n2. slice 的创建 方式 代码示例 说明 直接声明 var arr1 []int 其实是一个nil slice，array=nil,len=0,cap=0。此时没有开辟内存作为底层数组。 new arr2 := *new([]int) 也是一个nil slice，没有开辟内存作为底层数组。也没有设置元素容量的地方，此时只能通过append来添加元素，不能使用下标。 字面量 arr3 := []int{1,2,3} make arr4 := make([]int,2,5) 切片类型、长度、容量，其中容量可以不传，默认等于长度。 从切片或数组“截取” arr5 := arr4[1:2] 3. 关于 make 创建 slice Go 编译器会在编译期，根据以下两个条件来判断在哪个位置创建 slice：\n切片的大小和容量是否足够小 切片是否发生了逃逸 当要创建的切片非常小并且不会发生逃逸时，这部分操作会在编译期完成，并且创建在栈上或者静态存储区。如 n := make([]int,3,4) 会被直接转化成如下所示的代码：\nvar arr = [4]int n := arr[:3] 当发生逃逸或者比较大时，会在运行时调用 runtime.makeslice 函数在堆上初始化。而runtime.makeslice函数非常简单：\n// et是元素类型 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断len cap参数是否合法 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 在堆上申请一片连续的内存 return mallocgc(mem, et, true) } 这个函数的主要作用就是 计算当前切片所占用的内存空间并在堆上申请一段连续的内存，所需的内存空间采用以下的方式计算：\n内存空间 = 元素类型大小 * 切片容量cap 而元素类型的大小参照如下：\n类型 大小 bool, int8, uint8 1 bit int16, uint16 2 bit int32, uint32, float32 4 bit int, int64, uint64, float64, pointer 8 bit (1 个字节) string 16 bit (2 个字节) 长度为 n 的 array n * (对应的 type 的长度) TIPS：1 字节(Byte） = 8 位(bit)\nmallocgc 是专门用于内存申请的函数，后面会详细讲解。\n4. 切片截取 截取 是创建切片的一种方式，可以从数组或者切片直接截取，同时需要制定截取的起始位置。\n需要关注的是下面这种截取方式： arr1 = data[low : high : max]。这里的三个数字都是指原数组或切片的索引值，而非数量。\n这里的 low是最低索引值，是闭区间，也就是说第一个元素是位于data位于low索引处的元素；high是开区间，表示最后一个元素只能索引到 high - 1处；max也是开区间，表示容量为 max - 1。其中：len = high - low，cap = max - low，max \u0026gt;= high \u0026gt;= low。用下面的图来帮助说明：\n基于已有的数组或者切片创建新的切片，新 slice 和老 slice 会公用底层的数组，新老 slice 对底层数组的更改都会影响彼此。需要注意的是，如果某一方执行了append操作引起了 扩容 ，移动到了新位置，两者就不会影响了。所以关键问题在于二者是否会共用底层数组。\n我们通过一个例子来说明，该例子来自于雨痕 Go 学习笔记 P43，做了一些改造：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 55) s2 = append(s2, 77) s1[2] = 66 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } // 输出 [7 6 66] [5 4 3 2 100 200] [9 8 7 6 66 4 3 2 100 0] 让我们一步步来分析：\n首先，创建 slice、s1 和 s2：\nslice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] // len为3，cap默认到底层数组的结尾 s2 := s1[2:6:7] // len为4，cap为5 // 以上三个底层数组相同 之后，向 s2 尾部追加一个元素：\ns2 = append(s2, 55) s2的容量刚好还剩一个，直接追加，不会扩容。因为这三者此时还都共用同一个底层数组，所以这一改动，slice和s1都会受到影响：\n再次向 s2 追加一个元素：\ns2 = append(s2, 77) 此时，s2 的容量不够用，需要扩容。简单来说，扩容是新申请一块更大(具体多大，后面会说到，假设为原来的 2 倍)的内存块，将原来的数据 copy 过去，s2 的array指针指向新申请的那块内存。再次 append 之后：\n最后，修改 s1 索引为 2 处的元素：\ns1[2] = 66 此时 s2 已经使用了新开辟的内存空间，不再指向slice和s1指向的那个数组，因此 s2 不会受影响：\n后面打印 s1 的时候，只会打印出 s1 长度以内的元素。所以，只会打印出 3 个元素，虽然它的底层数组不止 3 个元素。\n5. append 扩容规则 之前说过，扩容是新申请一块更大的内存块，将原来的数据 copy 过去，原来切片的array指针指向新申请的那块内存。这里我们探讨这个“更大”到底是多大：\n第一步，预估扩容后的容量 newCap：\ndata = []int{1,2} data = appand(data,3,4,5) 扩容前的容量 oldCap = 2，新增 3 个元素，理论上应该扩容到 cap=5，之后会进行预估，求得 newCap 规则如下：\n如果 $oldCap * 2 \u0026lt; cap$，那么 newCap = cap；\n否则\n如果 扩容前元素个数oldLen \u0026lt; 1024​ ，那么直接翻倍，即 newCap = oldCap * 2； 否则(即 扩容前元素个数oldLen \u0026gt;= 1024 )，就先扩容 四分之一，也就是 1.25 倍，即 newCap = oldCap * 1.25。 即：\n这段规则的源码位于 /usr/local/go/src/runtime/slice.go：\nfunc growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { if old.len \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } ... } 上述例子中，oldCap=2，至少需要扩容到cap=5，根据预估规则，因为 oldCap*2=4 \u0026lt; 5，因此 newCap=cap=5，即预估结果为newCap=5。\n第二步，确定实际分配的内存，匹配到合适的内存规格\n理论上所需要内存 = 预估容量 * 元素类型大小，难道直接就会分配这么多的内存吗？并不是。\n首先元素类型大小已在 “一.3”中说明过，此处 int 类型的大小是 8bit(1 个字节)。接着看growslice函数：\nfunc growslice(et *_type, old slice, cap int) slice { ... var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) .... } 在这里，sys.PtrSize = 8，et类型是 int，所以 et.size == sys.PtrSize为 true，则 newcap * sys.PtrSize = 5 * 8 = 40。我们看看 roundupsize这个函数，位于 /usr/local/go/src/runtime/msize.go：\n// Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { // ... } } ... } 其中，_MaxSmallSize = 32768，smallSizeMax = 1024，smallSizeDiv = 8，而传进来的 size = 40。而：\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31} 所以上面roundupsize会返回：\nclass_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] = 48 在growslice中，capmem = 48，则最后计算得到的 newcap = int(capmem / sys.PtrSize) = int(48 / 8) = 6，即最终扩容后的容量为 6。而不是之前预估的 5。\n总结一下，首先使用预估规则预估一下需要的容量(本例中为 5)，然后用这个容量乘以 slice 元素的大小(单位是 bit，本例中 int 为 8)，之后根据在 class_to_size 中选择合适大小的值，比如 40，那应该选择比 40 大的更小的那个 48，这就是申请到的真正的容量内存，最后用真正的容量大小除以元素大小，即可得到真正的扩容后的 slice 的cap。\n6. slice 作为函数参数 函数调用处的参数称为 实参，函数定义处的参数称为 形参。形参是实参的拷贝，会生成一个新的切片，但二者指向底层数组的指针相同。\n当函数中没有出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,66,3,4,5,6] } func t1(s []int) { s[1] = 66 } 当函数中出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,2,3,4,5,6] } func t2(s []int) { s = append(s, 66) } 扩容后，指向的底层数组不同，互不影响。\n三、字符串(String) 字符串是 Go 语言中最常用的基础数据类型之一，虽然字符串往往被看做一个整体，但是实际上字符串是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组。\n在设计上，Go 语言中的string是一个只读的字节数组。当然，只读只意味着字符串会分配到只读的内存空间并且这块内存不会被修改，在运行时我们其实还是可以将这段内存拷贝到堆或者栈上，将变量的类型转换成 []byte 之后就可以进行，修改后通过类型转换就可以变回 string，Go 语言只是不支持直接修改 string 类型变量的内存空间。\nstring的底层结构如下：\n// /usr/local/go/src/runtime/string.go type stringStruct struct { str unsafe.Pointer len int } 可以看到和上面的切片结构非常相似，只是少了表示容量的cap。这是因为，字符串作为只读类型，我们并不会对齐进行扩容操作进而改变其自身的内存空间，所有在字符串上执行的写入操作都是通过拷贝实现的。\n关于字符串，讨论最多的是 string和[]byte互相转换的性能问题，在底层是通过 stringtoslicebyte 和 slicebytetostring两个函数实现的，其中出现了内存分配的情况，这里不做细究。\n在说unsafe 那篇文章里，提到了 实现string和[]byte 的零拷贝转换：这里再复习一下：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } ","permalink":"http://localhost:1313/posts/golang-%E6%95%B0%E7%BB%84-%E5%88%87%E7%89%87%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003cp\u003e在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\u003c/p\u003e","title":"Golang-数组,切片和字符串"},{"content":"一、 前言 我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\n最上面为高地址，最下面为低地址，分配时由高地址向低地址增长。函数的地址由低地址向高地址方向存放。\n从高地址到低地址依次为 栈空间、堆空间、全局静态变量区(数据区)、代码区。\n二、函数栈帧 函数执行时需要由足够的内存空间，用于存放 局部变量、返回值、参数等，这段空间对应内存中的栈。栈最上面是高地址，向下增长。\n分配给函数的栈空间，称为 函数栈帧(function stack frame)，栈底称为 栈基(bp)，栈顶称为 栈指针(sp)。函数调用结束后又会释放这个栈帧。bp 和 sp 始终指向正在执行的函数的栈帧。如果出现 A 调用 B，B 调用 C，C 调用 D，那么会出现由上到下分别为A的栈帧-\u0026gt;B的栈帧-\u0026gt;C的栈帧-\u0026gt;D的栈帧的情况:\n计算机执行函数时，会有专门的寄存器存放栈基 bp、栈指针 sp 和下一条要执行的指令 ip。\n所有的函数的栈帧布局都遵循统一的约定，所以被调用者是通过栈指针加上偏移量来定位到每个参数和返回值的。\nGo 在分配栈帧时是 一次性分配(主要是为了防止栈访问越界) ：(首先函数栈帧的空间在编译时期是可以确定的)确定栈基 bp，然后直接将栈指针 sp 移到所需最大栈空间的位置。之后通过栈指针 sp+偏移值这种相对寻址方式来使用函数栈帧。(例如需要将 3 和 4 依次入栈，则对应的指令分别是 sp+16 处存放 3，sp+8 处存放 4)\n由于函数栈帧的大小，可以在编译时期确定，对于栈消耗较大的函数，Go 编译器会在函数头部加上检测代码，如果发现需要进行栈增长，就会另外分配一块足够大的栈空间，并把原来栈上的数据拷过来，同时释放掉原来的栈空间。\n三、函数调用过程 有两个指令：call 和 ret。函数 call 指令实现跳转，而每个函数开始时都会分配栈帧，结束前又会释放自己的栈帧，ret 指令又会把栈恢复到之前的样子。\ncall的过程：\n将下一条指令的地址入栈，这就是返回地址，被调用函数执行结束后会回到这里； 跳转到被调用函数的入口处执行，这后面就是被调用函数的栈帧了。 ret过程：\n弹出返回地址； 跳转到这个返回地址 Go 与 C 语言不同的是，C 是通过寄存器和栈传递参数和返回值的，而 Go 是通过栈。下面通过举例说明 Go 中一个栈帧的结构以及函数调用过程中栈帧的变化：\n设有函数 A 和 B，在 A 内部调用了 B：\nfunc A() { x,y := 2,3 z := B(x,y) fmt.Println(x,y,z) } func B(m, n int) k int { return m + n } 首先需要了解的是，**被调用者的参数和返回值，都在调用者的函数栈帧中。**它们在栈中的顺序由上到下依次是：\nA 的局部变量 被调用函数 B 的返回值 传递给被调用函数 B 的参数(注意，参数顺序与实际书写书序相反) B 调用结束后的返回地址(A 中调用 B 之后要执行的命令，即 fmt.Println(x, y, z)) 调用者 A 的 bp 结构如下：\n而具体执行上述代码第 3 行也就是函数调用的详细过程如下：\n执行 call 函数：\na. 将调用者的下一条指令(第 4 行代码)入栈，这就是返回地址，被调用函数执行结束后会回到这里；\nb. 跳转到被调用者处(修改 ip 寄存器的值) 在被调用函数开始处有三步：\na. 将 sp 向下移动到足够的空间处(如 sp-24 处)；\nb. 调用者栈基(当前 bp 的值)入栈(调用者栈)(如存放到 sp+16 处)； 此时 bp 的值是被调用者 B 的栈基 结果是：bp 和 sp 始终指向正在执行的函数的栈帧； 接下来执行被调用函数剩下的部分；\na. 被调用者结束调用时，在 ret 函数前面还有两步：\n​ 1). 恢复调用者的栈基 bp 地址——第 2 步中的第 2 步，将栈该处的值赋给寄存器 bp\n​ 2). 释放自己的栈帧空间——第 2 步中的第 1 步，分配时向下移动了 24，则释放时向上移动多少 结果是：此时 bp 和 sp 已经恢复到调用者的栈帧了 执行 ret 步骤：\na. 弹出 call 指令的返回地址(对应过程 1 中的第 1 步)\nb. 跳转到弹出的这个地址(修改 ip 寄存器) 结果是：“被调用者”调用完毕，执行的是调用者的下一个指令，即调用完成(执行完被调用者)后，继续执行调用者函数。 如果在 B 中出现了defer操作，那么应该先执行defer，还是先执行return呢，还是先执行ret过程呢？\n答案是：Go 中的 return 并不是真正的返回，真正的返回操作是ret操作，return的作用仅仅是给返回值赋值，之后再执行defer操作，最后才是ret过程(释放自己的栈帧)。\n四、传参与返回值 理论部分已经全部说完了，下面通过一些实战来加深理解：\n为何有时通过函数交换变量位置却不成功？ func swap(a, b int) { a,b = b,a } func main() { a,b := 1,2 swap(a, b) fmt.Println(a,b) // 输出 1 2 // 交换失败 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2, a=1(入栈顺序与调用顺序相反)(没有返回值，对应3.传递给被调用函数 B 的参数) 执行 “a,b = b,a”，交换的是第 7 行入栈的两个变量而不是第 6 行入栈的调用者的局部变量 执行 ret 过程，返回之后，栈中 A 的局部变量并没有被改变，所以还是 a=1, b=2 再看下面的函数：\nfunc swap(a, b *int) { *a, *b = *b, *a } func main() { a,b := 1,2 swap(\u0026amp;a, \u0026amp;b) fmt.Println(a,b) // 输出 2 1 // 交换成功 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2 的地址, a=1 的地址(对应3.传递给被调用函数 B 的参数) 执行 “*a,*b = *b,*a”，传递的是 A 中变量的地址，实际上进行的是 A 中的变量的 b 和 A 中的变量的 a 交换 执行 ret 过程，返回之后，栈中 A 的局部变量被改变 有返回值，匿名返回值 func incr1(a int) int { var b int defer func() { a++ b++ }() a++ b = a return b } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 1 } 过程如下：前面说过，return 的作用相当于给返回值赋值，之后再执行 defer 函数，之后才是 ret 过程\n第 15 行，栈中从上到下为 a=0, b=0 第 16 行，incr1 的返回值，默认 0 值 第 2 行，incr1 的局部变量 b=0 第 9 行，incr1 的参数 a=0，自增后变成 2 第 10 行，incr1 的局部变量 b=1 第 11 行，incr1 的返回值被改变为 1 之后执行 defer 函数，incr1 的局部变量 a=3，incr1 的局部变量 b=1(注意，这里改变的是 incr1 的局部变量，而不是返回值) 返回，返回值依旧是 1 有返回值，非匿名返回值(命名返回值) func incr2(a int) (b int) { defer func() { a++ b++ }() a++ return a } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 2 } 过程与上述类似，只不过返回值变成了 incr1 中的 b，在第 8 步时首先被赋值 1，之后再 defer 中又自增，变成 2，因此返回值变成了 2。\n","permalink":"http://localhost:1313/posts/golang-%E5%85%B3%E4%BA%8E%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/","summary":"\u003ch2 id=\"一-前言\"\u003e一、 前言\u003c/h2\u003e\n\u003cp\u003e我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\u003c/p\u003e","title":"Golang-关于函数调用"},{"content":"选择优化的数据类型 MySQL 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\n更小的通常更好\n一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 0 ~ 200 ，那么字段类型设置为 unsigned tinyint 更好。\n简单就好\n简单数据类型的操作通常需要更少的 CPU 周期。例如整形比字符串的操作代价更低，因为字符串还要考虑 字符集 和 排序规则 ，使得字符串的比较比整形更加复杂。这里有两个例子：存储日期时，应该使用 MySQL 的内建类型( date 、 time 、 datetime 、 timestamp 等)而不是使用字符串；存储 IP 地址时，应该使用整型而非字符串， MySQL 中有专门的处理函数：\nmysql\u0026gt; select INET_ATON(\u0026#34;172.16.11.102\u0026#34;); +----------------------------+ | INET_ATON(\u0026#34;172.16.11.102\u0026#34;) | +----------------------------+ | 2886732646 | +----------------------------+ mysql\u0026gt; select INET_NTOA(2886732646); +-----------------------+ | INET_NTOA(2886732646) | +-----------------------+ | 172.16.11.102 | +-----------------------+ 行属性尽量避免 NULL\n一般情况下，某一行的默认属性是 NULL 。书中(《高性能 MySQL》)建议，最好指定列为 NOT NULL ，除非真的需要存储 NULL 值。这只是一个建议——如果计划在列上建索引，应该尽量避免设计成 可为 NULL 的列。\n1. 数字 1.1 整型(Whole Number) 可使用类型如下：\n类型 位数 范围 TINYINT 8 位（1 字节） -128~127 SMALLINT 16 位（2 字节） -32768~32767 MEDIUMINT 24 位（3 字节） -8388608~8388607（830 万多） INT 32 位（4 字节） -2147483648~2147483647（21 亿多） BIGINT 64 位（8 字节） -9223372036854775808~922, 3372, 0368, 5477, 5807（900 亿亿，反正很大啦） 整型有可选的 unsigned ，表示 非负 ，这大致可使正数的上限提高一倍。\n有符号和无符号整数使用相同的存储空间，有相同的性能，可根据实际情况选择以适合自己业务。\nMySQL 可以为整数类型指定宽度，例如 INT(11)， 但绝大多数情况下没有意义：对于存储和计算来说，**INT(11)**和 **INT(20)**是相同的，宽度不会限制值的合法范围，只是规定了 MySQL 的一些交互工具用来显示字符的个数。\n1.2 实数类型(Real Number) 实数是指 带有小部分的数字。我们能接触到的有 FLOAT 、 DOUBLE 和 DECIMAL 。这三个可以进一步划分： FLOAT 、 DOUBLE 称为浮点型， DECIMAL 就是 DECIMAL 类型。\n我们知道，标准的浮点运算由于硬件原因（篇幅所限具体原因请自行寻找），进行的是近似运算，如 Python 3.8 中 $0.1 + 0.2 = 0.30000000000000004$， Golang go1.13.4 darwin/amd64 中 fmt.Println(fmt.Sprintf(\u0026quot;%0.20f\u0026quot;, 0.1+0.2)) 输出$0.29999999999999998890 $ ，而 FLOAT 和 DOUBLE 所属的 浮点型 进行的就是这种运算。\n而 DECIMAL 用于存储精确的小数。因为 CPU 不支持对 DECIMAL 的直接计算，因此 在 MySQL 5.0及以后的版本 中， MySQL 服务器自身实现了 DECIMAL 的高精度计算。因此我们可以说，后期版本中，MySQL 既支持精确类型，也支持不精确类型。 相对而言， CUP 直接支持原生浮点运算，所以浮点运算明显更快。\nMySQL 使用二进制的形式存储 DECIMAL 类型。使用方式为 DECIMAL(总位数，小数点后位数) ，其中总位数最大为 65，小数点后位数最大为 30；并且位数与字节大小的对应关系为 9位/4字节 ，即每 9 位占 4 个字节，同时小数点占用一个字节。比如 DECIMAL(20, 9)共占用 5 个字节——小数点左边占用 3 个字节，小数点一个字节，小数点右边共占一个字节。\n浮点类型在存储同样范围的值时，通常比 **DECIMAL**使用更少的空间。 FLOAT 使用 4 个字节存储， DOUBLE 占用 8 个字节。需要注意的是，我们能选择的只是类型，即表示的范围大小，和整形一样，在 MySQL 底层进行计算的时候，所有的实数进行计算时都会转换成 DOUBLE 类型。\n2. 字符串 2.1 VARCHAR(变长字符串) VARCHAR 用于存储可变长字符串，是最常见的字符串数据类型。它比定长类型(CHAR)更加节省空间，因为它仅使用必要的空间。\n变长字符串 VARCHAR 需要使用额外的 1 个或 2 个字节记录字符串的长度：如果列的最大长度\u0026lt;=255 字节，则使用 1 个字节表示，否则使用 2 个字节。\nVARCHAR 节省空间，这对性能提升也有帮助，但由于行长是变的，如果通过 UPDATE 操作使得行长变得比原来更长，那就需要做一些额外的工作。不同引擎有不同的处理结果。\n当 VARCHAR 过长时，InnerDB 会将其保存为 BLOB，同时使用专门的外部区域来保存大文件，行中只保存对应的地址。\n2.2 CHAR(定长字符串) 当使用 CHAR(n) 时，会一次性分配足够的空间，注意这里的 n 指的是字符数而不是字节数。当存储 CHAR 时，会自动去掉末尾的空格，而 VARCHAR 不会。\nCHAR 非常适合存储很短的字符串，或者长度都很接近的字符串，例如密码的 MD5 值，因为这是一个定长的值。对于非常短的列， CHAR 比 VARCHAR 在存储空间上更有效率。\n关于“末尾空格截断”，通过下面的例子说明：\n\u0026gt; mysql\u0026gt; CREATE TABLE t1 (cl CHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t1(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t1; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3\u0026#39; | \u0026gt; +--------------------+ \u0026gt; ``` \u0026gt; \u0026gt; 我们再看下VARCHAR： \u0026gt; \u0026gt; ``` mysq \u0026gt; mysql\u0026gt; CREATE TABLE t2 (cl VARCHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t2(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t2; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3 \u0026#39; | \u0026gt; +--------------------+ 区别主要在 string3 后面的空格是否被截断。\n2.3 BLOB 和 TEXT BLOB 和 TEXT 都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。\n它们属于不同的数据类型：字符类型有 TINYTEXT, SMQLLTEXT, TEXT, MEDIUMTEXT, LONGTEXT，对应的二进制类型有 TINYBLOB, SMQLLBLOB, BLOB, MEDIUMBLOB, LONGBLOB。其中 BLOB 是 SMALLBLOB 的同义词，TEXT 是 SMALLTEXT 的同义词。\n当 BLOB 和 TEXT 的值太大时，InnerDB 会使用专门的“外部存储区域”进行存储实际内容，而行内使用 1~4 个字节存储一个外部内容的指针。\nBLOB 和 TEXT 家族之间仅有的不同是：BLOB 存储的是二进制的数据，没有排序规则和字符集，而 TEXT 有字符集和排序规则。\nMySQL 对 BLOB 和 TEXT 进行排序时与其他类型是不同的：它只针对没个列的最前 max_sort_length 字节而不是对整个字符串进行排序。如果需要排序的字符更少，可以尝试减小 max_sort_length ，或者使用 ORDER BY SUSTRING(column,length) 。\nMySQL 不能将 BLOB 或者 TEXT 列全部长度的字符串作为索引！\n3. 枚举、集合和位 3.1 枚举(ENUM) 枚举可以将一些不重复的字符串放到一个预定义的集合中，使用时也只能插入这个预定义集合中的某一个。\nMySQL 在存储枚举值时非常紧凑，在内部保存时，会将每个值在列表中的位置保存为整数(从 1 开始编号)，并在表的.frm 文件中保存“数字-字符串”映射关系的“查找表”；数据保存在两个字节中，因此枚举中可以有 $2^{16} - 1 = 65535$个。\nmysql\u0026gt; CREATE TABLE t2(e ENUM(\u0026#39;fish\u0026#39;,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;)); mysql\u0026gt; INSERT INTO t2(e) VALUES(\u0026#39;fish\u0026#39;),(\u0026#39;dog\u0026#39;),(\u0026#39;apple\u0026#39;),(1); # 注意，这里也可以世界使用枚举值对应的位置，如1对应\u0026#39;apple\u0026#39; # 查询枚举值，默认字符串表示 mysql\u0026gt; SELECT * FROM t2; +-------+ | e | +-------+ | fish | | dog | | apple | | fish | +-------+ # 使用数字形式表示枚举值 mysql\u0026gt; SELECT e+0 FROM t2; +------+ | e+0 | +------+ | 1 | | 3 | | 2 | | 1 | +------+ 尽量不要使用数字作为 ENUM 枚举常量，这种双重性很容易导致混乱，例如 ENUM('1','2','3') 。\n**注意：枚举字段是按照内部存储的整数而不是字符串顺序进行排序的。**一种绕过这种限制的方式是 刚开始就按照字典顺序来定义枚举值，另一中方式是使用 FIELD(列名，'arg1','arg2',…) 函数：\nmysql\u0026gt; SELECT e FROM t2 ORDER BY FIELD(e,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;,\u0026#39;fish\u0026#39;); +-------+ | e | +-------+ | apple | | dog | | fish | | fish | +-------+ 3.2 集合(SET) 如果说 ENUM 是单选的话，那 SET 就是多选。适合存储预定义集合中的多个值。同 ENUM 一样，其底层依旧通过整形存储。\n设定 set 的格式：\n字段名称 SET(\u0026#34;选项1\u0026#34;,\u0026#34;选项2\u0026#34;,...,\u0026#39;选项n\u0026#39;) 如 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); 同样的， SET 的每个选项值也对应一个数字，依次是 1，2，4，8，16...， 最多有 64 个选项。\n使用的时候，可以使用 set 选项的字符串本身（多个选项用逗号分隔），也可以使用多个选项的数字之和（比如：1+2+4=7）。\n通过实例来说明：\n# 建表 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); # 插入一个选项，字符串格式 INSERT INTO t3(hobby) VALUES(\u0026#39;swim\u0026#39;); # 插入多个选项，字符串格式，通过英文逗号分隔 INSERT INTO t3(hobby) VALUES(\u0026#39;swim,movie\u0026#39;); # 插入一个选项，数字格式 INSERT INTO t3(hobby) VALUES(1); # 等同于\u0026#39;swim\u0026#39; INSERT INTO t3(hobby) VALUES(4); # 等同于\u0026#39;movie\u0026#39; # 插入多个选项，数字格式 INSERT INTO t3(hobby) VALUES(7); # 等同于\u0026#39;swim,music,movie\u0026#39;，因为\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;分别为“1,2,4,8”，7=1+2+4. # 显示全部 mysql\u0026gt; SELECT * FROM t3; +------------------+ | hobby | +------------------+ | swim | | swim,movie | | swim | | movie | | swim,music,movie | +------------------+ # 查找包含movie的行 mysql\u0026gt; SELECT * FROM t3 WHERE FIND_IN_SET(\u0026#39;movie\u0026#39;,hobby) \u0026gt; 0; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 寻找包含排号为4的成员的行 mysql\u0026gt; SELECT * FROM t3 WHERE hobby \u0026amp; 4; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 直接使用字符串匹配 mysql\u0026gt; SELECT * FROM t3 WHERE hobby = \u0026#39;swim,movie\u0026#39;; +------------+ | hobby | +------------+ | swim,movie | +------------+ 3.3 位(BIT) NySQL 把 BIT 当成字符串类型而不是数字类型来存储。但是它的存储结果根据上下文会出现不同：\nmysql\u0026gt; CREATE TABLE t4(a BIT(8)); mysql\u0026gt; INSERT INTO t4(a) VALUES(b\u0026#39;00111001\u0026#39;); mysql\u0026gt; SELECT a, a+0 ,BIN(a) FROM t4; # bin()表示整数类型对应的二进制 +------+------+--------+ | a | a+0 | BIN(a) | +------+------+--------+ | 9 | 57 | 111001 | +------+------+--------+ 默认显示数字代表的 ASCII 码字符。\n","permalink":"http://localhost:1313/posts/mysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96/","summary":"\u003ch2 id=\"选择优化的数据类型\"\u003e选择优化的数据类型\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMySQL\u003c/code\u003e 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e更小的通常更好\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 \u003ccode\u003e0 ~ 200\u003c/code\u003e ，那么字段类型设置为 \u003ccode\u003eunsigned tinyint\u003c/code\u003e 更好。\u003c/p\u003e","title":"MySQL数据类型与优化"},{"content":"Docker 一、前言 Docker 是一个开源的应用容器引擎，可以让开发者将他们的应用以及依赖打包到一个可移植的容器中，这个容器可以发布并运行在任何流行的 Linux 环境下。\n理解：Docker 是什么？Docker 是一个容器，这个容器是可以随便移动的，就像一个箱子；箱子里是什么东西呢？箱子里是开发者写好的应用以及这个应用运行时的环境，即箱子里面是一个可以独立运行的沙盒应用；这个箱子有什么特点呢？可以随便搬动，并且能在任何 Linux 系统上直接运行（现在主流的服务器应用大多数都部署在 Linux 系统中）。\nDocker 的构想是实现Build, Ship, Run Anywhere，即通过对应用的 封装(Packaging) 、 分发(Distribution) 、 部署(Deployment) 、 运行(Runtime) 的生命周期进行管理，达到应用组件级别的“一次封装，到处运行”。这里的应用组件，既可以是一个 web 应用、一个编译环境，也可以是拥有运行环境的 web 服务，也可以是一套数据库平台服务，甚至是一个操作系统或者集群。\n二、Docker 架构 Docker 使用客户端-服务端架构。服务端负责构建、运行应用和分发容器（这个过程我是这样理解的：从上图可以看到有几个不同的角色：Client、daemon、registry、image 和 container，其中 registry 代表的是仓库，用来存储 image，同时我们也可以把 registry 中的 image（镜像）pull 到本地，进行修改之后 commit 回去，形成新的 image 存放在 registry，同时我们可以基于某个 image，在其中创建新的容器，这个容器中就是我们的应用和环境），客户端负责提供用户界面；Docker 客户端和守护进程之间使用 RESTful API，通过 unix 套接字或者网络接口进行通信，当我们使用 docker run 这样的命令时，客户端会将这些命令发送给他们的守护进程，然后守护进程执行这些命令；守护进程监听 Docker 客户端的请求并且管理服务端已有的 Docker 对象，如镜像、容器、网络。\n1. Registry（注册表） Docker Registry 用来存储 Docker 镜像。Docker Hub 是任何人都可以使用的公共注册中心，Docker 配置为默认在 Docker Hub 上查找镜像。当然你也可以运行自己的私人 Registry。\n当我们使用 docker pull 或者 docker run 的时候，将会从配置的 Registry 中提取所需要的镜像；使用 docker push 时，当前的镜像也将被推送到配置的 Registry 中。\n2. Image（镜像） 镜像是只读的，是用于创建一个容器的指令模板。通常情况下，一个镜像是基于另一个镜像，再加上自己的一些自定义配置形成的。举个例子，我们可以基于 Ubuntu 系统，在其基础上安装 nginx 以及其他 webserver 服务，以及这个服务运行时的各种配置信息，这样就行成了一个新的镜像。\n常见的虚拟机镜像，通常是由提供者打包成镜像文件，安装者从网上下载或是其他方式获得，恢复到虚拟机中的文件系统里；而 Docker 的镜像必须通过 Docker 打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。这样虽然失去了灵活性，但固定的格式意味着可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，使得在不同的机器中传递和共享 Docker 变得非常方便，这也是 Docker 能够提升工作效率的一处体现。\n通俗地讲，可以将 Docker 镜像理解为包含应用程序以及运行环境的基础文件系统，在容器启动的过程中，它以只读的方式被用于创建容器的运行环境。\nDocker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。\n对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，足以保证全球唯一性，这种编码（64 长度的字符串）的形式在 Docker 很多地方都有体现。由于镜像每层都有唯一的编码，就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，允许在镜像之间共享镜像层。举一个例子，由 Docker 官方提供的两个镜像 ElasticSearch 镜像和 Jenkins 镜像都是在 OpenJDK 镜像之上修改而得，实际使用的时候，这两个镜像是可以共用 OpenJDK 镜像内部的镜像层的。这带来的一项好处就是让镜像可以共用存储空间，达到 1+1\u0026lt;2 的效果，为在同一台机器里存放众多镜像提供了可能。\n2.1 镜像的命名 镜像的命名由三部分组成：username、repository 和 tag，他们的组织规则入下：\nusername 指上传镜像的用户；repository 表示镜像内容，形成对镜像的表意描述。有的镜像没有 username，这表明此镜像是由 Docker 官方进行维护的。\nrepository 表示镜像内容，形成对镜像的表意描述，通常采用的是软件名，这样的原因是，通常情况下，我们只在一个容器中运行一个应用，这样的命名可以更加方便的帮助我们识别镜像中的内容。\ntag 表示镜像版本，是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化，使用 tag 可以很好的区分和标识这些变化。tag 一般以版本号来命名。\n2.3 Container（容器） **容器是镜像的可运行实例。**默认情况下，一个容器和另外的容器机器主机相隔离，但是这都是可配置的。\n三、 概念理解 先说结论：一个”容器“，实际上是由 Linux Namespace 、 Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。\n1. LXC(Linux Container) Docker 其实是容器化技术的具体实现之一，采用 Golang 语言开发。很多人认为 Docker 是一种更轻量级的虚拟机，但事实上不是这样的，Docker 和虚拟机有本质的区别。容器在本质上讲，就是运行在操作系统上的一个进程，只不过加入了对资源的隔离和限制。Docker 正是基于容器的这个设计思想，采用 Linux Container 技术实现的核心管理引擎。\n为什么要进行这种设计呢？在默认情况下，一个操作系统里所有运行的进程共享 CPU 和内存资源，如果设计不当，在最极端的情况下，如果某进程出现死循环可能会耗尽所有的系统资源，其他的进程也会受到影响，这在企业级产品的场景下是不可接受的。\n不过，对资源进行隔离并不是新的发明，Linux 系统本身就支持操作系统级层面的虚拟化技术，叫做 Linux Container，即 LXC 的全称，它的作用是在操作系统的层次上为进程提供虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的 cpu 和 memory 节点，分配特定比例的 cpu 时间、IO 时间，限制可以使用的内存大小（包括内存和是 swap 空间），提供 device 访问控制，提供独立的 namespace（网络、pid、ipc、mnt、uts）。\nLXC，一种“操作系统层虚拟化”技术，为“linux 内核”容器功能的一个“用户空间接口”。LXC(LinuxContainer)是来自于 Sourceforge 网站上的开源项目，LXC 给 Linux 用户提供了用户空间的工具集，用户可以通过 LXC 创建和管理容器，在容器中创建运行操作系统就可以有效的隔离多个操作系统，实现操作系统级的虚拟化。最初的 Docker 容器技术基于 LXC 进行构建，后来 Docker 在自己的内核中刨除了 LXC。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。\n从前面的介绍中我们可以了解到，LXC 能够创建容器用于 Linux 系统的虚拟化，而 LXC 作为用户层管理工具主要提供了管理容器的接口，对实现容器的机制进行了封装隐藏，下面将对 LXC 容器的实现机制进行分析。LXC 有三大特色： cgroup 、 namespace 和 unionFS 。\nnamespace 这是另一个维度的资源隔离技术，与我们平常 C++程序开发中的 namespace 可以相类比。\n如果 cgroup 设计出来是为了隔离上面所描述的物理资源，那么 namespace 则用来隔离 PID、IPC、NETWORK 等系统资源。每一个 namespace 中的资源对其他 namespace 都是透明的，互不干扰。在每一个 namespace 内部，每一个用户都拥有属于自己的 init 进程，pid = 1，对于该用户来说，仿佛他独占了一台物理的 Linux 虚拟机。但是事实上，这个 namespace 中的 pid，只是其父容器的一个子进程而已。\n通过下图来加深理解：\n父容器有两个子容器，父容器的命名空间里有两个进程，id 分别为 3 和 4, 映射到两个子命名空间后，分别成为其 init 进程，这样命名空间 A 和 B 的用户都认为自己独占整台服务器。对于每一个命名空间，从用户看起来，应该像一台单独的 Linux 计算机一样，有自己的 init 进程(PID 为 1)，其他进程的 PID 依次递增，A 和 B 空间都有 PID 为 1 的 init 进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。从图中我们可以看到，进程 3 在父命名空间里面 PID 为 3，但是在子命名空间内，他就是 1. 也就是说用户从子命名空间 A 内看进程 3 就像 init 进程一样，以为这个进程是自己的初始化进程，但是从整个 host 来看，他其实只是 3 号进程虚拟化出来的一个空间而已。\n【参考】 DOCKER 基础技术：LINUX NAMESPACE（上）\nDOCKER 基础技术：LINUX NAMESPACE（下）\ncgroup（control group） 前面，我们介绍了 Linux Namespace，但是Namespace 解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。也就是说，虽然你通过 Namespace 把我 Jail 到一个特定的环境中去了，但是我在其中的进程使用用 CPU、内存、磁盘等这些计算资源其实还是可以随心所欲的。所以，我们希望对进程进行资源利用上的限制或控制。这就是 Linux CGroup 出来了的原因。\ncgroup 用来限定一个进程的资源使用，由 Linux 内核支持，可以限制和隔离 Linux 进程组（process groups）所使用的资源，比如 CPU、内存、磁盘和网络 IO，是 LXC 技术的物理基础。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。\nPrioritization: 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。\nAccounting: 一些审计或一些统计，主要目的是为了计费。\nControl: 挂起进程，恢复执行进程。\n使 ​​​ 用 ​​​ cgroup，系 ​​​ 统 ​​​ 管 ​​​ 理 ​​​ 员 ​​​ 可 ​​​ 更 ​​​ 具 ​​​ 体 ​​​ 地 ​​​ 控 ​​​ 制 ​​​ 对 ​​​ 系 ​​​ 统 ​​​ 资 ​​​ 源 ​​​ 的 ​​​ 分 ​​​ 配 ​​​、优先顺序、拒绝、监控和管理。可以更好地根据任务和用户分配硬件资源，提高总体效率。\n在实践中，系统管理员一般会利用 CGroup 做下面这些事（有点像为某个虚拟机分配资源似的）：\n隔离一个进程集合（比如：nginx 的所有进程），并限制他们所消费的资源，比如绑定 CPU 的核。\n为这组进程 分配其足够使用的内存\n为这组进程分配相应的网络带宽和磁盘存储限制\n限制访问某些设备（通过设置设备的白名单）\n【参考】DOCKER 基础技术：LINUX CGROUP\nunionFS unionFS 的含义是，可以把文件系统上多个目录内容联合挂载到同一个目录下，而目录的物理位置是分开的。\n我们来看一个例子(例子来自耗子叔的文章，但是原文中的不完善，我在这里补充一下)：\n首先我们建立两个目录(fruits 和 vegetables)，并在这两个目录中新建一些文件：\n# 创建目录 \u0026gt;\u0026gt;\u0026gt; mkdir fruits \u0026gt;\u0026gt;\u0026gt; mkdir vegetables \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;apple in fruits\u0026#34; \u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in fruits\u0026#34; \u0026gt; ./fruits/tomato \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;carrots in vegetables\u0026#34; \u0026gt; ./vegetables/carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in vegetables\u0026#34; \u0026gt; ./vegetables/tomato # 查看当前目录结构 \u0026gt;\u0026gt;\u0026gt; tree . . ├── fruits │ ├── apple │ └── tomato └── vegetables ├── carrots └── tomato 然后使用 aufs 进行 mount，注意 fruits 和 vegetables 的顺序：\n# 创建mount目录 \u0026gt;\u0026gt;\u0026gt; mkdir mnt # 把水果目录和蔬菜目录union mount到 ./mnt目录中 \u0026gt;\u0026gt;\u0026gt; sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt # 看一下当前的结构 \u0026gt;\u0026gt;\u0026gt; tree ./mnt ./mnt ├── apple ├── carrots └── tomato # 看一下mnt中的内容 \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables \u0026gt;\u0026gt;\u0026gt; cat ./mnt/tomato tomato in fruits 我们发现，fruits 和 vegetables 中的文件被 merge 到了一起，并且同名的文件只出现一次，默认以第一个文件夹为准。\n下面我们看一下 merge 后的文件和源文件之间的映射关系。第一步，修改源文件，merge 后的文件是否会受影响？\n# 修改fruits的apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 1 after fruits.apple\u0026#34; \u0026gt;\u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple # 查看mnt中的apple \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits append 1 after fruits.apple # 修改vevegtbles中的carrots echo \u0026#34;append 2 after vegetables.carrots\u0026#34; \u0026gt;\u0026gt; ./vevegtbles/carrots \u0026gt;\u0026gt;\u0026gt; cat ./vevegtbles/carrots carrots in vegetables append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots 由此可以得到：修改源文件，merge 后的文件也会同步改变。\n我们继续往下走：修改 mnt 中的文件，源文件会受到什么影响？\n\u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 3 after mnt.apple\u0026#34; \u0026gt;\u0026gt; ./mnt/apple # 查看源文件 \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple append 3 after mnt.apple # 重点来了，修改mnt.carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 4 in mnt.carrots\u0026#34; \u0026gt;\u0026gt; ./mnt/carrots tree . . ├── fruits │ ├── apple │ ├── carrots | └── tomato └── vegetables ├── carrots └── tomato \u0026gt;\u0026gt;\u0026gt; cat ./fruits/carrots append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots append 4 in mnt.carrots 我们 merge 后的第一个目录没有的文件，竟然将该文件复制进了第一个文件，然后进行了修改！\ndocker 通过一个叫做 copy-on-write (CoW) 的策略来保证 base 镜像的安全性，以及更高的性能和空间利用率。\nCopy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.\n当容器需要读取文件的时候: 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的 docker 容器共享运行时相同的文件)。 当容器需要添加文件的时候: 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候: 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候: 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 那么，这种 UnionFS 有什么用？\n历史上，有一个叫 Knoppix 的 Linux 发行版，其主要用于 Linux 演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把 CD/DVD 上的 image 运行在一个可写的存储设备上（比如一个 U 盘上），其实，也就是把 CD/DVD 这个文件系统和 USB 这个可写的系统给联合 mount 起来，这样你对 CD/DVD 上的 image 做的任何改动都会在被应用在 U 盘上，于是乎，你可以对 CD/DVD 上的内容进行任意的修改，因为改动都在 U 盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的 template，和另一个你的 working directory 给 union 在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个 ad hoc snapshot。\nDocker 把 UnionFS 的想像力发挥到了容器的镜像。你是否还记得我在介绍 Linux Namespace 上篇中用 mount namespace 和 chroot 山寨了一镜像。现在当你看过了这个 UnionFS 的技术后，你是不是就明白了，你完全可以用 UnionFS 这样的技术做出分层的镜像来。\n这就是 Docker 容器镜像分层实现的技术基础。所以我们说，Docker 中新的镜像并不是从头开始制作的，而是从一些 base 镜像的基础上创建并加上自定义修改而形成的，这些自定义的设置不会影响原来的 base 镜像。和 git 中的 commit 很像。这种设计的优点就是资源共享。试想一下，一台宿主机上运行 100 个基于 debian base 镜像的容器，难道每个容器中都保存一份重复的 debian 的拷贝吗？这显然不合理。借助 Linux 的 unionFS，宿主机只需要在磁盘上保存一份 base 镜像，内存中也加载一份，就能被所有基于这个 base 镜像的容器所共享。(举一个后面会遇到的例子：当我们使用 docker pull ubuntu:latest 这个命令的时候，可以看到如下的输出信息，从这个过程我们可以看出，镜像文件一般由若干层组成，使用 docker pull 下载中会获取并输出镜像的各层信息，当不同的镜像包括相同的层时，本地仅存了层的其中一份，减小了存储空间。)\n\u0026gt;\u0026gt;\u0026gt; docker pull ubuntu:latest latest: Pulling from library/ubuntu 35c102085707: Pull complete 251f5509d51d: Pull complete 8e829fe70a46: Pull complete 6001e1789921: Pull complete Digest: sha256:66cd4dd8aaefc3f19afd407391cda0bc5a0ade546e9819a392d8a4bd5056314e Status: Downloaded newer image for ubuntu:latest \u0026gt;\u0026gt;\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 5 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB 可以看到最新的 ubuntu 镜像只有 64M，而 centos 也只有 202M，是不是觉得太小了？这是因为 docker 在运行的时候直接使用了 docker 宿主机器的 kernel。\nLinux 操作系统由内核空间和用户空间组成。\n内核空间是 kernel，用户空间是 rootfs, 不同 Linux 发行版的区别主要是 rootfs. 比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。\n所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。\n需要注意的是，base 镜像只是用户空间和发行版一致。kernel 使用的是 docker 宿主机器的 kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。\nAUFS 有所有 Union FS 的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被 mount 好的目录。AUFS 的 whiteout 的实现是通过在上层的可写的目录下建立对应的 whiteout 隐藏文件来实现的。也就是说，如果我们想要删除某个地分支的文件，只需要在高分支的可写目录下，建立一个 whiteout的名字是’.wh.\u0026lt;filename\u0026gt;’ ，那么对应的下层的 \u0026lt;filename\u0026gt; 就会被删除，即使不被删除，也会不可见。\n当用 docker run 启动某个容器的时候，实际上容器的顶部添加了一个新的可写层，这个可写层也叫容器层。容器启动后，它里面的所有对容器的修改包括文件的增删改都只会发生在最顶部的容器层，而对下面的只读镜像层没有影响。\n【参考】DOCKER 基础技术：AUFS\n四、 Docker 镜像 刚开始学习时，很多人会分不清 镜像(image) 和 容器(container) 的区别。这里引用 Stackverflow：What is the difference between a Docker image and a container?的解释：\nAn instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.\nthe image is the recipe, the container is the cake ; -) you can make as many cakes as you like with a given recipe.\n镜像可以理解为一种 构建时(build-in)结构 ，而容器可以理解为一种 运行时(run-time)结构 。我们通常使用 docker service create 和 docker container run 从某个镜像启动一个或者多个容器。一旦容器从镜像启动之后，二者就变成了互相依赖的关系，并且在镜像启动的容器全部停止之前，镜像是无法被删除的。\n1. 镜像命名 docker pull DNS名称/用户名/镜像名:tag名 上述命令可以简写成 docker pull 镜像名 ，表示从 Docker 官方仓库中，默认拉取 tag 为 latest 的镜像。\n2. 常用命令 docker image pull xxx: 下载镜像 docker image ls: 列出当前主机上的所有镜像(-a 列出所有 -p只列出id) docker image inspect xxx: 查看当前image的详情 docker image rm xxx: 删除某个镜像(docker image rm $(docker image ls -a) -f 删除本机上所有的镜像) docker container rm $(docker container ls -a | awk \u0026#39;$1 !=\u0026#34;CONTAINER\u0026#34; {print $1}\u0026#39;) -f：删除所有的container 四、 Dockerfile 在实际开发中，几乎都是采用 Dockerfile 来制作镜像，而很少会采用将容器整个提交的方式。Dockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件。在 Dockerfile 中，包含了构建一个镜像过程中需要执行的命令以及其他操作。常见的 Docker 命令如下：\nFROM 之前提到过，我们不会从 0 开始构建一个镜像，而是会选择一个已经存在的镜像作为 base。FROM 用于指定一个 base 镜像，之后的所有操作都是基于这个 base 镜像来执行的，Docker 会先获取这个给出的 base 镜像，然后在这个 base 镜像上进行后面的构建操作。FROM 支持三种格式：\nFROM \u0026lt;image\u0026gt; [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] [AS \u0026lt;name\u0026gt;] 一般使用第二种，当 tag 不写时，默认为 latest。除了选择现有的镜像之外，Docker 还存在一个特殊的镜像，叫 scratch，它表示一个空白的镜像。如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。\nRUN RUN 用来在构建 docker 镜像的过程中执行命令行命令。但是并不建议一条 shell 命令一个 RUN。为什么呢？之前说过，Dockerfile 中的每一条指令都会建立一层，RUN 也不例外。每一个 RUN 行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这条命令，执行结束后，commit 这一层的修改，构成新的镜像。如果有很多 RUN，会出现很多运行时不需要的东西，结果就是产生了非常臃肿、非常多层的镜像, 不仅增加了构建部署的时间，也很容易出错。正确的做法是将这些命令通过\u0026amp;\u0026amp;符号串起来，如果需要换行就是用“\\”来连接两行，简化为一层，并且及时删除下载的 tgz 文件等。因此，在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\nENV 用于设置环境变量。例如：\nENV VERSION=1.0 DEBUG=on \\ NAME=\u0026#34;Happy Feet\u0026#34; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。\nWORKDIR Dockerfile 中的 WORKDIR 指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。相当于设置根目录。当使用相对目录的情况下，采用上一个 WORKDIR 指定的目录作为基准，相当与 cd 命令，但不同的是指定了 WORKDIR 后，容器启动时执行的命令会在该目录下执行。\nCMD 与 ENTRYPOINT 之前了解到，Docker 不是虚拟机，容器就是进程。既然是进程，那么启动容器的时候，需要指定所运行的程序以及参数。CMD 就是用于默认的容器主进程的启动命令的。当然 Dockerfile 中也可以没有 CMD，在运行时指定也可以。\n另外需要注意的是，容器中运行一个服务没有前后台的概念。为什么呢？对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。举个例子，我们使用了\nCMD service nginx start 然后发现容器执行后就立即退出了，甚至在容器内去使用 systemctl 命令发现根本执行不了。原因是使用“service nginx start”，则是希望 upstart 以后以后台守护进程的形式启动 nginx 服务，但是“CMD service nginx start”会被理解成 CMD [ \u0026ldquo;sh\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;service nginx start\u0026rdquo;]，因此主进程实际上是 sh，那么当 service nginx start 命令结束以后，sh 也就消失了，sh 作为主进程退出了，自然就会使容器退出。正确做法是直接执行 nginx 可执行文件，并且要以前台的形式运行，如\nCMD nginx -g \u0026#39;daemon off;\u0026#39; ENTRYPOINT 的目的和 CMD 一样，都是指定容器启动程序以及参数。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为\n\u0026lt;ENTRYPOINT\u0026gt; \u0026#34;\u0026lt;CMD\u0026gt;\u0026#34; COPY 与 ADD COPY 指令将从构建上下文目录中 \u0026lt;源路径\u0026gt; 的文件/目录复制到新的一层的镜像内的 \u0026lt;目标路径\u0026gt; 位置。\u0026lt;源路径\u0026gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath. Match 规则，比如：\nCOPY package.json /usr/src/app/ \u0026lt;目标路径\u0026gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。\n在使用该指令的时候还可以加上 \u0026ndash;chown=: 选项来改变文件的所属用户及所属组。\nCOPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。使用 ADD 时，如果原路径是一个 url 或者压缩包，Docker 引擎会将这个 url 下载或者将压缩包解压之后再复制。看情况使用即可。\nEXPOSE 声明运行时容器提供服务的端口，这只是一个声明（即打算、推荐用这个端口），在运行是并不会因为这个声明而开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处：\n帮助镜像使用者理解这个镜像服务推荐使用的端口，以方便配置映射；\n在运行时使用端口映射，也就是 docker run -P 时( -P 表示随机映射)，会自动映射 EXPOSE 的端口。\n需要区分 docker run -P 和 docker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; ：\ndocker run -P 会随机映射宿主端口到 Dockerfile 中的 EXPOSE ，如： \u0026gt;\u0026gt;\u0026gt; cat Dockerfile FROM nginx:latest EXPOST 80 90 \u0026gt;\u0026gt;\u0026gt; docker build -t nginx-test . \u0026gt;\u0026gt;\u0026gt; docker run -d -P nginx-test \u0026gt;\u0026gt;\u0026gt; docker container ls # 输出 9e3f0b2d6569 nginx-test \u0026#34;/docker-entrypoint.…\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:32769-\u0026gt;80/tcp, 0.0.0.0:32768-\u0026gt;90/tcp compassionate_pascal 这其中会将本机的 32769 和 32768 暴露出来，同时映射到容器中的 80 和 90 。\ndocker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; 指定宿主机和容器的端口： \u0026gt;\u0026gt;\u0026gt; docker run -d -p 8080:80 nginx-test 此时访问宿主机的 curl 宿主机IP:8080 会映射到容器内的 80 端口。\nVOLUMN docker 提供一种机制，可以将宿主机上的某个目录与容器的某个目录(称为挂载点，或者卷)关联起来，容器挂载点下的内容就是宿主机对应目录下的内容，可以有以下效果：\n容器基于镜像创建，容器的文件系统包括镜像的只读层+可写层，容器进程所产生的的数据均保存在可写层上，一旦容器删除，上面的数据就没有了，除非手动备份下来。而 卷挂载 机制可以让我们把容器中的某个目录和宿主机关联，让容器中的数据持久保存在宿主机上，即使容器删除，产生的数据仍在。 当我们开发一个应用时，开发环境在本机，运行环境启动在一个 docker 容器中，当我们修改一处之后想看到效果，需要重启容器，这显然比较麻烦。此时可以设置容器与本机的某个目录同步，当我们修改主机上的内容是，不需要同步容器，对容器来说是自动生效的，比如一个 web 应用，修改 index.html 后，刷新之后马上就能看到效果。 多个容器运行一组关联服务，共享一些数据。 通过一个 nginx 实例加深理解：\n1. 指明宿主机的目录\n# 拉取nginx镜像 docker pull nginx:latest # 创建宿主机目录 mkdir -p /Users/hujiaming/Downloads/nginx_test/index # 自定义欢迎页内容 cat \u0026#34;\u0026lt;h1\u0026gt; Hello World \u0026lt;/h1\u0026gt;\u0026#34; \u0026gt;\u0026gt;\u0026gt; /Users/hujiaming/Downloads/nginx_test/index/index.html # 将宿主机端口8080映射到容器端口80，将宿主机目录 /Users/hujiaming/Downloads/nginx_test/index 映射到容器目录 /usr/share/nginx/html(这个目录中存放nginx默认的欢迎页index.html) docker run -d -p 8080:80 -v /Users/hujiaming/Downloads/nginx_test/index:/usr/share/nginx/html --name nginx nginx 此时访问 宿主机 IP:8080，会出现 Hello World 而不是 nginx 的默认欢迎页，当我们修改 nginx_test/index/index.html 内容时，刷新浏览器发现也会同步刷新。\n2. 未指定关联的主机目录\ndocker run -d -p 8080:80 -v /data --name nginx nginx 上述命令只设置了容器的挂载点，并没有指定关联的主机目录。这时候 docker 会自动绑定主机上的一个目录。可以通过 docker inspect \u0026lt;name\u0026gt; 查看:\n\u0026gt;\u0026gt;\u0026gt; docker run -d -it -v /data nginx # 查看得到Container ID为： a369cc1f6efa \u0026gt;\u0026gt;\u0026gt; docker inspect a369cc1f6efa # 输出 ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/data\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ], ... 上面 Mounts 下的每条信息记录了容器上一个挂载点的信息，\u0026ldquo;Destination\u0026rdquo; 值是容器的挂载点，\u0026ldquo;Source\u0026quot;值是对应的主机目录。可以看出这种方式对应的主机目录是自动创建的，其目的不是让在主机上修改，而是让多个容器共享。\n此外还可以使用 --volumn-from 参数指定和某个已经存在的容器共享挂载点。\n五、 实战 1. 在 Ubuntu19 中安装 docker # 旧版本中docker叫做 docker , docker.io , docker-engine，如果这些旧版本已经安装，先卸载掉他们 sudo apt-get remove docker docker-engine docker.io containerd runc # 添加依赖 sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 添加GPG curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 在 /etc/apt/sources.list中添加依赖 sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # 更新 sudo apt-get update # 安装docker服务 sudo apt-get install docker-ce 2. 启动和关闭容器 # 查看当前已有的image \u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 10 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB nginx latest 53f3fd8007f7 3 months ago 109MB centos 7 9f38484d220f 5 months ago 202MB jenkins latest cd14cecfdb3a 13 months ago 696MB # 启动(-it 告诉docker，开启容器的交互模式并将读者当前的shell连接到容器的终端；/bin/bash 是说用户在容器内部想运行bash这个进程) \u0026gt;\u0026gt;\u0026gt; docker run -it ubuntu:latest /bin/bash # 不关闭容器而退出容器 \u0026gt;\u0026gt;\u0026gt; 组合键 ctrl + PQ # 在宿主机器上查看运行的机器 \u0026gt;\u0026gt;\u0026gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a847b8ed22b4 ubuntu:latest \u0026#34;/bin/bash\u0026#34; 41 seconds ago Up 40 seconds dreamy_bardeen 6ccf082c4be6 centos:7 \u0026#34;/bin/bash\u0026#34; 4 hours ago Up 4 hours heuristic_tu # 连接到运行中的容器(记得将下面的dreamy_bardeen换成你自己的容器名称，在docker container ls结果最后一列) \u0026gt;\u0026gt;\u0026gt; docker container exec -it dreamy_bardeen bash # 停止容器 \u0026gt;\u0026gt;\u0026gt; docker container stop dreamy_bardeen # 杀死容器 \u0026gt;\u0026gt;\u0026gt; docker container rm dreamy_bardeen 3. 多阶段构建 编写如下 go 文件：\n# main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { engine := gin.Default() engine.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { name := c.Query(\u0026#34;name\u0026#34;) fmt.Println(\u0026#34;hello \u0026#34; + name) c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hello \u0026#34; + name}) }) engine.Run(\u0026#34;:8899\u0026#34;) } 使用 go mod :\ngo mod init demo_go go mod tidy 对于 Dockerfile 的编写，有三种方案：\n方案一：直接使用 golang 全镜像\nFROM golang:1.14-alpine EXPOSE 8899 WORKDIR /go/src/demo_go COPY . /go/src/demo_go RUN GOPROXY=https://goproxy.cn,direct go build -v -o main *.go ENTRYPOINT [ \u0026#34;./main\u0026#34; ] 方案二：使用两个 Dockerfile，第一个编译出可执行二进制，第二个直接将二进制复制进去执行\n# cat Dockerfile.build FROM golang:1.14-alpine WORKDIR /apps/demo_go COPY . . RUN go build -v -o app *.go # cat Dockerfile.copy FROM golang:1.14-alpine WORKDIR /root/ COPY app /root/app RUN chmod a+x /root/app EXPOSE 8899 ENTRYPOINT [\u0026#34;/root/app\u0026#34;] # 这二者通过一个build.sh文件组合在一起 # cat build.sh #!/bin/bash echo \u0026#34;start build demo_go:stage1\u0026#34; docker build -t demo_go:build . -f Dockerfile.build docker create --name extract demo_go:build docker cp extract:/apps/demo_go/app ./app docker rm -f extract echo \u0026#34;start build demo_go:stage2\u0026#34; docker build --no-cache -t demo_go:install . -f Dockerfile.copy rm -rf ./app 方案三：多阶段构建\n# 第一阶段，编译出可执行文件 FROM golang:1.14-alpine as builder WORKDIR /apps COPY . . RUN CGO_ENABLED=0 GOOS=linux GOPROXY=https://goproxy.cn,direct go build -v -a -o app *.go # 第二阶段，将第一阶段编译好的二进制复制进最后一个阶段的容器即可 FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /apps/app . EXPOSE 8899 CMD [\u0026#34;./app\u0026#34;] 分别使用不同的执行构建 image：\n# 第一种 docker build -t demo_go:source -f Dockerfile . # 第二种 bash build.sh # 第三种 docker build -t demo_go:multi -f Dockerfile.multi . 这三种方案有什么区别？我们看一下各自 image 的大小：\n\u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID SIZE demo_go copy ab80d3d110b6 401MB demo_go source 274bf686025c 474MB demo_go app 7e8207b60f07 394MB demo_go multi 62b316cc49bd 21.1MB 看出差距了？\n","permalink":"http://localhost:1313/posts/%E5%85%B3%E4%BA%8Edocker/","summary":"这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要","title":"关于docker"},{"content":"关于我 你好！我是 hujm2023，欢迎来到我的个人技术博客。\n关于本站 这里是我分享技术经验、学习心得和编程实践的地方。主要内容包括：\n技术栈 编程语言: Golang、Python、Java 数据库: MySQL、Redis 工具: Git、Docker、Kubernetes 系统: Linux 博客内容 算法与数据结构: LeetCode题解、经典算法实现 后端开发: Go语言深入解析、并发编程、性能优化 数据库技术: MySQL底层原理、Redis源码分析 系统架构: 分布式系统设计、微服务架构 开发工具: 效率工具使用技巧、最佳实践分享 技术理念 追求代码质量和工程实践 重视基础理论与实际应用的结合 持续学习，保持技术敏感度 乐于分享，共同进步 联系方式 如果你对文章内容有疑问，或者想要技术交流，欢迎通过以下方式联系我：\n邮箱: hujm.net@gmail.com GitHub: github.com/hujm2023 声明 本博客所有文章均为个人原创（除特别注明外），转载请注明出处。文章中的观点仅代表个人看法，如有错误欢迎指正。\n感谢你的访问，希望这些内容对你有所帮助！\n","permalink":"http://localhost:1313/about/","summary":"关于本站和作者","title":"关于"},{"content":" this is my first post\n","permalink":"http://localhost:1313/posts/hello/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003ethis is my first post\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"images/4.png\"\u003e\u003c/p\u003e","title":"Hello"},{"content":"前言 堆，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作 根节点（root node），根节点本身没有 父节点（parent node）。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\n优先级队列 是计算机科学中的一类抽象数据类型。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。优先队列往往用堆来实现。\nGolang实现一：根据原理简单实现 package minheap import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; ) /* * @CreateTime: 2021/7/6 21:57 * @Author: hujiaming * @Description: Golang实现最小堆 */ var ErrMinHeapEmpty = errors.New(\u0026#34;minHeap is empty\u0026#34;) const HeapHeadTag int64 = math.MinInt64 type MinHeap struct { elements []int64 } // NewMinHeap 创建一个最小堆实例 func NewMinHeap() *MinHeap { return \u0026amp;MinHeap{elements: []int64{HeapHeadTag}} } /* Add 将一个元素添加到最小堆中，并且添加后要使其满足最小堆的特性 首先将该元素插入到数组最后，然后对这最后一个元素进行 “上浮” 操作： 该元素与父元素进行大小比较，如果小于父元素，则和父元素交换位置，如此循环，直到 到达堆顶 或 子元素小于父元素。 */ func (mh *MinHeap) Add(v int64) { // 1. 先将元素插在数组最后面 mh.elements = append(mh.elements, v) // 2. 将最后一个元素上浮，使其符合最小堆的性质。其实是为 v 找位置 i := len(mh.elements) - 1 for ; mh.elements[i/2] \u0026gt; v; i /= 2 { mh.elements[i] = mh.elements[i/2] } mh.elements[i] = v } /* PopMin 弹出堆中最小的元素 对最小堆而言，移除元素，只能移除堆顶(最小值)的元素。 首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作： 将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。 */ func (mh *MinHeap) PopMin() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } res := mh.elements[1] last := mh.elements[len(mh.elements)-1] // idx 表示最后一个元素应该在的位置 var idx int for idx = 1; idx*2 \u0026lt; len(mh.elements); { // 找出子节点中较小的元素的 index minChildIdx := idx * 2 if minChildIdx \u0026lt; len(mh.elements)-1 \u0026amp;\u0026amp; mh.elements[minChildIdx+1] \u0026lt; mh.elements[minChildIdx] { minChildIdx++ } // 当前结点 大于 较小子节点，和这个较小子节点交换位置，继续循环 if last \u0026gt; mh.elements[minChildIdx] { mh.elements[idx] = mh.elements[minChildIdx] idx = minChildIdx continue } break } mh.elements[idx] = last mh.elements = mh.elements[:len(mh.elements)-1] return res, nil } // PeekHead 只返回堆顶元素(最小值)，不进行下沉操作 func (mh *MinHeap) PeekHead() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } return mh.elements[1], nil } // IsEmpty 最小堆是否是空的 func (mh *MinHeap) IsEmpty() bool { if len(mh.elements) == 0 || (len(mh.elements) == 1 \u0026amp;\u0026amp; mh.elements[0] == HeapHeadTag) { return true } return false } // Length 返回最小堆中的元素个数 func (mh *MinHeap) Length() int { return len(mh.elements) - 1 } // Print 打印代表最小堆的数组 func (mh *MinHeap) Print() { fmt.Println(mh.elements[1:]) } Test 如下：\nfunc TestMinHeap(t *testing.T) { mh := NewMinHeap() mh.Add(4) mh.Add(2) mh.Add(7) mh.Add(9) mh.Add(1) mh.Add(5) mh.Add(10) mh.Add(3) mh.Add(2) mh.Print() for !mh.IsEmpty() { fmt.Println(mh.PopMin()) } assert.Equal(t, mh.Length(), 0) } // 输出 /* [1 2 5 2 4 7 10 9 3] 1 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 3 \u0026lt;nil\u0026gt; 4 \u0026lt;nil\u0026gt; 5 \u0026lt;nil\u0026gt; 7 \u0026lt;nil\u0026gt; 9 \u0026lt;nil\u0026gt; 10 \u0026lt;nil\u0026gt; */ Golang 实现二：实现标准库 heap.Interface 接口 先看下标准库中的 Interface，位置在 container/heap/heap.go：\n// The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // An implementation of Interface can be sorted by the routines in this package. // The methods refer to elements of the underlying collection by integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the \u0026lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } 我们以此为基础，实现一个 优先级队列:\npackage priorityqueen type Item struct { value int64 // 实际值 priority int64 // 优先级 index int // 当前 item 在数组中的 index } // PriorityQueen 表示优先级队列 type PriorityQueen []*Item func (mh2 PriorityQueen) Len() int { return len(mh2) } func (mh2 PriorityQueen) Less(i, j int) bool { return mh2[i].priority \u0026lt; mh2[j].priority } func (mh2 PriorityQueen) Swap(i, j int) { mh2[i], mh2[j] = mh2[j], mh2[i] mh2[i].index = i mh2[j].index = j } // Push 将 x 添加到数组最后 func (mh2 *PriorityQueen) Push(x interface{}) { l := len(*mh2) c := cap(*mh2) if l+1 \u0026gt; c { cmh2 := make([]*Item, l, c/2) copy(*mh2, cmh2) *mh2 = cmh2 } *mh2 = (*mh2)[:l+1] item := (x).(*Item) item.index = l (*mh2)[l] = item } // Pop 返回数组最后一个元素 func (mh2 *PriorityQueen) Pop() interface{} { l := len(*mh2) c := cap(*mh2) if l \u0026lt; c/2 \u0026amp;\u0026amp; c \u0026gt; 25 { cmh2 := make([]*Item, l, c/2) copy(cmh2, *mh2) *mh2 = cmh2 } item := (*mh2)[l-1] item.index = -1 // for safety *mh2 = (*mh2)[:l-1] return item } // PopHead 弹出堆顶元素 func (mh2 *PriorityQueen) PopHead() *Item { if mh2.Len() == 0 { return nil } item := (*mh2)[0] heap.Remove(mh2, 0) return item } // PopWithPriority 弹出优先级小于 maxP 的堆顶元素，如果没有，返回 nil 和 当前堆顶和maxP的距离 func (mh2 *PriorityQueen) PopWithPriority(maxP int64) (*Item, int64) { if mh2.Len() == 0 { return nil, 0 } item := (*mh2)[0] if item.priority \u0026gt; maxP { return nil, item.priority - maxP } heap.Remove(mh2, 0) return item, 0 } // PeekHead 显示堆顶元素 func (mh2 *PriorityQueen) PeekHead() *Item { if mh2.Len() == 0 { return nil } heap.Init(mh2) item := (*mh2)[0] return item } 测试一下：\nfunc TestPriorityQueen(t *testing.T) { items := make([]*Item, 0) rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 10; i++ { v := rand.Int63n(100) items = append(items, \u0026amp;Item{ value: v, priority: v, index: i, }) } q := PriorityQueen(items) heap.Init(\u0026amp;q) fmt.Println(q.PeekHead()) maxP := int64(50) for _, i := range q { if i.priority \u0026lt; maxP { fmt.Println(fmt.Sprintf(\u0026#34;p: %d, v: %d\u0026#34;, i.priority, i.value)) } } fmt.Println(\u0026#34;====\u0026#34;) for i := 0; i \u0026lt; 10; i++ { item, _ := q.PopWithPriority(maxP) if item != nil { fmt.Println(item) } } fmt.Println(\u0026#34;====\u0026#34;) for { item := q.PopHead() if item == nil { break } fmt.Println(item) } } // 输出 /* \u0026amp;{5 5 0} p: 5, v: 5 p: 11, v: 11 p: 6, v: 6 p: 33, v: 33 ==== \u0026amp;{5 5 -1} \u0026amp;{6 6 -1} \u0026amp;{11 11 -1} \u0026amp;{33 33 -1} \u0026amp;{50 50 -1} ==== \u0026amp;{52 52 -1} \u0026amp;{73 73 -1} \u0026amp;{85 85 -1} \u0026amp;{97 97 -1} \u0026amp;{99 99 -1} */ Golang 标准库 heap.Interface 源码解析 整个包的实现非常简洁，加上注释以及空行，整个文件才只有120 行：\n// Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package heap provides heap operations for any type that implements // heap.Interface. A heap is a tree with the property that each node is the // minimum-valued node in its subtree. // // The minimum element in the tree is the root, at index 0. // // A heap is a common way to implement a priority queue. To build a priority // queue, implement the Heap interface with the (negative) priority as the // ordering for the Less method, so Push adds items while Pop removes the // highest-priority item from the queue. The Examples include such an // implementation; the file example_pq_test.go has the complete source. // package heap import \u0026#34;sort\u0026#34; // The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // Init establishes the heap invariants required by the other routines in this package. // Init is idempotent with respect to the heap invariants // and may be called whenever the heap invariants may have been invalidated. // The complexity is O(n) where n = h.Len(). func Init(h Interface) { // heapify n := h.Len() // (n/2 - 1) 处的结点是最后一棵子树(没有孩子结点)的根节点 for i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) } } // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 h.Swap(0, n) down(h, 0, n) return h.Pop() } // Remove removes and returns the element at index i from the heap. // The complexity is O(log n) where n = h.Len(). func Remove(h Interface, i int) interface{} { n := h.Len() - 1 if n != i { h.Swap(i, n) if !down(h, i, n) { up(h, i) } } return h.Pop() } // Fix re-establishes the heap ordering after the element at index i has changed its value. // Changing the value of the element at index i and then calling Fix is equivalent to, // but less expensive than, calling Remove(h, i) followed by a Push of the new value. // The complexity is O(log n) where n = h.Len(). func Fix(h Interface, i int) { if !down(h, i, h.Len()) { up(h, i) } } func up(h Interface, j int) { for { i := (j - 1) / 2 // parent if i == j || !h.Less(j, i) { break } h.Swap(i, j) j = i } } func down(h Interface, i0, n int) bool { i := i0 for { j1 := 2*i + 1 if j1 \u0026gt;= n || j1 \u0026lt; 0 { // j1 \u0026lt; 0 after int overflow break } j := j1 // left child if j2 := j1 + 1; j2 \u0026lt; n \u0026amp;\u0026amp; h.Less(j2, j1) { j = j2 // = 2*i + 2 // right child } if !h.Less(j, i) { break } h.Swap(i, j) i = j } return i \u0026gt; i0 } 我们关注其中几个核心实现：\ndown(h Interface, idx, heapLen int) 下沉操作：\n首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作：\n将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。\n为什么元素 i 比它的两个子节点都小，就可以跳出循环，不再继续下去呢？这是由于，在 Init 函数中，第一个开始 down 的元素是第 n/2 - 1 个，可以保证总是从最后一棵子树开始 down，因此可以保证 Init-\u0026gt;down 时，如果元素 i 比它的两个子节点都小，那么该元素对应的子树，就是最小堆。\nup(h Interface, curIdx int) 上浮操作：\n主要用在 Push 中，当我们向最小堆插入一个元素时，现将其插入到数组最后，之后进行上浮操作，此时的 curIdx 就是数组最后一个元素的 index，即 h.Len() - 1。当前元素与其父元素进行比较，如果当前元素小于父元素，则与父元素交换位置，如此往复，直到堆顶或者当前元素大于父元素。\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E5%B0%8F%E5%A0%86%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E7%9A%84golang%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/%E5%A0%86%E7%A9%8D\"\u003e堆\u003c/a\u003e，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为\u003cstrong\u003e最小堆（min heap）\u003c/strong\u003e；反之，若母节点的值恒大于等于子节点的值，此堆称为\u003cstrong\u003e最大堆（max heap）\u003c/strong\u003e。在堆中最顶端的那一个节点，称作 \u003cstrong\u003e根节点（root node）\u003c/strong\u003e，根节点本身没有 \u003cstrong\u003e父节点（parent node）\u003c/strong\u003e。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\u003c/p\u003e","title":"最小堆以及优先级队列的Golang实现"},{"content":"select 的缺陷 目前对于高并发的解决方案是 一个线程处理所有连接，在这一点上 select 和 epoll 是一样的。但 当大量的并发连接存在、但短时间内只有少数活跃的连接时，select 的表现就显得捉襟见肘了。\n首先，select 用在有活跃连接时，所以，在高并发的场景下 select 会被非常频繁地调用。当监听的连接以数万计的时候，每次返回的只是其中几百个活跃的连接，这本身就是一种性能的损失。所以内核中直接限定死了 select 可监听的文件句柄数：\n// include/uapi/linux/posix_types.h #define __FD_SETSIZE 1024 其次，内核中实现 select 的方式是 轮询，即每次检测都会遍历所有的 fd_set 中的句柄，时间复杂度为 O(n)，与 fd_set 的长度呈线性关系，select 要检测的句柄数越多就会越费时。\npoll 和 select 的实现机制没有太大差异，相比 select，poll 只是取消了最大监控文件描述符的限制，并没有从根本上解决 select 的缺陷。\n下面这张图中所表达的信息中，当并发连接较小时，select 和 epoll 差距非常小，当并发数逐渐变大时，select 性能就显得非常乏力：\n需要注意的是，这个前提是 保持大量连接，但是只有少数活跃连接，如果活跃连接也特别多，那 epoll 也会有性能问题。\nepoll 相关的数据结构与方法 与 epoll 相关的系统调用有以下三个：\n这三个方法可以在 Linux 系统的机器上通过 man 2 xxx 的方式查看具体用法\n/* 返回 epoll 实例的文件句柄，size 没有实际用途，传入一个大于 0 的数即可。 */ int epoll_create(int size); /* 让 epoll(epfd)实例 对 目标文件(fd) 执行 `ADD | DEL | MOD` 操作，并指定”关心“的事件类型 */ int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); /* 阻塞等待所”关心“的事件发生 */ int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 与 select 相比，epoll 分清了 频繁调用 和 不频繁调用 的操作。例如，epoll_ctl 是不太频繁调用的，而 epoll_wait 是非常频繁调用的。\n这是 epoll 最常见的 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; int main(void) { int epfd,nfds; struct epoll_event ev; // ev用于注册事件，表示自己关心的事哪些事件 struct epoll_event events[5]; // events 用于接收从内核返回的就绪事件 epfd = epoll_create(1); // 创建一个 epoll 实例 ev.data.fd = STDIN_FILENO; // 我们关心的是命令行输入 ev.events = EPOLLIN|EPOLLET; //监听读状态同时设置ET模式(这个后面会讲，可以简单理解成：文件内容发生变化时才会触发对应的事件) epoll_ctl(epfd, EPOLL_CTL_ADD, STDIN_FILENO, \u0026amp;ev); // 注册epoll事件 for(;;) { nfds = epoll_wait(epfd, events, 5, -1); // 进入死循环，最后的 -1 表示无限期阻塞，直到有事件发生 // epoll_wait 返回，表示有对应的事件发生，事件的信息存储在 events 数组中。nfds 表示数组的长度。接下来逐个处理事件 for(int i = 0; i \u0026lt; nfds; i++) { if(events[i].data.fd==STDIN_FILENO) printf(\u0026#34;welcome to epoll\u0026#39;s word!\\n\u0026#34;); } } } 接下来我们看看 epoll 相关的数据结构。\neventpoll /* * This structure is stored inside the \u0026#34;private_data\u0026#34; member of the file * structure and represents the main data structure for the eventpoll * interface. */ struct eventpoll { // 保护 rbr(红黑树) 和 rdllist(等待队列) struct mutex mtx; // 等待队列，用来保存对一个 epoll 实例调用 epoll_wait() 的所有进程。 // 当调用 epoll_wait 的进程发现没有就绪的事件需要处理时，就将当前进程添加到此队列中，然后进程睡眠；后续事件发生，就唤醒这个队列中的所有进程(也就是出现了惊群效应) wait_queue_head_t wq; // 当被监视的文件是一个 epoll 类型时，需要用这个等待队列来处理递归唤醒。 // epoll 也是一种文件类型，因此一个 epoll 类型的 fd 也是可以被其他 epoll 实例监视的。 // 而 epoll 类型的 fd 只会有“读就绪”的事件。当 epoll 所监视的非 epoll 类型文件有“读就绪”事件时，当前 epoll 也会进入“读就绪”状态。 // 因此如果一个 epoll 实例监视了另一个 epoll 就会出现递归。如 e2 监视了e1，e1 上有读就绪事件发生，e1 就会加入 e2 的 poll_wait 队列中。 wait_queue_head_t poll_wait; // 就绪列表(双链表)，产生了用户注册的 fd读写事件的 epi 链表。 struct list_head rdllist; // 保护 rdllist 和 ovflist 。 rwlock_t lock; /* RB tree root used to store monitored fd structs */ // 红黑树根结点，管理所有\u0026#34;关心\u0026#34;的 fd struct rb_root_cached rbr; // 单链表，当 rdllist 被锁定遍历向用户空间发送数据时，rdllist 不允许被修改，新触发的就绪 epitem 被 ovflist 串联起来， // 等待 rdllist 被处理完了，重新将 ovflist 数据写入 rdllist struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ // 创建 eventpoll 的用户结构信息。 struct user_struct *user; // eventpoll 对应的文件结构，Linux 中一切皆文件，epoll 也是一个文件。 struct file *file; /* used to optimize loop detection check */ u64 gen; struct hlist_head refs; }; 如上面 demo 中所示，\nepitem // 红黑树用于管理所有的要监视的文件描述符 fd。当我们向系统中添加一个 fd 时，就会对应地创建一个 epitem 结构体。 // epitem 可以添加到红黑树，也可以串联成就绪列表或其它列表。 struct epitem { union { /* RB tree node links this structure to the eventpoll RB tree */ // 所在的红黑树 struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; }; /* List header used to link this structure to the eventpoll ready list */ // 所在的 eventpoll 的就绪列表 struct list_head rdllink; /* Works together \u0026#34;struct eventpoll\u0026#34;-\u0026gt;ovflist in keeping the single linked chain of items. */ // 关联的 eventpoll 中的 ovflist struct epitem *next; /* The file descriptor information this item refers to */ // 为最开始的 fd 创建 epitem 时的文件描述符信息 struct epoll_filefd ffd; /* List containing poll wait queues */ // poll 等待队列 struct eppoll_entry *pwqlist; /* The \u0026#34;container\u0026#34; of this item */ // 所在的 eventpoll struct eventpoll *ep; /* List header used to link this item to the \u0026#34;struct file\u0026#34; items list */ struct hlist_node fllink; /* wakeup_source used when EPOLLWAKEUP is set */ struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ struct epoll_event event; }; epoll 工作流程 epoll 是有状态的, 内核中维护了一个数据结构用来管理所要监视的 fd，这个数据结构是 eventpoll；\n在 eventpoll 中有一颗红黑树, 用来快速的查找和修改要监视的 fd，每个节点被封装成 epitem 结构；\n在 eventpoll 中有一个列表, 用来收集已经发生事件的 epitem , 这个 list 叫 ready list(rdllist)。\n通过 epoll_ctl 函数添加进来的事件都会被放在红黑树的某个节点内，所以，重复添加是没有用的。当把事件添加进来的时候会完成关键的一步——该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数，该回调函数在内核中被称为：ep_poll_callback。这个回调函数其实就所把这个事件添加到rdllist这个双向链表中——一旦有事件发生，epoll就会将该事件添加到双向链表中。那么当我们调用 epoll_wait 时，epoll_wait 只需要检查 rdlist 双向链表中是否有存在注册的事件，有则返回，效率非常可观。\nepoll_create 细节 // 创建一个 eventpoll 对象，并且关联文件资源 static int do_epoll_create(int flags) { int error, fd; struct eventpoll *ep = NULL; struct file *file; // ... // 创建并初始化核心结构 eventpoll，赋值给 ep error = ep_alloc(\u0026amp;ep); if (error \u0026lt; 0) return error; // 创建一个文件(文件句柄 fd 和 file结构) fd = get_unused_fd_flags(O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (fd \u0026lt; 0) { error = fd; goto out_free_ep; } // 注意，在这里将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象 file = anon_inode_getfile(\u0026#34;[eventpoll]\u0026#34;, \u0026amp;eventpoll_fops, ep, O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (IS_ERR(file)) { error = PTR_ERR(file); goto out_free_fd; } // 绑定 fd 和 file，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程。 ep-\u0026gt;file = file; fd_install(fd, file); return fd; // ... } 这个函数很简单，主要做以下几件事：\n创建并初始化核心结构 eventpoll，赋值给变量 ep； 创建一个 文件句柄fd 和 文件 file结构体，并绑定 fd 和 file、绑定 file 和 eventpoll(将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象)，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程，这也间接说明 epoll 也是一种文件。 关于绑定 fd 和 file，参考：彻底理解 Linux 中的 文件描述符(fd)\nepoll_ctl 细节 // epoll_ctl 的详细实现 int do_epoll_ctl( int epfd/*epoll 文件描述符*/, int op /*操作类型*/, int fd /*要监控的目标文件描述符*/, struct epoll_event *epds/*要监视的事件类型*/, bool nonblock, ) { int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct eventpoll *tep = NULL; // epoll 对应的文件 f = fdget(epfd); // fd 对应的文件 tf = fdget(fd); /* The target file descriptor must support poll */ // epoll 并不能监控所有的文件描述符，只能监视支持 poll 方法的文件描述符 // 其实是检查对应的 file 中的 file_operations 中是否有 poll 方法，即当前文件类型是否实现了 poll 方法(普通文件没有实现，socket 或者 epoll 类型等都实现了，所以可以被 epoll 监控) if (!file_can_poll(tf.file)) goto error_tgt_fput; /* Check if EPOLLWAKEUP is allowed */ // 检查是否允许 EPOLLWAKEUP if (ep_op_has_event(op)) ep_take_care_of_epollwakeup(epds); // epoll 监视的不是自己 error = -EINVAL; if (f.file == tf.file || !is_file_epoll(f.file)) goto error_tgt_fput; // 在 do_epoll_create 实现里 anon_inode_getfile 已经将 private_data 与 eventpoll 关联。 ep = f.file-\u0026gt;private_data; // 当我们添加进来的 file 是一个 epoll 类型的文件时，有可能造成循环引用的死循环。在这里提前检查避免这种情况 error = epoll_mutex_lock(\u0026amp;ep-\u0026gt;mtx, 0, nonblock); if (error) goto error_tgt_fput; if (op == EPOLL_CTL_ADD) { if (READ_ONCE(f.file-\u0026gt;f_ep) || ep-\u0026gt;gen == loop_check_gen || is_file_epoll(tf.file)) { // ... } } // 查找 要添加的 fd 是否已经在红黑树上了，如果是，返回对应的 epitem 结构，否则返回 NULL epi = ep_find(ep, tf.file, fd); error = -EINVAL; switch (op) { case EPOLL_CTL_ADD: // 增加fd if (!epi) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; // fd 不在红黑树上，就将此 fd 添加到红黑树上管理。默认关注的事件是 EPOLLERR | EPOLLHUP error = ep_insert(ep, epds, tf.file, fd, full_check); } else error = -EEXIST; break; case EPOLL_CTL_DEL: // 删除fd if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: // 修改fd事件类型 if (epi) { if (!(epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE)) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; error = ep_modify(ep, epi, epds); } } else error = -ENOENT; break; } mutex_unlock(\u0026amp;ep-\u0026gt;mtx); // ... } 在 do_epoll_ctl() 的参数中，操作类型有三种：\nEPOLL_CTL_ADD： 往事件表中注册fd上的事件； EPOLL_CTL_DEL：删除fd上的注册事件； EPOLL_CTL_MOD：修改fd上的注册事件。 而 struct epoll_event 结构表示事件类型，常见的有：\n// eventpoll.h #define EPOLLIN (__force __poll_t)0x00000001 // 有可读数据到来 #define EPOLLPRI (__force __poll_t)0x00000002 // 有紧急数据可读：1. TCP socket 上有外带数据；2. 分布式环境下状态发生改变；3. cgroup.events类型的文件被修改 #define EPOLLOUT (__force __poll_t)0x00000004 // 有数据要写 #define EPOLLERR (__force __poll_t)0x00000008 // 文件描述符上发生错误(不管有没有设置这个 flag，epoll_wait 总是会检测并返回这样的错误) #define EPOLLHUP (__force __poll_t)0x00000010 // 该文件描述符被挂断。常见 socket 被关闭（read == 0） #define EPOLLRDHUP (__force __poll_t)0x00002000 // 对端已关闭链接，或者用 shutdown 关闭了写链 /* Set the Edge Triggered behaviour for the target file descriptor */ #define EPOLLET ((__force __poll_t)(1U \u0026lt;\u0026lt; 31)) // ET 工作模式 /* Set the One Shot behaviour for the target file descriptor */ /* 一般情况下，ET 模式只会触发一次，但有可能出现多个线程同时处理 epoll，此标志规定操作系统最多触发其上注册的一个可读或者可写或者异常事件，且只触发一次，如此无论线程再多，只能有一个线程或进程处理同一个描述符 */ #define EPOLLONESHOT ((__force __poll_t)(1U \u0026lt;\u0026lt; 30)) /* Set exclusive wakeup mode for the target file descriptor */ /* 唯一唤醒事件，主要为了解决 epoll_wait 惊群问题。多线程下多个 epoll_wait 同时等待，只唤醒一个 epoll_wait 执行。 该事件只支持 epoll_ctl 添加操作 EPOLL_CTL_ADD */ #define EPOLLEXCLUSIVE ((__force __poll_t)(1U \u0026lt;\u0026lt; 28)) 关于什么是 “ET(边缘触发)” 和 “LT(水平触发)”，后面会详细说。\nep_insert static int ep_insert(struct eventpoll *ep, const struct epoll_event *event, struct file *tfile, int fd, int full_check) { // ep_insert(ep, epds, tf.file, fd, full_check); // tf 表示 fd 对应的 file 结构 int error, pwake = 0; __poll_t revents; long user_watches; // epoll 文件对象中所监视的 fd 数量 struct epitem *epi; struct ep_pqueue epq; struct eventpoll *tep = NULL; // 当 fd 类型是 epoll 时，tep 用来保存 fd 对应的 eventpoll 结构 // 要监视的文件也是 epoll 类型，用 tep 保存对应的 eventepoll 结构 if (is_file_epoll(tfile)) tep = tfile-\u0026gt;private_data; lockdep_assert_irqs_enabled(); // 判断 epoll 监视的文件个数是否超出系统限制 user_watches = atomic_long_read(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); if (unlikely(user_watches \u0026gt;= max_user_watches)) return -ENOSPC; if (!(epi = kmem_cache_zalloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ // 创建一个双链表，头和尾都是它自己 INIT_LIST_HEAD(\u0026amp;epi-\u0026gt;rdllink); epi-\u0026gt;ep = ep; ep_set_ffd(\u0026amp;epi-\u0026gt;ffd, tfile, fd); // epitem 与 fd 绑定 epi-\u0026gt;event = *event; epi-\u0026gt;next = EP_UNACTIVE_PTR; // 目标文件是 epoll 类型 if (tep) mutex_lock_nested(\u0026amp;tep-\u0026gt;mtx, 1); /* Add the current item to the list of active epoll hook for this file */ if (unlikely(attach_epitem(tfile, epi) \u0026lt; 0)) { kmem_cache_free(epi_cache, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); return -ENOMEM; } if (full_check \u0026amp;\u0026amp; !tep) list_file(tfile); // 当前进程的用户的 epoll_watches 加一 atomic_long_inc(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); // 将初始化后的 epitem 添加到红黑树中 ep_rbtree_insert(ep, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); // 不允许递归监视太多的 epoll if (unlikely(full_check \u0026amp;\u0026amp; reverse_path_check())) { ep_remove(ep, epi); return -EINVAL; } if (epi-\u0026gt;event.events \u0026amp; EPOLLWAKEUP) { error = ep_create_wakeup_source(epi); if (error) { ep_remove(ep, epi); return error; } } /* Initialize the poll table using the queue callback */ epq.epi = epi; // 注册回调函数，作用：add our wait queue to the target file wakeup lists. 在tcp_sock-\u0026gt;sk_sleep中插入一个等待者 // 不同的系统实现 poll 的方式不同，如socket的话, 那么这个接口就是 tcp_poll() init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc); // 可能此时已经有事件存在了, revents返回这个事件 revents = ep_item_poll(epi, \u0026amp;epq.pt, 1); // ... // 如果此时就有关注的事件发生，我们将其放到就绪队列中 if (revents \u0026amp;\u0026amp; !ep_is_linked(epi)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); // 唤醒等待的线程，告诉他们有活干了 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) wake_up(\u0026amp;ep-\u0026gt;wq); if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; } // ... } ep_insert 先申请一个 epitem 对象 epi，并初始化 epitem 的两个 list 的头指针：rdllink(指向 eventpoll 的 rdllist)、pwqlist(指向包含此 epitem 的所有 poll wait queue)，通过 fs 将 epitem、fd 和 file 绑定，通过 epitem.ep 将此 epitem 和 传入的 eventpoll 对象绑定，通过传入的 event 对 epitem.events 赋值，紧接着，将这个 epitem 加入到 eventpoll 的 红黑树中。整个过程结束后，epitem 本身就完成了和 eventpoll 以及 被监视文件fd 的关联。但还要做一件事：将 epitem 加入目标文件的 poll 等待队列并注册对应的回调函数。\n在 ep_insert() 中有一行是 init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc);，这其实是注册了一个回调函数——将文件的 poll() 方法与此方法绑定，当文件就绪，就会调用此方法。\n关于 等待队列 的实现，参考：理解 Linux 等待队列\n我们知道，当一个进程加入等待队列之后，需要将设置对应的唤醒函数，当资源就绪的时候调用这个设置好的唤醒函数：\n// 链表中的一个结点 struct wait_queue_entry { unsigned int flags; // 标志，如 WQ_FLAG_EXCLUSIVE，表示等待的进程应该独占资源（解决惊群现象） void *private; // 等待进程相关信息，如 task_struct wait_queue_func_t func; // 唤醒函数 struct list_head entry; // 前后结点 }; 我们再来看下 init_waitqueue_func_entry 这个方法：\nstatic inline void init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func) { wq_entry-\u0026gt;flags = 0; wq_entry-\u0026gt;private = NULL; wq_entry-\u0026gt;func = func; } 正是将等待队列中的结点的唤醒函数设置为 ep_ptable_queue_proc ！\n我们来详细看看 ep_ptable_queue_proc 的实现：\n/* // 当该文件描述符对应的文件有事件到达后，回调用这个函数 // 首先根据pt拿到对应的epi。然后通过pwq将三者关联。 // @file: 要监听的文件 // @whead: 该fd对应的设备等待队列，每个设备的驱动都会带 // @pt: 调用文件的poll传入的东西。 */ static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct ep_pqueue *epq = container_of(pt, struct ep_pqueue, pt); struct epitem *epi = epq-\u0026gt;epi; struct eppoll_entry *pwq; // epitem 的私有项，为每一个 fd 保存内核的 poll。 // 这个结构体主要完成 epitem 和 epitem事件发生时 callback 函数的关联，将唤醒回调函数设置为 ep_poll_callback，然后加入设备等待队列 // ... // 将pwq的等待队列和回调函数ep_poll_callback关联 // ep_poll_callback 才是真正意义上的 poll() 醒来时的回调函数，当设备就绪，就会唤醒设备的等待队列中的进程，此时 ep_poll_callback 会被调用 init_waitqueue_func_entry(\u0026amp;pwq-\u0026gt;wait, ep_poll_callback); pwq-\u0026gt;whead = whead; pwq-\u0026gt;base = epi; // 将 进程对应的等待双链表结点 放入等待队列whead // 将eppoll_entry挂在到fd的设备等待队列上。也就是注册epoll的回调函数 ep_poll_callback if (epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, \u0026amp;pwq-\u0026gt;wait); else add_wait_queue(whead, \u0026amp;pwq-\u0026gt;wait); pwq-\u0026gt;next = epi-\u0026gt;pwqlist; epi-\u0026gt;pwqlist = pwq; } 我们来看看 ep_poll_callback 干了什么：\n/* * This is the callback that is passed to the wait queue wakeup * mechanism. It is called by the stored file descriptors when they * have events to report. * * This callback takes a read lock in order not to contend with concurrent * events from another file descriptor, thus all modifications to -\u0026gt;rdllist * or -\u0026gt;ovflist are lockless. Read lock is paired with the write lock from * ep_scan_ready_list(), which stops all list modifications and guarantees * that lists state is seen correctly. */ static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key) { int pwake = 0; struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-\u0026gt;ep; __poll_t pollflags = key_to_poll(key); unsigned long flags; int ewake = 0; // ... /* * If we are transferring events to userspace, we can hold no locks * (because we\u0026#39;re accessing user memory, and because of linux f_op-\u0026gt;poll() * semantics). All the events that happen during that period of time are * chained in ep-\u0026gt;ovflist and requeued later on. */ // 因为要访问用户空间，所以此时对 rdllist 的访问不应该加锁。如果恰巧这个时候有对应的 // 事件发生，应该将其放到 ovflist 中之后再调度。 if (READ_ONCE(ep-\u0026gt;ovflist) != EP_UNACTIVE_PTR) { if (chain_epi_lockless(epi)) ep_pm_stay_awake_rcu(epi); } else if (!ep_is_linked(epi)) { // 将当前的 epitem 添加到 eventpool 的就绪队列中 /* In the usual case, add event to ready list. */ if (list_add_tail_lockless(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist)) ep_pm_stay_awake_rcu(epi); } /* * Wake up ( if active ) both the eventpoll wait list and the -\u0026gt;poll() * wait list. */ // 同时唤醒 eventpool 和 poll 的等待的进程 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) { if ((epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) \u0026amp;\u0026amp; !(pollflags \u0026amp; POLLFREE)) { switch (pollflags \u0026amp; EPOLLINOUT_BITS) { case EPOLLIN: if (epi-\u0026gt;event.events \u0026amp; EPOLLIN) ewake = 1; break; case EPOLLOUT: if (epi-\u0026gt;event.events \u0026amp; EPOLLOUT) ewake = 1; break; case 0: ewake = 1; break; } } wake_up(\u0026amp;ep-\u0026gt;wq); } if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; // ... return ewake; } ep_wait 细节 入口在\nSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { struct timespec64 to; return do_epoll_wait(epfd, events, maxevents, ep_timeout_to_timespec(\u0026amp;to, timeout)); } 实际调用的是 do_epoll_wait：\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). * * @epfd: 对应的 eventpoll 文件描述符 * @events: 用于接收已经就绪的事件 * @maxevents：所监听的最大事件个数 * @to：超时事件(-1表示无限制等待) */ // epoll_wait 的具体实现 static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, struct timespec64 *to) { int error; struct fd f; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents \u0026lt;= 0 || maxevents \u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ // 确保用户传进来的地址空间是可写的 if (!access_ok(events, maxevents * sizeof(struct epoll_event))) return -EFAULT; /* Get the \u0026#34;struct file *\u0026#34; for the eventpoll file */ // 获取 epoll 实例 f = fdget(epfd); if (!f.file) return -EBADF; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; // 确保传进来的 epfd 是 epoll 类型 if (!is_file_epoll(f.file)) goto error_fput; /* * At this point it is safe to assume that the \u0026#34;private_data\u0026#34; contains * our own data structure. */ ep = f.file-\u0026gt;private_data; /* Time to fish for events ... */ // 执行具体的 poll，如果有事件产生，返回的 error 就是对应的事件个数，对应的事件也会同时从 eventpoll 对应的 rdllist(就绪队列) 中写入到传进来的 events 数组中 error = ep_poll(ep, events, maxevents, to); error_fput: fdput(f); return error; } 我们看下 ep_poll 的实现细节：\n/** * ep_poll - 检索已经就绪的事件，并将其从内核空间传送到用户空间传进来的events 列表中 * * @ep: eventpoll 实例指针 * @events: 存放就绪事件的用户空间的数组的指针 * @maxevents: events 数组的长度 * @timeout: 获取就绪事件操作的最大超时时间。如果是 0，表示不阻塞；如果是负数，表示一直阻塞 * * Return: 成功收到的事件的个数，或者失败时对应的错误码。 */ static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 设置超时 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { // 有具体的超时时长 slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. */ // 用户设置不阻塞。 timed_out = 1; } // 检查 ep.rdllist 或 ep.ovflist 中是否有就绪的事件，如果有返回就绪事件的个数。否则返回 0 eavail = ep_events_available(ep); while (1) { if (eavail) { // rdllist 中已经有事件了，将其传送到用户空间。 // 如果没有对应的事件并且也没到超时时间，就再等等，直到超时 res = ep_send_events(ep, events, maxevents); if (res) return res; } // 走到这一步，说明没有就绪事件 // 用户设置不阻塞，直接返回 if (timed_out) return 0; // always false eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查当前进程是否有信号处理，返回不为0表示有信号需要处理。 if (signal_pending(current)) return -EINTR; init_wait(\u0026amp;wait); write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有就绪事件，如果没有，让当前进程睡眠(然后进程就阻塞在这里了...) eavail = ep_events_available(ep); if (!eavail) __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 重新计算超时时间 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 进程被唤醒了，说明有事件发生！ __set_current_state(TASK_RUNNING); /* * We were woken up, thus go and try to harvest some events. * If timed out and still on the wait queue, recheck eavail * carefully under lock, below. */ eavail = 1; if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); /* * If the thread timed out and is not on the wait queue, * it means that the thread was woken up after its * timeout expired before it could reacquire the lock. * Thus, when wait.entry is empty, it needs to harvest * events. */ if (timed_out) // list_empty 检查 list 是否为空 eavail = list_empty(\u0026amp;wait.entry); // 将 wait 从 ep 的等待队列中删除 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 我们再来看 ep_send_events的实现：\nstatic int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) { struct epitem *epi, *tmp; LIST_HEAD(txlist); poll_table pt; int res = 0; if (fatal_signal_pending(current)) return -EINTR; init_poll_funcptr(\u0026amp;pt, NULL); mutex_lock(\u0026amp;ep-\u0026gt;mtx); // 将 rdllist 中的元素全部添加到 txlist 中，并清空 ep.rdllist ep_start_scan(ep, \u0026amp;txlist); // 迭代器，逐个处理从 ep-\u0026gt;rdllist 中取出后放在 txlist 中的 epitem // epi 表示正在处理的对象(cursor) list_for_each_entry_safe(epi, tmp, \u0026amp;txlist, rdllink) { struct wakeup_source *ws; __poll_t revents; if (res \u0026gt;= maxevents) break; ws = ep_wakeup_source(epi); if (ws) { if (ws-\u0026gt;active) __pm_stay_awake(ep-\u0026gt;ws); __pm_relax(ws); } // 重置 epitem 中的 rdllink list_del_init(\u0026amp;epi-\u0026gt;rdllink); // 检查就绪事件的 flag 是否是调用方需要的 revents = ep_item_poll(epi, \u0026amp;pt, 1); if (!revents) continue; // 内核向用户态复制数据 if (__put_user(revents, \u0026amp;events-\u0026gt;events) || __put_user(epi-\u0026gt;event.data, \u0026amp;events-\u0026gt;data)) { list_add(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;txlist); ep_pm_stay_awake(epi); if (!res) res = -EFAULT; break; } res++; events++; // 处理水平触发和边缘触发的场景 if (epi-\u0026gt;event.events \u0026amp; EPOLLONESHOT) epi-\u0026gt;event.events \u0026amp;= EP_PRIVATE_BITS; else if (!(epi-\u0026gt;event.events \u0026amp; EPOLLET)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); } } ep_done_scan(ep, \u0026amp;txlist); mutex_unlock(\u0026amp;ep-\u0026gt;mtx); return res; } 而其中的 ep_item_poll，不同的驱动程序，都会有自己的 poll 方法，如果是 TCP套接字，这个poll方法就是 tcp_poll。在 TCP 中，会周期性的调用这个方法调用频率取决于协议栈中断频率的设置。一旦有事件到达后，对应的 tcp_poll 方法被调用，tcp_poll 方法会回调用 sock_poll_wait()，该方法会调用这里注册的 ep_ptable_queue_proc 方法。epoll 其实就是通过此机制实现将自己的回调函数加入到文件的 waitqueue 中的。这也是 ep_ptable_queue_proc 的目的。\nstatic __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt, int depth) { struct file *file = epi-\u0026gt;ffd.file; __poll_t res; pt-\u0026gt;_key = epi-\u0026gt;event.events; if (!is_file_epoll(file)) // 非 epoll 类型的 fd，检查 socket 的就绪事件，fd 关联回调函数 ep_poll_callback。最终执行的 poll 是 tcp_poll res = vfs_poll(file, pt); else res = __ep_eventpoll_poll(file, pt, depth); return res \u0026amp; epi-\u0026gt;event.events; } 再谈 epoll 和 select 从更高的角度看，epoll 和 select 都是 I/O 多路复用，当我们在调用这类函数时，我们传入的是 关心的socket，接收到的返回是 就绪的 socket。那为何会有性能差距呢？我们尝试找出他们的不同点：\n对比 select epoll 连接数限制 1024 理论上无限制 内在处理机制 现行轮训 callback TODO TODO TODO 再回头看看 select 的 demo:\nint main(){ int fds[] = ...; // 关心的 socket 数组 fd_set source_fds; // 将我们关心的 socket 保存到 fd_set 中 fd_set temp_fds; // 临时变量，作为 select 的返回值 // 初始化 source_fds FD_ZERO(\u0026amp;source_fds); for (int i=0; i\u0026lt;fds.length; i++) { FD_SET(fds[i], \u0026amp;source_fds); } while(1) { // select 将一个 fd_set 作为入参，将就绪的 socket 又填充如这个入参中作为出参返回 // 因此，为了快速重置，设置一个临时变量，避免每次都要进行 source_fds 的重置 temp_fds = source_fds; // select 会阻塞，直到关心的 socket 上有事件发生 int n = select(..., \u0026amp;temp_fds, ...); // 在用户态遍历 socket，检查是否有我们关心的事件发生 for (int i=0; i \u0026lt; fds.length; i++) { if (FD_ISSET(fds[i], \u0026amp;temp_fds)) { // ... 进行对应的逻辑处理 FD_CLR(fds[i], \u0026amp;temp_fds); } } } return 0; } select 主要有两点限制：\n所能关注的 socket 太少，只能有 1024 个，对于一些大型 web 应用来说有点捉襟见肘； 尽管 FD_SET 是 O(1) 的操作，但返回后还要在用户态遍历一次整个 fd_set，这是一个线性操作 再回过头来看 epoll:\nint main() { int fds[] = ...; // 关心的 socket 数组 int epfd = epoll_create(...); // 创建 epoll 实例 // 将关心的 socket 添加到 epoll 中(红黑树等) for (int i=0; i \u0026lt; fds.length; i++){ epoll_ctl(epfd,EPOLL_CTL_ADD, fds[i], ...); } // 定义一个结构，用来接收就绪的事件 struct epoll_event events[MAX_EVENTS]; while(1){ // 如果无事件发生，那么进程将阻塞在这里 // 如果有事件发生，则返回就绪的事件个数，同时事件被存储在 events 中 int n = epoll_wait(epfd, \u0026amp;events,...); for (int i=0; i \u0026lt; n; i++) { // 通过下标取到返回的就绪事件，进行对应的逻辑处理 new_event = events[i]; } } return 0; } 每次epoll_wait 返回的都是活跃的 socket，根本不用全部遍历一遍 epoll 底层使用到了 红黑树 来存储所关心的 socket，查找效率有保证；注册的对应的事件通知是通过回调的方式执行的，这种解耦、相互协作的方式更有利于操作系统的调度。 ","permalink":"http://localhost:1313/posts/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/","summary":"\u003ch2 id=\"select-的缺陷\"\u003eselect 的缺陷\u003c/h2\u003e\n\u003cp\u003e目前对于高并发的解决方案是 \u003cstrong\u003e一个线程处理所有连接\u003c/strong\u003e，在这一点上 \u003ccode\u003eselect\u003c/code\u003e 和 \u003ccode\u003eepoll\u003c/code\u003e 是一样的。但 \u003cstrong\u003e当大量的并发连接存在、但短时间内只有少数活跃的连接时，\u003ccode\u003eselect\u003c/code\u003e 的表现就显得捉襟见肘了。\u003c/strong\u003e\u003c/p\u003e","title":"I/O多路复用之 epoll"},{"content":"看 select 源码，fd_set 这个结构体实际上是一个 long 型的数组，但是数组的长度依赖于系统中 typedef long int __fd_mask 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\n本文旨在抛开 select 相关的功能，彻底搞明白 fd_set 的存储原理、FD_SET() 等函数到底实现了什么效果。\n本次调试机器：\n$ uname -a Linux localhost 4.15.0-52-generic #56-Ubuntu SMP Tue Jun 4 22:49:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux fd_set 的源码中有非常多的预编译指令：\n// /usr/include/x86_64-linux-gnu/sys/select.h /* The fd_set member is required to be an array of longs. */ typedef long int __fd_mask; /* Some versions of \u0026lt;linux/posix_types.h\u0026gt; define this macros. */ #undef __NFDBITS /* It\u0026#39;s easier to assume 8-bit bytes than to get CHAR_BIT. */ #define __NFDBITS (8 * (int) sizeof (__fd_mask)) #define __FD_MASK(d) ((__fd_mask) (1UL \u0026lt;\u0026lt; ((d) % __NFDBITS))) /* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 我简单整理一下，去掉和本系统无关的，结果如下：\ntypedef long int __fd_mask; // 8 #define __NFDBITS (8 * (int) sizeof (__fd_mask) // 64 #define __FD_SETSIZE 1024 typedef struct { __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; // 长度为 1024/64=16，类型为 long } fd_set; 接着，我们看一个 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; void print_set1(fd_set *fdset); void print_set2(fd_set *fdset); int main() { fd_set fdset; FD_ZERO(\u0026amp;fdset); printf(\u0026#34;sizeof long int: %ld\\n\u0026#34;, sizeof(long int)); // 8 printf(\u0026#34;sizeof int: %ld\\n\u0026#34;, sizeof(int)); // 4 printf(\u0026#34;sizeof short: %ld\\n\u0026#34;, sizeof(short)); // 2 FD_SET(1, \u0026amp;fdset); FD_SET(2, \u0026amp;fdset); FD_SET(3, \u0026amp;fdset); FD_SET(7, \u0026amp;fdset); print_set1(\u0026amp;fdset); // 10001110 -\u0026gt; 第 1 2 3 7 位分别设置成了 1 FD_SET(15, \u0026amp;fdset); FD_SET(16, \u0026amp;fdset); FD_SET(31, \u0026amp;fdset); // 10000000000000011000000010001110 -\u0026gt; 长度为 32 FD_SET(32, \u0026amp;fdset); FD_SET(33, \u0026amp;fdset); FD_SET(62, \u0026amp;fdset); // 100000000000000000000000000001110000000000000011000000010001110 0-\u0026gt;长度为 63 print_set2(\u0026amp;fdset); FD_SET(63, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 0 -\u0026gt; 长度为 64 print_set2(\u0026amp;fdset); FD_SET(64, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 -\u0026gt; 长度还是 64，但产生了进位 print_set2(\u0026amp;fdset); FD_SET(128, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 1-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(129, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 3-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(1023, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1024, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1025, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 print_set2(\u0026amp;fdset); int isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 1，代表第 7 位被设置 FD_CLR(7, \u0026amp;fdset); print_set2(\u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000000001110 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 -\u0026gt; 第 7 位的 1 变成了 0 isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 0，代表第 7 位没有被设置 return 0; } void print_set2(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%llu \u0026#34;, (unsigned long long)fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } void print_set1(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%ld \u0026#34;,fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } print_set() 函数是我自己添加的，用于打印出 fd_set 中的 __fds_bits 数组中的内容。需要注意两点：\n数组长度是 16，是如何确定的？答：在处理过预编译指令之后，__FD_SETSIZE 的值是 1024，__NFDBITS 的值是 64，计算得到数组长度为 16；\n类型的长度如何确定？答：在最开始使用了 typedef long int __fd_mask，long int 其实就是 long，即 long signed integer type。熟悉 C语言的同学都知道，当我们描述 short、int 和 long 的长度时，只有对 short 的长度是肯定的，而对后两者都使用了 可能 的说法：可能长度为 8。这是因为 C语言 没有对其做出严格的规定，只做了宽泛的限制：short 占 2字节；int 建议为机器字长，64 位机器下占4字节；2 ≤ short ≤ int ≤ long，如上述代码中打印结果所示，在我测试的这台机器上，long 占 8字节 即 64位。\n接下来我们看 main() 中的代码：\n在调用 FD_SET() 设置 1 2 3 7 后，我们调用print_set1()打印结果，输出：142 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，数组第一位竟然是 142？！哪来的？但我们将 142 转成二进制就一下子了然了：10001110， 总共占 8 位，从右往左从 0 开始数，只有第 1 2 3 7 位被设置成了 1， 这个二进制对应的数就是 142，因为 142 完全在一个 long 的范围(64位)内，所以正常表示了。那如果我们对一个超过 long 范围的数调用 FD_SET()，会是什么效果？\n代码继续走到 FD_SET(62, \u0026amp;fdset)，我们调用 print_set1()，输出 4611686033459871886 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，4611686033459871886 转成二进制为 100000000000000000000000000001110000000000000011000000010001110，字符串长度为 63，可以看到，依旧在 long 的范围之内；执行到 FD_SET(63,\u0026amp;fdset) 呢，调用 print_set1()，输出 -4611686003394903922 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，出现了负数。我们想一下原因。只执行FD_SET(62,\u0026amp;fdset) 会将第 63 位处设置为 1，对应的二进制为 100000000000000000000000000000000000000000000000000000000000000(长度为 63)；根据 FD_SET() 的功能，我们可以猜测，FD_SET(63,\u0026amp;fdset) 会将第 64 位设置为 1，其对应的二进制应该是 1000000000000000000000000000000000000000000000000000000000000000(长度为 64)。\n在这里我们补充一个知识：参考这里 Wiki-无符号数，在计算机底层，有符号数可以表示特定范围内的整数(包括负数)，无符号数只能表示非负数(0 以及正数)，有符号数能够表示负数的原因是，最高位被用来当做符号位，1 表示负数，0 表示正数，代价就是所表示的数的范围少了一半，举个例子，8 位可以表示无符号数 [0,255](最小00000000；最大11111111，对应的十进制就是 255)，对应的有符号数范围就是 [-127,127]。\n再回头看 1000000000000000000000000000000000000000000000000000000000000000，__fd_mask 的类型是 long，是一个有符号数，最高位的 1 表示负数，后面的才是真正的值，于是这个二进制转成有符号十进制的结果就是 0，而且还是个 -0。为了验证我们的想法，我们将 print_set1() 换成 print_set2()，这两个函数唯一的不同是，将数组中的每一位的类型强转成了无符号数，这下结果就成了 9223372036854775808，符合我们的预期。 所以后面的调试，我们都使用 print_set2() 这个函数。\n刚才的 FD_SET(63,\u0026amp;fdset) 已经到达一个 long 的最大可 表示范围了，如果再多一位，会发生什么？我们看下 FD_SET(64, \u0026amp;fdset)，输出 13835058070314647694 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0，13835058070314647694 转换成二进制后为 1100000000000000000000000000001110000000000000011000000010001110(长度为 64)，和 设置 63 时的一样，但数组的第二位变成了 1。按照前面的推测，单独执行 FD_SET(64, \u0026amp;fdset)，应该将第 65 位设置成 1，长度为 65，但是 65 显然超过了 long 的可表示的长度(64位)，于是，产生了“进位”，这个进位的基本单位就是 64位，即 __NFDBITS 的值。于是，可以用如下 python 代码表示(python 对大数处理非常好，一般不会出现溢出)：\n#!/usr/local/env python3 # coding:utf-8 # get_fd_set_bin 返回 fd_set 表示的真实二进制(从右往左方向) # every_fd_bits 表示数组中每个元素代表多少位 # set_array 表示 fd_set 的 long 数组 def get_fd_set_bin(every_fd_bits, set_array): int_value = 0 for idx in range(len(set_array)): int_value = int_value | (set_array[idx] \u0026lt;\u0026lt; every_fd_bits * idx) return bin(int_value)[2:] # 输出 \u0026#34;0bxxxxxx\u0026#34;，为了方便展示，去掉前缀 # print_bin 将二进制按照 step 为一组打印 def print_bin(output, step=64): le = len(output) m = le % step padding = step - m if m != 0 else 0 output = output.zfill(le + padding) print(\u0026#39; \u0026#39;.join(\u0026#39;\u0026#39;.join(output[idx * step:(idx + 1) * step]) for idx in range((le + padding) // step))) 在我们当前的例子中，every_fd_bits = 64, set_array 的长度为 16。测试一下我们的代码：\n# 输入(相当于设置了 1 2 3 7) get_fd_set_bin(64, [142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000010001110 # 输入(相当于设置了 1 2 3 7 64) get_fd_set_bin(64, [142,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000000000001 0000000000000000000000000000000000000000000000000000000010001110 我用 Golang 做了简单实现：\npackage main import ( \u0026#34;math/big\u0026#34; \u0026#34;strings\u0026#34; ) type FdSet interface { FD_CLR(fd int) error FD_ISSET(fd int) (bool, error) FD_SET(fd int) error FD_ZERO() error FdSetString() string } type fdType uint64 const ( maxFdSetSize = 1024 fdMask = 8 // sizeof long int in c fdBits = 8 * fdMask ) type FdSetGolang struct { data [maxFdSetSize / fdBits]fdType } func NewGdSetGolang() *FdSetGolang { return \u0026amp;FdSetGolang{data: [maxFdSetSize / fdBits]fdType{}} } func (fs *FdSetGolang) FD_CLR(fd int) error { fs.clear(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ISSET(fd int) (bool, error) { return fs.isSet(fs.getMask(fd)), nil } func (fs *FdSetGolang) FD_SET(fd int) error { fs.set(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ZERO() error { for i := range fs.data { fs.data[i] = 0 } return nil } func (fs *FdSetGolang) FdSetString() string { tmp := make([]string, 0, len(fs.data)) for i := len(fs.data) - 1; i \u0026gt;= 0; i-- { if v := fs.uintBin(uint64(fs.data[i])); v != \u0026#34;\u0026#34; { tmp = append(tmp, v) } } // 最左边的那个，可以将前面的 0 全部去掉 if len(tmp) \u0026gt; 0 { t := tmp[0] if t != \u0026#34;\u0026#34; { for i := 0; i \u0026lt; len(t); i++ { if t[i] != \u0026#39;0\u0026#39; { tmp[0] = t[i:] break } } } } return \u0026#34;--\u0026gt;\u0026#34; + strings.Join(tmp, \u0026#34; \u0026#34;) + \u0026#34;\u0026lt;--\u0026#34; } func (fs *FdSetGolang) getMask(fd int) (idx int, n int) { return fd / fdBits, fd % fdBits } // set 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 1 func (fs *FdSetGolang) set(idx int, n int) { old := fs.data[idx] fs.data[idx] = 1\u0026lt;\u0026lt;n | old } // clear 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 0 func (fs *FdSetGolang) clear(idx int, n int) { if fs.isSet(idx, n) { fs.data[idx] ^= 1 \u0026lt;\u0026lt; n } } func (fs *FdSetGolang) isSet(idx, n int) bool { old := fs.data[idx] this := 1 \u0026lt;\u0026lt; n if int(old)\u0026amp;this == this { return true } return false } // uintBin 输出 n 的二进制表示 func (fs *FdSetGolang) uintBin(n uint64) string { if n == 0 { return \u0026#34;\u0026#34; } s := big.NewInt(0).SetUint64(n).Text(2) return strings.Repeat(\u0026#34;0\u0026#34;, fdBits-len(s)) + s } ","permalink":"http://localhost:1313/posts/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3linux-select%E4%B8%AD%E7%9A%84fd_set/","summary":"\u003cp\u003e看 \u003ccode\u003eselect\u003c/code\u003e 源码，\u003ccode\u003efd_set\u003c/code\u003e 这个结构体实际上是一个 \u003ccode\u003elong\u003c/code\u003e 型的数组，但是数组的长度依赖于系统中 \u003ccode\u003etypedef long int __fd_mask\u003c/code\u003e 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\u003c/p\u003e","title":"彻底理解Linux Select中的FD_SET"},{"content":"关于事务 事务的特性 原子性(Atomic, A)：要么全部执行，要么全部不执行； 一致性(Consistent, C)：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态； 隔离性(Isolation, I)：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务； 持久性(Durability, D)：事务提交后，其结果永久保存在数据库中。 事务ACID特性的实现思想\n原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 并发操作带来的问题 脏读(Dirty Reads)：一个事务在处理的过程中读取到了另一个未提交事务中的事务； 不可重复读(Non-Reapeatable Reads)：一个事务在读取某些数据后的某个时间再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了； 幻读(Phantom Reads)：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据。 不可重复读 和 幻读 区别是什么？\n不可重复读 的重点是 修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）\n幻读 的重点是 新增/删除：在同一事务中，同样的条件，第一次和第二次读出来的 记录数不一样。（因为中间有其他事务提交了插入/删除）\n事务的隔离级别 读未提交(Read UnCommitted)：所有的事务都可以看到其他事务未提交的修改(很少用到业务中)。(脏读：Y，不可重复读：Y，幻读：Y，) 读已提交(Read Committed)：只能看到其他已经提交的事务。(脏读：N，不可重复读：Y，幻读：Y) 可重复读(Reapeatable Read)：确保同一个事务在并发读取时数据一致(MySQL 默认的事务级别)。(脏读：N，不可重复读：N，幻读：Y) 可串行化(Serializable)：串行化读取数据(最高隔离级别，锁竞争激烈)。(脏读：N，不可重复读：N，幻读：N) 不同的数据库支持的隔离级别不同。在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据库中，只支持 Serializable (串行化)级别和 Read committed (读已提交)这两种级别，其中默认的为 Read committed 级别。\nMySQL 中有哪几种锁？ 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 什么是 MVCC？ 多版本并发控制(MultiVersion Concurrency Control) 是一种并发控制的方法，一般用在数据库管理系统中，实现对数据库的并发访问。\n为什么需要 MVCC？ 主要实现对数据的隔离，解决读写之间的阻塞问题，提高读写并发度。\n最原生的锁，锁住一个资源之后禁止其他任何线程访问。但是很多应用的场景都是 读多写少，很多数据的读取次数远远大于修改的次数，而这种读数据的操作之间进行排斥就显得很没必要； 所以出现了 读写锁，读锁与读锁不互斥，而写锁与写锁、写锁与读锁之间互斥，这样已经很大地提升了系统的并发能力。 后来人们发现并发读还是不够，又提出了一种让读写之间也不冲突的方法：快照读。就是读取数据的时候通过一种类似于 “快照” 的方式将第一眼看到的数据保存下来，这样读锁和写锁就不冲突了，不同的事务会看到自己特定版本的数据。当然，“快照”是一种概念模型，不同的数据库实现方式可能不太一样。 所以我们可以看到这样的“提高并发”的演进思路：\n普通锁，串行执行 \u0026ndash;\u0026gt; 读写锁，实现读读并发 \u0026ndash;\u0026gt; MVCC，实现读写并发。\nMVCC 解决了哪些问题？ 读写之间的阻塞问题：可以实现并发读写； 降低了死锁的概率：MySQL 的 InnoDB 的 MVCC 使用了乐观锁，读数据时并不需要加锁；对于写操作，也只锁定必要的行； 解决一致性读的问题：一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。 MVCC 只在 可重复读(REPEATABLE READ) 和 提交读(READ COMMITTED) 两个隔离级别下工作。其他两个隔离级别都和 MVCC 不兼容，因为 未提交读 总是读取最新的数据行，而不是符合当前事务版本的数据行。而 可串行化则会对所有读取的行都加锁。\nMVCC 如何实现的？ Innodb 中使用 B+树 作为索引的数据结构，并且主键所在的索引称为 聚簇索引(ClusterIndex)，聚簇索引的叶子结点保存了完整的一条数据。一张表只能有一个主键，所以也只能有一个聚簇索引，如果没有定义主键，InnoDB 将使用一个隐藏列作为聚簇索引。除了 聚簇索引，还有 二级索引(SecondaryIndex)，它的叶子结点中保存的是主键。\nInnoDB 的叶子段中保存了数据页，数据页中保存了行记录，而在行记录中有三个个重要的隐藏记录：\nDB_ROW_ID(隐藏行 ID)：隐藏的行 ID，用来生成默认的聚簇索引。如果我们创建表时没有指定聚簇索引，那么 InnoDB 会使用这个隐藏 ID来创建聚簇索引。 DB_TRX_ID(行的事务ID)：操作这行数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。新增一个事务时事务ID会增加，DB_TRX_ID 能够表示事务开始的先后顺序。 DB_ROLL_PT(行的回滚指针)：回滚指针，指向这行记录的 Undo Segment 中的 undo log。 MVCC 在 MySQL 中的实现依赖的是 undo log 和 ReadView。\nundo log：\n除了记录 redo log 之外，当进行数据修改时还会记录 undo log。undo log 用于数据的撤回操作，它记录修改的反向操作，比如插入对应删除，修改对应修改为原来的数据。undo log 分为两种：Insert 和 Update，Delete 可以看做是一种特殊的 Update，即在记录上修改删除标记。而 Insert undo log 在事务提交之后可以删除，因为用不到。所以我们可以理解为：update undo log记录了数据之前的数据信息，通过这些信息可以还原到之前版本的状态。\nReadView：\n也称为 一致性读视图。它并不实际存在，只是一个概念，通过 undo log 和版本计算出来，用以决定当前事务能看到哪些数据。\n对于 READ UNCOMMITTED 隔离级别，所有事务直接读取数据库的最新值即可；SERIALIZABLE 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 ReadView 的版本控制。\n所以我们才说 MVCC 只支持 Read Committed 以及 Repeated Read 隔离级别的实现，而核心逻辑就是依赖 undo log 以及版本控制。针对这个问题 InnoDB 在设计上增加了ReadView 的设计，ReadView 中主要包含当前聚簇索引对应的、当前系统中还有哪些活跃的读写事务，把它们的 事务ID 放到一个列表中，我们把这个列表命名为为 m_ids。对于查询时版本数据能否被看到的判断依据是：\n如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问； 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问； 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 先说结论：Read Committed 和 Repeatable Read 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同：\n在 Read Committed 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态； 在 Repeatable Read 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证 可重复读(Repeatale Read)。 腾讯面试：MySQL事务与MVCC如何实现的隔离级别？ 中有一个例子特别好，以截图方式展示：\nRead Committed 下的 ReadView：\nRepeatable Read 下的 ReadView：\nMySQL 中哪些存储引擎支持事务？ MySQL 服务器层不管理事务，事务是由下层的存储引擎实现的。支持事务的存储引擎有InnoDB 和 NDB Cluster。\n什么是自动提交？ MySQL 默认使用 InnoDB 引擎，并且默认采用 自动提交(AUTOCOMMITTED) 模式。也就是说，如果不是显式地开启一个事务，则每一个查询都被当成一个事务执行提交操作。\nMySQL 支持的存储引擎 我们主要关注三个：InnoDB、MyISAM 和 Memory。\nInnoDB MySQL 的默认事务型引擎，支持事务和外键。在你增删改查时匹配的条件字段带有索引时，InnoDB 使用 行级锁；在你增删改查时匹配的条件字段不带有索引时。InnoDB 使用的将是 表级锁。\nMyISAM 旧版本MySQL 的默认存储引擎。主要特点是快，不支持事务，也不支持外键。\nMemory 使用内存空间来创建表。Memory 类型的表访问非常快，因为它的数据是放在内存中的，并且默认使用 Hash 索引，但是一旦服务关闭，表中的数据就会丢失掉。\n关于索引 按照数据结构分：哈希索引、B+树索引 和 全文索引。\n按物理存储方式分：聚簇索引 和 二级索引。\nInnoDB到底支不支持哈希索引？\nInnoDB 用户无法手动创建哈希索引，这一层上说，InnoDB 确实不支持哈希索引; InnoDB 会 自调优(self-tuning)，如果判定建立 自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB 自己会建立相关哈希索引，这一层上说，InnoDB 又是支持哈希索引的。 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 B+树索引 所有的数据都在叶子节点，非叶子结点只存储叶子结点的索引，且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序的链表，这样就可以实现范围查询。优势：\nB+Tree 它的非叶子节点不存储数据，只存储索引，而数据会存放在叶子节点中。非叶子结点存储的索引越多，叶子结点能表示的数据就越多，同样数量情况下，树的高度越小，查找数据时进行的 IO 次数就越少。 全文索引 只支持英文，实现方式为 倒排索引：先分词，再建立对应的B+树索引。\nInnoDB 中的索引策略 覆盖索引 最左前缀原则 索引下推 索引下推优化是 MySQL 5.6 引入的，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 InnoDB 中创建索引有什么原则 最左前缀匹配原则 频繁作为查询条件的字段才去创建索引 频繁更新的字段不适合创建索引 索引列不能参与计算，不能有函数操作 优先考虑扩展索引，而不是新建索引，避免不必要的索引 在order by或者group by子句中，创建索引需要注意顺序 区分度低的数据列不适合做索引列(如性别） 定义有外键的数据列一定要建立索引。 对于定义为text、image数据类型的列不要建立索引。 删除不再使用或者很少使用的索引 MySQL 分库分表 分库分表方案 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。 分库分表可能遇到的问题 事务问题：需要用分布式事务啦 跨节点Join的问题：解决这一问题可以分两次查询实现 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。 数据迁移，容量规划，扩容等问题 ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID 跨分片的排序分页问题（后台加大pagesize处理？） MySQL InnoDB 索引为什么使用 B+树？ 可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？\n为什么不是一般二叉树？ 如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。\n为什么不是平衡二叉树呢？ 我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。\n那为什么不是B树而是B+树呢？ B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。 B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。 ","permalink":"http://localhost:1313/posts/mysql%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch3 id=\"关于事务\"\u003e关于事务\u003c/h3\u003e\n\u003ch4 id=\"事务的特性\"\u003e事务的特性\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e原子性(Atomic, A)\u003c/code\u003e：要么全部执行，要么全部不执行；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e一致性(Consistent, C)\u003c/code\u003e：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e隔离性(Isolation, I)\u003c/code\u003e：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e持久性(Durability, D)\u003c/code\u003e：事务提交后，其结果永久保存在数据库中。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e事务ACID特性的实现思想\u003c/p\u003e","title":"MySQL面试汇总"},{"content":"当我们谈论 Redis 时，应该谈论什么？ Redis 基本数据类型有哪些？以及他们各自的使用场景是什么？ 常见的有五种：字符串、哈希、列表、集合、有序集合。5.0 版本中新添加了 Stream 类型。\n字符串 String: 就是常规的 GET/SET 操作。是 Redis 最基本的数据类型，一个键最大能存储 512MB(底层数据结构：SDS)； 哈希 Hash：可以理解成一个键值对的集合，十分适合存储结构化数据。比如 MySQL 中有一条记录：id=1, name=demo, age=18，那么可以使用 hash 将其存到 Redis 中：HSET user:1 name demo age 18(数据结构：ZipList 或 HashTable)； 列表 List：就是简单的字符串列表，按照插入顺序排序。比较常见的场景是当做队列或者栈使用(数据结构：QuickList，是 ZipList 和 双向链表 的组合)。 集合 Set：存放的是一堆不重复值的集合，通常用来做去重，同时还提供了不同 Set 之间求交集、并集、合集等功能，业务上也能使用的到。它底层也是通过哈希表去实现的，可以做到增删改查都是 O(1) 的复杂度(数据结构：HashTable)。 有序集合 Sorted Set：跟 Set 一样，也是一堆不重复值的集合，不同的是每一个元素都会关联一个 float64 类型的分数，而 Redis 正是基于这个分数为集合中的成员进行排序的。比较常见的使用场景是存排行榜数据，去 Top N 会非常方便(数据结构：跳表SkipList)。 流式数据 Stream：这是 V5.0 版本引入的新的数据类型，用来弥补 Pub/Sub 的不足，工作模式类似于 kafka，可以使用 XADD 往一个 stream 中发送消息，而消费者可以是单个，也可以是消费者集群，并且任意一个消费者消费之后，必须手动调用 XACK 才会完全标志这条消息被处理，特别适合做消息队列。 Redis 使用场景 热数据存储：当成缓存中间件来使用，以缓解 DB 的压力。 做消息队列：我们可以使用它的 List 或 Stream 或 Pub/Sub 来实现一个消息队列，完成业务逻辑上的数据解耦； 排行榜：利用 Redis Sorted Set 实现； 限流器：利用单线程、原子递增等特性，可以记录某个用户在某段时间内的访问量，结合业务逻辑做到限流效果； 分布式锁：setnx 命令，设置成功表示拿到锁，不成功表示没拿到锁。 Redis 是单线程还是多线程？为什么这么快？ 4.0 以前，不管是主业务逻辑还是持久化，都是单线程； 4.0 版本，引入了多线程处理 AOF 等不太核心的操作，但主 Reactor 模型依旧使用单线程。主要是体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等; 6.0 版本，主 Reactor 真正引入多线程处理用户逻辑。 既然是单线程，为什么还这么快？\n官方的 QA 里说过，Redis 是基于内存的操作，CPU 并不是 Redis 的瓶颈，最大的瓶颈可能来自于机器内存大小以及网络带宽。快的原因：\n基于内存操作，并且有许多非常优秀的的数据结构为数据存储和处理做支撑； 单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能损失； 基于 I/O 多路复用 实现了自己类似于 Reactor 模型的事件库，大大提高网络处理能力。 Redis 是如何实现分布式锁的？ 主要利用 Redis 的 SETNX 命令实现：SETNX k v，当 k 不存在时，k v 设置成功并返回成功，表示拿到锁；k 已经存在则返回失败，加锁失败。操作结束后，可以使用 del k 删除，表示释放锁；也可以在加锁的同时，给这个锁一个过期时间，避免锁没有被显式释放而造成永久锁住。\n但上述方式也存在一些问题：\nSETNX 和 EXPIRE 并不是原子性操作，如果我 SET 之后因为网络原因没有 EXPIRE，锁因为没有设置超时时间而永远无法释放。很多开源的解决方案是 通过 lua 脚本同时设置过期时间，也可以 使用原生的 SET 命令，加上 nx 选项以及对应的过期时间，都可以解决没有 没有expire造成的锁不释放 问题。 使用了 expire，但有可能出现新的问题：就是加锁的一方的执行时间超过了 expire，此时锁自动过期释放，另一个线程获得锁，此时两个线程并发运行，就会出问题，而且如果当前线程处理完后调用 expire 也会将另一个线程的锁解除；而且这个锁也不是可重入锁。 针对这个问题，Redis 作者提出了在基于分布式环境下提出了更高级的分布式锁的实现：RedLock。(不过也并不是完美的，而且实际使用时也不会给你 5 个独立的 redis master)\n结论：Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。\n缓存雪崩、缓存穿透、缓存击穿等问题 缓存雪崩 现象：大量的热 key 设置了相同的过期时间，在该时刻这些热 key 全部失效，所有的请求铺天盖地都打到了 DB。\n解决方案：不要设置相同的过期时间，可以在一个 baseDuration 上加减一个随机数。\n缓存穿透 现象：一般的逻辑都是在 redis 中找不到，就会去 DB 查，然后将结果缓存到 Redis。但是如果某些 Key 在 DB 中也不存在(如小于 0 的用户 ID)，这类 Key 每次都会进行两次无用的查询。\n解决方案：\n加强非法参数的逻辑校验，提前返回失败； 将不存在的 Key 也缓存下来； 使用布隆过滤器，可以帮助识别：哪些数据一定不存在和可能存在，提前过滤一定不存在的数据。 缓存击穿 现象：某一个热点 key 扛着非常大的并发，某一时刻这个热点 key 失效，所有请求全部打到 DB 上，像是在墙上穿了一个洞。\n解决方案：1. 设置这个热点 key 永不过期；2. 如果非要更新，那么在这个热点 key 为空的时候，设置一个锁(比如 SETNX)，只让一个请求去数据库拉取数据，取完之后释放锁，恢复正常缓存逻辑。\nRedis 持久化方式以及实现细节 Redis 是在内存中处理数据的，但断电后内存数据会消失，因此需要将内存数据通过某种方式存储到磁盘上，以便服务器重启后能够恢复原有数据，这就是 Redis 的持久化。有三种方式：\nAOF日志(Append Only File)：文件追加方式，并且以文本的形式追加到文件中； RDB快照(Redis DataBase)：将某一时刻的内存数据，以二进制的形式全部存到磁盘中； 混合持久方式：v4.0 增加了混合持久化方式，集成了 RDB 和 AOF 的优点。 AOF AOF 采用的是写后日志的方式，现将数据写入内存，再记录到日志文件中。AOF 记录的是实际的操作命令和数据，即我们在终端输入的命令。等到重启恢复时，只需要将 AOF 文件中的命令重复执行一遍(涉及到 AOF 重写)。\n命令同步到 AOF 需要经历三个阶段：\n命令追加：Redis 将执行完的命令、命令的参数等信息“传播” AOF 程序中： 缓存追加：AOF 程序根据接收到的命令数据，将命令编码为自己的网络通信协议，然后将内容追加到服务器的 AOF 缓存中(redisServer 中有一个字段叫 sds aof_buf)； 文件写入和保存：缓存数据到一定条件，在事件处理器之后，会调 flushAppendOnlyFile 函数，这个函数会执行两个操作： WRITE：将 aof_buf 中的数据缓存写入 AOF 文件中； SAVE：调用 fsync 或者 fdataasync函数，将AOF 文件保存到磁盘中； 而 AOF 的文件保存模式有三种：\n不保存：WRITE 会被执行，SAVE 只会在服务关闭等常见会被执行一次，平常会被略过。这个时候，这两个操作都是由主线程来完成的，会阻塞主线程； 每秒保存一次：WRITE 每次都被执行，SAVE 启动子线程每秒执行一次。WRITE 操作由主进程执行，阻塞主进程；SAVE 操作由子线程执行，不直接阻塞主进程，但 SAVE 完成的快慢会影响 WRITE 的阻塞时长。 每执行一个命令保存一次：每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。这两个动作都由主线程执行，会阻塞主线程。 文件重写(bgrewriteaof):\n当开启的AOF时，随着时间推移，AOF文件会越来越大,当然redis也对AOF文件进行了优化，即触发AOF文件重写条件（后续会说明）时候，redis将使用bgrewriteaof对AOF文件进行重写。这样的好处在于减少AOF文件大小，同时有利于数据的恢复。常见的重写策略：\n重复或无效的命令不写入文件； 过期的数据不再写入文件； 多条命令合并写入。 RDB 按照指定时间间隔对你的数据集生成的时间点快照。它是 Redis 数据库中数据的内存快照，它是一个二进制文件（默认名称为：dump.rdb，可修改），存储了文件生成时 Redis 数据库中所有的数据内容。在 Redis Server 重启时可以通过加载 RDB 文件来还原数据库状态。 可用于 Redis 的数据备份、转移与恢复。\nrdbSave 负责将内存中的数据以 RDB 的格式保存到磁盘中，如果 RDB 文件已经存在，那么旧的文件会被新的文件替换。\n而 SAVE 和 BGSAVE 都会调用 rdbSave 函数，但他们的执行方式不同：\nSAVE 直接调用 rdbSave，阻塞 Redis 主进程，直到保存完为止。在主进程阻塞期间，服务器不能处理任何客户端请求； BGSAVE 则会 folk 出一个子进程，子进程调用 rdbSave，并在结束后向主进程发送信号通知。因为 rdbSave 是在子进程运行的，所以并不会阻塞主进程，在此期间服务器仍旧可以继续处理客户端的请求。 其他需要注意的：\n为了避免产生竞争条件， BGSAVE 执行时， SAVE 命令不能执行。 调用 rdbLoad 函数载入 RDB 文件时，不能进行任何和数据库相关的操作，不过订阅与发布方面的命令可以正常执行，因为它们和数据库不相关联。 AOF 文件的保存频率通常要高于 RDB 文件保存的频率， 所以一般来说， AOF 文件中的数据会比 RDB 文件中的数据要新。因此， 如果服务器在启动时， 打开了 AOF 功能， 那么程序优先使用 AOF 文件来还原数据。 只有在 AOF 功能未打开的情况下，Redis 才会使用 RDB 文件来还原数据。 混合持久化 混合持久化就是 同时结合 RDB 持久化以及 AOF 持久化混合写入 AOF文件。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据，缺点是 AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性差，并且 4.0 之前的版本并不识别；\n混合持久化同样也是通过 bgrewriteaof 完成的，不同的是当开启混合持久化时，fork 出的子进程先将共享的内存副本全量的以 RDB 方式写入 AOF文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有 RDB 格式和 AOF 格式的 AOF文件 替换旧的的 AOF文件。\n总结 RDB 优点：\n是一个非常紧凑的问题，特别适合文件备份以及灾难恢复； 节省性能。开启子进程不影响主进程功能。 RDB 缺点：\nRDB 是某一时刻的快照，无法保存全部数据，在请求较大时，丢失的数据会更多。 AOF 优点：\n数据更完整，秒级数据丢失(取决于设置fsync策略)； 文件内容可读性高，方便 debug。 AOF 缺点：\n文件体积更大，且恢复速度慢于 RDB。 Redis 如何实现高可用 Redis 实现高可用主要有三种方式：主从复制、哨兵模式，以及 Redis 集群。\n主从复制 在 主从复制 中，Redis server 分为两类：主库 master 和 从库 slave。主库可以进行读写操作，当写操作导致数据变化时会自动同步到从库。而从库一般是只读的，并接受来自主库的数据，一个主库可拥有多个从库，而一个从库只能有一个主库。\n哨兵模式 哨兵(sentinel) 是官方推荐的的 高可用(HA) 解决方案。Redis 的主从高可用解决方案，这种方案的缺点在于当 master 故障时候，需要手动进行故障恢复，而 sentinel 是一个独立运行的进程，它能监控一个或多个主从集群，并能在 master 故障时候自动进行故障转移，更为理想的是 sentinel 本身是一个分布式系统，其分布式设计思想有点类似于 zookeeper，当某个时候 Master 故障后，sentinel集群 采用一致性算法来选取Leader，故障转移由 Leader 完成。而对于客户端来说，操作 Redis 的主节点，我们只需要询问 sentinel，sentinel 返回当前可用的 master，这样一来客户端不需要关注的切换而引发的客户端配置变更。\nRedis 集群 从最开始的 一主N从，到 读写分离，再到 Sentinel 哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。为什么还需要 Redis 集群？这是因为某些场景下，单实例会存在一下几个问题：\n写并发：读操作可以通过负载均衡由诸多从节点分担，但所有的写操作只能由主节点完成，在海量数据高并发场景下，主节点压力也会飙升； 海量数据的存储压力：单实例本质上是只有一台主节点作为存储，其他从结点都是复制主节点的数据，也就是说，Redis 服务的存储能力取决于主节点所能承载的上线。 为了扩展写能力和存储能力，Redis引入集群模式。\nRedis3.0 加入了 集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的 master 节点上面，从而解决了海量数据的存储问题。\n同时 Redis集群 采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。\nRedis 也内置了高可用机制，支持 N 个 master节点 ，每个 master节点 都可以挂载多个slave节点，当 master节点 挂掉时，集群会提升它的某个slave节点 作为新的master节点。\nRedis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点(其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用)。\n问：集群中那么多 master节点，集群在存储的时候如何确定选择哪个节点呢？\n采用 类一致性哈希算法 实现节点选择。\n首先，集群将自己分成 16384 个 slot(槽位)，然后让每个节点分别负责一部分槽位(范围固定)。当某个 key 到来时，某个集群的 master 会先计算这个 key 应该被分配到哪个槽位(CRC16后的哈希值与 16384 取模的结果就是应该放入的槽位号)，如果这个槽位刚好是自己负责，那么开始处理并返回；如果不属于当前节点负责的范围，那么会返回一个 moved error，并告诉你应该去哪个节点指定这个写入命令。\n问：那集群如何实现扩容？\n通过 reshard(重新分片)来实现。它可以将已经分配给某个节点的任意数量的 slot 迁移给另一个节点，同时将对应 slot 的数据也全部迁移值新的节点。\nRedis 的过期策略以及内存淘汰机制 过期策略 定期随机检测删除：Redis 默认每隔 xxx ms就随机抽取设置了过期时间的 key，检测这些 key 是否过期，如果过期就删除。\n惰性删除：不再是 Redis主动去删除，而是在客户端获取某个 key 时，先检查是否过期，没过期则正常返回，如果过期则删除并且返回 nil。\n内存淘汰机制 惰性删除可以解决一些过期了，但没被定期删除随机抽取到的 key。但有些过期的 key 既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以 Redis 提供了内存淘汰机制来解决这个问题。\nRedis 在使用内存达到某个阈值(通过 maxmemory 配置)的时候，就会触发内存淘汰机制，选取一些 key 来删除。当内存不足以容纳新写入的数据时，内存淘汰有以下几种策略：\nnoeviction：报错。默认策略。 allkeys-lru：在所有的 key 中，删除最近最少使用的 key； allkeys-random：在所有的 key 中，随机移除某个 key； volatile-lru：在所有设置了过期时间的 key中，删除最近最少使用的 key； volatile-random：在所有设置了过期时间的 key中，随机移除某个 key； volatile-ttl：在所有设置了过期时间的 key中，有更早过期时间的 key 优先移除。 Redis 中 大key 和 热key 问题 大Key 问题 现象：\n什么是大 Key：\n单个简单的 key 存储的 value 很大：会导致网络拥塞，内存使用不均(集群模式下)； hash、set、zset 以及 list 结构中存储过多的元素：单个命令耗时太长容易阻塞其他命令，严重会引起集群发生故障切换，循环故障从而整个集群宕机。 如何发现：\nRedis 监控对超多 xxx 的 kv 报警； 定时脚本不断去 scan 拿到结果进而报警然后处理优化； 利用 redis-cli --bigkeys 命令行工具分析； 使用 redis-rdb-tools 工具对 RDB 文件进行分析 如何解决：\n删除：4.0 以后有 lazy delete，不会阻塞主线程。但这只是临时方案； hash： 使用 hscan + hdel set ： 使用 sscan + srem zset ： 使用 zremrangebyrank list ： 使用 scan + ltrim 拆分，然后使用 multiGet 获取; 热Key 问题 现象：\n突然有非常大的请求去访问 Redis 上的某个特定的key，流量过于集中，甚至达到物理网卡的上限，导致这台 Redis 服务器宕机。此时，这台Redis上的其他读写请求都变得不可用；热 key 会落到同一个 Redis 实例上，无法通过扩容解决；所有的请求都打在 DB 上，Redis 都扛不住，DB 大概率会挂掉。\n如何发现：\n业务经验预估 对用户行为数据分析，如点击、加购行为都会有打点数据 如果是集群，可以利用集群 proxy 统计分析 Redis v4.3 的 redis-cli 有一个 --hotkeys 选项，可以在命令行直接获取当前 namespace 中的热点 key(实现上是通过 scan + object freq 完成的)。 利用 redis-cli monitor 抓取数据，利用现有开源工具如 redis-faina 进行分析，统计出热 key。 怎么解决：\n增加 Redis 副本数量，将读请求的压力分配到不同的副本节点上； 业务上缓存(本地缓存)：比如使用一个大小限定的 map，每次去 Redis 查询前先检查内存中是否存在，如果存在就直接返回了。 集群条件下热key 备份：在集群条件下，一个 key 会被放入指定的实例的 slot，增加集群的节点数是没有用的。为了将针对某一个 key 的请求打散到不同的实例上，可以给对应的 key 增加前缀或者后缀，这样就可以实现将热key的流量让整个集群来分担，而不是某个节点。不过整个方案需要进行一定的业务开发，比如 key 前后缀的生成方式。 Redis 通信协议简单介绍 简称 RESP(Redis Serilization Protocol)，是 Redis 自定义的用于服务端和客户端之间的通信协议。特点是：实现简单、可读性强、快速解析。\n间隔符号，在 类Unix 下是 \\r\\n，在 Windows 是 \\n。\n+：简单字符串：\u0026quot;+OK\\r\\n\u0026quot; -：错误信息：\u0026quot;-Error unknow command 'foobar'\\r\\n\u0026quot; :：整数：\u0026quot;:1000\\r\\n\u0026quot; $：批量字符串：\u0026quot;$6\\r\\nfoobar\\r\\n\u0026quot;，前面的数组表示字符串长度 *：数组：\u0026quot;\\*2\\\\r\\\\n$2\\\\r\\\\nfoo\\\\r\\\\n$3\\\\r\\\\nbar\\\\r\\\\n\u0026quot;，数组包含2个元素，分别是字符串foo和bar。 ","permalink":"http://localhost:1313/posts/redis-%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch2 id=\"当我们谈论-redis-时应该谈论什么\"\u003e当我们谈论 Redis 时，应该谈论什么？\u003c/h2\u003e\n\u003ch3 id=\"redis-基本数据类型有哪些以及他们各自的使用场景是什么\"\u003eRedis 基本数据类型有哪些？以及他们各自的使用场景是什么？\u003c/h3\u003e\n\u003cp\u003e常见的有五种：\u003ccode\u003e字符串\u003c/code\u003e、\u003ccode\u003e哈希\u003c/code\u003e、\u003ccode\u003e列表\u003c/code\u003e、\u003ccode\u003e集合\u003c/code\u003e、\u003ccode\u003e有序集合\u003c/code\u003e。\u003ccode\u003e5.0\u003c/code\u003e 版本中新添加了 \u003ccode\u003eStream\u003c/code\u003e 类型。\u003c/p\u003e","title":"Redis 面试汇总"},{"content":"一、原理 0. 简介 channel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 容量capacity。\n在 runtime 中是通过 hchan 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\ntype hchan struct { qcount uint // 环形队列中已经有的元素个数 dataqsiz uint // 环形队列容量，就是用户创建时指定的 capacity buf unsafe.Pointer // 环形队列所在的地址 elemsize uint16 // channal 中元素类型的大小 closed uint32 // channel 是否关闭 elemtype *_type // channel 元素类型 sendx uint // 环形队列中已经发送的 index recvx uint // 环形队列中已经接受的 index recvq waitq // 等待接受 channel 中消息的 goroutine 队列 sendq waitq // 等待向 channel 中发送消息的 goroutine 队列 lock mutex } 1. 用法以及常见问题汇总 已经关闭的 channel，再次关闭会 panic 向已经关闭的 channel 发送数据会造成 panic 如果从 channel 中取出元素的方式是 for-range，则在 channel 关闭时会自动退出循环 func main() { ch := make(chan int, 10) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } // 注意这里的 close，如果没有，将会出现死锁 panic close(ch) }() for j := range ch { fmt.Println(j) } } close 一个 channel 时，如果还有 sender goroutine 挂在 channel 的发送队列中，则会引起 panic。首先 close 会唤醒所有在此 channel 等待队列中的 goroutine，使其状态变为 Grunable，再看下文 3 中的 sendchan 源码就知道，当 goroutine 被唤醒之后，还会去检查 channel 是否已经被关闭，如果被关闭则会 panic。\n从已经 close 的 channel 中取值(说明已经正常关闭，channel 是空的)，会返回 channel 元素的零值。区分零值还是真实值，可以使用 comma, ok 的语法：\nx, ok := \u0026lt;- ch if !ok{ // channel 已经被关闭 // ..... } If the receiving goroutine queue of the channel is not empty, in which case the value buffer of the channel must be empty, all the goroutines in the receiving goroutine queue of the channel will be unshifted one by one, each of them will receive a zero value of the element type of the channel and be resumed to running state.\n没有通过 make 来初始化的 channel 被称为 nil channel，关闭一个 nil channel 会直接 panic 2. 创建 channel // 初始化 channel func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // 如果 hchan 中的元素不包含指针，那么也就不需要 GC var c *hchan switch { case mem == 0: /* channel 中缓冲区大小是 0(ch := make(chan int, 0)) 或者 元素类型的大小是 0(ch := make(chan struct{})) 此时所需的空间只有 hchan 这一个元素的 */ // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: /* channel 中元素的类型不是指针。 此时所需要的空间除了 hchan 的，还有对应元素的：uintptr(size)*elem.size + hchanSize 因为不是指针，GC 也不会对channel中的元素进行 scan */ // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: /* channel 中的元素包含指针。 注意，这里进行了两次空间分配，一次是给 hchan，第二次是给 channel 中的元素 */ // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } 3. 向 channel 发送 // select {case \u0026lt;-xxx} 的入口 func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } // entry point for c \u0026lt;- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } // 向一个 channel 发送数据的具体实现 // c 就是 channel 实体，ep 表示要发送的数据，block 表示是否阻塞(正常业务逻辑中是 true，如果是 select 则是 false) func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { /* 应用层的 channel 是空的，如 var ch chan int ch \u0026lt;- 1 如果非阻塞，则直接返回； 如果阻塞，也就是向一个 nil channel 发送数据，那么将永久阻塞下去 需要注意的是，空的channel 和 已经关闭的channel是不同的。向空 channel 发送将永久阻塞，向 closed channel 发送将 panic。 */ if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 数据竞争相关的检测，后面专门说明 if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread\u0026#39;s view of c.closed and full(). /* 这里的 FastPath 其实是对 非阻塞channel(select) 操作判断的一种优化：已经要求不要在 channel 上发生阻塞， 那么这里迅速做一个判断，“能失败则立刻失败”——如果 非阻塞 \u0026amp;\u0026amp; 未关闭 \u0026amp;\u0026amp; 已经满了，那就不往后面走了。 // 检查 channel 是否已经满了 func full(c *hchan) bool { // 无缓冲的 channel if c.dataqsiz == 0 { // 如果等待队列中有 goroutine 等待，那么就返回 channel 未满，可以进行后续的处理 return c.recvq.first == nil } // 有缓冲的 channel，看环形链表中的元素数量是否已经到达容量 return c.qcount == c.dataqsiz } 如何理解这个 full？ 答：For a zero-capacity (unbuffered) channel, it is always in both full and empty status. */ if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 向一个已经关闭的 channel 发送数据，会造成 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). /* 这里也是一个 FastPath： 通常情况下往一个 channel 中发送数据，会先将数据复制到环形链表中，然后 等待接受的 goroutine 来取，再讲数据从唤醒链表中拷贝到 goroutine 中。 但是考虑一种情况，等待接收的 goroutine 早就在等了(等待队列不为空)， 这个时候发送过来一个数据，就没必要再先放进 buffer、再拷贝给等待 goroutine 了， 直接将数据从发送 goroutine 的栈拷贝到接受者 goroutine 的栈中，节省资源。 */ send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. /* 如果是有缓冲的 channel 并且 buffer 中空间足够，那么就将数据拷贝到 buffer 中。 同时更新 */ qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将数据从发送 goroutine 拷贝到 buffer 中 typedmemmove(c.elemtype, qp, ep) // 发送 index++ c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } // buffer 中 已有元素数量++ c.qcount++ unlock(\u0026amp;c.lock) return true } // 如果是非阻塞的 channel(select)，发送的工作已经走完了，可以返回了，后面的都是阻塞 channel 要做的事 if !block { unlock(\u0026amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. // 在 channel 上阻塞，receiver 会帮我们完成后续的工作 // 将当前的发送 goroutine 打包成一个 sudog 结构 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 将打包好的 sudog 入队到 channel 的 sendq(发送队列)中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 将这个发送 g 的状态改变：Grunning -\u0026gt; Gwaiting，之后进入休眠 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren\u0026#39;t considered as roots of the // stack tracer. KeepAlive(ep) // 后面的是当前 goroutine 被唤醒后的逻辑 // 醒来后检查一下状态，才会返回成功 // someone woke us up. if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 醒来后发现 channel 已经被关闭了，直接 panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } 4. 从 channel 中接收 func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } // entry points for \u0026lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller\u0026#39;s stack. // 从 hchan 中接收数据，并将数据拷贝到 ep 对应的空间中。ep 可以是 nil，这种情况下数据会被丢弃； // 如果 ep 不为 nil，那么必须指向 堆 或者 调用者g的栈地址 // 这里的返回值 selected 表示是否被 select 到，received 表示是否成功接收到数据 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 从一个阻塞的 nil channel 中接收数据，则会永久阻塞 if c == nil { if !block { return } // 这种情况其实就是 goroutine 泄露 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // FastPath: 如果不阻塞并且没有内容可接收，直接返回 false false if !block \u0026amp;\u0026amp; empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026#34;open and empty\u0026#34;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026amp;c.closed) == 0 { // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. // 走到这里，说明 channel 是非阻塞的，并且已经关闭了，而且 channel 中没有数据留下，此时会返回对应值的零值 if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 当前 channel 中没有数据可读，直接返回 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { // 将 ep 设置成对应元素的零值 typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). /* 这里也是一个 FastPath：如果我们去接收的时候，发现 buffer 是空的，但是 发送等待队列不为空，那么直接从这个等待的 goroutine 中拷贝数据。 如果 buffer 不为空，那么需要先从 buffer 中拿，然后将等待队列中的元素再放到 buffer 中 */ recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } if c.qcount \u0026gt; 0 { // Receive directly from queue // 如果 buffer 中有数据可取，直接从 buffer 中拿 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 将 buffer 中的数据拷贝到目标地址 if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 清空 buffer 中取出的元素的内容 typedmemclr(c.elemtype, qp) // 接收 index++ c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // buffer 中 总数-- c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 如果非阻塞，返回 false if !block { unlock(\u0026amp;c.lock) return false, false } // no sender available: block on this channel. // 如果是阻塞的 channel，那么接收的 goroutine 将阻塞在这里 // 将等待的 goroutine 打包成 sudog，并将其放到等待队列中，之后休眠 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // 被唤醒 // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 如果 channel 没有被关闭，那就是真的 receive 到数据了 return true, success } 5. 关闭 channel func closechan(c *hchan) { // close 一个 nil channel 将 panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) // close 一个已经 closed 的 channel，将 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } // 明确关闭 channel c.closed = 1 var glist gList // release all readers /* 将所有的接收等待队列中的 goroutine 全部弹出， 每一个 goroutine 将会收到 channel 中元素类型的零值， 并且恢复到 Grunning 状态 */ for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { // 这一步设置零值 typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) /* 将所有发送队列中的 goroutine 全部弹出，并恢复到 Grunning 状态。 恢复到后将继续进行“往 channel buffer 中发送数据”操作 但这个方法中已经将 closed 设置成 1，恢复运行后会检查，如果已经 closed，则会直接 panic */ for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 二、使用 如何正确关闭 channel 不同的场景介绍几种建议方案，尤其是生产-消费模型相关的。\n1. M receivers, one sender, the sender says \u0026ldquo;no more sends\u0026rdquo; by closing the data channel 一个生产者、多个消费者，由 producer 来关闭 channel，通知数据已经发送完毕。\nfunc main(){ consumerCnt := 10 // 这里可以是缓冲的，也可以是非缓冲的 taskChan := make(chan int, consumerCnt) wg := \u0026amp;sync.WaitGroup{} go func() { for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for data := range taskChan { fmt.Printf(\u0026#34;consumer %d received: %d\\n\u0026#34;, idx, data) } }(i) } }() for i := 0; i \u0026lt; consumerCnt * 2; i++ { taskChan \u0026lt;- i } close(taskChan) wg.Wait() } 2. One receiver, N senders, the only receiver says \u0026ldquo;please stop sending more\u0026rdquo; by closing an additional signal channel 一个 consumer、多个 producer 场景，多添加一个用于 通知 的 channel，由其中一个消费者告诉生产者“已经够了，不要再发了”。\nfunc main(){ rand.Seed(time.Now().UnixNano()) producerCnt := 10 taskChan := make(chan int) wg := \u0026amp;sync.WaitGroup{} // 用于信号通知 stopChan := make(chan struct{}) // 多个 producer 一直在生产消息，直到收到停止的信号 for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { // 这是一个 try-receive 操作，尝试能否快速退出 select { case \u0026lt;-stopChan: return default: } // 即使上面刚进行了判断没有退出，但到这一步的过程中 stopChan 可能就有数据 或者 被close了 select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- rand.Intn(1000): } } }(i) } // 一个消费者 wg.Add(1) go func() { defer wg.Done() for value := range taskChan { // 在这里确定要退出的逻辑 if value%7 == 0 { fmt.Println(value) fmt.Printf(\u0026#34;%d is times of 7, bye \\n\u0026#34;, value) // 在这里使用 close(stopChan) 和 stopChan \u0026lt;- struct{}{} 都能达到同样的效果 close(stopChan) // stopChan \u0026lt;- struct{}{} return } fmt.Println(value) } }() wg.Wait() } 3. M receivers, N senders, any one of them says \u0026ldquo;let\u0026rsquo;s end the game\u0026rdquo; by notifying a moderator to close an additional signal channel 多个 producer、多个 consumer 的场景下，当其中任何一个发生异常时，全部退出。这种场景下，不能让任何一个 producer 或者 consumer 来关闭 taskChan，也不能让任何一个 consumer 来关闭 stopChan 进而通知所有的 goroutine 退出。这个时候，我们可以再添加一个类似于主持人角色的 channel，让它来做 close stopChan 这个操作。\nfunc main(){ rand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int, consumerCnt) stopChan := make(chan struct{}) // 这里必须使用有缓冲的 buffer，主要是为了避免 moderator 还没启动时就已经有一个 toStop 消息到达导致它没收到 toStop := make(chan string, 1) var stoppedBy string // moderator go func() { stoppedBy = \u0026lt;-toStop close(stopChan) }() // producer for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { value := rand.Intn(10000) if value == 0 { // 达到退出的条件 /* 注意这里的用法，直接换成 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) 是否可行？ 答案是不行，会造成死锁。 */ select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx): default: } return } // 剩下的逻辑和前一个 demo 一样 select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- value: } } }(i) } wg := \u0026amp;sync.WaitGroup{} // consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case value := \u0026lt;-taskChan: // 达到 consumer 的退出条件 if value%7 == 0 { select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, value): default: } return } fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;exit by\u0026#34;, stoppedBy) } 注意当 producer 或者 consumer 达到退出的条件时，往 toStop channel 发送数据的方式。因为 toStop 的容量只有 1，直接使用 toStop \u0026lt;- fmt.Sprintf(\u0026quot;consumer-%d\u0026quot;, value) ，当 toStop 满了塞不下了，那么所有的往里面塞的 goroutine 都将被阻塞挂起，而这些 goroutine 还在等 stopChan 通知退出，而 moderator 的实现里，只接收一个，这就造成了死锁。所以正确做法是，通过 select 尝试往 toStop 中发送，成功还好，不成功(说明已经有其他的 goroutine 通知了)直接 return。\n也可以不使用“通过 select 尝试发送”的方式，那就是让 toStop 的容量变成容纳所有可能发送的 goroutine 的数量，这个时候就可以放心直接往 toStop 里灌数据了：\n// ... toStop := make(chan string, producerCnt + consumerCnt) // ... // producer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) // ... // consumer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, idx) 4. A variant of the \u0026ldquo;N sender\u0026rdquo; situation: the data channel must be closed to tell receivers that data sending is over 上面三个 demo 中，我们都没有对 tashChan 进行明确的 close，close 操作交给了 GC。但是有些场景下，会要求没数据时一定要关闭 taskChan，然后通知调用consumer明确告知“数据已经发送完了”。但是当有多个 producer 时，直接关闭肯定行不通。再这样的场景下，可以引入一个 middle channel ，producer 的数据不再直接发给 consumer，而是先发给middle channel，这个 middle channel 只有一个 sender，可以做到 close taskChan 了。\nrand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int) middleChan := make(chan int) closing := make(chan string) done := make(chan struct{}) var stoppedBy string stop := func(by string) { select { case closing \u0026lt;- by: \u0026lt;-done case \u0026lt;-done: } } // 多个 producer，将数据发送给 middle channel for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { select { case \u0026lt;-done: return default: } value := rand.Intn(10000) if value%7 == 0 { fmt.Println(value, \u0026#34; will stop\u0026#34;) stop(\u0026#34;producer-\u0026#34; + strconv.Itoa(idx)) return } select { case \u0026lt;-done: return case middleChan \u0026lt;- value: } } }(i) } // middle channel go func() { exit := func(v int, needSend bool) { close(done) if needSend { taskChan \u0026lt;- v } close(taskChan) } for { select { case stoppedBy = \u0026lt;-closing: exit(0, false) return case v := \u0026lt;-middleChan: select { case stoppedBy = \u0026lt;-closing: exit(v, true) return case taskChan \u0026lt;- v: } } } }() wg := \u0026amp;sync.WaitGroup{} // 多个 consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-done: return default: } for value := range taskChan { fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;stopped by\u0026#34;, stoppedBy) ","permalink":"http://localhost:1313/posts/golang-channel%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一原理\"\u003e一、原理\u003c/h2\u003e\n\u003ch3 id=\"0-简介\"\u003e0. 简介\u003c/h3\u003e\n\u003cp\u003echannel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 \u003ccode\u003e容量capacity\u003c/code\u003e。\u003cbr /\u003e\n在 \u003ccode\u003eruntime\u003c/code\u003e 中是通过 \u003ccode\u003ehchan\u003c/code\u003e 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\u003cbr /\u003e\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\u003cbr /\u003e\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\u003c/p\u003e","title":"Golang Channel详解"},{"content":" Redis 设计与实现\u0026ndash;事件 中有很清晰的说明。\nredis 要处理的事件有两种类型：\n文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发； 时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。 一、时间事件 时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\n每个时间事件主要由三个属性组成：\nwhen ：以毫秒格式的 UNIX 时间戳为单位，记录了应该在什么时间点执行事件处理函数。 timeProc ：事件处理函数。 next 指向下一个时间事件，形成链表。 根据 timeProc 函数的返回值，可以将时间事件划分为两类：\n如果事件处理函数返回 ae.h/AE_NOMORE ，那么这个事件为单次执行事件：该事件会在指定的时间被处理一次，之后该事件就会被删除，不再执行。 如果事件处理函数返回一个非 AE_NOMORE 的整数值，那么这个事件为循环执行事件：该事件会在指定的时间被处理，之后它会按照事件处理函数的返回值，更新事件的 when 属性，让这个事件在之后的某个时间点再次运行，并以这种方式一直更新并运行下去。 这些常规操作主要包括：\n更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 对不合理的数据库进行大小调整。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主节点的话，对附属节点进行定期同步。 如果处于集群模式的话，对集群进行定期同步和连接测试。 二、文件事件 Redis 服务器通过在多个客户端之间进行多路复用， 从而实现高效的命令请求处理： 多个客户端通过套接字连接到 Redis 服务器中， 但只有在套接字可以无阻塞地进行读或者写时， 服务器才会和这些客户端进行交互。\nRedis 将这类因为对套接字进行多路复用而产生的事件称为文件事件（file event）， 文件事件可以分为读事件和写事件两类。\n1. 读\u0026ndash;标志着客户端命令请求的发送状态 当一个新的客户端连接到服务器时， 服务器会给为该客户端绑定读事件， 直到客户端断开连接之后， 这个读事件才会被移除。\n有两种状态：\n等待：客户端只是连接到服务器，并没有发送命令； 就绪：客户端给服务端发送命令请求、并且请求已经到达(相应的套接字可以无阻塞地执行读操作)时，读事件状态更新为“就绪”。 当一个新的客户端连接到服务器\n2. 写\u0026ndash;标志着客户端对命令结果的接受状态 服务器只会在有命令结果要传回给客户端时， 才会为客户端关联写事件， 并且在命令结果传送完毕之后， 客户端和写事件的关联就会被移除。\n也只有两种状态：\n等待：有结果返回，但客户端还未能执行无阻塞写时； 就绪：有结果返回，并且能无阻塞写时。 当客户端向服务器发送命令请求， 并且请求被接受并执行之后， 服务器就需要将保存在缓存内的命令执行结果返回给客户端， 这时服务器就会为客户端关联写事件。\n3.读 和 写的关系 读事件只有在客户端断开和服务器的连接时，才会被移除。这也就是说，当客户端关联写事件的时候，实际上它在同时关联读/写两种事件。因为在同一次文件事件处理器的调用中， 单个客户端只能执行其中一种事件（要么读，要么写，但不能又读又写）， 当出现读事件和写事件同时就绪的情况时，事件处理器优先处理读事件————也就是说， 当服务器有命令结果要返回客户端， 而客户端又有新命令请求进入时， 服务器先处理新命令请求。\n4. 常见的文件事件 为Server端的接口（TCP Socket，Unix Socket，管道）客户端连接的可读事件（在server.c的initServer()函数中） 为各个客户端连接的Socket添加读/写事件（在networking.c中） AOF的管道（Pipe）添加读/写事件（在aof.c中） Cluster集群连接的读/写事件（在cluster.c中） 主从复制连接的读/写事件（在replication.c中） Redis哨兵模式连接的读/写事件（在sentinel.c中） ","permalink":"http://localhost:1313/posts/redis%E4%BA%8C-%E4%BB%80%E4%B9%88%E6%98%AF-redis-%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://redisbook.readthedocs.io/en/latest/internal/ae.html\"\u003eRedis 设计与实现\u0026ndash;事件\u003c/a\u003e 中有很清晰的说明。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eredis 要处理的事件有两种类型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发；\u003c/li\u003e\n\u003cli\u003e时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"一时间事件\"\u003e一、时间事件\u003c/h3\u003e\n\u003cp\u003e时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\u003cbr /\u003e\n每个时间事件主要由三个属性组成：\u003c/p\u003e","title":"Redis(二): 什么是 Redis 中的事件"},{"content":"一、前言 在关注 redis 单线程/多线程 时，有几个重要的时间节点：\nBefore Redis v4.0，真正的单线程； Redis v4.0，引入多线程处理 AOF 等任务，但核心的网络模型中依旧使用单线程； Redis v6.0，正式在网络模型中实现 I/O多线程。 从 Redis v1.0 到 Redis v6.0以前，Redis 的核心网络模型一直都是一个典型的 单Reactor模型，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 单Reactor模型 的所有运作细节，为以后更好地理解新的 Multi-Reactors/Master-Workers 模型做准备。\n注：本文基于 Redis v5.0.0 版本分析。\n二、概览 Reactor 模式本质上指的是使用 I/O多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O) 的模式。传统的 单Reactor 模型中有三种角色：\nReactor：主线程，模型核心，通过事件循环不断处理事件，如果是新的连接事件，则交给 Acceptor，如果是已经连接的 I/O 事件，则交给 Handler； Acceptor：负责 server 和 client 的连接。Reactor 模式一条最重要的原则就是：I/O 操作不能阻塞主线程循环，所以对于阻塞的网络 I/O，一般都是通过 I/O 多路复用实现的，如 Linux 上的epoll，这样可以最大程度地满足“一个线程非阻塞地监听多个 I/O 事件”。当有新的连接到来是，Acceptor 创建一个新的 socket，并将这个 socket添加到 epoll 的监听队列中，指定事件类型(读事件 或 写事件)，指定对应事件发生时的回调函数，这样当此客户端的请求到来时，epoll 会调用设定好的回调函数(可以理解成 Handler)； Handler：真正的业务处理逻辑。已经建立连接的客户端请求到来后，触发 epoll 的读事件，调用 Handler 执行具体的业务逻辑。 Redis v6.0 之前的网络模型就是一个典型的 单Reactor 模型：\n我们先逐一认识一下对应的角色概念：\naeEventLoop：这是 Redis 自己实现的一个高性能事件库，里面封装了适配各个系统的 I/O多路复用(I/O multiplexing)，除了 socket 上面的事件以外，还要处理一些定时任务。服务启动时就一直循环，调用 aeProcessEvent 处理事件； client ：代表一个客户端连接。Redis 是典型的 CS 架构（Client \u0026lt;---\u0026gt; Server），客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。Redis 使用结构体 client 存储客户端的所有相关信息，包括但不限于封装的套接字连接 \u0026ndash; *conn，当前选择的数据库指针 \u0026ndash;*db，读入缓冲区 \u0026ndash; querybuf，写出缓冲区 \u0026ndash; buf，写出数据链表 \u0026ndash; reply等； acceptTcpHandler：角色 Acceptor 的实现，当有新的客户端连接时会调用这个方法，它会调用系统 accept 创建一个 socket 对象，同时创建 client 对象，并将 socket 添加到 EventLoop 的监听列表中，并注册当对应的读事件发生时的回调函数 readQueryFromClient，即绑定 Handler，这样当该客户端发起请求时，就会调用对应的回调函数处理请求； readQueryFromClient：角色 Handler 的实现，主要负责解析并执行客户端的命令请求，并将结果写到对应的 client-\u0026gt;buf 或者 client-\u0026gt;reply 中； beforeSleep：事件循环之前的操作，主要执行一些常规任务，比如将 client 中的数据写会给客户端、进行一些持久化任务等。 有了这写概念，我们可以试着描绘一下 客户端client 与 Redis server 建立连接、发起请求到接收到返回的整个过程：\nRedis 服务器启动，开启主线程事件循环 aeMain，注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来； 客户端和服务端建立网络连接，acceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上作为对应事件发生时的回调函数，并初始化一个 client 绑定这个客户端连接； 客户端发送请求命令，触发读就绪事件，主线程调用 readQueryFromClient 通过 socket 读取客户端发送过来的命令存入 client-\u0026gt;querybuf 读入缓冲区； 接着调用 processInputBuffer，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 根据 Redis 协议解析命令，最后调用 processCommand 执行命令； 根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族的一系列函数将响应数据写入到对应 client 的写出缓冲区：client-\u0026gt;buf 或者 client-\u0026gt;reply ，client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client 添加进一个 LIFO 队列 clients_pending_write； 在事件循环 aeMain 中，主线程执行 beforeSleep --\u0026gt; handleClientsWithPendingWrites，遍历 clients_pending_write 队列，调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 sendReplyToClient 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。 三、事件库 aeEventLoop 实现细节 先来看核心数据结构：\n/* State of an event based program */ typedef struct aeEventLoop { int maxfd; // 当前已经注册在此的最大文件描述符 int setsize; // 可“关心”的文件描述符数量 long long timeEventNextId; // 下一个 timer 的id time_t lastTime; // 上一轮事件循环时的系统事件，用来诊断系统时间偏差 aeFileEvent *events; // 注册的文件事件 aeTimeEvent *timeEventHead; // 注册的时间事件 aeFiredEvent *fired; // 就绪的事件 int stop; // 事件轮询是否停止 void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; // 下一次事件轮训之前的钩子函数 aeBeforeSleepProc *aftersleep; // 事件轮询结束后的钩子函数 } aeEventLoop; /* File event structure */ typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE) */ aeFileProc *rfileProc; // 读事件就绪时的回调函数 aeFileProc *wfileProc; // 写事件就绪时的回调函数 void *clientData; // fd 对应的 client 实例 } aeFileEvent; /* Time event structure */ typedef struct aeTimeEvent { long long id; /* time event identifier. */ long when_sec; /* seconds */ long when_ms; /* milliseconds */ aeTimeProc *timeProc; aeEventFinalizerProc *finalizerProc; void *clientData; struct aeTimeEvent *next; } aeTimeEvent; /* A fired event */ typedef struct aeFiredEvent { int fd; int mask; } aeFiredEvent; 关于 时间事件 和 文件事件，可参考：redis 中的事件(时间事件和文件事件)到底是什么？\naeEventLoop 的 Prototypes 有很多，我们关注几个重要的：\n1. aeEventLoop *aeCreateEventLoop(int setsize) 创建一个 aeEventLoop 实例 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; int i; if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;lastTime = time(NULL); eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; if (aeApiCreate(eventLoop) == -1) goto err; /* Events with mask == AE_NONE are not set. So let\u0026#39;s initialize the * vector with it. */ for (i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } 这个方法的实现很简单，就是一些成员变量的初始化。需要注意的是 aeApiCreate，在 src/ae.c 的最开始，有下面的代码：\n/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \u0026#34;ae_evport.c\u0026#34; #else #ifdef HAVE_EPOLL #include \u0026#34;ae_epoll.c\u0026#34; #else #ifdef HAVE_KQUEUE #include \u0026#34;ae_kqueue.c\u0026#34; #else #include \u0026#34;ae_select.c\u0026#34; #endif #endif #endif 这段代码的意思是，根据当前的系统类型，选择性能最好的 I/O多路复用 库，比如当前系统是 Linux，那么应该使用 ae_epoll，Mac 下使用 ae_kqueue等，ae_select 是保底方案。而 ae_xxx 是对不同系统下的 I/O多路复用 的封装，将底层的不同系统调用都通过统一的 API接口 和 数据结构 aeApiStates 暴露出去，供上层调用。我们看下 Linux 系统中 aeApiCreate 的实现：\ntypedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } // 创建 epoll 实例 state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 而 Mac 下的实现又是这样的：\ntypedef struct aeApiState { int kqfd; struct kevent *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct kevent)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;kqfd = kqueue(); if (state-\u0026gt;kqfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 2. aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) 监听文件事件 int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) { if (fd \u0026gt;= eventLoop-\u0026gt;setsize) { errno = ERANGE; return AE_ERR; } aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; if (aeApiAddEvent(eventLoop, fd, mask) == -1) return AE_ERR; fe-\u0026gt;mask |= mask; if (mask \u0026amp; AE_READABLE) fe-\u0026gt;rfileProc = proc; if (mask \u0026amp; AE_WRITABLE) fe-\u0026gt;wfileProc = proc; fe-\u0026gt;clientData = clientData; if (fd \u0026gt; eventLoop-\u0026gt;maxfd) eventLoop-\u0026gt;maxfd = fd; return AE_OK; } 同样，aeApiAddEvent 在不同系统下有不同的实现，在 Linux 系统中，会调用 epoll_ctl ，将 fd 添加到 epoll 实例的监听列表中，同时指定对应事件触发时的回调函数为 *proc。\n3. aeProcessEvents(aeEventLoop *eventLoop, int flags) 事件轮训处理的核心逻辑 /* The function returns the number of events processed. */ int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; // 只处理时间事件和文件事件 if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; // 先处理文件事件 if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { // 计算下一次时间事件到来之前应该阻塞等待的时长 // 调用底层的 poll 函数，获取已经就绪的事件 numevents = aeApiPoll(eventLoop, tvp); // 如果设置了 aftersleep 钩子函数，那应该在 poll 之后调用 if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); // 调用对应事件的回调函数 for (j = 0; j \u0026lt; numevents; j++) { aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[eventLoop-\u0026gt;fired[j].fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fd = eventLoop-\u0026gt;fired[j].fd; int rfired = 0; // 读事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { rfired = 1; fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } // 写事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!rfired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } processed++; } } // 最后再处理时间事件 if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; /* return the number of processed file/time events */ } 四、Redis 单线程流程详解 在这个 section，我们将通过源码的角度，看看 section 1 中的 Redis 的 单Reactor 网络模型中的实现细节，我们对照这张图开始：\n1. server 启动，创建 EventLoop 在 src/server.c 中的 main 方法中，当服务器启动时，会调用 initServer方法，在这个方法中，Redis 会创建全局唯一的 aeEventLoop 实例，并注册 Server socket 到对应的多路复用组件上，同时指定回调函数为 acceptTcpHandler，意思是服务器接收到新的连接时，应该调用 acceptTcpHandler 这个回调函数。\nvoid initServer(void) { ... // 创建全局唯一的 EventLoop 实例 server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } ... /* Create an event handler for accepting new connections in TCP and Unix * domain sockets. */ // ipfd 表示服务启动是监听的 socket 对应的 fd，epoll 监听此 fd，有读事件发生(新连接到来)时调用回调函数 acceptTcpHandler for (j = 0; j \u0026lt; server.ipfd_count; j++) { if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL) == AE_ERR) { serverPanic( \u0026#34;Unrecoverable error creating server.ipfd file event.\u0026#34;); } } } .... 2. 新连接到来时创建连接以及 client 实例 在前面我们将 server 对应的 socket 添加到 epoll 的监听队列，当有新的连接到来时，会触发读事件就绪，此时回调函数 acceptTcpHandler 就会被调用：\nvoid acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 创建 connect fd，代表 Redis Server 和客户端的一个连接(socket) cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), \u0026amp;cport); if (cfd == ANET_ERR) { if (errno != EWOULDBLOCK) serverLog(LL_WARNING, \u0026#34;Accepting client connection: %s\u0026#34;, server.neterr); return; } serverLog(LL_VERBOSE, \u0026#34;Accepted %s:%d\u0026#34;, cip, cport); acceptCommonHandler(cfd, 0, cip); } static void acceptCommonHandler(int fd, int flags, char *ip) { client *c; // 1. 为 connect fd 创建一个 Client 对象 if ((c = createClient(fd)) == NULL) { serverLog(LL_WARNING, \u0026#34;Error registering fd event for the new client: %s (fd=%d)\u0026#34;, strerror(errno), fd); close(fd); /* May be already closed, just ignore errors */ return; } // 2. 检查是否超过了最大连接数 if (listLength(server.clients) \u0026gt; server.maxclients) { char *err = \u0026#34;-ERR max number of clients reached\\r\\n\u0026#34;; /* That\u0026#39;s a best effort error message, don\u0026#39;t check write errors */ if (write(c-\u0026gt;fd, err, strlen(err)) == -1) { /* Nothing to do, Just to avoid the warning... */ } server.stat_rejected_conn++; freeClient(c); return; } // 3. 检查 protect mode 是否开启，如果开启，不允许远程登录 if (server.protected_mode \u0026amp;\u0026amp; server.bindaddr_count == 0 \u0026amp;\u0026amp; server.requirepass == NULL \u0026amp;\u0026amp; !(flags \u0026amp; CLIENT_UNIX_SOCKET) \u0026amp;\u0026amp; ip != NULL) { ... } server.stat_numconnections++; c-\u0026gt;flags |= flags; } client *createClient(int fd) { client *c = zmalloc(sizeof(client)); ... // 1. 标记 fd 为非阻塞 anetNonBlock(NULL, fd); // 2. 设置不开启 Nagle 算法 anetEnableTcpNoDelay(NULL, fd); // 3. 设置 KeepAlive if (server.tcpkeepalive) anetKeepAlive(NULL, fd, server.tcpkeepalive); // 4. 为 fd 创建对应的文件事件监听对应 socket 的读事件，并指定对应事件发生之后的回调函数为 readQueryFromClient if (aeCreateFileEvent(server.el, fd, AE_READABLE, readQueryFromClient, c) == AE_ERR) { close(fd); zfree(c); return NULL; } // 5. 默认使用 0 号 db selectDb(c, 0); uint64_t client_id; // 6. 设置 client 其他默认属性 atomicGetIncr(server.next_client_id, client_id, 1); c-\u0026gt;id = client_id; c-\u0026gt;fd = fd; ... return c; } 在这个方法中，主要做了以下几件事：\n为新连接创建一个 socket，并将这个 socket 添加到 epoll 的监听队列中，注册读事件，并指定对应读事件触发后的回调函数为 readQueryFromClient； 创建一个 client 对象，将 client、socket 等互相绑定，建立联系。 3. 客户端请求到来，执行具体的 handler 在 createClient 中我们知道对应客户端的 socket 上有事件发生时，回调函数是 readQueryFromClient。这个方法主要做一件事：将客户端的请求读取到 client 对象的 querybuf 中。之后再调用 processInputBufferAndReplicate 进一步处理请求。\nvoid readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 调用 read 从 socket 中读取客户端请求数据到 client-\u0026gt;querybuf c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); nread = read(fd, c-\u0026gt;querybuf+qblen, readlen); ... // 如果 client-\u0026gt;querybuf 的大小超过 client_max_querybuf_len，直接返回错误，并关闭连接 if (sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClient(c); return; } // 处理客户端请求 processInputBufferAndReplicate(c); } 再来看 processInputBufferAndReplicate 的实现，它其实是 processInputBuffer 的封装，多加了一层判断：如果是普通的 server，则直接调用 processInputBuffer ；如果是主从客户端，还需要将命令同步到自己的从服务器中。\nvoid processInputBufferAndReplicate(client *c) { if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) { processInputBuffer(c); } else { size_t prev_offset = c-\u0026gt;reploff; processInputBuffer(c); size_t applied = c-\u0026gt;reploff - prev_offset; if (applied) { replicationFeedSlavesFromMasterStream(server.slaves, c-\u0026gt;pending_querybuf, applied); sdsrange(c-\u0026gt;pending_querybuf,applied,-1); } } } processInputBuffer 会试着先从缓冲区中解析命令类型，判断类型，之后调用 processCommand 执行：\nvoid processInputBuffer(client *c) { // 设置 server 的当前处理 client 为c，可以理解为获得了 server 这把锁 server.current_client = c; // 不断从 querybuf 中取出数据解析成成对的命令，直到 querybuf 为空 while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { // 进行一些 flags 的判断 ... // 根据命令类型判断是 单条指令 还是 多条指令一起执行 if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); } // 参数个数为 0 时重置客户端，可以接收下一个命令 if (c-\u0026gt;argc == 0) { resetClient(c); } else { // 执行命令 if (processCommand(c) == C_OK) { // 集群信息同步 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MULTI)) { /* Update the applied replication offset of our master. */ c-\u0026gt;reploff = c-\u0026gt;read_reploff - sdslen(c-\u0026gt;querybuf) + c-\u0026gt;qb_pos; } // 如果不是阻塞状态，则重置client，可以接受下一个命令 if (!(c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) || c-\u0026gt;btype != BLOCKED_MODULE) resetClient(c); } // 释放“锁” if (server.current_client == NULL) break; } } // 重置 querybuf if (c-\u0026gt;qb_pos) { sdsrange(c-\u0026gt;querybuf,c-\u0026gt;qb_pos,-1); c-\u0026gt;qb_pos = 0; } server.current_client = NULL; } 我们再来看 processCommand，在真正执行命令之前，会进行非常多的校验，校验通过后才会真正执行对应的命令。\nint processCommand(client *c) { // 1. 如果命令是 quit，则直接退出 if (!strcasecmp(c-\u0026gt;argv[0]-\u0026gt;ptr, \u0026#34;quit\u0026#34;)) { addReply(c, shared.ok); c-\u0026gt;flags |= CLIENT_CLOSE_AFTER_REPLY; return C_ERR; } // 2. 在 command table 寻找对应命令的处理函数， c-\u0026gt;cmd = c-\u0026gt;lastcmd = lookupCommand(c-\u0026gt;argv[0]-\u0026gt;ptr); ... // 3. 用户权限校验 if (server.requirepass \u0026amp;\u0026amp; !c-\u0026gt;authenticated \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand) { flagTransaction(c); addReply(c, shared.noautherr); return C_OK; } // 4. 如果是集群模式，还需要处理集群 node 重定向 if (server.cluster_enabled \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_LUA \u0026amp;\u0026amp; server.lua_caller-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;getkeys_proc == NULL \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;firstkey == 0 \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand)) { ... } // 5. 处理 maxmemory 情形 if (server.maxmemory \u0026amp;\u0026amp; !server.lua_timedout) { ... } // 6. 非 master 或者 磁盘有问题是，不要进行 AOF 等持久化操作 int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE \u0026amp;\u0026amp; server.masterhost == NULL \u0026amp;\u0026amp; (c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE || c-\u0026gt;cmd-\u0026gt;proc == pingCommand)) { flagTransaction(c); if (deny_write_type == DISK_ERROR_TYPE_RDB) addReply(c, shared.bgsaveerr); else addReplySds(c, sdscatprintf(sdsempty(), \u0026#34;-MISCONF Errors writing to the AOF file: %s\\r\\n\u0026#34;, strerror(server.aof_last_write_errno))); return C_OK; } // 7. 当此服务器时master时：如果配置了 repl_min_slaves_to_write，当slave数目小于时，禁止执行写命令 if (server.masterhost == NULL \u0026amp;\u0026amp; server.repl_min_slaves_to_write \u0026amp;\u0026amp; server.repl_min_slaves_max_lag \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE \u0026amp;\u0026amp; server.repl_good_slaves_count \u0026lt; server.repl_min_slaves_to_write) { flagTransaction(c); addReply(c, shared.noreplicaserr); return C_OK; } // 8. 当只读时，除了 master 的命令，不执行任何其他指令 if (server.masterhost \u0026amp;\u0026amp; server.repl_slave_ro \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE) { addReply(c, shared.roslaveerr); return C_OK; } // 9. 当客户端处于 Pub/Sub 时，只处理部分命令 if (c-\u0026gt;flags \u0026amp; CLIENT_PUBSUB \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != pingCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != subscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != unsubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != psubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != punsubscribeCommand) { addReplyError(c, \u0026#34;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\u0026#34;); return C_OK; } // 10. 服务器为slave，但是没有连接 master 时，只会执行带有 CMD_STALE 标志的命令，如 info 等 if (server.masterhost \u0026amp;\u0026amp; server.repl_state != REPL_STATE_CONNECTED \u0026amp;\u0026amp; server.repl_serve_stale_data == 0 \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_STALE)) { flagTransaction(c); addReply(c, shared.masterdownerr); return C_OK; } // 11. 正在加载数据库时，只会执行带有 CMD_LOADING 标志的命令，其余都会被拒绝 if (server.loading \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_LOADING)) { addReply(c, shared.loadingerr); return C_OK; } // 12. 当服务器因为执行lua脚本阻塞时，只会执行部分命令，其余都会拒绝 if (server.lua_timedout \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != replconfCommand \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == shutdownCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;n\u0026#39;) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == scriptCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;k\u0026#39;)) { flagTransaction(c); addReply(c, shared.slowscripterr); return C_OK; } // 13. 真正执行命令 if (c-\u0026gt;flags \u0026amp; CLIENT_MULTI \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != discardCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != multiCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != watchCommand) { // 如果是事务命令，则开启事务，命令进入等待队列 queueMultiCommand(c); addReply(c, shared.queued); } else { // 否则调用 call 直接执行 call(c, CMD_CALL_FULL); c-\u0026gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); } return C_OK; } 最后就是 call 函数，这是 Redis 执行命令的核心函数，它会处理通用的执行命令的前置和后续操作：\n如果有监视器 monitor，则需要将命令发送给监视器； 调用 redisCommand 的 proc 方法，执行对应具体的命令逻辑； 如果开启了 CMD_CALL_SLOWLOG，则需要记录慢查询日志； 如果开启了 CMD_CALL_STATS，则需要记录一些统计信息； 如果开启了 CMD_CALL_PROPAGATE，则当 dirty 大于0时，需要调用 propagate 方法来进行命令传播(命令传播就是将命令写入 repl-backlog-buffer 缓冲中，并发送给各个从服务器中。)。 void call(client *c, int flags) { .... start = ustime(); c-\u0026gt;cmd-\u0026gt;proc(c); duration = ustime() - start; .... } 经过上面的过程，命令执行结束，对应的结果已经写在了 client-\u0026gt;buf缓冲区 或者 client-\u0026gt;reply链表中：client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client添加进一个 LIFO 队列 server.clients_pending_write。\n4. 在下一次事件循环之前，将写缓冲区中的数据发送给客户端 这个过程在主事件循环之前的钩子函数 beforeSleep 中，这个函数在 main 中指定，在 aeMain 中执行：\nint main(int argc, char **argv) { ... aeSetBeforeSleepProc(server.el, beforeSleep); aeSetAfterSleepProc(server.el, afterSleep); aeMain(server.el); // 启动单线程网络模型 .... } void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; // 这是一个死循环，一直到 redis-server 停止 while (!eventLoop-\u0026gt;stop) { if (eventLoop-\u0026gt;beforesleep != NULL) eventLoop-\u0026gt;beforesleep(eventLoop); aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP); // 处理三个事件：time file call_after_sleep } } 再具体的实现中，我们只关注如何将写缓冲区的数据写回给客户端：\nvoid beforeSleep(struct aeEventLoop *eventLoop) { ... /* Handle writes with pending output buffers. */ handleClientsWithPendingWrites(); .... } int handleClientsWithPendingWrites(void) { listIter li; listNode *ln; int processed = listLength(server.clients_pending_write); // clients_pending_write 是一个 client 队列，listRewind 获取一个用于迭代的游标 listRewind(server.clients_pending_write,\u0026amp;li); // 当队列不为空时，持续进行下面的逻辑处理 while((ln = listNext(\u0026amp;li))) { client *c = listNodeValue(ln); c-\u0026gt;flags \u0026amp;= ~CLIENT_PENDING_WRITE; // 将遍历过 client 从队列中删除 listDelNode(server.clients_pending_write,ln); /* If a client is protected, don\u0026#39;t do anything, * that may trigger write error or recreate handler. */ if (c-\u0026gt;flags \u0026amp; CLIENT_PROTECTED) continue; // 将 client 的数据写回 client 对应的s ocket if (writeToClient(c-\u0026gt;fd,c,0) == C_ERR) continue; // 这次一次性没发完，那就给对应 socket 创建额外的写事件 if (clientHasPendingReplies(c)) { int ae_flags = AE_WRITABLE; /* For the fsync=always policy, we want that a given FD is never * served for reading and writing in the same event loop iteration, * so that in the middle of receiving the query, and serving it * to the client, we\u0026#39;ll call beforeSleep() that will do the * actual fsync of AOF to disk. AE_BARRIER ensures that. */ if (server.aof_state == AOF_ON \u0026amp;\u0026amp; server.aof_fsync == AOF_FSYNC_ALWAYS) { ae_flags |= AE_BARRIER; } if (aeCreateFileEvent(server.el, c-\u0026gt;fd, ae_flags, sendReplyToClient, c) == AE_ERR) { freeClientAsync(c); } } } return processed; } 对 client-\u0026gt;buf 和 client-\u0026gt;reply 的处理在 writeToClient 方法中：\n/* Write data in output buffers to client. Return C_OK if the client * is still valid after the call, C_ERR if it was freed. */ int writeToClient(int fd, client *c, int handler_installed) { ssize_t nwritten = 0, totwritten = 0; size_t objlen; clientReplyBlock *o; while(clientHasPendingReplies(c)) { // 优先处理 buf，先发送一批。在执行之前会判断如果 client-\u0026gt;buf 中有数据，则发送 client-\u0026gt;buf 中的 if (c-\u0026gt;bufpos \u0026gt; 0) { nwritten = write(fd,c-\u0026gt;buf+c-\u0026gt;sentlen,c-\u0026gt;bufpos-c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If the buffer was sent, set bufpos to zero to continue with * the remainder of the reply. */ if ((int)c-\u0026gt;sentlen == c-\u0026gt;bufpos) { c-\u0026gt;bufpos = 0; c-\u0026gt;sentlen = 0; } } else { // client-\u0026gt;buf 中没数据了，则处理 client-\u0026gt;reply 链表中剩下的 o = listNodeValue(listFirst(c-\u0026gt;reply)); objlen = o-\u0026gt;used; if (objlen == 0) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); continue; } nwritten = write(fd, o-\u0026gt;buf + c-\u0026gt;sentlen, objlen - c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If we fully sent the object on head go to the next one */ if (c-\u0026gt;sentlen == objlen) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); c-\u0026gt;sentlen = 0; /* If there are no longer objects in the list, we expect * the count of reply bytes to be exactly zero. */ if (listLength(c-\u0026gt;reply) == 0) serverAssert(c-\u0026gt;reply_bytes == 0); } } if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } server.stat_net_output_bytes += totwritten; if (nwritten == -1) { if (errno == EAGAIN) { nwritten = 0; } else { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, strerror(errno)); freeClient(c); return C_ERR; } } if (totwritten \u0026gt; 0) { /* For clients representing masters we don\u0026#39;t count sending data * as an interaction, since we always send REPLCONF ACK commands * that take some time to just fill the socket output buffer. * We just rely on data / pings received for timeout detection. */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } // 数据全部发送完毕了，那么前一步因为没发完而创建的文件监听事件可以从 EventLoop 中删除了 if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; if (handler_installed) aeDeleteFileEvent(server.el,c-\u0026gt;fd,AE_WRITABLE); /* Close connection after entire reply has been sent. */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClient(c); return C_ERR; } } return C_OK; } ","permalink":"http://localhost:1313/posts/redis%E4%B8%80-redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e在关注 \u003cstrong\u003eredis 单线程/多线程\u003c/strong\u003e 时，有几个重要的时间节点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBefore \u003ccode\u003eRedis v4.0\u003c/code\u003e，真正的单线程；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v4.0\u003c/code\u003e，引入多线程处理 \u003ccode\u003eAOF\u003c/code\u003e 等任务，但\u003cstrong\u003e核心的网络模型中依旧使用单线程\u003c/strong\u003e；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v6.0\u003c/code\u003e，正式在网络模型中实现 \u003ccode\u003eI/O多线程\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e从 \u003ccode\u003eRedis v1.0\u003c/code\u003e 到 \u003ccode\u003eRedis v6.0以前\u003c/code\u003e，Redis 的核心网络模型一直都是一个典型的 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e 的所有运作细节，为以后更好地理解新的 \u003cstrong\u003eMulti-Reactors/Master-Workers\u003c/strong\u003e 模型做准备。\u003c/p\u003e","title":"Redis系列(一): Redis 单线程事件循环"},{"content":"题目描述 使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\n1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z 思路 使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\n代码参考 func printEach() { letter, number := make(chan bool), make(chan bool) wait := sync.WaitGroup{} go func() { i := 1 for { select { case \u0026lt;-number: fmt.Print(i) i++ letter \u0026lt;- true } } }() wait.Add(1) go func(wait *sync.WaitGroup) { str := \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34; i := 0 for { select { case \u0026lt;-letter: if i \u0026gt;= len(str) { wait.Done() return } fmt.Print(str[i : i+1]) i++ if i \u0026gt;= len(str) { wait.Done() return } number \u0026lt;- true } } }(\u0026amp;wait) // 让数字先开始打印 number \u0026lt;- true // 等待循环结束，表示整个打印可以结束了 wait.Wait() // 最后关闭 channel，防止内存泄露 close(letter) close(number) } 代码解释：\nletter 用于通知打印字母，number 用于通知打印数字。\nsync.Waitgroup{} 用于阻塞主线程等待整个打印过程结束。\n倒数第 4 行中的 number \u0026lt;- true 表示让数字先开始打印。\n结束后记得关闭 channel，防止内存泄露\n扩展 有三个函数，分别可以打印 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo;，要求每个函数都起一个 goroutine，并按照 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo; 的顺序打印在屏幕上，5 次。\nfunc printCatDogFish(){ cat, dog, fish := make(chan struct{}), make(chan struct{}), make(chan struct{}) wg := \u0026amp;sync.WaitGroup{} target := 100 go func() { // cat for { select { case \u0026lt;-cat: fmt.Println(\u0026#34;cat\u0026#34;) dog \u0026lt;- struct{}{} } } }() go func() { // dog for { select { case \u0026lt;-dog: fmt.Println(\u0026#34;dog\u0026#34;) fish \u0026lt;- struct{}{} } } }() wg.Add(1) go func(w *sync.WaitGroup) { // fish defer w.Done() i := 0 for { select { case \u0026lt;-fish: fmt.Println(\u0026#34;fish\u0026#34;) i++ if i \u0026gt;= target { return } cat \u0026lt;- struct{}{} } } }(wg) cat \u0026lt;- struct{}{} wg.Wait() close(cat) close(dog) close(fish) } ","permalink":"http://localhost:1313/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003ch3 id=\"题目描述\"\u003e题目描述\u003c/h3\u003e\n\u003cp\u003e使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"思路\"\u003e思路\u003c/h3\u003e\n\u003cp\u003e使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\u003c/p\u003e","title":"面试题:交替打印数字和字符串"},{"content":" 本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\n一、介绍 当我们谈论加解密方式时，通常有两种情形：对称加密 和 非对称加密。\n对于 对称加密，加密和解密使用同一份秘钥，加密者必须将加密方式告知使用者，否则使用者无法解密，这就面临着 “秘钥配送问题”。\n而在 非对称加密 中，有公钥和私钥加密使用公钥，解密使用私钥；公钥是公开的，任何人都可以获得，私钥则是保密的。只有持有私钥的人才能解开被对应公钥加密的数据。因此非对称加密算法，也称公钥加密算法。\n如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。\n1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做 RSA算法。从那时直到现在，RSA 算法一直是最广为使用的\u0026quot;非对称加密算法\u0026quot;。毫不夸张地说，只要有计算机网络的地方，就有 RSA 算法。\n这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA 密钥是 768 个二进制位。也就是说，长度超过 768 位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024 位的 RSA 密钥 基本安全，2048 位的密钥极其安全。\n二、使用 Golang 的标准库中已经对 RSA 相关的加密算法进行了实现，这里展示基本用法 以及 使用自定义密码 的场景。\n对 RSA 的使用大致分为三个步骤：\nRSAGenKey 生成公钥和私钥； RSAEncrypt 加密数据，传入 待加密数据 和 公钥，返回 加密后的数据； RSADecrypt 解密数据，传入 被加密的数据 和 私钥，返回 解密后的数据。 1. RSA 加密的基本用法 // RSAGenKey 生成公私钥 func RSAGenKey(bits int) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥（bits=1024基本安全，2048 极其安全） privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 4、通过pem将设置的数据进行编码，并写入磁盘文件 // fPrivate, err := os.Create(\u0026#34;privateKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPrivate.Close() // err = pem.Encode(fPrivate, block1) // if err != nil { // return err // } // 4. 有两种方式，一种是将秘钥写入文件，一种是当成返回值返回，由使用者自行决定 prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } // fPublic, err := os.Create(\u0026#34;publicKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPublic.Close() // pem.Encode(fPublic, \u0026amp;block2) // 同样，可以将公钥写入文件，也可以直接返回 pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // RSAEncrypt 对数据进行加密操作 func RSAEncrypt(src []byte, pubKey []byte) (res []byte, err error) { block, _ := pem.Decode(pubKey) // 使用X509将解码之后的数据 解析出来 keyInit, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return } publicKey := keyInit.(*rsa.PublicKey) // 使用公钥加密数据 res, err = rsa.EncryptPKCS1v15(rand.Reader, publicKey, src) return } // 对数据进行解密操作 func RSADecrypt(src []byte, prvKey []byte) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo:\nfunc main() { sourceData := \u0026#34;我的头发长，天下我为王\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKey(2048) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecrypt(encryptData, prvKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 我的头发长，天下我为王 after encrypt: [153 1 185 195 ...(很长的字节数组)] after decrypt: 我的头发长，天下我为王 equal? true 2. 使用自定义密码的 RSA 算法 有时候我们想在随机生成的基础上加上自定义的密码，可以使用下面的方式：\n// RSAGenKeyWithPwd generate rsa pair key with specified password func RSAGenKeyWithPwd(bits int, pwd string) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥 privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 通过自定义密码加密 if pwd != \u0026#34;\u0026#34; { block1, err = x509.EncryptPEMBlock(rand.Reader, block1.Type, block1.Bytes, []byte(pwd), x509.PEMCipherAES256) if err != nil { return nil, nil, err } } prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // 加密方式与 RSAEncrypt 没有区别，可以共用 // RSADecryptWithPwd decrypt src with private key and password func RSADecryptWithPwd(src []byte, prvKey []byte, pwd string) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes if pwd != \u0026#34;\u0026#34; { blockBytes, err = x509.DecryptPEMBlock(block, []byte(pwd)) if err != nil { return nil, err } } privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo：\nfunc main() { sourceData := \u0026#34;好的代码本身就是最好的说明文档\u0026#34; pwd := \u0026#34;123456\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKeyWithPwd(2048, pwd) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecryptWithPwd(encryptData, prvKey, pwd) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 好的代码本身就是最好的说明文档 after encrypt: [136 134 26 233 ...(很长的字节数组)] after decrypt: 好的代码本身就是最好的说明文档 equal? true 参考文章： golang 使用 RSA 生成公私钥，加密，解密，并使用 SHA256 进行签名，验证 GO 语言 RSA 加密解密 go - 如何在 golang 中使用密码创建 rsa 私钥 RSA 算法原理（一） ","permalink":"http://localhost:1313/posts/golang%E4%B8%AD%E4%BD%BF%E7%94%A8rsa%E8%BF%9B%E8%A1%8C%E5%8A%A0%E8%A7%A3%E5%AF%86/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003e本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\u003c/p\u003e\n\u003ch2 id=\"一介绍\"\u003e一、介绍\u003c/h2\u003e\n\u003cp\u003e当我们谈论加解密方式时，通常有两种情形：\u003cstrong\u003e对称加密\u003c/strong\u003e 和 \u003cstrong\u003e非对称加密\u003c/strong\u003e。\u003c/p\u003e","title":"Golang中使用RSA进行加解密"},{"content":"介绍 boltdb 是一个使用 Go 编写的键值对数据库，它的目标是 简单、快速和稳定的轻型数据库，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\n使用 1. 安装 go get github.com/boltdb/bolt/... 2. 打开(Open)一个数据库文件连接 func main() { dbPath := \u0026#34;./data.db\u0026#34; // 指定你的数据库文件要存储的地方 db, err := bolt.Open(dbPath, os.ModePerm, nil) if err != nil { panic(err) } ... } bolt 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 Open 操作添加超时：\ndb, err := bolt.Open(dbPath, os.ModePerm, \u0026amp;bolt.Options{Timeout: time.Second * 5}) 运行如上代码，如果 5 秒内未能成功打开文件，会返回一个 timeout 错误。\n3. 事务(Transaction) 在某一时刻， bolt 只允许有一个读写事务 或者 允许多个只读事务。其事务的隔离级别对应 MySQL 中的 可重复读，即每一个事务在 commit 之前，多次读库多看到的信息视图是一致的。\n3.1 读写事务(Read-write Transactions) 启动一个 读写事务，可以通过下面的方式：\nerr := db.Update(func(tx *bolt.Tx) error { ... return nil }) if err != nil { log.Fatal(err) } 或者：\n// open a Read-write transaction with the first argument `true` tx,err := db.Begin(true) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } Update 中的函数就是一个 可重复读 的事务，在这个函数里面可以进行任何的数据库操作。最后需要通过 return nil 来提交修改；如果提交一个 error，那么整个修改会进行 Rollback，回到最初的状态，不会产生任何改变。注意，在 Update 中手动进行 Rollback，会造成 panic。\n3.2 只读事务(Read-only Transactions) 通过下面的方式打开一个只读事务：\nerr := db.View(func(tx *bolt.Tx) error { ... return nil }) 或者：\n// open a Read-only transaction with the first argument `false` tx,err := db.Begin(false) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } 需要注意的是，在 View 只读事务中，无法做一些“写入”操作，能做的可以是：读一个 bucket，读对应 bucket 中的值，或者复制整个 db。注意，在 View 中手动进行 Rollback，会造成 panic。\n3.3 批量读写事务(Batch read-write transactions) 通过以下方式使用 Batch：\nerr := db.Batch(func(tx *bolt.Tx) error { b := tx.Bucket(bucketName) for i := 0; i \u0026lt; 100; i++ { if err := b.Put([]byte(fmt.Sprintf(\u0026#34;name-%d\u0026#34;, i+1)), []byte(fmt.Sprintf(\u0026#34;%d\u0026#34;, rand.Int31n(math.MaxInt32)))); err != nil { return err } } return nil }) Batch 和 Update 相似，以下情形除外：\nBatch 中的操作可以被合并成一个 transaction； 传给 Batch 的函数可能被执行多次，不管返回的 error 是否为 nil 这也就意味着，Batch 里面的操作必须是幂等的，这似乎会带来一些额外的工作，因此之建议在 多个 goroutine 同时调用的时候使用。\n创建一个 DB 对象是线程安全的，但一个事务里面的操作并不是线程安全的。另外，读写事务 和 只读事务 不应该相互依赖，或者不应该同时在同一个 goroutine 中被长时间打开，因为 读写事务 需要周期性地 re-map 数据，但是当 只读事务 打开时，这个操作会造成死锁。\n4. bolt 的读与写 首先，不管是读还是写，都需要先指定一个 bucket，这个概念类似于关系型数据库中的 table。对于 bucket 的操作，有以下几种：\nCreateBucket 创建一个 bucket ，但当 bucket 已经存在时，会返回错误 bucket already exists；如果成功，会返回一个 Bucket对象： bucketName := \u0026#34;my-bucket\u0026#34; _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，当 bucket 已经存在时，会返回错误 b, err := tx.CreateBucket([]byte(bucketName)) if err != nil { return err } // ... do some thing return nil }) CreateBucketIfNotExists 创建一个 bucket，创建成功 或 bucket已经存在时，返回 Bucket 对象： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // ... return nil }) Bucket 选择一个已经存在的 bucket，bucket 不存在时不会报错，但返回的 Bucket 对象为 nil，后续所有对 b 的操作都会造成空指针错误： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式选择一个已经存在的 bucket b, err := tx.Bucket([]byte(bucketName)) if err != nil { return err } fmt.Println(b == nil) // 如果 bucket 不存在，则 b 为 nil，后面所有对 b 的操作都会造成空指针错误 return nil }) DeleteBucket 删除一个已经存在的 bucket，如果 bucket 不存在会返回 bucket not found 错误。 _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式删除一个已经存在的 bucket，如果 bucket 不存在会返回 `bucket not found` 错误 err := tx.DeleteBucket([]byte(bucketName)) if err != nil { return err } return nil }) 4.1 写 或 修改 只有一种方式：使用 Put(k,v []byte) 方法。\n_ = db.Update(func (tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // set name = Jemmy err = b.Put([]byte(\u0026#34;name\u0026#34;),[]byte(\u0026#34;Jemmy\u0026#34;)) if err != nil { return err } }) Value 不一定是一个字符串，你可以存储整个序列化后的对象：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket111\u0026#34; err = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } u := \u0026amp;User{ ID: 1, Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) err = b.Put([]byte(key), data) if err != nil { return err } fmt.Printf(\u0026#34;%s\\n\u0026#34;, b.Get([]byte(key))) return nil }) if err != nil { log.Fatal(err) } } 输出：\n{\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 比较有用的一个技巧：可以使用 NextSequence() 得到一个递增的 unique identifier，你可以把它理解成 MySQL 中的递增主键：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket222\u0026#34; err = db.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } for i:=0;i\u0026lt;5;i++ { u := \u0026amp;User{ Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } // 获取一个主键值。只有当 Tx被关闭 或者 b不可写 时，才会返回错误。在 Update() 函数中不可能发生 id, err := b.NextSequence() if err != nil { return err } u.ID = id // 将 user 序列化成 []byte data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) // 使用 Put 保存 err = b.Put([]byte(key), data) if err != nil { return err } } return nil }) if err != nil { log.Fatal(err) } _ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) } 输出：\nkey=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 4.2 读取 正如上面代码所示，你可以使用 func (b *Bucket) Get(key []byte) []byte 。下面介绍一些更高阶的用法：\n遍历整个 bucket: bolt 通过 byte-sorted 的顺序在 bucket 中存储键值对，这个设计使得对 key 的迭代遍历非常方便也非常快：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 使用 游标 cursor 可以非常方便地移动，类似的函数还有：\nFirst() Move to the first key. Last() Move to the last key. Seek() Move to a specific key. Next() Move to the next key. Prev() Move to the previous key. 所以你可以使用下面的方式进行倒序遍历：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.Last(); k != nil; k, v = c.Prev() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 当然，如果你明确知道你要遍历整个 bucket，并且是正序输出，也可以通过 ForEach：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) err := b.ForEach(func(k, v []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) return nil }) if err != nil { return err } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 前缀匹配搜索，可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() prefix := []byte(\u0026#34;1\u0026#34;) for k, v := c.Seek(prefix); k != nil \u0026amp;\u0026amp; bytes.HasPrefix(k, prefix); k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 范围搜索，也可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() min := []byte(\u0026#34;1\u0026#34;) max := []byte(\u0026#34;3\u0026#34;) for k, v := c.Seek(min); k != nil \u0026amp;\u0026amp; bytes.Compare(k, max) \u0026lt;= 0; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} ","permalink":"http://localhost:1313/posts/boltdb%E4%BD%BF%E7%94%A8%E4%B8%80%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/boltdb/bolt\"\u003eboltdb\u003c/a\u003e 是一个使用 Go 编写的键值对数据库，它的目标是 \u003cstrong\u003e简单、快速和稳定的轻型数据库\u003c/strong\u003e，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\u003c/p\u003e\n\u003ch2 id=\"使用\"\u003e使用\u003c/h2\u003e\n\u003ch3 id=\"1-安装\"\u003e1. 安装\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ego get github.com/boltdb/bolt/...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-打开open一个数据库文件连接\"\u003e2. 打开(Open)一个数据库文件连接\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;./data.db\u0026#34;\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 指定你的数据库文件要存储的地方\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edb\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebolt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eOpen\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eos\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eModePerm\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tpanic(\u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003ebolt\u003c/code\u003e 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 \u003ccode\u003eOpen\u003c/code\u003e 操作添加超时：\u003c/p\u003e","title":"Boltdb使用(一)基本用法"},{"content":" 实验机器：MacBook Pro (Retina, 15-inch, Mid 2015)\nGolang 版本：go version go1.14.6 darwin/amd64\n一、前言 网卡 也称 网络适配器，是电脑与局域网进行相互连接的设备，在 OSI 七层模型中，工作在 物理层 和 数据链路层，其作用可以简单描述为：\n将本机的数据封装成帧，通过网线发送到网络上去； 接收网络上其他设别传过来的帧，将其重新组合成数据，向上层传输到本机的应用程序中。 这里的网卡指的是真实的网卡，是一个真实的物理设备。今天我们要了解的是一个叫 虚拟网卡 的东西。\n在当前的云计算时代，虚拟机和容器的盛行离不开网络管理设备，即 虚拟网络设备，或者说是 虚拟网卡。虚拟网卡有以下好处：\n对用户来说，虚拟网卡和真实网卡几乎没有区别。我们对虚拟网卡的操作不会影响到真实的网卡，不会影响到本机网络； 虚拟网卡的数据可以直接从用户态读取和写入，这样方便我们在用户态进行一些额外的操作(比如截包、修改后再发送出去) Linux 系统中有众多的虚拟网络设备，如 TUN/TAP 设备、VETH 设备、Bridge 设备、Bond 设备、VLAN 设备、MACVTAP 设备 等。这里我们只关注 TUN/TAP 设备。\ntap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。\n二、理解 tun/tap 数据传输过程 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备(OSI 模型的第三层：网络层，即IP 层),也就是说，通过它可以处理来自网络层的数据，更通俗一点的说，通过它，通过它我们可以处理 IP 数据包。\n先看一下正常情况下的物理设备是如何工作的：\n这里的 ethx 表示的就是一台主机的真实的网卡接口，一般一台主机只会有一块网卡，像一些特殊的设备，比如路由器，有多少个口就有多少块网卡。\n我们先看一下 ifconfig 命令的输出：\n$ ifconfig ... en0: flags=8863\u0026lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST\u0026gt; mtu 1500 options=400\u0026lt;CHANNEL_IO\u0026gt; ether ac:bc:32:96:86:01 inet6 fe80::456:7cb8:3dc5:2722%en0 prefixlen 64 secured scopeid 0x4 inet 10.0.0.176 netmask 0xffffff00 broadcast 10.0.0.255 nd6 options=201\u0026lt;PERFORMNUD,DAD\u0026gt; media: autoselect status: active ... 可以看到 etho 这个网卡接口分配到的 IP 地址是 10.0.0.176，这是一块物理网卡，它的两端分别是 内核协议栈 和 外面的网络，从物理层收到的数据，会被转发给内核进而通过某种接口被应用层的用户程序读到；应用程序要想和网络中的另一个进程进行数据通信，会先将数据发送给内核，然后被网卡发送出去。\n接下来我们看一看 tun/tap 设备的工作方式：\n上图中应用层有两个应用程序，而 网络协议栈 和 网络设备(eth0 和 tun0) 都位于内核层，对于 socket，可以这么理解：socket 就像是一组 接口(interface)，它将更复杂的 TCP/IP 协议簇隐藏在 socket 接口后面，只对用户暴露更简单的接口，就像操作系统隐藏了底层的硬件操作细节而只对用户程序暴露接口一样，它是 应用层 与 TCP/IP协议簇 通信的中间软件抽象层。\ntun0 就是一个 tun/tap 虚拟设备，从上图中就可以看出它和物理设备 eth0 的区别：虽然它们的一端都是连着网络协议栈，但是 eth0 另一端连接的是物理网络，而 tun0 另一端连接的是一个 应用层程序，这样协议栈发送给 tun0 的数据包就可以被这个应用程序读取到，此时这个应用程序可以对数据包进行一些自定义的修改(比如封装成 UDP)，然后又通过网络协议栈发送出去——这就是目前大多数 代理 的工作原理。\n假如 eth0 的 IP 地址是 10.0.0.176，而 tun0 配的 IP 为 192.168.1.2。上图是一个典型的使用 tun/tap 进行 VPN 工作的原理，发送给 192.168.1.0/24 的数据通过 应用程序 B 这个 隧道 处理(隐藏一些信息)之后，利用真实的物理设备 10.0.0.176 转发给目的地址(假如为 49.233.198.76)，从而实现 VPN。我们看下每一个流程：\nApplication A 是一个普通的应用程序，通过 Socket A 发送了一个数据包，这个数据包的目的地址是 192.168.1.2； Socket A 将这个数据包丢给网络协议栈； 协议栈根据数据包的目的地址，匹配本地路由规则，得知这个数据包应该由 tun0 出去，于是将数据包丢给了 tun0； tun0 收到数据包之后，发现另一端被 Application B 打开，于是又将数据包丢给了 Application B； Application B 收到数据包之后，解包，做一些特殊的处理，然后构造一个新的数据包，将原来的数据嵌入新的数据包中，最后通过 Socket B 将数据包转发出去，这个时候新数据包的源地址就变成了 eth0 的地址，而目的地址就变成了真正想发送的主机的地址，比如 49.233.198.76； Socket B 将这个数据包丢给网络协议栈； 协议栈根据本地路由得知，这个数据包应该从 eth0 发送出去，于是将数据包丢给 eth0； eth0 通过物理网络将这个数据包发送出去 简单来说，tun/tap 设备的用处是将协议栈中的部分数据包转发给用户空间的特殊应用程序，给用户空间的程序一个处理数据包的机会，比较常用的场景是 数据压缩、加密等，比如 VPN。\n三、使用 Golang 实现一个简易 VPN 先看客户端的实现：\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; \u0026#34;github.com/songgao/water\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; ) /* * @CreateTime: 2020/11/16 11:08 * @Author: hujiaming * @Description: 数据传输过程： 用户数据，如ping --\u0026gt; 协议栈conn --\u0026gt; IfaceWrite --\u0026gt; IfaceRead --\u0026gt; 协议栈conn --\u0026gt; 网线 */ var ( serviceAddress = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;10.0.0.245:9621\u0026#34;, \u0026#34;service address\u0026#34;) tunName = flag.String(\u0026#34;dev\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;local tun device name\u0026#34;) ) func main() { flag.Parse() // create tun/tap interface iface, err := water.New(water.Config{ DeviceType: water.TUN, PlatformSpecificParams: water.PlatformSpecificParams{ Name: *tunName, }, }) if err != nil { color.Red(\u0026#34;create tun device failed,error: %v\u0026#34;, err) return } // connect to server conn, err := net.Dial(\u0026#34;tcp\u0026#34;, *serviceAddress) if err != nil { color.Red(\u0026#34;connect to server failed,error: %v\u0026#34;, err) return } // go IfaceRead(iface, conn) go IfaceWrite(iface, conn) sig := make(chan os.Signal, 3) signal.Notify(sig, syscall.SIGINT, syscall.SIGABRT, syscall.SIGHUP) \u0026lt;-sig } /* IfaceRead 从 tun 设备读取数据 */ func IfaceRead(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 在这里你可以对拿到的数据包做一些数据，比如加密。这里只对其进行简单的打印 color.Cyan(\u0026#34;get data from tun: %v\u0026#34;, packet[:n]) // 通过物理连接，将处理后的数据包发送给目的服务器 err = forwardServer(conn, packet[:n]) if err != nil { color.Red(\u0026#34;forward to server failed\u0026#34;) } } } /* IfaceWrite 从物理连接中读取数据，然后通过 tun 将数据发送给 IfaceRead */ func IfaceWrite(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 从物理请求中读取数据 nr, err := conn.Read(packet) if err != nil { color.Red(\u0026#34;WRITE: read from tun failed\u0026#34;) break } // 将处理后的数据通过 tun 发送给 IfaceRead _, err = iface.Write(packet[4:nr]) if err != nil { color.Red(\u0026#34;WRITE: write to tun failed\u0026#34;) } } } // forwardServer 通过物理连接发送一个包 func forwardServer(conn net.Conn, buff []byte) (err error) { output := make([]byte, 0) bsize := make([]byte, 4) binary.BigEndian.PutUint32(bsize, uint32(len(buff))) output = append(output, bsize...) output = append(output, buff...) left := len(output) for left \u0026gt; 0 { nw, er := conn.Write(output) if er != nil { err = er } left -= nw } return err } 再看服务端的实现：\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; ) /* * @CreateTime: 2020/11/16 11:39 * @Author: hujiaming * @Description: */ var clients = make([]net.Conn, 0) func main() { listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:9621\u0026#34;) if err != nil { color.Red(\u0026#34;listen failed,error: %v\u0026#34;, err) return } color.Cyan(\u0026#34;server start...\u0026#34;) for { // 对客户端的每一个连接，都起一个 go 协程去处理 conn, err := listener.Accept() if err != nil { color.Red(\u0026#34;tcp accept failed,error: %v\u0026#34;, err) break } clients = append(clients, conn) color.Cyan(\u0026#34;accept tun client\u0026#34;) go handleClient(conn) } } func handleClient(conn net.Conn) { defer conn.Close() buff := make([]byte, 65536) for { n, err := conn.Read(buff) if err != nil { if err != io.EOF { color.Red(\u0026#34;read from client failed\u0026#34;) } break } // broadcast data to all clients for _, c := range clients { if c.RemoteAddr().String() != conn.RemoteAddr().String() { c.Write(buff[:n]) } } } } 在这里，我们把 网络协议栈 抽象成了一个黑盒。在接下来的步骤中，我们将逐渐抽丝剥茧，一步步了解网络协议栈的工作原理，以及用 Golang 去实现它。\n四、参考 原创 详解云计算网络底层技术——虚拟网络设备 tap/tun 原理解析 TUN/TAP概述及操作 TUN/TAP设备浅析 https://github.com/ICKelin/article/issues/9 ","permalink":"http://localhost:1313/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tuntap/","summary":"\u003cblockquote\u003e\n\u003cp\u003e实验机器：\u003ccode\u003eMacBook Pro (Retina, 15-inch, Mid 2015)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eGolang 版本：\u003ccode\u003ego version go1.14.6 darwin/amd64\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e网卡\u003c/strong\u003e 也称 \u003cstrong\u003e网络适配器\u003c/strong\u003e，是电脑与局域网进行相互连接的设备，在 \u003ccode\u003eOSI\u003c/code\u003e 七层模型中，工作在 \u003cstrong\u003e物理层\u003c/strong\u003e 和 \u003cstrong\u003e数据链路层\u003c/strong\u003e，其作用可以简单描述为：\u003c/p\u003e","title":"虚拟网络设备tuntap"},{"content":"一、前言 公司后端服务已经全部微服务化，想要调试某个服务可以使用 grpcui，但要对某个接口进行压测，grpcui 还做不到。诸多努力之后找到本次主角：https://github.com/bojand/ghz，官网：ghz.sh。\n推荐理由：简洁！可以一次性解决掉 proto 文件相互之间引用的烦心事！\n二、使用 这里只介绍在 Mac 环境下的用法，其他环境请参阅官网。\n另：我们仍旧使用 GOPATH 方式来管理包，我的： export GOPATH=/Users/hujiaming/go ，本次测试目录为：/Users/hujiaming/go/src/hujm.net。\n1. 安装 直接使用 brew 来安装：\nbrew install ghz 如果不成功，可以直接去 https://github.com/bojand/ghz/releases 下载二进制，下载后放在 PATH 中即可。\n注：还需要有 protoc 工具。\n2. 生成 protoset 文件 如果你的 proto 文件中还引用了其他文件，强烈建议使用 protoset 方式。\n假如我在如下的 proto 中定义一个 GRPC服务：\n/** * @filename: api.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/offer.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/association.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; service ApiService { rpc CreateSKUAssociations(CreateSKUAssociationsReq) returns (CreateSKUAssociationsReply) {}; } message CreateSKUAssociationsReq { repeated Association associations = 1 [ (validator.field) = {repeated_count_min : 1} ]; } message CreateSKUAssociationsReply {} 而 Association 是定义在 \u0026quot;xxx/cm/fulfillment/offermanager/offerpb/association.proto” 文件中的：\n/** * @filename: association.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; message Association { int64 offer_id = 1 [ (validator.field) = {int_gt : 1000000000} ]; string sku_code = 2 [ (validator.field) = {string_not_empty : true} ]; string author = 3 [ (validator.field) = {string_not_empty : true} ]; } 如果采用非 protoset 方式，可能要先生成 association.pb.go，再生成 api.pb.go 文件。这里我们采用 protoset 方式，一步到位：\nprotoc \\ --include_imports \\ -I. -I/usr/local/include \\ -I/usr/local/go \\ -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \\ -I$GOPATH/src \\ --proto_path=. \\ --descriptor_set_out=api.bundle.protoset \\ api.proto 需要注意的点如下：\n如果你的 proto 文件中有引用，上述命令中一定要有 include_imports 参数； 在后面运行时如果出现 no descriptor found for \u0026quot;xxxxxx\u0026quot;，可能是某个文件没有通过 -I 引用进来，记得加上重新执行。 不出意外，会在当前目录下生成 api.bundle.protoset 文件。\n3. 执行压测任务 可以看一下 ghz 的用法：\n$ ghz --help usage: ghz [\u0026lt;flags\u0026gt;] [\u0026lt;host\u0026gt;] Flags: -h, --help Show context-sensitive help (also try --help-long and --help-man). --config= Path to the JSON or TOML config file that specifies all the test run settings. --proto= The Protocol Buffer .proto file. --protoset= The compiled protoset file. Alternative to proto. -proto takes precedence. --call= A fully-qualified method name in \u0026#39;package.Service/method\u0026#39; or \u0026#39;package.Service.Method\u0026#39; format. -i, --import-paths= Comma separated list of proto import paths. The current working directory and the directory of the protocol buffer file are automatically added to the import list. --cacert= File containing trusted root certificates for verifying the server. --cert= File containing client certificate (public key), to present to the server. Must also provide -key option. --key= File containing client private key, to present to the server. Must also provide -cert option. --cname= Server name override when validating TLS certificate - useful for self signed certs. --skipTLS Skip TLS client verification of the server\u0026#39;s certificate chain and host name. --skipFirst=0 Skip the first X requests when doing the results tally. --insecure Use plaintext and insecure connection. --authority= Value to be used as the :authority pseudo-header. Only works if -insecure is used. -c, --concurrency=50 Number of requests to run concurrently. Total number of requests cannot be smaller than the concurrency level. Default is 50. -n, --total=200 Number of requests to run. Default is 200. -q, --qps=0 Rate limit, in queries per second (QPS). Default is no rate limit. -t, --timeout=20s Timeout for each request. Default is 20s, use 0 for infinite. -z, --duration=0 Duration of application to send requests. When duration is reached, application stops and exits. If duration is specified, n is ignored. Examples: -z 10s -z 3m. -x, --max-duration=0 Maximum duration of application to send requests with n setting respected. If duration is reached before n requests are completed, application stops and exits. Examples: -x 10s -x 3m. --duration-stop=\u0026#34;close\u0026#34; Specifies how duration stop is reported. Options are close, wait or ignore. -d, --data= The call data as stringified JSON. If the value is \u0026#39;@\u0026#39; then the request contents are read from stdin. -D, --data-file= File path for call data JSON file. Examples: /home/user/file.json or ./file.json. -b, --binary The call data comes as serialized binary message or multiple count-prefixed messages read from stdin. -B, --binary-file= File path for the call data as serialized binary message or multiple count-prefixed messages. -m, --metadata= Request metadata as stringified JSON. -M, --metadata-file= File path for call metadata JSON file. Examples: /home/user/metadata.json or ./metadata.json. --stream-interval=0 Interval for stream requests between message sends. --reflect-metadata= Reflect metadata as stringified JSON used only for reflection request. -o, --output= Output path. If none provided stdout is used. -O, --format= Output format. One of: summary, csv, json, pretty, html, influx-summary, influx-details. Default is summary. --connections=1 Number of connections to use. Concurrency is distributed evenly among all the connections. Default is 1. --connect-timeout=10s Connection timeout for the initial connection dial. Default is 10s. --keepalive=0 Keepalive time duration. Only used if present and above 0. --name= User specified name for the test. --tags= JSON representation of user-defined string tags. --cpus=8 Number of cpu cores to use. --debug= The path to debug log file. -e, --enable-compression Enable Gzip compression on requests. -v, --version Show application version. Args: [\u0026lt;host\u0026gt;] Host and port to test. 需要关注的几个参数：\n--skipTLS --insecure：如果服务不支持 HTTPS 的话，可以使用此参数跳过 TLS 验证；\n--protoset：指定本次运行的 protoset 文件路径，即上面生成的 api.bundle.protoset；\n--call：需要调用的方法名，格式为：包名.服务名.方法名。比如我要调用 offerpb 包下的 ApiService 服务的 CreateSKUAssociations 方法，那么 call 参数应该是： --call offerpb.ApiService.CreateSKUAssociations；\n--data：本次请求的参数，通过 jsonString 的格式传入；\n--data-file：本次请求的参数，只不过通过文件的形式传入，文件中是标准的通过 json 序列化后的数据；\n--metadata：metadata 参数，通过 jsonString 的格式传入；\n-c：并发数，默认 50(这里有坑，具体参照官网解释：-c。虽然会其多个 goroutine，但是所有的 goroutine 会公用一个连接)；\n-n：请求数，默认 200。n 不能小于 c。\n假设 ApiService服务的地址是：localhost:58784。我们执行下面的命令，发起一次压测任务：\n$ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data \u0026#39;{\u0026#34;associations\u0026#34;:[{\u0026#34;sku_code\u0026#34;: \u0026#34;test:6985079117562211244\u0026#34;,\u0026#34;offer_id\u0026#34;: 8629237865019910744,\u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34;}]}\u0026#39; \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 当你的请求参数比较多时，将他们放在一个文件中、然后使用 --data-file 参数是更好的选择：\n$ cat test_data.json { \u0026#34;associations\u0026#34;: [ { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6237052533738512496\u0026#34;, \u0026#34;offer_id\u0026#34;: 5655307241153104444, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:2156276639623439583\u0026#34;, \u0026#34;offer_id\u0026#34;: 6360134836979240095, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:8361104385030719827\u0026#34;, \u0026#34;offer_id\u0026#34;: 3705044490439993926, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6023087259299523902\u0026#34;, \u0026#34;offer_id\u0026#34;: 3776027093787512475, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:9196748606623463644\u0026#34;, \u0026#34;offer_id\u0026#34;: 1506864634761125694, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; } ] } $ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data-file /Users/hujiaming/go/src/hujm.net/test_data.json \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 看下输出：\nSummary: Count:\t1000 Total:\t743.17 ms Slowest:\t194.74 ms Fastest:\t37.67 ms Average:\t69.32 ms Requests/sec:\t1345.59 Response time histogram: 37.670 [1]\t| 53.377 [384]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 69.084 [349]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 84.791 [138]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 100.498 [26]\t|∎∎∎ 116.205 [2]\t| 131.912 [0]\t| 147.619 [16]\t|∎∎ 163.326 [33]\t|∎∎∎ 179.033 [17]\t|∎∎ 194.739 [34]\t|∎∎∎∎ Latency distribution: 10 % in 46.59 ms 25 % in 49.94 ms 50 % in 57.28 ms 75 % in 69.51 ms 90 % in 102.33 ms 95 % in 163.38 ms 99 % in 183.99 ms Status code distribution: [OK] 1000 responses Summary 的参数：\nCount：完成的请求总数，包括成功的和失败的； Total：本次请求所用的总时长，从 ghz 启动一直到结束； Slowest：最慢的某次请求的时间； Fastest：最快的某个请求的时间； Average：(所有请求的响应时间) / Count。 Requests/sec：RTS，Count / Total 的值。 三、参考资料 https://github.com/bojand/ghz Simple gRPC benchmarking and load testing tool ","permalink":"http://localhost:1313/posts/%E4%BD%BF%E7%94%A8ghz%E5%8E%8B%E6%B5%8Bgrpc%E6%8E%A5%E5%8F%A3/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e公司后端服务已经全部微服务化，想要调试某个服务可以使用 \u003ca href=\"https://github.com/fullstorydev/grpcui\"\u003e\u003ccode\u003egrpcui\u003c/code\u003e\u003c/a\u003e，但要对某个接口进行压测，\u003ccode\u003egrpcui\u003c/code\u003e 还做不到。诸多努力之后找到本次主角：\u003ca href=\"https://github.com/bojand/ghz\"\u003ehttps://github.com/bojand/ghz\u003c/a\u003e，官网：\u003ca href=\"https://ghz.sh\"\u003eghz.sh\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e推荐理由：简洁！可以一次性解决掉 \u003ccode\u003eproto\u003c/code\u003e 文件相互之间引用的烦心事！\u003c/p\u003e","title":"使用ghz压测GRPC接口"},{"content":"一、简介 默克尔树是一种典型的二叉树结构，由一个根节点、一组中间节点 和 一组叶节点 组成。默克尔树最早由 Merkle Ralf 在 1980 年提出，曾广泛用于 文件系统 和 P2P 系统中，比如 Git、区块链、IPFS 等大名鼎鼎的项目或技术。\n他又被称为 哈希树，即存储哈希值的树。树的叶子结点是 数据块(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\n最下面的叶节点包含存储数据或其哈希值。 非叶子节点（包括中间节点和根节点）都是它的两个孩子节点内容的哈希值。 如果是奇数个叶子结点，那么其父节点保存的哈希值就是它本身或者复制一份自己凑成对再进行哈希的结果(具体实现取决于实际情况) 当然，默克尔树可以推广到多叉树的情形，此时非叶子节点的内容为它所有的孩子节点的内容的哈希值。\n二、原理与用途 最开始，我们有一组已经准备好的数据块(比如文件)，他们根据某个标准有序(比如根据文件名字典排序)，而每一个文件都有唯一的哈希值与之对应。这是最底层的情况，当我们向上走的时候，每两个当前层的节点(左右孩子结点)的哈希值可以重新组合，形成一个新的节点(父节点)，这个新的结点中不存储数据，其哈希值为左右孩子结点组合后再次使用预设的哈希函数求哈希值。如此以往，直到生成树根，这个树根我们称为 Merkel Root。有一个特殊情况需要注意，有可能某一层的节点数是奇数，这样就会剩下最后一个结点，再没有结点与其组队生成父节点，这种情况下有两种解决方案：一种是复制一份自己；另一种是不复制，让其父节点只有它一个子节点，而且是左孩子结点。\n目前，默克尔树的典型应用场景包括如下几种。\n快速比较大量数据 对每组数据排序后构建默克尔树结构。当两个默克尔树根相同时，则意味着所代表的两组数据必然相同。否则，必然不同。\n由于 Hash 计算的过程可以十分快速，预处理可以在短时间内完成。利用默克尔树结构能带来巨大的比较性能优势。\n快速定位修改 假如我们基于文件 D0~D3 构建如上的默克尔树，如果 D2 被修改，那么会影响到结点 N2、N2 和 Root。此时我们可根据发生变化的节点，沿着 Root -\u0026gt; N5 -\u0026gt; N2， 通过 O(logN) 的时间复杂度快速定位到哪个结点发生了变化。\n零知识证明 它指的是证明者能够在不向验证者提供任何有用的信息的情况下(没有泄露信息)，使验证者相信某个论断是正确的。有一个很简单的例子：A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法：\nA 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。\nB 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。\n后面的第二种方法属于零知识证明。它的好处在于，在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。\n在默克尔树中，我们仍旧以上图为例，如何向他人证明我拥有 D0 这个数据，而不用暴露更多系统的信息呢？模仿上面的例子，验证者随机提供数据 D1、D2 和 D3，证明者构造如图的默克尔树，并公布 N1 、N5 和 Root。验证者自行计算 Root 值，看是否一致，从而检验 D0 是否存在，因为如果存在，N0 一定相同，那么 N4(N0-N1) 也一定相同、Root(N4-N5)也一定相同。整个过程中验证着没有得到任何除了 D0 外的敏感信息(其他的 D)。\n三、Golang 实现 首先，我们定义需要的结构：\n// Node 表示默克尔树中的 叶结点、非叶结点 或者 Root type Node struct { Tree *MerkleTree // 所在的 Merkle Tree Parent *Node // 父节点 Left *Node // 左孩子 Right *Node // 右孩子 leaf bool // 是否叶子结点 Hash []byte // 如果是叶子结点，则为叶子结点数据的哈希值；如果是非叶子结点，则为左右孩子哈希值组合后的哈希值 C Content // 叶子结点存储的数据块 } // Content 代表一个数据块 type Content interface { CalculateHash() ([]byte, error) Equals(other Content) (bool, error) } // MerkleTree 默克尔树 type MerkleTree struct { Root *Node // Merkle Root 树根 merkleRoot []byte // 树根的哈希值 Leafs []*Node // 所有的叶子结点 hashStrategy func() hash.Hash // 计算哈希的方法 } 需要注意的是，hashStrategy 是一个函数，其返回 type hash.Hash interface，目前最常见的实现是 sha256.New 等，这里为了说明清楚原理，我们自己实现一个，计算 hash 时，只是简单将其转化为 []byte 即可：\ntype myHash struct { hash []byte data []byte blockSize int } func newMyHash() hash.Hash { h := \u0026amp;myHash{ data: make([]byte, 0), blockSize: 64, } return h } // Write 将 p 中的数据更新进 m func (m *myHash) Write(p []byte) (n int, err error) { nn := 0 if len(m.data) == 0 { m.data = p nn = len(p) } else { m.data = append(m.data, 38) m.data = append(m.data, p...) nn = len(m.data) + 1 + len(p) } return nn, nil } // Sum 后面追加 func (m *myHash) Sum(b []byte) []byte { m.data = append(m.data, b...) return m.data } func (m *myHash) Reset() { m.data = make([]byte, 0) m.blockSize = 64 } func (m *myHash) Size() int { return len(m.data) } func (m *myHash) BlockSize() int { return m.blockSize } func newMyHashFunc() hash.Hash { return newMyHash() } 另外，对于 type Content interface，我们也简单实现一个：\ntype myContent string func newMyContent(s string) myContent { return myContent(s) } func (c myContent) CalculateHash() ([]byte, error) { //hash := md5.New() //hash.Write(c.ToBytes()) //return hash.Sum(nil), nil return []byte(c), nil } func (c myContent) Equals(other merkletree.Content) (bool, error) { return reflect.DeepEqual(c, other), nil } 创建 接下来我们提供一个构造方法：\n//NewTree creates a new Merkle Tree using the content cs. func NewTree(cs []Content) (*MerkleTree, error) { var defaultHashStrategy = sha256.New // 默认使用 sha256.New 进行哈希 t := \u0026amp;MerkleTree{ hashStrategy: defaultHashStrategy, } root, leafs, err := buildWithContent(cs, t) // 逐层构建结点 if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } // NewTreeWithHashStrategy 效果同 NewTree，不过使用自定义的哈希函数 func NewTreeWithHashStrategy(cs []Content, hashStrategy func() hash.Hash) (*MerkleTree, error) { t := \u0026amp;MerkleTree{ hashStrategy: hashStrategy, } root, leafs, err := buildWithContent(cs, t) if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } 接着我们来看 buildWithContent 做了什么：\n// buildWithContent 主要将 Content 转变成 Node，为下一步的逐层构建做好准备 func buildWithContent(cs []Content, t *MerkleTree) (*Node, []*Node, error) { if len(cs) == 0 { return nil, nil, errors.New(\u0026#34;error: cannot construct tree with no content\u0026#34;) } var leaves []*Node // 将当前的所有 Content 转化成 Node，放在数组 leaves 中 for _, c := range cs { hash, err := c.CalculateHash() if err != nil { return nil, nil, err } leaves = append(leaves, \u0026amp;Node{ Hash: hash, C: c, leaf: true, Tree: t, }) } root, err := buildIntermediate(leaves, t) // 逐层构建默克尔树，最后返回树根 if err != nil { return nil, nil, err } return root, leaves, nil } 再看 buildIntermediate 如何逐层构建：\nfunc buildIntermediate(nl []*Node, t *MerkleTree) (*Node, error) { var nodes []*Node // 如果是单数，不复制自己以凑成对，而是使自己的父节点只有一个左孩子结点(自己)，没有右孩子结点 for i := 0; i \u0026lt; len(nl); i += 2 { h := t.hashStrategy() left, right := i, i+1 var chash []byte if right == len(nl) { // 单数个，父节点计算哈希时只计算左孩子的 chash = nl[left].Hash } else { // 双数个，父节点从左右子孩子的哈希计算得到自己的哈希 chash = append(nl[left].Hash, nl[right].Hash...) } if _, err := h.Write(chash); err != nil { return nil, err } // 生成父节点 node := \u0026amp;Node{ Left: nl[left], Hash: h.Sum(nil), Tree: t, } if right \u0026lt; len(nl) { node.Right = nl[right] } nodes = append(nodes, node) if right \u0026lt; len(nl) { node.Right.Parent = node } nl[left].Parent = node // 如果只有两个，说明当前构造的 node 就是根节点，结束递归 if len(nl) == 2 { return node, nil } } // 递归调用 return buildIntermediate(nodes, t) } 打印 为了方便调试，我们先实现反序列化默克尔树——逐层遍历二叉树。逐层遍历二叉树是数据结构课程中的基础操作，需要用到一个队列，我们先实现一个简单的队列：\ntype queue struct { data []*Node } func newQueue() queue { q := queue{data: make([]*Node, 0)} return q } // 入队 func (q *queue) enqueue(c *Node) { q.data = append(q.data, c) } // 出队 func (q *queue) dequeue() *Node { if len(q.data) == 0 { return nil } data := q.data[0] q.data = q.data[1:] return data } // 是否为空 func (q *queue) isEmpty() bool { return len(q.data) == 0 } // 队列中元素个数 func (q *queue) len() int { return len(q.data) } 借助队列实现默克尔树的打印：\n// Print 打印默克尔树 func (m *MerkleTree) Print() { if len(m.Leafs) == 0 { fmt.Println(\u0026#34;empty tree\u0026#34;) return } q := newQueue() q.enqueue(m.Root) for !q.isEmpty() { size := q.len() for i := 0; i \u0026lt; size; i++ { tmp := q.dequeue() if tmp == nil { break } if !tmp.leaf { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } else { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } if tmp.Left != nil { q.enqueue(tmp.Left) } if tmp.Right != nil { q.enqueue(tmp.Right) } } fmt.Print(\u0026#34;\\n\u0026#34;) } } 查找 先看实现：\n// 查找 content 对应的从上到下的路径，index 表示是否为左孩子 func (m *MerkleTree) GetMerklePath(content Content) ([][]byte, []int64, error) { for _, current := range m.Leafs { ok, err := current.C.Equals(content) if err != nil { return nil, nil, err } if ok { currentParent := current.Parent var merklePath [][]byte var index []int64 for currentParent != nil { // 当前节点是父节点的右孩子 if bytes.Equal(currentParent.Right.Hash, current.Hash) { merklePath = append(merklePath, currentParent.Right.Hash) index = append(index, 1) } else { merklePath = append(merklePath, currentParent.Left.Hash) index = append(index, 0) } current = currentParent currentParent = currentParent.Parent } // 添加 root if len(merklePath) \u0026gt; 0 { if bytes.Equal(m.Root.Left.Hash, merklePath[0]) { index = append(index, 0) } else { index = append(index, 1) } merklePath = append(merklePath, m.Root.Hash) } return merklePath, index, nil } } return nil, nil, nil } 验证(证明) 首先验证一棵默克尔树是否是有效的：\nfunc (m *MerkleTree) VerifyTree() (bool, error) { calculatedMerkleRoot, err := m.Root.verifyNode() if err != nil { return false, err } // 重新根据各个结点构建一棵默克尔树，并得到其 root，看是否与已存在的相同 if bytes.Compare(m.merkleRoot, calculatedMerkleRoot) == 0 { return true, nil } return false, nil } func (n *Node) verifyNode() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } var ( rightBytes []byte leftBytes []byte err error ) // 递归处理 if n.Right != nil { rightBytes, err = n.Right.verifyNode() if err != nil { return nil, err } } if n.Left != nil { leftBytes, err = n.Left.verifyNode() if err != nil { return nil, err } } h := n.Tree.hashStrategy() if _, err := h.Write(append(leftBytes, rightBytes...)); err != nil { return nil, err } return h.Sum(nil), nil } 再次验证某个 Content 是否属于这棵树(零知识证明)：\nfunc (m *MerkleTree) VerifyContent(content Content) (bool, error) { for _, l := range m.Leafs { ok, err := l.C.Equals(content) if err != nil { return false, err } // 存在于已知的节点中 if ok { // 逐层计算 hash，并比较 currentParent := l.Parent for currentParent != nil { h := m.hashStrategy() var allBytes []byte leftBytes, err := currentParent.Left.calculateNodeHash() if err != nil { return false, err } allBytes = leftBytes if currentParent.Right != nil { rightBytes, err := currentParent.Right.calculateNodeHash() if err != nil { return false, err } allBytes = append(allBytes, rightBytes...) } if _, err := h.Write(allBytes); err != nil { return false, err } if bytes.Compare(h.Sum(nil), currentParent.Hash) != 0 { return false, nil } currentParent = currentParent.Parent } return true, nil } } return false, nil } // calculateNodeHash 计算当前 node 的哈希(左右孩子哈希值组合后，再求哈希) func (n *Node) calculateNodeHash() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } h := n.Tree.hashStrategy() var allBytes []byte allBytes = n.Left.Hash if n.Right != nil { allBytes = append(allBytes, n.Right.Hash...) } if _, err := h.Write(allBytes); err != nil { return nil, err } return h.Sum(nil), nil } 重建 // RebuildTree 根据保存的文件块(leaves)重新构建默克尔树 func (m *MerkleTree) RebuildTree() error { var cs []Content for _, c := range m.Leafs { cs = append(cs, c.C) } root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 也可以根据提供的 []Content 重新构建：\n// RebuildTreeWith 根据提供的 content 完全重建一棵树 func (m *MerkleTree) RebuildTreeWith(cs []Content) error { root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 四、参考文档 Merkle 树结构 Merkle Tree（默克尔树）算法解析 go 语言实现的 merkle 树 我修改了部分实现 ","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%BB%98%E5%85%8B%E5%B0%94%E6%A0%91/","summary":"\u003ch2 id=\"一简介\"\u003e一、简介\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Merkle_tree\"\u003e默克尔树\u003c/a\u003e是一种典型的二叉树结构，由\u003cstrong\u003e一个根节点\u003c/strong\u003e、\u003cstrong\u003e一组中间节点\u003c/strong\u003e 和 \u003cstrong\u003e一组叶节点\u003c/strong\u003e 组成。默克尔树最早由 \u003ccode\u003eMerkle Ralf \u003c/code\u003e在 1980 年提出，曾广泛用于 \u003cstrong\u003e文件系统\u003c/strong\u003e 和 \u003cstrong\u003eP2P\u003c/strong\u003e 系统中，比如 \u003ccode\u003eGit\u003c/code\u003e、区块链、\u003ccode\u003eIPFS\u003c/code\u003e 等大名鼎鼎的项目或技术。\u003c/p\u003e\n\u003cp\u003e他又被称为 \u003cstrong\u003e哈希树\u003c/strong\u003e，即存储哈希值的树。树的叶子结点是 \u003cstrong\u003e数据块\u003c/strong\u003e(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\u003c/p\u003e","title":"优秀数据结构--默克尔树"},{"content":"一、前言 前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\n有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\n这道题本质上是解决 判断数据是否存在于一个大集合中。我当时的回答大致是：前面设置一个 布隆过滤器，可以判断哪些 key 一定不存在、哪些可能存在；通过布隆过滤器的检测之后，后面再设置 n 个 redis 数据库(桶)，通过一个 hash 函数进行分桶操作，之后在某个桶中判断某个 key 是否存在就是 O(1) 的时间复杂度。\n需要注意的是，在计算机中，判断一个元素是不是在一个集合中，通常是用 hash 来解决，这在数据量不大的时候是可以的，但是当数据量很大的时候存储空间就会爆炸。\n当时面试官并没有表示满意或者不满意，毕竟这和其他众多更加底层的面试题比起来，只是冰山一角。最后的面试结果是通过，但因为薪资没有达到我的期望，因此也就没有后续了。\n正好国庆假期有时间，系统总结一下 布隆过滤器 的原理，介绍现有的 Redis 实现，并希望通过 Golang 简单实现，算是学习与总结。\n二、原理 布隆过滤器(Bloom Filter) 由 布隆 于 1970 年提出，在这里可以看到原论文：Space/time Trade-offs in Hash Coding with Allowable Errors。从论文标题可以看出，布隆过滤器在时空复杂度方面有着非常大的优势，同时使用到了哈希，但是存在误算率。实际上，布隆过滤器由 一个很长的二进制数组 和 一系列哈希函数 组成，它的作用是 可以检索一个元素是否存在于一个集合中，优点是 插入与查询的时空效率都远超一般的算法，缺点是 存在一定的误识别率 和 删除困难。\n下面我们看一下布隆过滤器的工作流程：\n布隆过滤器本质上是由长度为 m 的 位向量 或者 位列表 (仅包含 0 或者 1 的列表)组成，并且列表的所有元素被初始化为 0：\n当然还会有一系列哈希函数：\n当我们插入一个 key 时，先通过几个哈希函数得到各自的哈希值，然后将位列表对应位设置为 1：\n再插入元素时，继续将对应位设置为 1 即可，而不用担心之前的值是否为 1：\n当我们查询 another_key 是否在上面的位列表中时，还是经过同样的哈希函数，得到各个列表索引值，进而得到位列表处的值，之后进行判断：如果全为 1，则表示可能存在，如果出现一个为 0，则表明一定不存在。\n为什么说当 结果全为 1 时可能存在，而不是 一定存在？假设我们要查一个单词 test 是否存在，其计算的哈希索引值分别为 [2, 5, 14]，位列表中对应的值也全是 1，但是三个 1 是由 hu 和 Jemmy 两个单词插入的结果，原来并没有 test，这种情况下就会出现误判。\n你可以在这个在线网站 Bloom Filters 上自己体会一下这个过程。\n我们假设位列表的长度为 m，有 k 个哈希函数，那么其误判率大概为：\n对于给定的 m 和 n，当\n的时候，误差率取得最小值。具体的推导过程可参考这篇文章：布隆过滤器的误判率该如何计算？ - Xdims 的回答 - 知乎。我们只需要记住结论即可：\n不要让实际元素数量远大于初始化数量； 如果实际元素数量超过初始化数量，则应该选择更大的 m 重建布隆过滤器，将之前的元素进行批量 add。 三、在 Redis 中使用 在低版本需要安装插件并且重新启动：\n下载插件并安装 cd ~/Documents \u0026amp;\u0026amp; git clone https://github.com/RedisBloom/RedisBloom \u0026amp;\u0026amp; cd RedisBloom \u0026amp;\u0026amp; make # 会得到一个 redisbloom.so 文件 重启 redis-server： # 在redis-cli中关闭服务器，其他方法比如 命令行下 kill -9 (redis-server的pid)是没用的 shutdown # 之后退出 # 重启 redis-server /usr/local/etc/redis.conf --loadmodule ~/Documents/RedisBloom/redisbloom.so \u0026amp; 重新进入 redis-cli 即可。 常用命令如下：\nbf.add name key ：往名为 name 的布隆过滤器中添加一个 key bf.madd name key1 key2 ... keyn: 往名为 name 的布隆过滤器中批量添加多个 key bf.exists name key：检查 key 是否存在于名为 name 的布隆过滤器中 bf.mexists name key1 key2 ... keyn：查询多个 key 是否存在于布隆过滤器中。 五、使用 Golang 实现 package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;github.com/spaolacci/murmur3\u0026#34; \u0026#34;hash\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;unsafe\u0026#34; ) /* * @CreateTime: 2020/10/7 17:28 * @Author: Jemmy(hujm20151021@gmail.com) * @Description: 布隆过滤器 实现 */ // BloomFilter 布隆过滤器的struct type BloomFilter struct { m uint8 // 位数组长度为 2^m n uint64 // 已有元素 k uint32 // 哈希函数的个数 hashFunc []hash.Hash64 // 哈希函数，使用 murmur3 算法，性能好实现简单，但是易于遭受DDoS攻击 data []byte sync.RWMutex // 读写锁 } // NewBloomFilter 初始化一个布隆过滤器 // m 表示位数组长度为 2的m次方 // k 表示哈希函数的个数 func NewBloomFilter(m uint8, k int) *BloomFilter { if k \u0026lt;= 0 { panic(\u0026#34;invalid number k for hashFunc num \u0026#34;) } hashFunc := make([]hash.Hash64, k) // 初始化哈希函数 for i := 0; i \u0026lt; k; i++ { hashFunc[i] = murmur3.New64WithSeed(uint32(i)) } filter := \u0026amp;BloomFilter{ m: m, n: 0, k: uint32(k), hashFunc: hashFunc, data: make([]byte, 1\u0026lt;\u0026lt;m), } // 防止创建数组越界 if len(filter.data) == 0 { panic(\u0026#34;m is too big to make slice\u0026#34;) } return filter } // exists 检查元素是否存在于集合中 // true: 可能存在 // false: 一定不存在 func (b *BloomFilter) exists(data []byte) bool { b.RLock() defer b.RUnlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) f.Reset() if b.data[position] == 0 { return false } } return true } func (b *BloomFilter) add(data []byte) { b.Lock() defer b.Unlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) b.data[position] = 1 f.Reset() } b.n++ } // Reset 清空布隆过滤器中的所有元素 func (b *BloomFilter) Reset() { b.Lock() defer b.Unlock() b.data = make([]byte, 1\u0026lt;\u0026lt;b.m) b.n = 0 } // Number 返回过滤器中的元素个数 func (b *BloomFilter) Number() uint64 { b.RLock() defer b.RUnlock() return b.n } // AddString 向布隆过滤器中添加字符串对象 func (b *BloomFilter) AddString(s string) { b.add(stringToBytes(s)) } // ExistsString 检查s是否存在于集合中 func (b *BloomFilter) ExistsString(s string) bool { return b.exists(stringToBytes(s)) } // AddNumber 添加数字m func (b *BloomFilter) AddNumber(m uint64) { b.add(uint64ToBytes(m)) } // ExistsNumber 检查数字m是否存在于集合中 func (b *BloomFilter) ExistsNumber(m uint64) bool { return b.exists(uint64ToBytes(m)) } // AddBytes 添加 序列化后的对象 func (b *BloomFilter) AddBytes(data []byte) { b.add(data) } // ExistsBytes 检查对象data是否存在 func (b *BloomFilter) ExistsBytes(data []byte) bool { return b.exists(data) } /* ********************************************* 辅助函数 ***************************************************** */ // stringToBytes 将string转换成byte数组，零拷贝 func stringToBytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } // bytesToString byte数组转换成string，零拷贝 func bytesToString(b []byte) string { return *(*string)(unsafe.Pointer(\u0026amp;b)) } // uint64ToBytes 将uint64转为byte数组 func uint64ToBytes(num uint64) []byte { data := make([]byte, 8) binary.LittleEndian.PutUint64(data, num) return data } 写一个测试一下：\nfunc main() { filter := NewBloomFilter(10, 3) filter.AddNumber(1) filter.AddNumber(2) filter.AddNumber(3) filter.AddNumber(4) filter.AddNumber(5) filter.AddNumber(7) filter.AddString(\u0026#34;hu\u0026#34;) filter.AddString(\u0026#34;Jemmy\u0026#34;) fmt.Println(filter.Number()) // 8 fmt.Println(filter.ExistsNumber(3)) fmt.Println(filter.ExistsNumber(5)) fmt.Println(filter.ExistsNumber(6)) fmt.Println(filter.ExistsString(\u0026#34;Jemmy\u0026#34;)) fmt.Println(filter.ExistsString(\u0026#34;jemmy\u0026#34;)) } // 输出 8 true true false true false 【参考资料】\n布隆过滤器论文\n维基百科 布隆过滤器\n在线演示\n","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E7%BB%84%E4%BB%B6-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\u003c/p\u003e","title":"优秀组件-布隆过滤器"},{"content":"一、前言 大家应该对 二分查找算法 不陌生，二分查找之所以能达到 O(logN) 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 随机访问数据 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\n事实上，对于一个有序的链表，我们可以通过建索引的方式，做到类似二分查找的效果。\n假设我们有一个已经排好序的链表(其实是一个双链表，这里为了方便，看待成单链表)：\n如果要对这个链表进行查找，那将是 O(n) 的时间复杂度，我们做一些额外的工作：先对链表中每两个结点建一个索引构成一级索引，再对一级索引进行同样的操作得到二级索引：\n当我们要查找元素 20 时，从最高层开始查，则查找路线应该是 1(向右)-\u0026gt;8(向右)-\u0026gt;14(向下)-\u0026gt;14(向右)-\u0026gt;20，经过了 5 个结点；如果直接在原始链表中查找，需要经过 11 个结点，速度有很明显的提升。不过你也发现了，这是典型的 空间换时间 ，虽然查找速度提升了，但是需要花费空间去存储每一层的索引，占用了更大的空间。\n这种带多级索引的链表结构，就是我们今天要详细学习的 跳表。许多开源软件中都有使用到 跳表 这种数据结构，比如 Redis 中的 zset ，我也是最近看 redis 源码才发现对 skiplist 了解甚少，才决定专门学习一遍。\n二、跳表的性质 跳表 可以视为一个 水平排列(Level)、垂直排列(Tower) 的位置(position，对具体结点 Entry 访问的抽象) 的二维集合。跳表具有如下性质：\n由多层(Level)组成，最底层为第 1 层，向上一层为第 2 层，以此类推。层数不会超过规定的一个最大值 LMAX；\n每一层都是一个拥有头结点的有序列表，第 1 层的链表包含所有的元素；\n如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。 这也是 “第 k 层是第 k-1 层的索引” 描述的体现。\n为了节省空间，第一层之上都不存储实际数据，只有指针，包含同层下一个元素的指针 和 同列下一个元素的指针。\n当查找元素时，会从最顶层链表的头节点开始遍历。以升序跳表为例，如果当前节点的下一个节点包含的值比目标元素值小，则继续向右查找。如果下一个节点的值比目标值大，就转到当前层的下一层去查找。重复向右和向下的操作，直到找到与目标值相等的元素为止。以下为找到元素 20 的路径：\n三、跳表的 Golang 实现 跳表首先由 William Pugh 在其 1990 年的论文《Skip lists: A probabilistic alternative to balanced trees》中提出。由该论文的题目可以知道两点：\n跳表是概率型数据结构。 跳表是用来替代平衡树的数据结构。准确来说，是用来替代自平衡二叉查找树（self-balancing BST）的结构。 在这里我们用 Golang 具体实现一遍。\n首先定义需要的结构体：\ntype Node struct { Value int // 某个结点的值，为了方便理解，这里暂时使用 int forward []*Node // 存储该节点所有层的下一个节点的信息，纵向观察，数组的长度是固定的，为 maxLevel。 curLevel int // 本节点最高层 } type SkipList struct { head *Node // 当前结点 length int // (最后一层)总结点长度 maxLevel int // 跳表的最大层 } 这里最让人疑惑的是 forward []*Node 这个属性，它用来存储该结点所有层的下一个节点。怎么理解呢？看上图，对于结点 8 来说，第一层该结点的下一个节点是 9，第二层该结点的下一个节点是 10，第三层该结点的下一个节点是 14，当 maxLevel = 3(代表forward数组长度为 3) 时，结点 8 的 forward 的应该是 [9, 10, 14]。\n当我们要定位一个元素时，从最顶层 先行后列、从上到下 进行对比。怎么个先行后列？从最顶层开始，如上图，这就选定了第一个元素 1，如果当前的元素比要定位的元素小并且后面的元素不为空时，将当前的位置水平向右移动(p = p.forward[i])，否则，向下移动。重复这个动作，直到找到合适的位置。\n接下来我们还要有一个初始化 SkipList 的操作：\n// CreateSkipList 初始化一个 SkipList func CreateSkipList(base,maxLevel int) *SkipList { s := new(SkipList) s.head = new(Node) s.maxLevel = maxlevel // 第一列默认全都为 base ，并且不计算在 length 中 s.head.curLevel = maxlevel - 1 // 计算层数的时候，为了和 forward 数组保持一致，从第 0 层开始计数 s.head.forward = make([]*Node, maxlevel) s.head.Value = base s.length = 0 return s } 我们先看插入一个元素：\n1. 插入新元素 第一步，确定这个元素的位置；第二步，确定这个元素应该有的层数。\n参考之前的性质：如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。这个概率我们可以通过一个函数来解决：\n// func (s *SkipList) getNodeLevel() int { var level int = 0 // 根据性质 第1层包含所有的元素，所以第一层肯定包含这个新元素，所以默认在第一层 rand.Seed(time.Now().UnixNano()) for { // 第 k 层 有 1/2 的概率成为 k-1 层的索引，并且不会超过最大层 if rand.Intn(2) == 1 || level \u0026gt;= s.maxLevel-1 { break } level++ } return level } 接下来我们看插入的过程：\nfunc (s *SkipList) Insert(value int) (bool, error) { v, err := checkSkipListValid(s) if v == false { return false, err } p := s.head newNode := new(Node) newNode.Value = value newNode.forward = make([]*Node, s.maxLevel) level := s.getNodeLevel() // 当前节点所包含的层数 // forward []*Node 存储该节点所有层的下一个节点的信息 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从最高层开始，向下移动 for { // 找到应该插入的位置 if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; value { p = p.forward[i] // 不为空且插入的值比当前值大，向右移动 } else { // 当前值的当前行的后继为空或者大于插入值，应该向下走，即 i-1 break } } //find the last Node which match user defined IsLess() condition in i level //insert new Node after the node // 在第i层找到应该插入的最佳位置，然后在该位置插入新的节点 // level层以下都有这个节点 if i \u0026lt;= level { // 相当于链表的插入操作，新节点在当前层的下一个节点就是当前节点的后一个节点 newNode.forward[i] = p.forward[i] p.forward[i] = newNode // 当前节点的后一个节点就是新节点 } } newNode.curLevel = level s.length++ // 更新节点长度加一 return true, nil } 我们通过一组图来说明这个情况：\n加入我们设定 maxLevel = 5、插入节点 10 时得到的 level = 1，那么效果如下：\n当我们继续 插入元素 20 时，假如计算得到 level = 2，从上述代码第 15 行开始进去循环，从节点 p = base 开始遍历，在第二个 for 循环，也就是第 17 行里面，base 的 forward = [10, 10, nil, nil, nil] ，第 4 层和第 3 层都直接跳过。\n当 i = 2 也就是第 2 层时，base.forward[2] = nil，所以不会走到第 20 行，但是此时 i \u0026lt;= level，于是有 newNode.forward[2] = p.forward[2] = base.forward[2] = nil，也就是第 2 层的下一个结点，p.forward[2] = base.forward[2] = newNode(结点 20)：\n当 i = 1 也就是第 1 层时，在第 19 行处，base.forward[1] = 10 != nil，并且 10 \u0026lt; 20，因此会走到底 20 行，p = p.forward[i] = base.forward[1] = 10，之后跳出内层循环，来到第 30 行，同样执行赋值操作：\n同样，当 i = 0 即最底下一层时，操作步骤和 i=1 时一样，最终效果为：\n再比如我们 插入元素 15。假如得到的 level = 0，即只出现在最底层。i \u0026gt;= 1 这个过程和插入 20 时没多大区别：\n当 i = 0 时，第 19 行代码中，base.forward[0] = 10 != nil，并且 ·10 \u0026lt; 15，因此 p = p.forward[0] = 10，继续内层循环，此时发现虽然 p.forward[0] = 结点10.forward[0] = 20 != nil，但是 20 \u0026gt; 15，因此跳出内层循环，在下面第 30 行，将 结点 15 插在了结点 10 和结点 20 的中间，效果如下：\n2. 查找元素 查找元素 value 是否在跳表中，如果存在返回对应的 Node，否则返回 nil。\n还是固定的遍历策略，先看代码：\n//try to find the first node which not match the user defined IsLess() condition func (s *SkipList) Search(value int) *Node { p := s.head // 从最高层开始 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从左往右 for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i] \u0026lt; value { p = p.forward[i] // 当前节点的 next 不空，且当前值小于待查找值，则向右移动 } else { break } } } // 假如我们需要查找 value=14，此时已经定位到第一层的10 p = p.forward[0] // 还是要再判断一下p的 value，比如我们要查找14，那 p=15 就不符合，应该返回 nil if p.Value != value { return nil } return p } 3. 删除元素 假设我们已经有了如下的跳表：\n代码如下：\nfunc (s *SkipList) RemoveNode(obj int) bool { var update []*Node = make([]*Node, s.maxLevel) // 用来存储被删除结点每一层的前缀 p := s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; obj { p = p.forward[i] } else { break } } update[i] = p } p = p.forward[0] // 删除的节点不存在 if p == nil || p.Value \u0026lt; obj || obj \u0026lt; p.Value { return false } for i := p.curLevel; i \u0026gt;= 0; i-- { // 将被删除结点的前缀，指向删除结点的 next update[i].forward[i] = p.forward[i] } s.length-- return true } 现在我们想 删除结点 20。运行到第 16 行时，update = [15, 10, base, base, base]。p = p.forward[0] = 20，即此时 p 指向被删除的节点。在第 23 行，从 结点 20 的最高层开始，逐层替换掉被删除结点的前缀结点的后缀结点。\n4. 逐层打印跳表 直接看代码：\nfunc (s *SkipList) Traverse() { var p *Node = s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p != nil { fmt.Print(\u0026#34;%d\u0026#34;,p.Value) if p.forward[i] != nil { fmt.Print(\u0026#34;--\u0026gt;\u0026#34;) } p = p.forward[i] } else { break } } fmt.Println() p = s.head } } 四、时空复杂度分析 都是 O(logn)。具体证明方法请阅读 【参考文献】中 2 跟 3 。\n五、总结 跳表 是一个非常优秀的数据结构，在 Redis 中被用来作为 zset 的底层实现，但是 Redis 的实现比上述设计要复杂的多，比如其引入了 span 表示当前节点到下一个 forward 跨过了几个元素，用来快速计算排名等。\n不过有一点，二叉平衡树也能用来做排序查找，为什么 Redis 不采用树形结构呢？其实 Redis 的作者已经在 这里 说出了原因：\nThere are a few reasons:\nThey are not very memory intensive. It\u0026rsquo;s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.\nA sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.\nThey are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.\n大致意思就是：\n跳表更加节省内存，并且计算随机层数的函数，可以由自己随意更改来获得更多或者更少的索引；\nzset 经常用来实现整体遍历操作，这一点上二者相差无几；\n跳表在调试的时候更容易操作一些。\n【参考文献】\n1. Golang 跳表的实现 https://github.com/GrassInWind2019/skipList/blob/master/src/skipList/skipList.go 2. 跳表时空复杂度分析 https://lotabout.me/2018/skip-list/ 3. 一文彻底搞懂跳表的各种时间复杂度、适用场景以及实现原理 ","permalink":"http://localhost:1313/posts/%E8%B7%B3%E8%A1%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e大家应该对 \u003cstrong\u003e二分查找算法\u003c/strong\u003e 不陌生，二分查找之所以能达到 \u003ccode\u003eO(logN)\u003c/code\u003e 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 \u003cstrong\u003e随机访问数据\u003c/strong\u003e 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\u003c/p\u003e","title":"跳表原理以及Golang实现"},{"content":"首先明确，Redis 是一个使用 C 语言编写的键值对存储系统。Redis 是众所周知的 “快”，一方面，它是一个内存数据库，所有的操作都是在内存中完成的，内存的访问速度本身就很快；另一方面，得益于它底层的数据结构。Redis 的常见类型可在这个网页找到：Redis 命令参考简体中文版，其使用到的底层数据结构有如下六种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和 整数数组。本篇文章，将具体了解这些底层数据结构的实现。\n本文所涉及源码位于：https://github.com/redis/redis，所选版本为 6.0.8。\n绘图工具为 draw.io\n涉及到内存操作的函数：\nvoid *zmalloc(size_t size); // 调用zmalloc函数，申请size大小的空间 void *zcalloc(size_t size); // 调用系统函数calloc申请内存空间 void *zrealloc(void *ptr, size_t size); // 原内存重新调整为size空间的大小 void zfree(void *ptr); // 调用zfree释放内存空间 char *zstrdup(const char *s); // 字符串复制方法 size_t zmalloc_used_memory(void); // 获取当前以及占用的内存空间大小 void zmalloc_enable_thread_safeness(void); // 是否设置线程安全模式 void zmalloc_set_oom_handler(void (*oom_handler)(size_t)); // 可自定义设置内存溢出的处理方法 float zmalloc_get_fragmentation_ratio(size_t rss); // 获取所给内存和已使用内存的大小之比 size_t zmalloc_get_rss(void); // 获取RSS信息(Resident Set Size) size_t zmalloc_get_private_dirty(void); // 获得实际内存大小 size_t zmalloc_get_smap_bytes_by_field(char *field); // 获取/proc/self/smaps字段的字节数 size_t zmalloc_get_memory_size(void); // 获取物理内存大小 void zlibc_free(void *ptr); // 原始系统free释放方法 一、底层数据结构 1. 简单动态字符串 源码文件：sds.h\n1.1 数据结构 SDS（Simple Dynamic Strings, 简单动态字符串）是 Redis 的一种基本数据结构，主要是用于存储字符串和整数。 在 Redis 3.2 版本以前，SDS 的实现如下：\nstruct sdshdr { // 记录 buf 数组中已使用字节的数量，等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; 比如，字符串 Redis6.0 的结构如下：\nSDS 遵循 C 字符串以空字符结尾的惯例， 但保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面， 并且为空字符分配额外的 1 字节空间， 以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的， 所以这个空字符对于 SDS 的使用者来说是完全透明的——这样做的好处是，SDS 可以直接使用 C 库中的有关字符串的函数。\n但是在 Redis 3.2 以后，为了提高效率以及更加节省内存，Redis 将 SDS 划分成一下五种类型：\nsdshdr5 sdshdr8 sdshdr16 sdshdr32 sdshdr64 先看 sdshdr5，增加了一个 flags 字段来标识类型，用一个字节(8 位)来存储：\n// Note: sdshdr5 is never used, we just access the flags byte directly. struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 前 3 位表示类型, 后 5 为表示长度 */ char buf[]; }; 对于 sdshdr5 ，因为其可存储长度最大为 2^5 - 1 = 31，当字符串长度超过 31 时，仅靠 flag 的后 5 为表示长度是不够的，这时需要使用其他的四个结构来保存：\nstruct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; // 已使用长度 1字节 uint8_t alloc; // 总长度 1字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; // 已使用长度 2字节 uint16_t alloc; // 总长度 2字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; // 已使用长度 4字节 uint32_t alloc; // 总长度 4字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; // 已使用长度 8字节 uint64_t alloc; // 总长度 8字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; C/C++ 中 __packed 的作用：\n假设有以下结构体：\nstruct { char a; // 1 字节 int b; // 4 字节 char c[2]; // 2 字节 double d; // 8 字节 }Struct_A; 在计算机内存中，结构体变量的存储通常是按字长对齐的，比如在 8 位机上，就按照 1 字节(8 位)对齐，上述结构体占用 1+4+2+8=15​ 字节的内存；在 16 位机上，按照 2 字节对齐，则该结构体占用 2+4+2+8=16​ 字节。也就是说，在更高位的机器中，如果按照默认的机器字长做内存对齐的标准，那总会有一些空间是浪费的，比如上面 16 位时，为了对齐，使用了 2 字节来存储一个char类型的变量。为什么要对齐？这是因为对内存操作按照整字存取会有更高的效率，是 “以空间换时间” 的思想体现。当然，在空间更优先的情况下，也可以不使用默认的机器字长做内存对齐，这个时候，使用 __packed___关键字，可以强制使编译器将结构体成员按照 1 字节进行内存对齐，可以得到非对齐的紧凑型结构体。\n1.2 API 创建 SDS /* Create a new sds string starting from a null terminated C string. */ sds sdsnew(const char *init) { size_t initlen = (init == NULL) ? 0 : strlen(init); // 拿到要创建的字符串的长度 return sdsnewlen(init, initlen); // 传入字符串、字符串长度，调用 sdsnewlen 动态分配内存 } sds sdsnewlen(const void *init, size_t initlen) { void *sh; sds s; char type = sdsReqType(initlen); // 根据字符串长度得到合适的类型 // 一般情况下，创建一个空字符串的目的都是为了后面的append操作，因此，空字符串的情况下，直接创建SDS_TYPE_8，减少后面的扩容操作 if (type == SDS_TYPE_5 \u0026amp;\u0026amp; initlen == 0) type = SDS_TYPE_8; // 计算类型对应的结构体头部长度(len alloc flags的长度) int hdrlen = sdsHdrSize(type); // 指向flag的指针 unsigned char *fp; // 申请内存，内存大小为 结构体头部长度+字符串长度(buf)+1，这里+1是因为要考虑 \u0026#39;\\0\u0026#39; 字符 sh = s_malloc(hdrlen+initlen+1); if (sh == NULL) return NULL; if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); // 将s指向buf s = (char*)sh+hdrlen; // 将 s-1 指向flag fp = ((unsigned char*)s)-1; // 对sds结构体变量进行赋值 switch(type) { case SDS_TYPE_5: { *fp = type | (initlen \u0026lt;\u0026lt; SDS_TYPE_BITS); break; } case SDS_TYPE_8: { SDS_HDR_VAR(8,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = initlen; *fp = type; break; } ... } if (initlen \u0026amp;\u0026amp; init) memcpy(s, init, initlen); // 在s的最后添加\u0026#39;\\0\u0026#39; s[initlen] = \u0026#39;\\0\u0026#39;; // 返回指向 buf 数组的指针s return s; } 注意，创建 SDS 时返回给上层的是指向 buf 数组的指针 s，而不是结构体的指针，那如何找到结构体中的其他元素呢？上面提到了 __packed__ 关键字，使用 1 字节进行内存对齐，那么知道了 buf 的地址，将其减去对应类型的长度(偏移量)，就能得到结构体中其他类型的地址。\n清空 SDS 清空一个 SDS 有两个途径：\n第一种是直接调用 s_free() 函数：\n/* Free an sds string. No operation is performed if \u0026#39;s\u0026#39; is NULL. */ void sdsfree(sds s) { if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1])); } 另一种方式是 重置 len 为 0 的方式，这种情况下 buf 所占用的空间并没有被清除掉，新的数据会直接覆盖 buf 中的原有数据而无需再申请新的内存空间：\n/* Modify an sds string in-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */ void sdsclear(sds s) { sdssetlen(s, 0); s[0] = \u0026#39;\\0\u0026#39;; } 拼接 SDS 拼接使用的是 sds sdscatsds(sds s, sds t)，但最终调用的还是 sdscatlen：\n// 将 t 拼接到 s 后面。调用此方法之后，sds底层的buf可能经过了扩容迁移了原来的位置，注意更新原来变量中对应的指针 sds sdscatsds(sds s, const sds t) { return sdscatlen(s, t, sdslen(t)); } sds sdscatlen(sds s, const void *t, size_t len) { size_t curlen = sdslen(s); // 计算当前s的长度 s = sdsMakeRoomFor(s,len); // 空间不够的话扩容，确保s的剩余空间足够放得下t if (s == NULL) return NULL; // 扩容失败 memcpy(s+curlen, t, len); // 拼接 sdssetlen(s, curlen+len); // 更新s的属性len s[curlen+len] = \u0026#39;\\0\u0026#39;; // 给s最后加上 \u0026#39;\\0\u0026#39; return s; } 接下来我们详细看一下扩容规则，在函数 sdsMakeRoomFor 中：\n// 将sds s的 buf 的可用空间扩大，使得调用此函数之后的s能够再多存储 addlen 长度的字符串。 // 注意：此方法并未改变 sds 的len属性，仅仅改变的是 sds 的 buf 数组的空间。 sds sdsMakeRoomFor(sds s, size_t addlen) { void *sh, *newsh; size_t avail = sdsavail(s); // 当前的可用空间长度：s.alloc - s.len size_t len, newlen; char type, oldtype = s[-1] \u0026amp; SDS_TYPE_MASK; int hdrlen; // 情况1：剩余长度大于所需要长度，没必要扩容，直接返回 if (avail \u0026gt;= addlen) return s; len = sdslen(s); // 当前字符串长度 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 新字符串长度 // 情况2：扩容 // 情况2.1： 如果 新长度 \u0026lt; 1MB，则按 新长度的2倍 扩容 // 否则，就按 新长度+1MB 扩容 if (newlen \u0026lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; // 计算新长度的类型 type = sdsReqType(newlen); // 还是为了后续使用减少扩容次数的原因，将 sdshdr5 变为 sdshdr8 if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) { // 如果新长度对应的类型没变，则直接调用 s_realloc 扩大动态数组即可 newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; } else { /* Since the header size changes, need to move the string forward, * and can\u0026#39;t use realloc */ // 类型发生了改变，意味着sds结构体头部的三个属性的类型也要跟着变化，此时直接重新申请一块内存 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; // 原s的数据拷贝到新的内存上 memcpy((char*)newsh+hdrlen, s, len+1); // 释放掉原来的s的空间，并将其更新为刚才新申请的 s_free(sh); s = (char*)newsh+hdrlen; // 更新 flag s[-1] = type; // 更新 len sdssetlen(s, len); } // 更新 alloc sdssetalloc(s, newlen); return s; } 代码中注释已经很清楚了，这里再总结一下扩容策略：如果 剩余长度 avail \u0026gt;= 新增长度 addlen ，则无需扩容；否则，如果 avail + addlen \u0026lt; 1MB，按照 2 * (avail + addlen)扩容，否则按照 avail + addlen + 1MB 扩容。\n1.3 总结 创建 SDS 时返回的是指向 buf 数组的指针，而不是 SDS 类型的对象，这样的好处是兼容了已有的 C 语言中的相关函数； 读取内容时，先通过类对应类型计算偏移量，再通过 len 属性来限制读取的长度，杜绝了缓冲区溢出，二进制安全； 根据字符串的长度，定义了五种不同的类型，节省了空间； 进行字符串拼接时，会通过 sdsMakeRoomFor 函数来决定是否有底层 buf 数组的扩容操作。 2. 双端链表 源码文件：adlist.h\n2.1 数据结构 当我们使用 lpush 或者 rpush 的时候，其实底层对应的数据结构就是一个双端链表。\n首先我们来了解结点 listNode：\ntypedef struct listNode { struct listNode *prev; // 头指针 struct listNode *next; // 尾指针 void *value; // 具体的值，因为值的类型不确定，此处使用万能指针 } listNode; 虽然使用多个 listNode就已经足够表示一个双端链表，但是为了更方便，Redis 还有如下结构：\ntypedef struct list { listNode *head; // 头指针 listNode *tail; // 尾指针 void *(*dup)(void *ptr); // 拷贝结点函数 void (*free)(void *ptr); // 释放结点值函数 int (*match)(void *ptr, void *key); // 判断两个结点是否相等的函数 unsigned long len; // 链表长度 } list; 他们的关系可用如下图表示：\n2.2 API 创建 list 对象 创建的是一个 list 对象，首先会尝试申请分配空间，失败返回 NULL ：\n// 创建的只是一个 list 对象，这个对象可以被 AlFreeList() 释放掉，但是仅仅释放的是这个 list 对象，其上面的 listNode 对象还需要另外手动释放 list *listCreate(void) { struct list *list; // 申请分配内存，失败返回 NULL if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 给其他属性赋值 list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; list-\u0026gt;dup = NULL; list-\u0026gt;free = NULL; list-\u0026gt;match = NULL; // 最终返回 list 对象 return list; } 添加元素 listNode 到 list 给一个带头的双向链表添加元素，有三种添加方法：头插入 、 尾插入 和 指定位置，分别对应的操作为 lpush 、rpush 和 linsert。对于 lpush 和 rpush 的实现如下，本质上就是对双端链表的基础操作：\nlist *listAddNodeHead(list *list, void *value) { listNode *node; // 申请分配内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; // 将 listNode 插入到 list 的元素中 if (list-\u0026gt;len == 0) { // 如果之前 list 没有元素，那么 list 的 head 和 tail 均指向当前的 listNode list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { // 链表的头插入 node-\u0026gt;prev = NULL; node-\u0026gt;next = list-\u0026gt;head; list-\u0026gt;head-\u0026gt;prev = node; list-\u0026gt;head = node; } // 更新 len list-\u0026gt;len++; // 返回的是传进来的 list ，失败返回的是 NULL return list; } // 尾插入，过程和头插入类似 list *listAddNodeTail(list *list, void *value) { listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (list-\u0026gt;len == 0) { list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { node-\u0026gt;prev = list-\u0026gt;tail; node-\u0026gt;next = NULL; list-\u0026gt;tail-\u0026gt;next = node; list-\u0026gt;tail = node; } list-\u0026gt;len++; return list; } 关于 linsert ，其用法如下：\nLINSERT key BEFORE|AFTER pivot value\n将值value插入到列表key当中，位于值pivot之前或之后。\n当pivot不存在于列表key时，不执行任何操作。\n当key不存在时，key被视为空列表，不执行任何操作。\n如果key不是列表类型，返回一个错误。\n在 Redis 底层，对应的方法为 listInsertNode，当然，为了找到 old_node，前面还需要遍历 list，这个操作的时间复杂度是 O(n)，我们这里只关注如何插入元素：\n// 在 list 的 old_node 的前或后(after\u0026lt;0,在前面增加；after\u0026gt;0，在后面增加)新增值为 value 的新listNode list *listInsertNode(list *list, listNode *old_node, void *value, int after) { listNode *node; // 为新增的 listNode 申请内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (after) { // after\u0026gt;0，在后面插入 node-\u0026gt;prev = old_node; node-\u0026gt;next = old_node-\u0026gt;next; if (list-\u0026gt;tail == old_node) { list-\u0026gt;tail = node; } } else { // after\u0026lt;0，在前面插入 node-\u0026gt;next = old_node; node-\u0026gt;prev = old_node-\u0026gt;prev; if (list-\u0026gt;head == old_node) { list-\u0026gt;head = node; } } if (node-\u0026gt;prev != NULL) { node-\u0026gt;prev-\u0026gt;next = node; } if (node-\u0026gt;next != NULL) { node-\u0026gt;next-\u0026gt;prev = node; } // 更新 len list-\u0026gt;len++; // 成功 返回传进来的 list return list; } 删除元素 删除元素的情况有以下几种：清空整个 list ，删除某个 listNode。\n我们先看清空整个 list ，它只是释放掉了这个 list 上连的所有的 listNode ，而 list 对象并没有被销毁：\n/* Remove all the elements from the list without destroying the list itself. */ void listEmpty(list *list) { unsigned long len; listNode *current, *next; current = list-\u0026gt;head; len = list-\u0026gt;len; // 遍历整个链表，逐个释放空间，直到为空 while(len--) { next = current-\u0026gt;next; if (list-\u0026gt;free) list-\u0026gt;free(current-\u0026gt;value); zfree(current); current = next; } list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; } 而下面这个 listRelease 方法，会释放所有：\n/* Free the whole list. * * This function can\u0026#39;t fail. */ void listRelease(list *list) { listEmpty(list); // 先清空所有的 listNode zfree(list);\t// 再释放 list } 然后看删除某个具体的 listNode：\nvoid listDelNode(list *list, listNode *node) { // 是否是 list 中的第一个元素 if (node-\u0026gt;prev) node-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; else list-\u0026gt;head = node-\u0026gt;next; // 是否是 list 中的最后一个元素 if (node-\u0026gt;next) node-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; else list-\u0026gt;tail = node-\u0026gt;prev; // 释放当前节点的值 if (list-\u0026gt;free) list-\u0026gt;free(node-\u0026gt;value); // 释放内存 zfree(node); // 更新 len list-\u0026gt;len--; } 2.3 总结 Redis 基于双端链表，可以提供各种功能：列表键、发布订阅功能、监视器等；\n因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表；\n仔细看过源代码后会发现，这是一个典型的双端链表，其底层实现与我在《数据结构》中遇到的如出一辙，这也从侧面说明了熟悉基本的数据结构的重要性。\n3. 字典 字典，由一个个键值对构成，首先想一下，一个字典应该提供什么样的功能？键值对用来存储数据，之后还要能插入数据、修改数据、删除数据、遍历(读取)数据，字典最大的特点就是上面这些所有的操作都可以在 O(1) 的时间复杂度里完成。\n比如在 redis-cli 中，我输入如下命令：\nredis\u0026gt; set name Jemmy 这条命令在 redis 的内存中生成了一个键值对(key-value)，其中 key 是 name，value 是 Jemmy的字符串对象，\nRedis 的字典采用 哈希表 来实现。一个哈希表，你可以简单把它想成一个数组，数组中的每个元素称为一个桶，这也就对应上我们经常所说，一个哈希表由多个桶组成，每个桶中保存了键值对的数据(哈希桶中保存的值其实并不是值本身，而是一个指向实际值的指针)。\n提到哈希，首先要关注的是哈希算法以及解决哈希冲突的方式。哈希算法的具体实现我们暂时不关心，只需要知道 Redis 使用的是 MurmurHash2，“这个算法的优点在于：即使输入的键是有规律的，算法仍能够给出一个很好的随机分布性，计算速度也很快”；对于解决哈希冲突的方法，最常见的是 开放地址法 和 拉链法。二者实现原理在 Golang-map 详解 中已经说过，这里不再细讲，目前只需要知道，Redis 采用拉链法解决哈希冲突。\n在 Redis 中，有以下几个概念：哈希表、哈希表结点和字典，他们的关系大致可以描述为：字典是一个全局的字典，一个字典中包含两个哈希表，一个正在使用，另一个用作扩容用；哈希表中包含多个哈希表结点。接下来我们详细看下每个结构的具体实现：\n源码文件：dict.h\n3.1 数据结构 哈希表结点 哈希表节点使用 dictEntry 结构表示， 每个 dictEntry 结构都保存着一个键值对：\ntypedef struct dictEntry { // key void *key; // value，可以是指针 uint64_t int64_t double中的某一个 union { void *val; uint64_t u64; int64_t s64; double d; } v; // 指向另一个哈希表结点的指针，连接哈希值相同的键值对，用来解决哈希冲突 struct dictEntry *next; } dictEntry; 哈希表 typedef struct dictht { dictEntry **table; // dictEntry数组，dictEntry代表一个键值对 unsigned long size; // 哈希表大小(容量) unsigned long sizemask; // 值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 unsigned long used; // 哈希表已有结点的数量 } dictht; 下图可以表示 哈希表 dictht 和 哈希表结点 dictEntry 之间的关系：\n字典 typedef struct dict { dictType *type; // 类型对应的特定函数 void *privdata; // 私有数据 dictht ht[2]; // 两个哈希表，一个正常使用，另一个用于扩容 long rehashidx; // rehash 索引值，扩容时使用，正常时为-1 unsigned long iterators; // 正在运行的迭代器的数量 } dict; 这里的 type 是一个指向 dictType 结构体的指针，而每一个 dictType 结构体保存了 一组用于操作特定类型键值对的函数，不同的类型有不同的操作函数，privdata 保存了需要传递给特定类型函数的可选参数：\ntypedef struct dictType { // 计算哈希值的函数 uint64_t (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键是否相同的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj); } dictType; ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。\n除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。\n下图展示了一个普通状态(没有进行 rehash )的字典：\n3.2 哈希冲突的解决方式 当两个以上的键经过哈希函数计算之后，落在了哈希表数组的同一个索引上面，我们就称这些键发生了 哈希冲突(hash collision)。\nRedis 的哈希表使用 链接法来解决键冲突： 每个哈希表节点(dictEntry)都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。写入时，因为没有直接指向链的最后一个元素的指针，因此为了更少的时间复杂度， Redis 采用的是在链表头部插入；读取时，先定位到链头，之后逐个比较值是否与所求相同，直到遍历完整个链。\n比如上图中，在 dictht.table 的 3 号桶中已经存在一个键值对 k1-v1，此时又新加入一个键值对 k2-v2，经过哈希计算后正好也落在 3 号桶中，经过插入后结果如下：\n3.4 rehash 细节 当哈希表的键值对数量太多或者太少时，需要根据实际情况对哈希表的大小进行扩大或者缩小，这个过程通过 rehash(重新散列) 来完成。 而判断是否进行 rehash ，是在向哈希表插入一个键值对的时候，接下来我们通过分析源代码的方式，详细了解 rehash 的细节。\n首先，添加一个新键值对，用到的是 dictAdd 方法：\n/* Add an element to the target hash table */ int dictAdd(dict *d, void *key, void *val) { dictEntry *entry = dictAddRaw(d,key,NULL); // 将键值对封装成dictEntry if (!entry) return DICT_ERR; // 如果创建dictEntry，返回失败 dictSetVal(d, entry, val); // 键不存在，则设置dictEntry结点的值 return DICT_OK; } 我们接着看 dictAddRaw，这一步主要将键值对封装成一个 dictEntry 并返回 ：\n// 将 key 插入哈希表中 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing) { long index; dictEntry *entry; dictht *ht; // 如果哈希表正在rehash，则向前 rehash一步(渐进式rehash的体现) // 是否正在进行 rehash，是通过 dict.rehashidx == -1 来判断的 if (dictIsRehashing(d)) _dictRehashStep(d); // 调用_dictKeyIndex() 检查键是否存在，如果存在则返回NULL if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; // 获取当前正在使用的ht，如果正在 rehash，使用 ht[1]，否则使用 ht[0] ht = dictIsRehashing(d) ? \u0026amp;d-\u0026gt;ht[1] : \u0026amp;d-\u0026gt;ht[0]; // 为新增的节点分配内存 entry = zmalloc(sizeof(*entry)); // 将结点插入链表头部 entry-\u0026gt;next = ht-\u0026gt;table[index]; ht-\u0026gt;table[index] = entry; // 更新结点数量 ht-\u0026gt;used++; // 设置新节点的键，使用的是 type 属性中的 keyDup 函数 dictSetKey(d, entry, key); return entry; } 我们再看 _dictKeyIndex 这个方法，作用是计算某个 key 应该存储在哪个空的 bucket ，即需要返回这个 key 应该存储在 dictEntry 数组的 index，如果已经存在，返回 -1。需要注意的是，当哈希表正在 rehash 时，返回的 index 应该是要搬迁的 ht：\n// 传进来的 existing 是 NULL, hash是通过 type 中的哈希函数计算的 static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing) { unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; // 检查是否需要扩展哈希表，如果需要则进行扩展 if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table \u0026lt;= 1; table++) { idx = hash \u0026amp; d-\u0026gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-\u0026gt;ht[table].table[idx]; while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (existing) *existing = he; return -1; } he = he-\u0026gt;next; } if (!dictIsRehashing(d)) break; } return idx; } 最后，我们关注 检查是否需要 rehash，需要则启动 的 _dictExpandIfNeeded：\nstatic int _dictExpandIfNeeded(dict *d) { // 如果正在 rehash，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果哈希表中是空的，则将其收缩为初始化大小 DICT_HT_INITIAL_SIZE=4 if (d-\u0026gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // 在 (ht[0].used/ht[0].size)\u0026gt;=1前提下，如果 系统允许扩容 或者 ht[0].used/t[0].size\u0026gt;5 时，容量扩展为原来的2倍 if (d-\u0026gt;ht[0].used \u0026gt;= d-\u0026gt;ht[0].size \u0026amp;\u0026amp; (dict_can_resize || d-\u0026gt;ht[0].used / d-\u0026gt;ht[0].size \u0026gt; dict_force_resize_ratio)) { return dictExpand(d, d-\u0026gt;ht[0].used * 2); // 扩容至原来容量的2倍 } return DICT_OK; } 仔细看看 dictExpand 是如何扩展哈希表容量的，这个函数中，判断是否需要扩容，如果需要，则新申请一个 dictht ，赋值给 ht[0]，然后将字典的状态设置为 正在 rehash(rehashidx \u0026gt; -1)，需要注意的是，这个方法中并没有实际进行键值对的搬迁：\n// 扩容 或者 新建一个 dictht int dictExpand(dict *d, unsigned long size) { /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 如果正在 reahsh 或者 传进来的size不合适(size比当前已有的容量小，正常情况下这是不可能的)，直接返回错误 if (dictIsRehashing(d) || d-\u0026gt;ht[0].used \u0026gt; size) return DICT_ERR; dictht n; // 新哈希表 // 计算 扩展或缩放新哈希表容量 的大小，必须是2的倍数 unsigned long realsize = _dictNextPower(size); // 如果计算扩容后的新哈希表的容量，和原来的相同，就没必要扩容，直接返回错误 if (realsize == d-\u0026gt;ht[0].size) return DICT_ERR; // 为新哈希表申请内存，并将所有的指针初始化为NULL n.size = realsize; n.sizemask = realsize - 1; n.table = zcalloc(realsize * sizeof(dictEntry *)); n.used = 0; /* Is this the first initialization? If so it\u0026#39;s not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果原来的哈希表是空的，意味着这是在新建一个哈希表，将新申请的 dictht 赋值给 ht[0]，直接返回创建成功 if (d-\u0026gt;ht[0].table == NULL) { d-\u0026gt;ht[0] = n; return DICT_OK; } // 如果不是新建哈希表，那就是需要实打实的扩容，此时将刚才新申请的 哈希表 赋值给 ht[1]，并将当前字典状态设置为\u0026#34;正在rehash\u0026#34;(rehashidx \u0026gt; -1) d-\u0026gt;ht[1] = n; d-\u0026gt;rehashidx = 0; return DICT_OK; } // 哈希表的容量必须是 2的倍数 static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size \u0026gt;= LONG_MAX) return LONG_MAX + 1LU; while (1) { if (i \u0026gt;= size) return i; i *= 2; } } 什么时候进行 桶 的搬迁呢？这里涉及到一个名词：渐进式扩容。我们知道，扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面，如果哈希表中的键值对数量少，那么一次性转移过去不是问题；但是键值对的数量很大，几百万几千万甚至上亿，那么一次性搬完的计算量+单线程很有可能使 redis 服务停止一段时间。因此，为了避免 rehash 对服务造成影响，服务不是一次性 rehash 完成的，而是 分多次、渐进式地将 ht[0] 中的键值对搬迁到 ht[1] 中。\n源码中真正执行搬迁的函数是 _dictRehashStep：\n// _dictRehashStep 让 rehash 的动作向前走一步(搬迁一个桶)，前提是当前字典没有被遍历，即iterators==0，iterators表示当前正在遍历此字典的迭代器数目 static void _dictRehashStep(dict *d) { if (d-\u0026gt;iterators == 0) dictRehash(d, 1); } 再看 dictRehash ：\n// dictRehash 向前 rehash n步。如果还没有搬迁完，返回 1，搬迁完成返回0 int dictRehash(dict *d, int n) { // 当dictRehash时，rehashidx指向当前正在被搬迁的bucket，如果这个bucket中一个可搬迁的dictEntry都没有，说明就没有可搬迁的数据。 // 这个时候会继续向后遍历 ht[0].table 数组，直到找到下一个存有数据的bucket位置，如果一直找不到，则最多向前走 empty_visits 步，本次搬迁任务结束。 int empty_visits = n * 10; // 整个dict的 rehash 完成了，返回0 if (!dictIsRehashing(d)) return 0; // 外层大循环，确保本次最多向前走n步 以及 ht[0].table中还有值 while (n-- \u0026amp;\u0026amp; d-\u0026gt;ht[0].used != 0) { dictEntry *de, *nextde; // 确保 rehashidx 不会超过 ht[0].table 的长度，因为 rehashidx 指向当前正在被搬迁的bucket，其实就是 ht[0].table 数组的下标，这里保证数组下标访问不会越界 assert(d-\u0026gt;ht[0].size \u0026gt; (unsigned long)d-\u0026gt;rehashidx); // 当前的bucket搬迁完了，继续寻找下一个bucket，知道全部为空 或者 向前走的步数超过了限定值 while (d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] == NULL) { d-\u0026gt;rehashidx++; if (--empty_visits == 0) return 1; } // 终于找到了可搬迁的某个bucket中的 dictEntry de = d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx]; // 将这个 bucket 中的所有 dictEntry 包括链表上的，前部搬迁到新的 ht[1] 中 while (de) { uint64_t h; nextde = de-\u0026gt;next; // 获取当前键值对在新的哈希表中的桶的序号，这里进行取模的是 ht[1]的sizemask，所以 h 很大概率会与在 ht[0] 中的不一样 h = dictHashKey(d, de-\u0026gt;key) \u0026amp; d-\u0026gt;ht[1].sizemask; // 更新 新桶与旧桶 中的属性 de-\u0026gt;next = d-\u0026gt;ht[1].table[h]; d-\u0026gt;ht[1].table[h] = de; d-\u0026gt;ht[0].used--; d-\u0026gt;ht[1].used++; de = nextde; } // 搬迁完成，将原来的ht[0]中的bucket置空 d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] = NULL; // rehashidx 自增，表示又搬完了一个桶 d-\u0026gt;rehashidx++; } // 检查是否搬完了整张表 if (d-\u0026gt;ht[0].used == 0) { // 全部完成搬迁，则释放掉ht[0]的内存，将ht[1]的内容放到ht[0]中，重置ht[1]，并标志rehash完成(rehashidx=-1) zfree(d-\u0026gt;ht[0].table); d-\u0026gt;ht[0] = d-\u0026gt;ht[1]; _dictReset(\u0026amp;d-\u0026gt;ht[1]); d-\u0026gt;rehashidx = -1; return 0; } // 否则后面的动作还要继续搬迁 return 1; } 那什么时候会进行渐进式rehash呢？在源码中搜索 _dictRehashStep：有以下几处出现了：\ndictAddRaw ：向字典增加一个键值对时； dictGenericDelete：查找并移除某个键值对时； dictFind ：根据 key 查找对应的 dictEntry 时； dictGetRandomKey：返回一个随机的 dictEntry 时； dictGetSomeKeys：随机返回指定 count 个 dictEntry 时，会进行 count 次 _dictRehashStep 总结一下：\n为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。\n3.5 API 添加键值对 dictAdd 在上面讲 rehash 时，使用的例子，就是 添加键值对，这里不再赘述。\n删除键值对 dictDelete 其底层调用的是 dictGenericDelete：\n// 找到key对应的键值对，并移除它。此处dictDelete 调用时传入 nofree=0 static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) { uint64_t h, idx; dictEntry *he, *prevHe; int table; // 如果字典中键值对数量为0，返回 未找到 if (d-\u0026gt;ht[0].used == 0 \u0026amp;\u0026amp; d-\u0026gt;ht[1].used == 0) return NULL; // 如果当前处于 rehash 阶段，则往前进行一步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table \u0026lt;= 1; table++) { // 获取桶的索引 idx = h \u0026amp; d-\u0026gt;ht[table].sizemask; // 获取桶中的第一个 dictEntry he = d-\u0026gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表，找到之后将其从链表中删除 while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (prevHe) prevHe-\u0026gt;next = he-\u0026gt;next; else d-\u0026gt;ht[table].table[idx] = he-\u0026gt;next; if (!nofree) { dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } d-\u0026gt;ht[table].used--; return he; } prevHe = he; he = he-\u0026gt;next; } // 如果没有再 rehash，就没必要再去 ht[1] 中寻找了 if (!dictIsRehashing(d)) break; } return NULL; // 没找到，返回 NULL } 查找键值对 dictFind 过程跟 dictGenericDelete 一模一样， dictGenericDelete 还多了一个删除操作。\n4. 跳表 会有专门的一篇文章来讲。看这里：跳表原理以及 Golang 实现\n5. 整数集合 当一个集合中只包含整数，并且元素的个数不是很多的话，redis 会用整数集合作为底层存储，它的一个优点就是可以节省很多内存，虽然字典结构的效率很高，但是它的实现结构相对复杂并且会分配较多的内存空间。当然，当整数集合中的 元素太多(redis.conf 中 set-max-intset-entries=512) 或者 添加别的类型的元素是，整个整数集合会被转化成 字典。\n源码文件：intset.h\n5.1 数据结构 整数集合（intset） 是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。\ntypedef struct intset { // 编码方式 uint32_t encoding; // 集合中包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; } intset; contents 数组中的元素按照从小到大的顺序排列，并且保证没有重复值；length 表示整数集合中包含的元素数量，即 contents 数组的长度。虽然 contents 数组的类型是 int8_t，但实际上并不保存 int8_t 类型的值，而是会根据实际 encoding 的值做出判断，比如 encoding = INTSET_ENC_INT16，那么数组的底层类型均为 int16_t ，整个数组中的元素类型都是 int16_t：\n/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 \u0026lt; INTSET_ENC_INT32 \u0026lt; INTSET_ENC_INT64. */ #define INTSET_ENC_INT16 (sizeof(int16_t)) // int16 16位 #define INTSET_ENC_INT32 (sizeof(int32_t)) // int32 32位 #define INTSET_ENC_INT64 (sizeof(int64_t)) // int64 64位 // 返回 v 对应的 encoding 值 static uint8_t _intsetValueEncoding(int64_t v) { if (v \u0026lt; INT32_MIN || v \u0026gt; INT32_MAX) return INTSET_ENC_INT64; else if (v \u0026lt; INT16_MIN || v \u0026gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16; } 下面是一个使用 INTSET_ENC_INT16 编码的、长度为 6 的整数集合：\n5.2 API 初始化 intset // 创建一个空的 intset intset *intsetNew(void) { // 为 intset 对象申请空间 intset *is = zmalloc(sizeof(intset)); // 默认使用 INTSET_ENC_INT16 作为存储大小 is-\u0026gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 数组长度为0，因为没有初始化的操作 is-\u0026gt;length = 0; return is; } 这里有一点需要注意，创建 intset 的时候并没有初始化 contents 数组，应为没必要。在常规情况下，访问数组是根据数组第一个元素地址加上类型大小作为偏移值读取，但是 intset 的数据类型依赖于 encoding，读取的时候通过 memcpy 按照 encoding 的值重新计算偏移量暴力读取的，属于 非常规操作数据，因此，刚开始没必要申请数组的空间，等添加一个元素时，动态扩容该元素的大小的内存即可。\n添加元素 我们先看代码：\n// 在 intset 中添加一个整数 intset *intsetAdd(intset *is, int64_t value, uint8_t *success) { uint8_t valenc = _intsetValueEncoding(value); // 根据要插入的 value 的类型 获取对应的 encoding uint32_t pos; if (success) *success = 1; // success = NULL if (valenc \u0026gt; intrev32ifbe(is-\u0026gt;encoding)) { // 插入元素的 encoding 值大于 intset 当前的，升级 return intsetUpgradeAndAdd(is,value); } else { // 插入元素的 encoding 值小于等于当前 intset 的，则找到这个 value 应该插入的位置，赋值给 pos，已经存在的话直接返回 if (intsetSearch(is,value,\u0026amp;pos)) { if (success) *success = 0; return is; } // 动态扩容 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 将 pos 位置后面的元素整体向后挪一位，给 pos 腾位置 if (pos \u0026lt; intrev32ifbe(is-\u0026gt;length)) intsetMoveTail(is,pos,pos+1); } // 将 pos 位置设置为 value _intsetSet(is,pos,value); // 更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } // 动态扩容，即将原来数组的容量 (is.length*encoding) 调整为 ((is.length+1)*encoding) static intset *intsetResize(intset *is, uint32_t len) { uint32_t size = len*intrev32ifbe(is-\u0026gt;encoding); is = zrealloc(is,sizeof(intset)+size); return is; } // 暴力迁移pos位置之后的数据，为pos位置挪出位置 static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) { // from = pos, to = pos+1 // src 表示 pos 相对于数组头部的迁移量 // dst 表示 pos下一个元素相对于数组头部的偏移量 void *src, *dst; // pos位置 距离数组末尾的元素个数，bytes*类型大小 即是pos后面的所有元素的总长度 uint32_t bytes = intrev32ifbe(is-\u0026gt;length)-from; // encoding uint32_t encoding = intrev32ifbe(is-\u0026gt;encoding); if (encoding == INTSET_ENC_INT64) { src = (int64_t*)is-\u0026gt;contents+from; dst = (int64_t*)is-\u0026gt;contents+to; bytes *= sizeof(int64_t); } else if (encoding == INTSET_ENC_INT32) { src = (int32_t*)is-\u0026gt;contents+from; dst = (int32_t*)is-\u0026gt;contents+to; bytes *= sizeof(int32_t); } else { src = (int16_t*)is-\u0026gt;contents+from; dst = (int16_t*)is-\u0026gt;contents+to; bytes *= sizeof(int16_t); } // 从 src 复制 bytes 个字符到 dst memmove(dst,src,bytes); } 整个过程可以简单总结为：先判断当前插入值的 encoding 是否超过了 intset 的，如果超过了，进行升级，升级 操作我们待会儿再看。没超过的话，需要找到当前元素应该插入的位置 pos ，查找 操作我们还是待会儿再看。之后是动态扩容，动态扩容的过程有：先将数组容量增加，之后将 pos 后面的元素整体移一位，最后将 value 值写入 pos 处。特别需要注意的是，将 pos 后面的元素整体后移一位 这一步，没有逐个移动元素，而是计算好 src 和 dst，直接调用 memmove 将 src 处的 bytes 个字符复制到 dst 处，这正是利用了 intset 数组非常规读取数组的特点。下面通过一个例子看一下插入的过程：\n升级 当插入的元素的类型比集合中现有所有元素的类型都要长时，需要先将数组整个升级之后，才能继续插入元素。升级 指的是 将数组类型变成和插入值类型相同的过程。\n升级过程大致可分为三个步骤：\n根据新元素类型，扩展底层数组的大小，并为新元素分配空间； 将底层数组的所有元素都转化成与新元素相同，并将转换后的元素放在合适的位置上，并且在防止的过程中，需要维持底层数组中数组顺序不变； 将新元素添加到新数组中 下面我们直接看代码：\nstatic intset *intsetUpgradeAndAdd(intset *is, int64_t value) { uint8_t curenc = intrev32ifbe(is-\u0026gt;encoding); // 当前 encoding uint8_t newenc = _intsetValueEncoding(value); // 插入元素的 encoding int length = intrev32ifbe(is-\u0026gt;length); // 插入到 数组最左边 还是 数组最右边。为什么会是最值？因为要升级，所以插入值肯定超出了现有 encoding 对应类型的最值，要么是负数越界，要么是正数越界 int prepend = value \u0026lt; 0 ? 1 : 0; // 首先，设置 intset 的 encoding 为插入元素的 encoding(更大的那个) is-\u0026gt;encoding = intrev32ifbe(newenc); // 根据新元素类型 扩展数组大小 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 从数组最后一个元素开始遍历，将其放入合适的位置。prepend 的作用就是确保我们能给待插入值留下最左边的位置 或 最右边的位置 while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); // 在数组头部或者数组尾部插入 value if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-\u0026gt;length),value); // 最后更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } 通过一个例子说明升级的过程：\n注意：整数集合没有降级操作！一旦对数组进行了升级， 编码就会一直保持升级后的状态。\n查找 在 intset 中查找 value 是否存在，如果存在，返回 1，同时将 pos 值设置为数组的索引值；如果不存在，返回 0，同时将 pos 设置成应该存放的位置的索引值：\nstatic uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) { int min = 0, max = intrev32ifbe(is-\u0026gt;length)-1, mid = -1; int64_t cur = -1; // 当 intset 中没有元素时，直接返回 if (intrev32ifbe(is-\u0026gt;length) == 0) { if (pos) *pos = 0; return 0; } else { // 大于当前数组中最大值 或 小于最小值，也是直接返回 if (value \u0026gt; _intsetGet(is,max)) { if (pos) *pos = intrev32ifbe(is-\u0026gt;length); return 0; } else if (value \u0026lt; _intsetGet(is,0)) { if (pos) *pos = 0; return 0; } } // 因为数组有序，所以采用二分法查找位置是一个非常正确的选择 while(max \u0026gt;= min) { mid = ((unsigned int)min + (unsigned int)max) \u0026gt;\u0026gt; 1; cur = _intsetGet(is,mid); if (value \u0026gt; cur) { min = mid+1; } else if (value \u0026lt; cur) { max = mid-1; } else { break; } } if (value == cur) { // value 已经存在 if (pos) *pos = mid; return 1; } else { // value 不存在 if (pos) *pos = min; return 0; } } 5.3 总结 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 整数集合中的元素不能太对，当超过配置值后，会被转化成字典。 6. 压缩列表 压缩列表 是 Redis 自己实现的一个数据存储结构，有点类似数组，通过一片连续的空间存储数据，只不过数组的每个元素大小都相同，压缩列表允许每个元素有自己的大小。其核心思想，就是在一个连续的内存上，模拟出一个链表的结构。\n在源代码中有这么一段描述：\nThe ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist.\n大致意思是：ziplist 是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist 可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以 O(1) 的时间复杂度在表的两端提供 push 和 pop 操作。但由于每次操作都需要重新分配 ziplist 使用的内存，所以实际的复杂度与 ziplist 使用的内存量有关。\n源码文件：ziplist.h\n6.1 数据结构 ziplist 并没有实际的 struct 表示，但在 ziplist.c 中有如下描述：\nThe general layout of the ziplist is as follows:\n\u0026lt;zlbytes\u0026gt; \u0026lt;zltail\u0026gt; \u0026lt;zllen\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;entry\u0026gt; \u0026hellip; \u0026lt;entry\u0026gt; \u0026lt;zlend\u0026gt;\nzlbytes：本身占用 4 字节，整个压缩列表占用的总字节数(包括他自己) zltail：本身占用 4 字节，起始位置到最后一个结点的偏移量，用来快速定位最后一个元素，在反向输出压缩列表时会有用 zllen：本身占用 2 字节，压缩列表包含的元素个数 entry：元素内容。用数组存储，内存上紧挨着 zlend：本身占用 1 字节，压缩列表结束的标志位，一般为常量 0xFF 接下来看 entry 这个结构：\n\u0026lt;prevlen\u0026gt; \u0026lt;encoding\u0026gt; \u0026lt;entry-data\u0026gt;\nprevlen：1 字节或者 5 字节，表示前一个 entry 长度，在反向遍历的时候会有用 encoding：1、2 或 5 字节，表示当前 entry 的编码方式，表示当前 entry 的类型，integer 或 string entry-data：实际所需的字节数，结点真正的值，可以是 integer 或 string。它的类型和长度由 encoding 来决定 接下来我们详细关注这三个参数：\nprevlen 以字节为单位，记录前一个 entry 的长度。prevlen 的长度可以是 1 字节 或者 5 字节：\n当前一个结点的长度小于 254 字节时，prevlen 的长度为 1 字节，前一个 entry 的长度就保存在这一个字节中； 当前一个结点的长度大于等于 254 字节时，prevlen 的长度为 5 字节，其中第一个字节会被设置成 0xFE(十进制的 254)，表示这是一个 5 字节长 的 prevlen，后面的四个字节则保存前一个 entry 的长度。 prevlen 的作用是：在反向遍历压缩数组时，可以通过当前元素的指针，减去 prevlen ，就能得到前一个元素的地址。\nencoding 节点的 encoding 属性记录了节点的 entry-data 属性所保存 数据的类型 以及 长度：\n一字节、两字节或者五字节长， 值的最高位为 00 、 01 或者 10 的是字节数组编码： 这种编码表示节点的 content 属性保存着 字符串(字节数组)， 数组的长度由编码除去最高两位之后的其他位记录： 编码 编码长度 content 中保存的值 00bbbbbb 1 字节 长度小于等于 63 字节的字节数组(6 位分辨位，2^6 = 64，除去全 0 的) 01bbbbbb | xxxxxxxx 2 字节 长度小于等于 16383 字节的字节数组(14 位分辨位，2^14 = 16384，除去全 0 的) 10000000 | xxxx…xxxx(32 位) 5 字节 长度小于等于 4294967295 字节的字节数组(32 位分辨位，2^32 = 4294967296) 一字节长， 值的最高位以 11 开头的是整数编码： 这种编码表示节点的 entry-data 属性保存着整数值， 整数值的类型和长度由编码除去最高两位之后的其他位记录: 编码 编码长度 entry-data 中保存的值 11000000 1 字节 int16_t 类型整数 11010000 1 字节 int32_t 类型整数 11100000 1 字节 int64_t 类型整数 11110000 1 字节 24 位有符号整数 11111110 1 字节 8 位有符号整数 1111xxxx 1 字节 使用这一编码的节点没有相应的 entry-data 属性， 因为编码本身的 xxxx 四个位已经保存了一个介于 0 和 12 之间的值， 所以它无须 entry-data 属性。 entry-data 节点的 entry-data 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。\n6.2 API 创建ziplist 返回一个只包含 \u0026lt;zlbytes\u0026gt;\u0026lt;zltail\u0026gt;\u0026lt;zllen\u0026gt;\u0026lt;zlend\u0026gt; 的 ziplist：\nunsigned char *ziplistNew(void) { unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; // 头部的 4+4+2 和 尾部的1 总共 11 字节 unsigned char *zl = zmalloc(bytes); // 这里的ziplist类型是一个 char 数组，而不是某个具体的结构体 ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); // 设置 zlbytes 为 初始分配的值，即 bytes ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); // 设置 zltail 为 header 结束的地方 ZIPLIST_LENGTH(zl) = 0; // 设置 zllen 为 0 zl[bytes-1] = ZIP_END; // 最后一个字节存储常量 255 ，表示 ziplist 结束 return zl; } 插入ziplistInsert 这个函数的作用是 在 ziplist 的任意数据项前面插入一个新的数据项：\nunsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { return __ziplistInsert(zl,p,s,slen); } // 在 p 处 插入 s，s 的长度为 slen；插入后s占据p的位置，p及其后面的数据整体后移。其中 p 指向 ziplist 中某一个 entry 的起始位置，或者 zlend(当向尾部插入时) unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { // reqlen 表示 将 s 变成一个 entry 所需要的总字节数，即 prevlen,encoding,entry-data 的总长度 size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; // 随便使用一个一眼就能看出来的值表示当前变量未被逻辑初始化，避免 warning zlentry tail; if (p[0] != ZIP_END) { // 如果不是插入尾部，则根据p获取 p所在的 entry 的前一个 entry 的 prevlen，需要保存 prevlen的字节数保存在 prevlensize(1字节或者5字节，前面有介绍) ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); } else { // p 指向的是 尾部标志 unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) { // 获取 ziplist 最后一个 entry 的长度，保存在 prevlen 中 prevlen = zipRawEntryLength(ptail); } } // 尝试能否转化成整数 if (zipTryEncoding(s,slen,\u0026amp;value,\u0026amp;encoding)) { // 可以转化成 int，则 reqlen 即为存储此 int 所需的字节数，即 entry-data 的长度 reqlen = zipIntSize(encoding); } else { // 无法转换成 int，那就是字节数组，reqlen 就是要存入的字符串的长度，即 entry-data 的长度 reqlen = slen; } // reqlen reqlen += zipStorePrevEntryLength(NULL,prevlen); // 再加上 prevlen 的长度 reqlen += zipStoreEntryEncoding(NULL,encoding,slen); // 再加上 encoding 的长度 // 当不是向尾部插入时，我们必须确保下一个 entry 的 prevlen 等于当前 entry 的长度 int forcelarge = 0; // 【1】nextdiff 存储的是p的prevlen的变化值(新元素长度reqlen - p之前entry的prelen)，具体解释看代码后面【1】处的解释 nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 \u0026amp;\u0026amp; reqlen \u0026lt; 4) { nextdiff = 0; forcelarge = 1; // 这种情况下意味着，本来可以用 1 字节的，却使用了 5 个字节 } /* Store offset because a realloc may change the address of zl. */ // 存储 p 相对于 ziplist 的偏移量，因为 resize 可能改变 ziplist 的起始地址 offset = p-zl; // 到这一步已经能确定 ziplist 需要的总的容量了，调用 resize 调整 ziplist 的大小 zl = ziplistResize(zl,curlen+reqlen+nextdiff); // 重新定位 p p = zl+offset; // 将 p 以及其后面的数据移动为 s 挪地方，别忘了更新 zltail 的值 if (p[0] != ZIP_END) { // 在p前面腾出reqlen字节给新entry使用（将p move到p+reqlen，考虑了prelen缩减或增加） memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); // 更新 s 的后一个 entry（p+reqlen即p的新地址）的prevlen； if (forcelarge) // 【2】强制使用 5 字节存储，避免连锁更新时的大量重新分配空间操作，不进行缩容 zipStorePrevEntryLengthLarge(p+reqlen,reqlen); else // 计算 reqlen 进而判断使用 1 字节 还是 5 字节 zipStorePrevEntryLength(p+reqlen,reqlen); // 更新 zltail ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); // 更新zltail zipEntry(p+reqlen, \u0026amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); } } else { // 如果是在尾部插入，则直接修改 zltail 为 s ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); } // 如果 nexydiff 不等于0，整个 s 后面的 ziplist 的 prevlen 都可能发生变化，这里尝试进行维护 if (nextdiff != 0) { offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; // 改变的只是 p 后面的，前面的没变，因此 s 插入的位置没变 } // 存入 s 这个 entry p += zipStorePrevEntryLength(p,prevlen); p += zipStoreEntryEncoding(p,encoding,slen); if (ZIP_IS_STR(encoding)) { memcpy(p,s,slen); } else { zipSaveInteger(p,value,encoding); } // ziplist 的长度加 1 ZIPLIST_INCR_LENGTH(zl,1); return zl; } // 将 ziplist 的长度变成 len unsigned char *ziplistResize(unsigned char *zl, unsigned int len) { zl = zrealloc(zl,len); ZIPLIST_BYTES(zl) = intrev32ifbe(len); zl[len-1] = ZIP_END; return zl; } 解释【1】：这种情况发生在 插入的位置不是尾部 的情况，我们假设 p 的前一个元素为 p0，此时 p 的 prevlen 存储的是 p0 的长度。但是由于要将 s 插入到 p 之前，那么 p 的 prevlen 的值就应该变成 s 的长度，这样 p 本身的长度也就发生了变化，有可能变大也有可能变小。这个变化了多少的值就是 nextdiff，如果变大了，nextdiff 是正数，否则是负数。如果是负数，只有一种情况，那就是 p0 的长度大于 254，用 5 个字节存；而 s 的长度小于 254，用 1 个字节存就够了。\n解释【2】：关于 forcelarge，这是一个已经被修改后的 bug，大致意思是，这种操作发生在 连锁更新(90 行) 的时候，为了防止大量的重新分配空间的动作，如果一个 entry 的长度只需要 1 个字节就能够保存,但是连锁更新时如果原先已经为 prevlen 分配了 5 个字节,则不会进行缩容操作。关于为何，可以参考这篇文章：Redis 的一个历史 bug 及其后续改进，作者对这个 bug 进行了复现，以及提到了 Redis 对此作出的更新(提出了更优化的结构 listpack)。\n我们接着说 连锁更新。回忆一个 entry 的结构，其中 prevlen 表示前一个 entry 的长度：如果前一个结点长度小于 254，则 prevlen 占用 1 字节，否则占用 5 字节。现在， 考虑这样一种情况： 在一个压缩列表中， 有多个连续的、长度介于 250 字节到 253 字节之间的节点 e1 至 eN 。因为 e1 至 eN 的所有节点的长度都小于 254 字节， 所以记录这些节点的长度只需要 1 字节长的 prevlen 属性， 换句话说， e1 至 eN 的所有节点的 prevlen 属性都是 1 字节长的。此时，如果我们在 e1 前面插入一个长度大于 254 的元素 m，因为 e1 的 prevlen 仅为 1 字节，无法保存大于 254 的数，因此，我们还要对 ziplist 进行空间重分配操作，使得 e1 能够保存 m 的长度，即将 ziplist 的大小再增加 4 字节，让 e1 的 prevlen 大小由 1 字节变为 5 字节，这种操作我们称为 m 对 e1 发生了 扩展。回到刚才的情况，现在麻烦来了，e1 大小发生了变化，肯定超过了原来的 254，此时 e1 需要对 e2 进行扩展，又到后面，e2 需要对 e3 进行扩展……程序需要不断地对压缩列表执行空间重分配操作， 直到 eN 为止。\nRedis 将这种在特殊情况下产生的连续多次空间扩展操作称之为 “连锁更新”（cascade update）。我们看看 连锁更新 的具体实现：\n// p 指向第一个不需要更新的 entry unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) { size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; // 当 p 是 ziplist 的”尾巴“时停止更新 while (p[0] != ZIP_END) { zipEntry(p, \u0026amp;cur); // 【1】将 entry 解码称为一个易于操作的 entry 结构体，细节见代码后解释 rawlen = cur.headersize + cur.len; // 当前节点的长度 rawlensize = zipStorePrevEntryLength(NULL,rawlen); // 存储当前节点所需要的 prevlen 大小 // 没有下一个节点，直接返回 if (p[rawlen] == ZIP_END) break; // 获取 p 的下一个节点 zipEntry(p+rawlen, \u0026amp;next); // 如果下一个节点的 prevlen 等于当前节点的 长度，则没必要更新，直接退出循环 if (next.prevrawlen == rawlen) break; // 下一个节点的 prevlen 小于当前节点的长度(当前节点长度为 5 字节，next 的 prevlen 为1 字节) if (next.prevrawlensize \u0026lt; rawlensize) { // ziplist的地址可能发生改变，先记录 p 相对于zl起始位置的偏移量 offset = p-zl; // 额外需要申请的空间 5 - 1 = 4 extra = rawlensize-next.prevrawlensize; // 改变 ziplist 的容量 zl = ziplistResize(zl,curlen+extra); // 重新计算 p 的位置 p = zl+offset; /* Current pointer and offset for next element. */ np = p+rawlen; // next 的新地址 noffset = np-zl; // next新地址相对于 ziplist 头部的偏移量 // 更新 zltail if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra); } // 扩展 next 的 prevlen，并将数据拷贝 memmove(np+rawlensize, np+next.prevrawlensize, curlen-noffset-next.prevrawlensize-1); // 在扩展后的 next 的 prevlen 中重新记录 p 的长度 zipStorePrevEntryLength(np,rawlen); /* Advance the cursor */ // 更新 p 为下一个 entry p += rawlen; // 更新 p 的长度(需要加上扩展的 prevlen 的 extra 个字节) curlen += extra; } else { // 这种情况下，next 的 prevlen 足够表示 当前 p 的长度 if (next.prevrawlensize \u0026gt; rawlensize) { // next 的 prevlen \u0026gt; p 的长度(next.prevlen = 5 结点，p的长度小于 5 个结点)，此时应该 缩容，但出于性能以及操作的方便性(减少后续连锁更新的可能性)，我们通常不进行缩容，这个时候，直接将 next 的 prevlen 设置为 5 个结点 zipStorePrevEntryLengthLarge(p+rawlen,rawlen); } else { // 相等 zipStorePrevEntryLength(p+rawlen,rawlen); } // next 的长度并没有发生变化(没有缩容)，终止循环 break; } } return zl; } 解释【1】：“辅助结构体” zlentry，这个结构体与 ziplist 中的一个实际 entry 相对应，其作用是为了更加方便地操作一个 实际的 entry：\ntypedef struct zlentry { unsigned int prevrawlensize; // 存储 prevrawlen 所需要的字节数，同样也有 1字节 和 5字节之分 unsigned int prevrawlen; // 对应 prevlen unsigned int lensize; // 存储 len 所需要的字节数 unsigned int len; // 当前 entry 的长度 unsigned int headersize; // ziplist头部大小: prevrawlensize + lensize unsigned char encoding; // 编码方式 unsigned char *p; // 指向某个实际 entry 的地址 } zlentry; 其他的一些操作，比如删除、查找，过程与插入类似，无非就是各个 entry 地址的计算，删除时还有可能涉及到连锁更新。 这里不再描述，想了解的可以根据上面的思路自己研究源代码。\n6.3 总结 ziplist是 redis 为了节省内存，提升存储效率自定义的一种紧凑的数据结构，每一个 entry 都保存这上一个 entry 的长度，可以很方便地进行反向遍历； 添加和删除节点可能会引发连锁更新，极端情况下会更新整个ziplist，但是概率很小； 在 Redis 中，当元素个数较少时，哈希表(hset 等操作) 和 列表(lpush 等操作) 的底层结构都是 ziplist。 7. 紧凑列表 源码文件：listpack.h\n实现文档：Listpack specification\n紧凑列表是 压缩列表 的升级版，目的是在未来代替 ziplist。\n有时间再完善。\n二、 Redis 对象对应的数据结构 前面大致介绍了 简单动态字符串 sds、双端链表 adlist、字典 dict、跳表 skiplist、整数集合 intset 和 压缩列表 ziplist 等基础数据结构，同时我们知道 Redis 中有 字符串对象(string)、列表对象(list)、哈希对象(hash)、集合对象(set) 和 有序集合对象(zset) 等五种对象，他们都至少用了上面一种基础数据结构来实现。在 Redis 中，客户端的一条命令以及参数会被解释成一个 robj 结构体：\n源码文件： server.h\ntypedef struct redisObject { unsigned type : 4; // 类型 unsigned encoding : 4;\t// 编码 unsigned lru : LRU_BITS; // 对象最后被访问的时间，我们暂时不关注 LRU int refcount;\t// 引用次数 void *ptr;\t// 指向实现对象的数据结构 } robj; /* Object types */ #define OBJ_STRING 0 /* String object. */ #define OBJ_LIST 1 /* List object. */ #define OBJ_SET 2 /* Set object. */ #define OBJ_ZSET 3 /* Sorted set object. */ #define OBJ_HASH 4 /* Hash object. */ /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The \u0026#39;encoding\u0026#39; field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 // 简单动态字符串 sds #define OBJ_ENCODING_INT 1 // long 类型 #define OBJ_ENCODING_HT 2 // 字典 dict #define OBJ_ENCODING_ZIPMAP 3 // zipmap(弃用) #define OBJ_ENCODING_LINKEDLIST 4 // 双端链表 adlist #define OBJ_ENCODING_ZIPLIST 5 // 压缩列表 ziplist #define OBJ_ENCODING_INTSET 6 // 整数集合 intset #define OBJ_ENCODING_SKIPLIST 7 // 跳表 skiplist #define OBJ_ENCODING_EMBSTR 8 // 采用embstr编码的sds #define OBJ_ENCODING_QUICKLIST 9 // qunicklist，用于列表 #define OBJ_ENCODING_STREAM 10 // 紧凑列表 listpack #define LRU_BITS 24 obj 的作用大致为：\n为多种数据类型提供一种统一的表示方式。 允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。 支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。 说到底， robj 所表示的就是 五种 Object types 和 11 中 Object encoding 之间的对应方式，起到一个桥梁作用。这种对应关系可用如下的图来表示：\n","permalink":"http://localhost:1313/posts/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-1-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","summary":"\u003cp\u003e首先明确，\u003ccode\u003eRedis\u003c/code\u003e 是一个\u003cstrong\u003e使用 C 语言编写的键值对存储系统\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 是众所周知的 “\u003cstrong\u003e快\u003c/strong\u003e”，一方面，它是一个内存数据库，所有的操作都是在\u003cstrong\u003e内存\u003c/strong\u003e中完成的，内存的访问速度本身就很快；另一方面，得益于它\u003cstrong\u003e底层的数据结构\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 的常见类型可在这个网页找到：\u003ca href=\"https://redis.readthedocs.io/en/2.4/index.html\"\u003eRedis 命令参考简体中文版\u003c/a\u003e，其使用到的底层数据结构有如下六种：\u003cstrong\u003e简单动态字符串\u003c/strong\u003e、\u003cstrong\u003e双向链表\u003c/strong\u003e、\u003cstrong\u003e压缩列表\u003c/strong\u003e、\u003cstrong\u003e哈希表\u003c/strong\u003e、\u003cstrong\u003e跳表\u003c/strong\u003e和 \u003cstrong\u003e整数数组\u003c/strong\u003e。本篇文章，将具体了解这些底层数据结构的实现。\u003c/p\u003e","title":"Redis源码阅读--1.基础数据结构与对象"},{"content":"一、常见的索引类型 1. 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 创建自定义的哈希索引：\n通过一个实例来说明：\n提出问题：假如我们要存储大量的URL，同时还有通过 URL 查询该条记录的需求，应该如何建立索引？ 调研：如果直接在 URL 上建立索引，那么索引会很长，并且很大 解决方案：删除原来 URL 上的索引，新增一个被索引的 url_crc 列，存储 URL 列被 CRC32 之后的值，之后的查询可通过这个索引来查。缺点是还要花时间维护这个索引列。 # 建表 CREATE TABLE url_demo ( id int unsigned NOT NULL auto_increment, url varchar(255) NOT NULL, url_crc int unsigned NOT NULL DEFAULT 0, PRIMARY KEY(id) ); # 为了减少维护工作，可以创建一个触发器 DELIMITER // CREATE TRIGGER url_demo_crc_ins BEFORE INSERT ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; CREATE TRIGGER url_demo_crc_upd BEFORE UPDATE ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; // DELIMITER ; # 之后可验证增删改查 INSERT INTO url_deml(url) VALUES(\u0026#34;https://www.baidu.com\u0026#34;); SELECT * FROM url_demo; +----+-----------------------+------------+ | id | url | url_crc | +----+-----------------------+------------+ | 1 | https://www.baidu.com | 3010065587 | +----+-----------------------+------------+ UPDATE url_demo SET url=\u0026#34;https://www.google.com\u0026#34; WHERE id=1; SELECT * FROM url_demo; +----+------------------------+-----------+ | id | url | url_crc | +----+------------------------+-----------+ | 1 | https://www.google.com | 857627499 | +----+------------------------+-----------+ # 查询某个具体的URL时，必须使用下面的查询方法： SELECT * FROM url_demo WHERE url_crc=CRC32(\u0026#34;https://www.google.com\u0026#34;) AND url=\u0026#34;https://www.google.com\u0026#34;; 2. B-Tree 索引 当人们谈论索引时，如果没有特别指明类型，那多半说的是 B-Tree 索引。它使用 B 树(部分引擎使用 B+树)作为底层的数据结构，这通常意味着被索引的值都是按顺序存储的(首先是个 二叉排序树)，并且每一个叶子节点到根节点的举例相同(变形的 多叉排序树)。树的深度和表的大小直接相关。\n假如我们有如下数据表：\nCREATE TABLE people ( last_name varchar(64) NOT NULL, first_name varchar(64) NOT NULL, dob date NOT NULL, gender enum(\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;) NOT NULL, key(last_name, first_name, dob) ); 下图显示了该索引时如何组织数据的：\n以下情况，索引(key(last_name, first_name, bob))是有效的：\n全值匹配：指查询的列和索引中的列完全匹配(字段以及对应的字段顺序)，例如 SELECT * FROM people WHERE last_name= ‘Allen’ AND first_name = 'Cuba' AND bob = '1960-01-01'； 最左前缀匹配：索引的顺序非常重要： 可以匹配所有last_name = ‘Allen’的人，因为 last_name 是索引列中最左边的； 可以只匹配某一列的值得开头部分，如 last_name 全部以 K 开头，即 last_name like 'K%’，注意，这里也是针对最左边的列； 可以匹配 last_name 在 Allen 和 Barrymore 之间的人，即 last_name \u0026gt; ‘Allen’ AND last_name \u0026lt; 'Barrymore’，这里也是针对最左边列； 精准访问某一列并范围匹配另一列：例如第一列last_name全匹配，第二列first_nbame 范围匹配；或者last_name和first_name全匹配，第三列bob范围匹配。 只访问索引的查询：即 覆盖索引。即select的字段就属于索引列，而不用通过“回表”再拿一次。关于覆盖索引，后面会详细介绍。 以下情况，索引会失效（即不会使用之前创建的索引 key(last_name, first_name, bob)）：\n单独列非最左列，索引失效，即 如果不是按照索引的最左列开始查找，无法使用索引。例如：无法查找 WHERE first_name = ‘Bill’；例如 WHERE bob = '1960-01-01’；例如 WHERE first_name like 'K%'。因为查询的列都不是该索引的最左列。同理，WHERE last_name like '%L’也会失效。 跳过某一列，索引失效。即 WHERE last_name='Allen' AND bob='1960-01-01’也不会使用该索引，因为跳过了列first_name。 某列范围查询，右边所有列无法使用索引优化查询。如 WHERE last_name='Allen' AND first_name like ‘J%’ AND bob='1960-01-01’，那么 bob 列无法使用索引优化查询，因为中间的first_name LIKE是一个范围条件。 如果使用B-Tree，创建多列索引时，列的顺序非常重要！\n二、高性能的索引策略 正确地创建和使用索引是实现高性能查询的基础。下面介绍如何正确地运用索引。\n1. 查询时，索引列单独放在比较符号的一侧 如果查询中的列不是独立的，则 MySQL 不会使用索引。 独立的列 是指索引列不能是表达式的一部分，也不能是函数的参数。\n下面这个查询就无法使用score列的索引：\nSELECT * FROM student WHRER score + 1 = 90; 我们都知道上述查询中表达式的值是 89，但是MySQL 无法解析这个方程式。我们应该养成简化 MySQLWHERE条件的习惯，始终将索引列单独放在比较符号的一侧。\n2. 前缀索引和索引选择性 索引选择性是指 不重复的索引数(I) 和 数据表的记录总数(S) 的比值，即 $I/S$，根据其计算方式可知，$I/S \u0026lt;= 1$，并且索引选择性越高，查询性能越高，因为索引选择性高的索引可以让 MySQL 在查询的时候 过滤掉更多行。单一列的索引的选择性是 1，是最好的。\n既然单一列的索引选择性是最好的，我们为什么还要讨论这个问题？想一下要对 某一些很长的列建立索引，这时索引会变的非常大，有可能出现索引文件远大于数据文件的情况。这个时候对整个字段建立索引就显得不太明智，此时索引选择性可以作为一个辅助工具，帮助我们 选择足够长的前缀以保持较高的选择性，同时又不能太长。\n如何选择合适的前缀长度？方法是 计算完整列的选择性，然后逐个计算前缀的选择性，选择最接近完整列的那一个。\n假如完整列的选择性为 0.0312，而不同前缀长度对应的选择性结果为：\n当长度大于 7 时，再增加前缀长度，性能提升的幅度就已经很小了。于是建立索引：\nALTER TABLE demo ADD KEY(city(7)); 优点：使索引又快又小的这种方法；\n缺点：无法使用前缀索引进行 GROUP BY 和 ORDER BY，也无法进行覆盖扫描(覆盖索引)。\n3. 多列索引 我们经常会听到有人说“把 WHERE 条件里面的列都建上索引”这种模糊的建议，但事实上，如果不从实际出发，大多数情况下，在多个列上简历单独的索引并不能提高 MySQL 的查询性能。\nMySQL 5.0 之后引入了一种叫 索引合并(Index Merge) 的策略，一定程度上可以提高多个单列索引查询时的性能。\n关于 索引合并 ，看这篇文章：索引合并\n在以下情况下，建议使用多列索引而不是在每个单独列上建立索引：\n当出现对多个索引做相交操作时(通常是多个 AND 操作)，这通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引； 当出现对多个索引做联合操作时(通常是多个 OR 操作)，通常需要耗费大量的 CPU 和内存用以对结果的缓存、归并和排序上，特别是某些索引的选择性不高时，需要合并扫描大量的数据。 4. 选择合适的列顺序 当使用 B-Tree 索引时，由于其“最左匹配”的性质，索引列的顺序往往意味着索引首先按照最左列进行排序，然后是第二列。对于如何选择多列索引的顺序，有一个经验法则： 将选择性最高的列放在索引最前列。\n5. 聚簇索引 MySQL 的 InnoDB 索引数据结构是 B+树，主键索引叶子节点的值存储的就是 MySQL 的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提。\n首先，用一句话解释什么是聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引。所以主键就是聚簇索引。\n对应地，什么是非聚簇索引？也称二级索引，索引的存储和数据的存储是分离的，在 InnoDB 引擎中，二级索引中存储的是主键值，先通过查找二级索引得到对应的主键值，再通过主键值回表查询需要的字段。\n二级索引使用主键值当做行的指针，会让二级索引占用更多的空间，换来的好处是，InnoDB 在移动行时无需更新索引中的这个指针——这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。\n在 InnoDB 中，主键一定是聚簇索引，InnoDB 一定有主键(如果没有手动设定，InnoDB 会默认创建一个)，并且一张表只允许有一个聚簇索引。\n建议：InnoDB 中应该尽可能按照主键的顺序去插入数据，一般使用一个递增的 bigint 类型 作为主键。最差的情况是使用值完全随机的列如 UUID 作为主键！\n6. 覆盖索引 前面提到过，InnoDB 中，非聚簇索引所存储的值为主键值，要想获得其他列的值，还要进行一个被称为 “回表” 的操作——也就是说，使用非聚簇索引查询更多列，要进行两次查询。但是想一想，如果我们差的刚好就是主键 id，如 SELECT id FROM student WHERE name='Tom';，此时我们需要的列就在二级索引中，不需要再执行“回表”操作，这个操作，可以极大地提高性能。\n如果一个索引包含(或者说 覆盖) 所有查询的字段的值，我们就称为**“覆盖索引”**。\n为什么覆盖索引能提高性能？因为减少了“回表”的操作，减少了很多次随机 IO。\n7. 学会使用 EXPLAIN 在需要执行的 SQL 语句前面加上EXPLAIN，可以查询和分析这条 SQL 语句的执行记录，对我们优化查询效率有很大的帮助。\n先看一个EXPLAIN的示例：\nmysq\u0026gt; explain select * from city\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: city partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 366 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 其他的几个列暂时不考虑，只对 type 和 EXTRA 做记录：\ntype 关联类型，或访问类型——MySQL 如何查找表中的行。以下按照从最差到最优的方式介绍：\nALL： 全表扫描。 index：按照索引次序扫描。跟全表扫描一样，只不过扫描时按照索引顺序进行而不是按照每一行。它的优点是：避免了排序操作。缺点是：要承担按索引次序读取整个表的开销(如果是非聚簇索引，那么索引次序是有序的，但存储的主键不一定是有序的，回表的时候进行的就是随机 IO，此时开销会更大，还不如 ALL)。如果在EXTRA列中看到“Using index”，说明 MySQL 正在使用覆盖索引。 range：范围扫描，即带有WHERE或BETWEEN或\u0026lt;等比较符号的查询语句。比全表扫描好一些，因为不需要遍历全部索引，只需要从满足条件的行开始计算。开销与index相同。 ref：非主键 非唯一索引 等值查找。 eq_ref：主键索引 或 非空唯一索引 进行等值查找。 cost：常量连接，表最多只有一行匹配，通常用于 主键 或者 唯一索引 进行等值比较。 system：系统表，少量数据，往往不需要进行磁盘 IO (可以当成 cost 连接的特例) extra extra 表示 MySQL 如何解析这条查询，参数更多地显示一些关于索引的信息。它的最常用的选值如下：\nusing index：表示本次查询将使用 覆盖索引，避免了 回表 的操作，即 where 筛选条件是索引的前导列 并且 select 选择的列被索引覆盖，没有 回表 操作。 using where：限制了哪一行，也就是说，读取结束之后使用了 Table Filter 进行了过滤。不管查询条件有没有覆盖索引，只要筛选条件没有使用索引，就会有 using where。 using where; using index：查询的列被索引覆盖，但是 筛选条件不是前导列 或者 筛选条件是前导列但是使用了范围查询。 NULL：查询的列未被索引覆盖，但是筛选条件使用了索引的前导列。这种情况意味着用到了索引，但是 select 的字段没有被索引覆盖，因此还要进行 回表 操作，“不是纯粹地使用索引，也没有完全用到索引”，所以为 NULL(没有信息)。 using index condition：查询的列没有被索引全部覆盖，筛选条件使用了索引的前导列的范围查询 或者 查询条件使用到了索引但还有一些别的条件。 上面的这些情形可用如下的表格总结：\n","permalink":"http://localhost:1313/posts/mysql%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95/","summary":"\u003ch2 id=\"一常见的索引类型\"\u003e一、常见的索引类型\u003c/h2\u003e\n\u003ch3 id=\"1-哈希索引\"\u003e1. 哈希索引\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e哈希索引(Hash Index)\u003c/strong\u003e 基于哈希表实现，\u003cstrong\u003e只适合精确匹配，不适合范围查找\u003c/strong\u003e。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算\u003ccode\u003e哈希code\u003c/code\u003e，通过 \u003cstrong\u003eK-V\u003c/strong\u003e 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\u003c/p\u003e","title":"MySQL关于索引"},{"content":"1. 堆排序 堆 是一种数据结构，它具有如下特征：\n是一棵完全二叉树 父节点的值 \u0026gt; 子节点的值 1.1 完全二叉树 若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是 完全二叉树。\n完全二叉树有一个很重要的特点，它的元素可以全部放在一个数组中，这个数组中的元素排列非常紧密，不会出现零值的情况。比如下面这棵树，对应的数组为： [25, 14, 13, 4, 2, 10]。\n如果我们从上到下、从左到右的顺序去遍历这棵树，会发现，元素顺序与数组中完全对应。于是会有下面的公式：\n设数组中父节点的 index 值为i，则左孩子的 index 值为 2*i+1，右孩子的 index 值为 2*i+2。这样数组和数的关系就对应上了。这是堆排序的基础。\n1.2 heapify 我们称 将一棵树变成堆的过程 称为 heapify。具体来说是将 parent、left 和 right这三个结点，通过交换，使得 parent 为最大(left和right哪个大没关系)，因为数的定义是递归的，所以上面这个交换过程也是递归的。此时需要决定的是从下到上，还是从上到下。答案是如果是大根堆，从下到上进行 heapify 过程，因为从上到下的，处理完父节点，还不确定这个父节点是不是就是整个堆中的最大，而从下到上可以看成是一个不断往上 “喂” 最大值的过程。可以写出代码：\n// heapify 从数组的第i个元素为父节点，使其符合大根堆的特性。前提，左右子树均已经是大根堆了 func heapify(arr []int, n int, i int) { if i \u0026gt;= n { return } // 第i个结点的左右孩子分别为 left := 2*i + 1 right := 2*i + 2 // 求得父节点、左孩子、右孩子之间的最大值 maxIndex := i if left \u0026lt; n \u0026amp;\u0026amp; arr[left] \u0026gt; arr[maxIndex] { maxIndex = left } if right \u0026lt; n \u0026amp;\u0026amp; arr[right] \u0026gt; arr[maxIndex] { maxIndex = right } // 如果发生了交换，需要递归去处理对应的子树 if maxIndex != i { // 交换 使得parent为最大的那个 arr[i], arr[maxIndex] = arr[maxIndex], arr[i] //fmt.Println(arr[maxIndex], arr[left], arr[right]) // 此时，修改了原来的结构，为了保证交换后的子树也继续是大根堆，这里递归调用调整子树 heapify(arr, n, maxIndex) } } 1.3 build heap 当我们从下到上构建一个大根堆的时候，没必要从最后一个元素开始，需要从最后一个有孩子的父节点开始，所以第一步是先找到 最后一个有孩子的父节点。方法很简单，找到最后一个孩子，再根据他们之间的关系很容易就能求得其父节点的索引值。之后遍历所有的有孩子的节点，即剩下的 13 , 14, 25，这三个元素刚好按照数组索引的顺序递减，因此可以写出代码：\n// buildHeap 从底向上构建大根堆 func buildHeap(arr []int) { n := len(arr) parent := (n - 1 - 1) / 2 // n-1为数组最后一个元素的index，其父节点为 ((n-1) - 1) / 2 for i := parent; i \u0026gt;= 0; i-- { // 从这个父节点开始，一直到第一个元素，从下到上构建不断heapify heapify(arr, n, i) } } 1.4 heap sort 构建出大根堆之后，堆顶(也就是数组index=0)的元素就是最大值。此时，我们将数组第一个元素和最后一个元素交换位置，之后缩小数组长度再次从头到尾进行 heapify ，之后再交换，最后的结果就是 数组从尾巴到头的元素一次递减。\nfunc heapSort(arr []int) { buildHeap(arr) // 构建大根堆 // 最后一个元素 与 第一个元素(最大)交换，之后再次heapify，再交换，结果就是从尾到头数值依次减小 for i := len(arr) - 1; i \u0026gt;= 0; i-- { arr[0], arr[i] = arr[i], arr[0] heapify(arr, i, 0) } } 2. 插入排序 它的工作原理是构建有序序列，对于未排序的数据，在已经排好序的序列中从后向前扫描，放入合适的位置。\n优点是：对近乎有序的一组数排序，其时间复杂度可以接近线性。 这个特性非常重要！谨记！！\n步骤：\n第一步，将第一个元素看成有序序列，第二个元素到最后一个元素看成未排序的序列； 从头到尾扫描未排序的序列，将这个元素插入到前面的有序序列的合适位置。为了 稳定性 的目的，如果某个元素和有序序列中的某个元素相同，应该将这个元素放在有序序列元素的后面。 // insertionSort 插入排序 func insertionSort(arr []int) { sortedIndex := 0 // 有序序列的最后一个元素 // 遍历所有的未排序元素 for i := sortedIndex + 1; i \u0026lt; len(arr); i++ { // 从当前元素开始向前遍历有序序列 for j := i; j \u0026gt; 0; j-- { // 当前值大于等于前面的，终止循环 if arr[j-1] \u0026lt;= arr[j] { break } // 如果当前值比前一个小，交换，之后循环再不断交换 arr[j-1], arr[j] = arr[j], arr[j-1] } } } 3. 希尔排序 是插入排序的改进版本，更高效一些，但是它是不稳定的。具体步骤如下：\n以 gap 为间隔分组 分好的组内内部排好序 降低 gap，重复上述步骤，直到 gap 变成 1，此时变成对整个数组进行排序 有一个问题，组内排序，采用什么方法？答案是 插入排序法，原因就是，在 gap 不断减小的过程中，数组主键接近有序，此时借助插入排序的优点：对近乎有序的一组数排序，其时间复杂度可以接近线性。是一个不错的选择。\nfunc shellSort(arr []int) { gap := 1 // 计算gap，简单点，可以让gap变成数组长度的一半 for gap \u0026lt; len(arr)/3 { gap = gap*3 + 1 } for gap \u0026gt; 0 { for i := gap; i \u0026lt; len(arr); i++ { tmp := arr[i] j := i - gap // 每次之和当前组内前面的元素比较交换 for j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp { arr[j+gap] = arr[j] j -= gap } arr[j+gap] = tmp } gap /= 3 // 更新gap } } 4. 快速排序 采用的是“分而治之”的思想。步骤如下：\n第一步，挑出基准元素(一般取第一个元素) 对数组进行排序，使得所有小于基准的排在前面，大于基准的排在基准后面。最后返回分区的位置。这个操作我们称之为 partition。 递归地 把小于基准值元素的子数列和大于基准值元素的子数列排序 func quickSort(arr []int) []int { return _QuickSort(arr, 0, len(arr)-1) } func _QuickSort(arr []int, left, right int) []int { if left \u0026lt; right { partitionIndex := partition(arr, left, right) _QuickSort(arr, left, partitionIndex-1) _QuickSort(arr, partitionIndex+1, right) } return arr } func partition(arr []int, startIndex, endIndex int) int { var ( pivot = arr[startIndex] // 基准 left = startIndex right = endIndex ) for left != right { // right指向倒数第一个小于基准的数 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026lt; arr[right] { right-- } // left指向顺数第一个大于基准的 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026gt;= arr[left] { left++ } // 交换left和right处的值 if left \u0026lt; right { arr[left], arr[right] = arr[right], arr[left] } } // 此时left=right，将left与pivot处的值交换即可 arr[startIndex], arr[left] = arr[left], arr[startIndex] return left } ","permalink":"http://localhost:1313/posts/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","summary":"\u003ch2 id=\"1-堆排序\"\u003e1. 堆排序\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e堆\u003c/strong\u003e 是一种数据结构，它具有如下特征：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e是一棵完全二叉树\u003c/li\u003e\n\u003cli\u003e父节点的值 \u0026gt; 子节点的值\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"11-完全二叉树\"\u003e1.1 完全二叉树\u003c/h3\u003e\n\u003cp\u003e若设二叉树的深度为\u003ccode\u003eh\u003c/code\u003e，除第 \u003ccode\u003eh\u003c/code\u003e 层外，其它各层 \u003ccode\u003e(1～h-1)\u003c/code\u003e 的结点数都达到最大个数，第 \u003ccode\u003eh\u003c/code\u003e 层所有的结点都连续集中在最左边，这就是 \u003cstrong\u003e完全二叉树\u003c/strong\u003e。\u003c/p\u003e","title":"排序算法"},{"content":"位运算 位运算讲究技巧，需要多积累经验。\n一、背景知识 Go 语言支持的 位运算符 如下：\n运算符 描述 规则 \u0026amp; 按位 与 二者同为 1 时结果才为 1，否则为 0 | 按位 或 二者同为 0 时结果才为 0，否则是 1 ^ 按位 异或 相同为 0，相异为 1 \u0026laquo; 左移 n 位，相当于乘以 2 的 n 次方 后面补 0 \u0026raquo; 右移一位，相当于除以 2 的 n 次方 截掉最后一位 1. 与 将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的对应位同为 1 时，该位才为 1，否则为 0。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a \u0026amp; b) // 0001 0100 上述例子中，我们从最后一位开始，逐位运算。可以看到只有 倒数第3位 和 倒数第5位 都是 1，结果中也只有倒数第 3 位和倒数第 5 位是 1。\n规律：\n任何数 \u0026amp; 0 = 0； 任何数 \u0026amp; 任何数 = 任何数； 2.或 将参与运算的两个数 各对应的二进制位 相或。只有当二者对应位全部是 0 时，该位结果才是 0，其他情况结果全为 1。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0011 1111 规律：\n任何数 | 0 = 任何数 任何数 | 任何数 = 任何数 3. 异或 逐位异或，对应位相同，结果为 0，否则为 1——可以理解为 “抵消 1” 效果。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0010 1011 规律：\n任何数 ^ 任何数 = 0 任何数 ^ 0 = 任何数 任何数 ^ 1 = ~任何数(按位取反) 二、经典题目 1. 二进制中 1 的个数 LeetCode 题目： 191. 位 1 的个数 1.1 题目描述 请实现一个函数，输入一个整数，输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n举例：\n输入：00000000000000000000000000001011 输出：3 解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 \u0026#39;1\u0026#39;。 1.2 思路 思路 1 最后一位通过和 1 进行 与运算，可以判断最后一位是否为 1；然后将要计算的数字向右移动 1 位，再计算是否最后一位是否为 1。逐渐循环，知道直到要计算的数变成 0。\nfunc hammingWeight(num uint32) int { result := 0 // 保存1出现的次数 for num \u0026gt; 0 { if num\u0026amp;1 == 1 { result++ // 最后一位是 1 } num \u0026gt;\u0026gt;= 1 // 将原数右移一位 } return result } 思路 2 某一位通过和 1 进行 与运算，可以判断该位是是否为 1。题目指定了 32 位无符号整数，那么循环 32 次，从最后一位开始逐位判断，如何向前移动？左移一位即可。\nfunc hammingWeight(num uint32) int { result := 0 base := uint32(1) for i := 0; i \u0026lt; 32; i++ { if base\u0026amp;num != 0 { result++ } base \u0026lt;\u0026lt;= 1 } return result } 思路 3 出发点：n \u0026amp; (n-1)，会消除 n 最后一个 1。因此，n \u0026amp; (n-1) 总是能把 n中最低位的 1 变成 0 ，并保持其他位不变。具体什么原因，暂时不做深究。\nfunc hammingWeight(num uint32) int { result := 0 for num \u0026gt; 0 { result++ num \u0026amp;= num - 1 } return result } 2. 判断一个数是否为 2 的幂 LeetCode 题目：231. 2 的幂 2.1 题目描述 给定一个整数，编写一个函数来判断它是否是 2 的幂次方。\n示例：\n输入: 1 输出: true 解释: 20 = 1 2.2 解题思路 如果将 2 的所有次幂的二进制写出来，你会发现这些数的规律：最高位都是 1，其余位全是 0。也就是说，如果一个数为 2 的次幂，那么它只有一个 1，而且是在最高位，同时也是最后一个 1。再回想一下上一题中的思路三，n \u0026amp; (n-1) 会消除最后一个 1，于是乎：\nfunc isPowerOfTwo(n int) bool { return n \u0026gt; 0 \u0026amp;\u0026amp; n\u0026amp;(n-1) == 0 } 3. 使用位运算求和 LeetCode 题目：剑指 Offer 65. 不用加减乘除做加法 3.1 题目描述 写一个函数，求两个整数之和，要求在函数体内不得使用 “+”、“-”、“*”、“/” 四则运算符号。\n举例：\n输入: a = 1, b = 1 输出: 2 提示：\na, b 均可能是负数或 0 结果不会溢出 32 位整数 3.2 解题思路 我们用 n 表示无进位和，c 表示进位，那么 sum = a + b = n + c，而位运算可以分别计算出 n 和 c。以两个 1 位的二进制数求和为例：\na b 无进位和 n 进位 c 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 10 从上表中可以看出，n = a ^ b，c = (a\u0026amp;b) \u0026lt;\u0026lt; 1。借用 leetcode 上大神的一张图：\n但是在 sum = n + c 中还是使用了加法，而这种情况我们依旧可以使用上面的规律。这里可以使用一个循环来解决，需要存储n 和 c，循环直到c = 0 时停止，而此时n 即为结果。\nfunc add(a,b int) int { /* * 循环解法 for b != 0 { b, a = (a\u0026amp;b) \u0026lt;\u0026lt; 1, a ^ b } return a */ /* * 递归解法，比上面的循环解法更清晰 if b == 0 { return a } return add(a ^ b, (a \u0026amp; b) \u0026lt;\u0026lt; 1) */ } 4. 数组中出现的次数 LeetCode 题目：136. 只出现一次的数字 4.1 题目描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,1] 输出: 1 4.2 解题思路 回想前面背景知识中的 异或 的特性：任何数 ^ 任何数 = 0，并且 任何数 ^ 0 = 任何数。所以思路很明显，全部进行 异或 操作，出现两次的都会被“抵消”，最后剩下那个“没人要的”，就是我们要找的。\nfunc singleNumber(nums []int) int { if len(nums) == 0 { return 0 } // 整体异或运算 for i:=1;i\u0026lt;len(nums);i++ { nums[0] ^= nums[i] // 使用已有数组的第0个位置，节省空间 } return nums[0] } 4.3 进阶——只出现一次的数字 II LeetCode 题目：137. 只出现一次的数字 II 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,3,2] 输出: 3 使用一个 map 的解法这里没必要说了，因为使用了额外空间。\n思路 1 使用数学规律法——原数组去重、再乘以 3 得到的值，刚好就是要找的元素的 2 倍。Go 中没有 set 的这种数据结构，这里提供 Python 解法：\ndef singleNumber(nums){ return int((sum(set(nums))*3 - sum(nums))/2) } 思路 2 回想之前的 异或，发现有两个 1，该位结果是 0；二进制加法中，两个 1 相加，产生了进位，抛弃进位，其结果也是 0——这个过程，可以看成是对应位上 1 的个数对 2 取模的结果。如果是三个数呢？是不是三个数的对应位都是 1 的时候，该位结果才是 0，否则就是 1——对应位上的 1 的个数对 3 取模即可。\nfunc singleNumber(nums []int) int { result := 0 for i := 0; i \u0026lt; 64; i++ { // int至少32位，一般都是64位 // 初始化每一位1的个数为0 number := 0 for _, k := range nums { // 通过右移i位的方式，计算每一位1的个数 number += (k \u0026gt;\u0026gt; i) \u0026amp; 1 } // 对3取模后 最终将抵消后剩余的1放到对应的位数上 res |= (number) % 3 \u0026lt;\u0026lt; i } return res } 再如果 除 1 个元素外，每个元素出现了 4 次呢？原理一样，对 4 取模即可。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%BD%8D%E8%BF%90%E7%AE%97/","summary":"\u003ch1 id=\"位运算\"\u003e位运算\u003c/h1\u003e\n\u003cp\u003e位运算讲究技巧，需要多积累经验。\u003c/p\u003e\n\u003ch2 id=\"一背景知识\"\u003e一、背景知识\u003c/h2\u003e\n\u003cp\u003eGo 语言支持的 \u003cstrong\u003e位运算符\u003c/strong\u003e 如下：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e运算符\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e描述\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e规则\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026amp;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e与\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 1 时结果才为 1，否则为 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e|\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 0 时结果才为 0，否则是 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e^\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e异或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e相同为 0，相异为 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026laquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e左移 n 位，相当于乘以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e后面补 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026raquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e右移一位，相当于除以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e截掉最后一位\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"1-与\"\u003e1. 与\u003c/h3\u003e\n\u003cp\u003e将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的\u003cstrong\u003e对应位同为 1 时，该位才为 1，否则为 0\u003c/strong\u003e。\u003c/p\u003e","title":"LeetCode-位运算"},{"content":"leetcode 上 三数之和 问题：\n15. 三数之和 259. 较小的三数之和 16. 最接近的三数之和 1. 题目描述 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素a，b，c ，使得 a + b + c = 0？请你找出所有满足条件且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例：\n给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 2. 解题思路 直接跳过暴力解法，说说此题的思路。\n首先，对这个数字排一下序；\n之后，采取固定一个数，同时用双指针来查找另外两个数的方式求解：\n比如，先固定第一个元素，下一个元素设置为 left 指针，最后一个元素设置为 right 指针； 计算这三个数之和是否为 0，如果是，这就是一组满足条件的三元组；如果不是，看结果与 0 的关系，如果小于 0，则 left 向右移动，再比较，如果大于 0，则 right 向左移动一位，再比较。 当然，如果当 固定元素+left \u0026gt; 0 或者 固定元素+right \u0026lt; 0 时，就没必要再去比较了。 以下是代码实现：\nfunc threeSum(nums []int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { // 最外层循环为 固定指针 pin = i left = i + 1 // left 为固定指针的下一个元素 right = l - 1 // right 为最后一个元素 // 如果最小的大于0，不用再循环了 if nums[pin] \u0026gt; 0 { break } // 跳过 pin 相同的 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 找到一个三元组 if nums[pin]+nums[left]+nums[right] == 0 { result = append(result, []int{nums[pin], nums[left], nums[right]}) // 跳过left相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } // 跳过 right 相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1] { right-- } // 找到之后，同时改变 left++ right-- } else if nums[pin]+nums[left]+nums[right] \u0026lt; 0 { // 左指针向右移动 left++ } else { right-- } } } return result } 3. 进阶 1——较小的三数之和 给定一个长度为 n 的整数数组和一个目标值 target，寻找能够使条件 nums[i] + nums[j] + nums[k] \u0026lt; target 成立的三元组 i, j, k 个数（0 \u0026lt;= i \u0026lt; j \u0026lt; k \u0026lt; n）。\n示例：\n输入: nums = [-2,0,1,3], target = 2 输出: 2 解释: 因为一共有两个三元组满足累加和小于 2: [-2,0,1] [-2,0,3] 直接上代码：\nfunc threeSumSmaller(nums []int, target int) int { result := 0 // 满足条件的三元组数目 sort.Ints(nums) // 先排序 var pin, left, right int // 固定、左、右 指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { pin = i // 固定指针 left = i + 1 // 左指针指向固定指针的下一个 right = l - 1 // 右指针指向最后一个元素 for left \u0026lt; right { if nums[pin]+nums[left]+nums[right] \u0026gt;= target { // 说明这个 right 不能出现在三元组中, right 左移一位 right-- } else { // 从 left 到 right 之间的那几对都符合条件， left 右移一位 result += right - left left++ } } } return result } 4. 进阶 2——最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1 输出：2 解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 代码如下：\nfunc threeSumClosest(nums []int, target int) int { result := math.MaxInt32 // 结果 sort.Ints(nums) // 先排序 var pin, left, right int // 固定指针 左指针 右指针 l := len(nums) // 数组长度 // 求绝对值 abs := func(a int) int { if a \u0026lt; 0 { return -1 * a } return a } // 更新 result updateFunc := func(sum int) { if abs(sum-target) \u0026lt; abs(result-target) { result = sum } } for i := 0; i \u0026lt; l-2; i++ { pin = i left = i + 1 right = l - 1 // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 如果 right 左移一位，结果离得更远了，说明需要left向右移 //result = min(result, nums[pin]+nums[left]+nums[right]) sum := nums[right] + nums[left] + nums[pin] if sum == target { return target } updateFunc(sum) if sum \u0026gt; target { // 此时需要向左移动 right，并且移动到下一个不相等的 tmp := right - 1 for left \u0026lt; tmp \u0026amp;\u0026amp; nums[tmp] == nums[right] { tmp-- } right = tmp } else { // 向右移动left tmp := left + 1 for tmp \u0026lt; right \u0026amp;\u0026amp; nums[tmp] == nums[left] { tmp++ } left = tmp } } } return result } 5. 总结 解决此类问题，一般都是 升序后，外层循环 + 内层双指针 思路。其中最关键的是 左右指针移动的条件，一般都是和 target 比大小，大于 target 就向左移动右指针，小于 target 就向右移动左指针。\n由此延伸到 四数之和 问题，解决思路与之类似，设置两个固定指针，即外层两个循环，剩下的处理逻辑与 三数之和 一样。\n看一下 四数之和：\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n注意：\n答案中不可以包含重复的四元组。\n示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin1, pin2, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-3; i++ { pin1 = i // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] { continue } for j := i + 1; j \u0026lt; l-2; j++ { pin2 = j left = j + 1 right = l - 1 // 不要重复 if j \u0026gt; i+1 \u0026amp;\u0026amp; nums[j] == nums[j-1] { continue } for left \u0026lt; right { // 相等 if nums[pin1]+nums[pin2]+nums[left]+nums[right] == target { result = append(result, []int{nums[pin1], nums[pin2], nums[left], nums[right]}) for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } for left \u0026lt; right \u0026amp;\u0026amp; nums[right-1] == nums[right] { right-- } left++ right-- } else if nums[pin1]+nums[pin2]+nums[left]+nums[right] \u0026gt; target { right-- } else { left++ } } } } return result } ","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003e三数之和\u003c/code\u003e 问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum/\"\u003e15. 三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-smaller/\"\u003e259. 较小的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-closest/\"\u003e16. 最接近的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-题目描述\"\u003e1. 题目描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给你一个包含 \u003ccode\u003en\u003c/code\u003e 个整数的数组 \u003ccode\u003enums\u003c/code\u003e，判断 \u003ccode\u003enums\u003c/code\u003e 中是否存在三个元素\u003ccode\u003ea，b，c\u003c/code\u003e ，使得 \u003ccode\u003ea + b + c = 0\u003c/code\u003e？请你找出所有满足条件\u003cstrong\u003e且不重复\u003c/strong\u003e的三元组。\u003c/p\u003e","title":"LeetCode-三数之和问题"},{"content":"leetcode 上 twoSum 相关的问题：\n1. 两数之和 167. 两数之和 II - 输入有序数组 170. 两数之和 III .数据结构设计 1. 问题描述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 2. 解决思路 一般情况下，使用的是暴力穷举法，但是这种情况下时间复杂度为 $O(n^2)$，爆炸，不考虑。\n这里采用 空间换时间 的思路：\n设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的 索引i和 map[target-j] 即为所需要的。\n下面通过代码实现：\nfunc twoSum(nums []int, target int) []int { result := make([]int,0) m := make(map[int],int) for i,j := range nums { if v, ok := m[target-j]; ok { result = append(result, v) result = append(result, i) } m[j] = i } return result } 3. 进阶 设计并实现一个 TwoSum 的类，使该类需要支持 add 和 find 的操作。\nadd 操作 - 对内部数据结构增加一个数。\nfind 操作 - 寻找内部数据结构中是否存在一对整数，使得两数之和与给定的数相等。\n示例 1:\nadd(1); add(3); add(5); find(4) -\u0026gt; true find(7) -\u0026gt; false 示例 2:\nadd(3); add(1); add(2); find(3) -\u0026gt; true find(6) -\u0026gt; false 实现如下：\ntype TwoSum struct { M map[int]int } /** Initialize your data structure here. */ func Constructor() TwoSum { return TwoSum{M: make(map[int]int)} } /** Add the number to an internal data structure.. */ func (this *TwoSum) Add(number int) { this.M[number]++ // 这里的map中，key保存number，value保存出现的次数 } /** Find if there exists any pair of numbers which sum is equal to the value. */ func (this *TwoSum) Find(value int) bool { for key := range this.M { other := value - key // 第一种情况，针对出现了两次的元素、value为其2倍的，比如 [3,3]，value为6 if other == key \u0026amp;\u0026amp; this.M[other] \u0026gt; 1 { return true } // 第二种情况，针对出现过一次的元素，比如 [2,6], value 为8 if other != key \u0026amp;\u0026amp; this.M[other] \u0026gt; 0 { return true } } return false } 4. 总结 对于题目 1 和题目 167： 设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的索引i和 map[target-j] 即为所需。\n对于题目 170： 设计数据结构时，map 的 key 为元素，value 为该元素出现的此时。查找时，考虑两种情况：一种是 [3,3]--\u0026gt;6 的情况，一种是 [2,5] --\u0026gt; 7 的情况。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003etwoSum\u003c/code\u003e 相关的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum/\"\u003e1. 两数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/\"\u003e167. 两数之和 II - 输入有序数组\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-iii-data-structure-design/\"\u003e170. 两数之和 III .数据结构设计\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-问题描述\"\u003e1. 问题描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\u003c/p\u003e","title":"LeetCode-两数之和问题"},{"content":"一、设计原理 哈希表(也就是我们说的map)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是O(1)，是典型的 以空间换时间 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：哈希函数 和 冲突解决方法。\n1. 哈希函数 可以将任意长度的数据 映射 到有限长度的域上。通俗解释：你可以把它抽象成一个黑盒(一个函数 f)，它的输入是任意数据 m，输出是另一段固定范围的数据 n，即f(m) = n，n 可以作为 m 的特征(指纹)。\n对任意两个输入m1和m2，如果他们的输出均不同，则称这个函数为 完美哈希函数。如果存在m1和m2，有 f(m1) = f(m2)，则称这个函数为 不均匀哈希函数，这个现象称为 哈希碰撞。\n完美哈希函数很难找到，比较实际的做法是 让哈希函数的结果尽可能地分布均匀，然后通过工程上的手段解决哈希碰撞的问题。但是哈希的结果一定要尽可能均匀，结果不均匀的哈希函数会造成更多的冲突并导致更差的读写性能。\n2. 解决哈希冲突的方法 在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多最终也会造成冲突。\n然而我们的哈希函数往往都是不完美的，输出的范围是有限的，所以一定会发生哈希碰撞，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。\n2.1 开放寻址法 这种方法的核心思想在于 线性探测，通常情况下，这种哈希表的底层数据结构就是数组。先计算index，判断数组的这个index处是否有值，如果没有，直接存入；否则从这个index向后遍历，直到找到一个为空的index。可以大致用下面的代码表示：\nfunc hash1(source string) int { arr := make([]string,10,10) index := hash(source) % len(arr) tmp := index for { if arr[index%len(arr)] == \u0026#34;\u0026#34; { return index }else { index++ } if index == tmp { return -1 // 没找到 } } } 查找的时候，还是先计算 index ，如果数组在该位置的数刚好是要找的，直接返回，否则需要向后逐步遍历比较。在某些情况下，当装载的元素太多时，哈希表的性能会急剧下降，最差的结果就是每次增加和查找，都需要遍历整个数组，此时整个哈希表完全失效。\n2.2 拉链法 与开放地址法相比，拉链法是哈希表中最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。\n拉链法使用链表作为底层数据结构，我们把这个链表称为桶。这种方法对哈希冲突的解决方法是：直接在相同哈希值的结点后面增加一个链表结点。查询的时候，先找到对应链表第一个结点，之后遍历链表寻找符合要求的那个。\n在一个性能比较好的哈希表中，每一个桶中都应该有 01 个元素，有时会有 23 个，很少会超过这个数量，计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：\n装载因子 := 元素数量/桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。\n二、用到的数据结构 我的 Go 版本：\ngo version go1.14.6 darwin/amd64 Go 语言中对哈希表的实现方案是：使用拉链法解决哈希冲突。同时使用了多个数据结构组合来标识哈希表。\n在源码中，表示map 的结构体是 hmap：\n// A header for a Go map. type hmap struct { count int // 当前哈希表中元素个数，调用len(m)时直接返回此值 flags uint8 // B uint8 // 当前哈希表持有的 buckets 数量的对数，即 buckets数量 = 2^B noverflow uint16 // overflow 的 buckets 的近似数(buckets\u0026lt;16时是准确的) hash0 uint32 // 哈希种子，在创建哈希表时确定的随机数，并在调用哈希函数的时候作为参数传入 buckets unsafe.Pointer // 指向 buckets 数组，大小为 2^B，如果元素个数为0则为nil oldbuckets unsafe.Pointer // 渐进式扩容时用于保存之前的 buckets，扩容的时候，buckets 长度会是 oldbuckets 的两倍 nevacuate uintptr // 指示扩容进度，表示即将迁移的旧桶编号 extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. 溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 目前已经使用的溢出桶的地址 oldoverflow *[]*bmap // 在扩容阶段存储旧桶用到的溢出桶的地址 nextOverflow *bmap // 指向下一个空闲溢出桶 } buckets 是一个指针，最终指向的是一个结构体：\n// A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 } bmap 结构体其实不止包含 tophash 字段，由于哈希表中可能存储不同类型的键值对并且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导，这些字段在运行时也都是通过计算内存地址的方式直接访问的，所以它的定义中就没有包含这些字段，实际上的 bmap 是这样的：\ntype bmap struct { topbits [8]uint8 // tophash数组 keys [8]keytype // key数组 values [8]valuetype // value数组 pad uintptr overflow uintptr // 当当前桶存满时，发现还有可用的溢出桶，就会用此指针链接一个溢出桶，溢出桶也是 bmap 结构 } 如上图所示，hmap的桶就是 bmap，每一个 bmap 最多能存储 8 个键值对，这些键值对之所以会落在同一个桶，是因为他们经过哈希计算之后，得到的哈希结果是 “一类的”。当单个桶中存储的数据过多而无法装满时，就会使用 extra.overflow 中的桶存储溢出的数据。上面两种桶在内存中是连续的，我们暂且称之为 常规桶 和 溢出桶。\n我们来看看 bmap 的内部组成：\n最开始是 8 个 tophash，每个 tophash 都是对应哈希值的高 8 位。需要注意的是，key 和 value 是各自放在一起的，这样的好处是为了padding 时节省空间。每一个桶被设计成最多只能存放 8 个键值对，如果有第 9 个键值对落入当前的桶，那就需要再构建一个桶(溢出桶)，然后用 overflow 指针连接起来。\n三、使用 1. 初始化 无论是通过字面量还是运行时，最终底层都会调用 makemap 方法：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // 计算哈希占用的内存是否溢出或者产出能分配的最大值 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } if h == nil { h = new(hmap) } // 获取随机的哈希种子 h.hash0 = fastrand() // 根据传入的hint计算需要的最少的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 创建用于保存桶的数组 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 需要注意的是 makeBucketArray 函数，这个函数会根据传入的 B 计算出的需要创建的桶的数量 在内存中分配一片连续的空间用于存储数据。当桶的数量小于 $2^4$ 时，由于数据较少，使用溢出桶的可能性比较低，这时会省略创建的过程以减少额外开销；当桶的数量多于 $2^4$ 时，就会额外创建 $2^{B-4}$ 个溢出桶。正常情况下，溢出桶和常规桶在内存中的存储空间是连续的，只不过被 hmap 的不同字段引用。\n另外注意makemap 的返回，是一个 *hmap ，指针类型，这个时候传给函数在函数中改变的就是原来的 map ，即 改变map类型的形参，是可以影响实参的。这一点和之前的 slice 不同，slice 返回的是一个 slice 结构体，虽底层共用数组，但是扩容后就与原来的数据脱钩了。\n举个例子，下面的代码：\nmap := make(map[string]string, 10) Go 源码中的负载因子是 6.5 ，在源码 /usr/local/go/src/runtime/map.go:70 可以找到：\n// Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 这里的map 的键值对个数是 10，根据 负载因子 = 键值对个数/桶个数，得到 需要的桶的个数为 2。此时不会创建更多的溢出桶。\n2. 写 源码中执行 写入 操作的是 mapassign 函数，该函数较长，我们分步来看(每一步我会在关键位置写上注释，也更容易理解过程)。\n首先，函数会根据传入的键计算哈希，确定所在的桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // a.调用key类型对应的哈希算法得到哈希 hash := t.hasher(key, uintptr(h.hash0)) // b.设置 写 标志位 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // c.根据 hash 计算位于哪个 bucket bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // d.如果 map 正在扩容，此操作确保此 bucket 已经从 hmap.oldbuckets 被搬运到 hmap.buckets growWork(t, h, bucket) } // e.取得 bucket 所在的内存地址 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) // f.计算此bucket中的tophash，方法是：取高8位 top := tophash(hash) // ... } 在 64 位机器上，步骤 a 计算得到的 hash 值共有 64 个 bit 位。之前提到过，hmap.B 表示桶的数量为 $2^{h.B}$。这里用得到的哈希值的最后 B 个 bit 位表示落在了哪个桶中，用哈希值的 高 8 位表示此 key 在 bucket 中的位置。\n还是以上面的map = make(map[string]int, 10)为例，计算可知 B=2，则应该用后 2 位用来选择桶，高 8 位用来表示 tophash。 某个 key 经过哈希之后得到的 hash=01100100 001011100001101110110010011011001000101111000111110010 01，后两位 01 代表 1 号桶。\n然后，会有两层循环，最外层循环 bucket 以及其链接的溢出桶(如果有的话)，内存逐个遍历所有的tophash： var inserti *uint8 // 目标元素在桶中的索引 var insertk unsafe.Pointer // 桶中键的相对地址 var elem unsafe.Pointer // 桶中值的相对地址 bucketloop: // 最外层是一个死循环，其实是当前 bucket 后面链接的溢出桶(overflow) for { // bucketCnt=8，因为一个bucket最多只能存储8个键值对 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 找到一个tophash不同的 if b.tophash[i] != top { // isEmpty判断当前tophash是否为正常tophash值而不是系统迁移标志 if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // 已经找到一个可以放置的位置了，为什么不直接break掉？是因为有可能K已经存在，需要找到对应位置然后更新掉 } // 如果余下位置都是空的，则不再需要往下找了 if b.tophash[i] == emptyRest { break bucketloop } continue } // tophash 相同后，还需要再比较实际的key是否相同 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // key已经在map中了，更新之 if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } // 外层循环接着遍历这个bucket后面链接的overflow ovf := b.overflow(t) if ovf == nil { break } b = ovf } 在上述代码中有出现isEmpty 以及 emptyRest 等标志位，这其实是 tophash 的状态值，在源码 /usr/local/go/src/runtime/map.go:92 中可以找到：\n// // Possible tophash values. We reserve a few possibilities for special marks. emptyRest = 0 // 这个 cell 是空的, 并且在当前bucket的更高的index 或者 overflow中，其他的都是空的 emptyOne = 1 // 这个 cell 是空的 evacuatedX = 2 // K-V 已经搬迁完毕，但是 key 在新的 bucket 的前半部分(扩容时会提到) evacuatedY = 3 // 同上，key 在新的 bucket 的后半部分 evacuatedEmpty = 4 // cell 是空的，并且已经被迁移到新的 bucket 上 minTopHash = 5 // 正常的 tophash 的最小值 由此也可知，正常的 tophash 是 大于 minTopHash 的。\n如果此时 (键值对数已经超过负载因子 或者 已经有太多的溢出桶) \u0026amp;\u0026amp; 当前没有处在扩容阶段，那么 开始扩容： // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } 具体的扩容过程后面再细说，这里暂不讨论。\n如果没有找到合适的 cell 来存放这个键值对(桶满了)，则 使用预先申请的保存在 hmap.extra.nextoverflow 指向的溢出桶 或者 创建新桶 来保存数据，之后将键值对插入到相应的位置： if inserti == nil { // all current buckets are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } // 将键值对移动到对应的空间 typedmemmove(t.key, insertk, key) *inserti = top h.count++ 而使用预分配的溢出桶还是申请新的桶，在 newoverflow 函数中：\nfunc (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap if h.extra != nil \u0026amp;\u0026amp; h.extra.nextOverflow != nil { // 如果有预分配的 bucket ovf = h.extra.nextOverflow if ovf.overflow(t) == nil { // 并且预分配的溢出桶还没有使用完，则使用这个溢出桶，并更新 h.extra.nextOverflow 指针 h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize))) } else { // 预分配的溢出桶已经用完了，则置空 h.extra.nextOverflow指针 ovf.setoverflow(t, nil) h.extra.nextOverflow = nil } } else { // 没有可用的溢出桶，则申请一个新桶 ovf = (*bmap)(newobject(t.bucket)) } // 更新h.noverflow(overflow的树木)，如果h.B \u0026lt; 16，则自增1，否则“看可能性”自增(没啥用，感兴趣可以自己研究一下) h.incrnoverflow() if t.bucket.ptrdata == 0 { h.createOverflow() *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) return ovf } 3. 读 我们再来说说 读 的过程。map 的读取有两种方式：带 comma 和 不带 comma 的。这两种方式，其实底层调用的分别是：\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer // v1 := m[key] func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) // v2, isExist := m[key] 这两个函数大同小异，我们只看 mapaccess1。我们还是采用分步的方式来从源码中探究细节：\n根据 key 计算得到 hash 值，同时确定在哪个 bucket 中寻找： // 这个函数永远不会返回 nil ，如果map是空的，则返回对应类型的 零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026amp;zeroVal[0]) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map read and map write\u0026#34;) } // 得到 hash 值 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // 本例中m=31 // 得到 bucket b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { // 正处在扩容阶段 // 如果不是等量扩容(后面会讲到) if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. // 非等量扩容，那就是渐进式扩容，在原来基础上增加了2倍，为了得到原来的，这里除以2 m \u0026gt;\u0026gt;= 1 // m=15 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 是否处于扩容阶段 if !evacuated(oldb) { b = oldb } } top := tophash(hash) 和前面 写 的过程类似，也是两个大循环，外层遍历 bucket 以及链接在后面的 溢出桶，内层遍历每个 bucket 中的 tophash，直至找到需要的 键值对： bucketloop: // 外层循环溢出桶 for ; b != nil; b = b.overflow(t) { // bucketCnt=8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { // 和当前index的tophash不相等，并且后面的cell都是空的，说明后面就没不要再去遍历了，直接退出循环，返回对应元素的零值 if b.tophash[i] == emptyRest { break bucketloop } continue } // 找到对应的 key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // tophash相同，还要判断完整的key是否相同 if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } // 根据偏移找到对应的value，直接返回 return e } } } // 没找到，返回对应类型的零值 return unsafe.Pointer(\u0026amp;zeroVal[0]) 另外，编译器还会根据 key 的类型，将具体的操作用更具体的函数替换，比如 string 对应的是 mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer，函数的参数直接就是具体的类型，这么做是因为提前知道了元素类型，而且由于 bmap 中 key 和 value 各自放在一起，内存布局非常清晰，这也是前面说的 “减少 padding 带来的浪费”的原因。\n4. 扩容 在前面介绍 写 过程时，我们跳过了有关扩容的内容，现在回过头来看一下：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } // ... } // 判断h是否正在扩容。 扩容结束之后，h.oldbuckets 会被置空 func (h *hmap) growing() bool { return h.oldbuckets != nil } // 判断map中的键值对数目与已有的buckets 是否超过负载因子 即 count/2^B 与 6.5的大小关系 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 是否有太多的bucket func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. if B \u0026gt; 15 { B = 15 } // 翻译一下这条语句： // 如果 B \u0026lt; 15， 即 bucket总数 \u0026lt; 2^15 时，overflow的bucket数目不超过 2^B // 如果 B \u0026gt;= 15，即 bucket总数 \u0026gt; 2^15 时，overflow的bucket数目不超过 2^15 // 即 noverflow \u0026gt;= 2^(min(B,15)) return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 从现实角度出发，会有以下两种情形：\n在没有溢出、且所有的桶都装满了的情况下，装载因子是 8，超过了 6.5，表明很多的 bucket 中都快装满了，读写效率都会降低，此时进行扩容是必要的； 当装载因子很小、但是 bucket 很多的时候，map 的读写效率也会很低。什么时候会出现 “键值对总数很小、但 bucket 很多”的情况呢？不停地插入、删除元素。当插入很多元素时，导致创建了更多的 bucket ，之后再删除，导致某个 bucket 中的键值对数量非常少。“这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。” 对于上述两种情况，Go 有着不同的策略：\n对于第一种情况，城中人多房少，直接将 B 加一，建更多的房子即可； 对第二种情况，新开辟一块同样大小的空间，然后将旧空间中的键值对全部搬运过去，然后重新组织。 扩容 最基础的一个操作是 将原有的键值对搬到新开辟的空间，如果键值对数量太多，将严重影响性能。因此对于情况一，Go 采取 渐进式扩容，并不会一次全部搬完，每次最多只搬迁 2 个 bucket；第二种情况，称之为 等量扩容 ，可以理解成“内存整理”。接下来我们通过源码来分析实际的过程：\n执行扩容的函数是 hashGrow ， hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数和 evacuate() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。\n我们来看看 hashGrow 函数：\nfunc hashGrow(t *maptype, h *hmap) { // If we\u0026#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026#34;grow\u0026#34; laterally. // 首先通过 是否超过负载因子 判断进行渐进式扩容还是等量扩容 bigger := uint8(1) // 默认等量扩容 if !overLoadFactor(h.count+1, h.B) { // 如果没有超过负载因子，则进行等量扩容 bigger = 0 h.flags |= sameSizeGrow } // 申请新的 bucket 空间，并将原来的 h.buckets 字段 转移到 h.oldbuckets oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) // 将以前原有的buckets的标志位也转移到新申请的buckets去 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 执行grow操作 (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 // h.nevacuate指示扩容进度，表示当前正在搬迁旧的第几个bucket h.noverflow = 0 // 将溢出桶个数置为零 // 将extra中的overflow扔到oldoverflow中去 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026#34;oldoverflow is not nil\u0026#34;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 第 17 行涉及到的 flag 如下：\n// flags iterator = 1 // 可能有迭代器使用 buckets oldIterator = 2 // 可能有迭代器使用 oldbuckets hashWriting = 4 // 有协程正在向 map 中写入 key sameSizeGrow = 8 // 等量扩容（对应第二种情况） 我们再来看看实际执行扩容的 growWork 和 evacuate：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 还没搬迁完成的话，再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) } } evacuate 函数非常长，我们还是逐步去深入：\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位到老的bucket b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() // 存放增长之前的bucket数，结果为 2^B if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. /* // evacDst表示搬迁的目的区域. type evacDst struct { b *bmap // 搬去的bucket i int // bucket中键值对的index k unsafe.Pointer // pointer to current key storage e unsafe.Pointer // pointer to current elem storage } */ // 这里设置两个目标桶，如果是等量扩容，则只会初始化其中一个； // xy 指向新空间的高低区间的起点 var xy [2]evacDst x := \u0026amp;xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 如果是翻倍扩容，则同时初始化，之后会将旧桶中的键值对“分流”到两个新的目标桶中 if !h.sameSizeGrow() { // Only calculate y pointers if we\u0026#39;re growing bigger. // Otherwise GC can see bad pointers. y := \u0026amp;xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell for i := 0; i \u0026lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 当前cell的tophash if isEmpty(top) { // 当前cell为空，即没有key，则标志其为 “搬迁过”，然后继续下一个 cell b.tophash[i] = evacuatedEmpty continue } // 正常情况下，tophash只能是 evacuatedEmpty 或者 正常的tophash(大于等于minTopHash) if top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // 计算如何分流(将这个键值对放到x中还是y中) // 计算方法与前面相同 hash := t.hasher(k2, uintptr(h.hash0)) // !t.key.equal(k2, k2)这种情况，只能是float的NaN了 // 没有协程正在使用map \u0026amp;\u0026amp; 不是float的NaN if h.flags\u0026amp;iterator != 0 \u0026amp;\u0026amp; !t.reflexivekey() \u0026amp;\u0026amp; !t.key.equal(k2, k2) { // 在这种情况下，我们使用 tophash 的低位来作为分流的标准 useY = top \u0026amp; 1 top = tophash(hash) } else { if hash\u0026amp;newbit != 0 { useY = 1 // 新的位置位于高区间 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\u0026#34;bad evacuatedN\u0026#34;) } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026amp;xy[useY] // 放到高位置还是低位置 // 是否要放到 overflow 中 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That\u0026#39;s ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.ptrdata != 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } // 最后会调用 advanceEvacuationMark 增加哈希的 nevacuate 计数器，在所有的旧桶都被分流后清空哈希的 oldbuckets 和 oldoverflow 字段 if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 简单总结一下分流规则：\n对于等量扩容，从旧的 bucket 到新的 bucket，数量不变，因此可以按照 bucket 一一对应，原来是 0 号，搬过去之后还是 0 号； 对于渐进式扩容，要重新计算 key 的 哈希，才能决定落在哪个 bucket 。原来只有 2^B 个bucket ，确定某个 key 位于哪个 bucket 需要使用最后B 位；现在 B 增加了 1，那就应该使用最后的 B+1 位，即向前看一位。比如原来的 B=3，key1和key2的哈希后四位分别是 0x0101 和 0x1101，因为二者的后三位相同，所以会落在同一个 bucket 中，现在进行渐进式扩容，需要多看一位，此时key1和key2的哈希后四位不相同，因为倒数第 4 位有 0 和 1 两种取值，这也就是我们源码中说的 X 和 Y，key1和key2也就会落入不同的 bucket 中——如果是 0，分配到X，如果是 1 ，分配到 Y。 还有一种情况是上面函数中第 64 行 !t.key.equal(k2, k2)，即相同的 key ，对它进行哈希计算，两次结果竟然不相同，这种情况来自于 math.NaN()，NaN 的意思是 Not a Number，在 Go 中是 float64 类型(打印出来直接显示 “NaN”)，当使用它作为某个 map 的 key 时，前后计算出来的哈希是不同的，这样的后果是，我们永远无法通过 GET 操作获取到这个键值对，即使用 map[math.NaN] 是取不到想要的结果的，只有在遍历整个 map 的时候才会出现。这种情况下，在决定分流到 X 还是 Y 中时，就只能 使用tophash的最低位来决定 这个策略了——如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。\n关于 NaN：In computing, NaN, standing for Not a Number, is a member of a numeric data type that can be interpreted as a value that is undefined or unrepresentable, especially in floating-point arithmetic.\n在计算机科学中，NaN 代表 Not a Number，是一个 能够被打印出来的 未定义或者不可预知的 数字类型。\n我们简单总结一下哈希表的扩容设计和原理，哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，整个扩容过程并不是原子的，而是通过 growWork增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流；除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 sameSizeGrow(等量扩容) 这一机制，在出现较多溢出桶时会对哈希进行『内存整理』减少对空间的占用。————Go 语言设计与实现 3.3 哈希表\n5. 删除 Go 语言中删除一个 map 中的 key，使用的是特定的关键字 delete(map, key)。在底层，实际调用的 /usr/local/go/src/runtime/map.go 中的 mapdelete。这个函数的执行过程和 写 过程类似，如果在删除期间当前操作的桶遇到了扩容，就会对该桶进行分流，分流之后找到同种的目标元素完成键值对的删除工作。\n6. 遍历 理论上map 的遍历比较简单——“遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。” 但实际情况是，当我们在遍历一个处在扩容阶段的 map 时，不仅要考虑到已经搬过去的位于 h.buckets 的，还要考虑还没有搬的位于 h.oldbuckets 中的。\n接下来我们还是通过源码的方式逐步探寻 map 遍历 的奥秘。\n与之相关的函数分别是 mapiterinit 和 mapiternext，前者会初始化一个迭代器，之后循环调用后者进行迭代。迭代器结构如下：\ntype hiter struct { key unsafe.Pointer // key的指针，必须放在第一位，nil表示迭代结束 elem unsafe.Pointer // value指针，必须放在第二位 t *maptype // map中key的类型 h *hmap // 指向map的指针 buckets unsafe.Pointer // 初始化时指向的 bucket bptr *bmap // 当前遍历到的 map overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // 起始迭代的 bucket 编号 offset uint8 // 遍历时的偏移量(可以理解成遍历开始的 cell 号) wrapped bool // 是否从头遍历 B uint8 // h.B i uint8 // 当前的 cell 编号 bucket uintptr // 当前的 bucket checkBucket uintptr // 因为扩容，需要检查的 bucket } mapiterinit 主要是对 hiter 的初始化，需要关注的是这几行：\nfunc mapiterinit(t *maptype, h *hmap, it *hiter) { // ... // decide where to start r := uintptr(fastrand()) // bucketCntBits=3 if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } // bucketMask 即 1\u0026lt;\u0026lt;h.B -1 it.startBucket = r \u0026amp; bucketMask(h.B) // bucketCnt=8 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // ... } r 是一个随机数，这里假设我们的 m = make(map[string]int)， h.B=2，即有 2^2=4 个桶，可以计算得到 bucketMask(h.B)=3，二进制表示为 0000 0011，将 r 与这个数相与，就能得到 0~3 的 bucket 序号；同样，第 12 行，7 的二进制表示为 0000 0111，将 r 右移两位之后，与 7 相与，可以得到 0~7 的一个 cell 序号。这就是 map 每次遍历的 key 都是无序的原因。\n之后，使用这个随机的 bucket ，在里面的随机的这个 cell 处开始遍历，取出其中的键值对，直到回到这个 bucket 。\n接下来我们看 mapiternext 的细节：\nfunc mapiternext(it *hiter) { h := it.h if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext)) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t bucket := it.bucket b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // 回到了最开始遍历的那个 bucket，说明遍历结束了，可以退出迭代了 it.key = nil it.elem = nil return } if h.growing() \u0026amp;\u0026amp; it.B == h.B { // 如果我们当前遍历的 bucket 对应的原来的老的 bucket 的状态位显示为 “未搬迁”，则不再遍历当前的 bucket 而去遍历老的 bucket oldbucket := bucket \u0026amp; it.h.oldbucketmask() b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) if !evacuated(b) { checkBucket = bucket } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // 当前 cell 是空的，继续下一个 cell if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() { // 正好遇上扩容但是扩容还没完成，如果我们当前遍历的 bucket 对应的老 bucket还没有进行迁移，那么需要去遍历未搬迁的老的 bucket，但是！并不是遍历对应的全部的老的 bucket，而是只遍历 分流后会落在当前 bucket 的那部分键值对 if t.reflexivekey() || t.key.equal(k, k) { // 对于老 bucket 中不会分流到这个 bucket 的键值对，直接跳过 hash := t.hasher(k, uintptr(h.hash0)) if hash\u0026amp;bucketMask(it.B) != checkBucket { continue } } else { // 处理 math.NaN 情况，还是一样，看最低位来决定是不是落在当前这个 bucket if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue } } } if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // 对于 math.NaN 情况，我们只能通过遍历找到，对它的增删改查都是不可能的(这也是比较幸运的一件事，最起码能访问到，否则那真就成了“幽灵”了——占用空间又无可奈何，而且还能同一个 key 无限制地添加) it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else { // 开始迭代的时候，已经完成了扩容。此时 math.NaN 已经被放置到了别的 bucket 中，这种情况下只需要处置已经被 更新、删除或者删除后重新插入的情况。需要注意的是那些在 equal() 函数中判断为真的但是实际上他们的 key 不相同的情况，比如 +0.0 vs -0.0 rk, re := mapaccessK(t, h, k) if rk == nil { continue // key 已经被删除 } it.key = rk it.elem = re } it.bucket = bucket if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b } it.i = i + 1 it.checkBucket = checkBucket return } b = b.overflow(t) i = 0 goto next } 在 码农桃花源 深度解密 Go 语言之 map 中 map 遍历 一节，作者举了一个非常通俗易懂的例子，非常推荐，建议去看一下加深理解。\n四、总结 这是我第一次非常深入地看源码，也领会到了一切疑难杂症都会在源码面前原形毕露。map 操作的核心，就在于如何在各种情况下定位到具体的 key，搞清楚了这一点，其他问题看源码会更清晰。\nGo 语言中，哈希表的实现采用的哈希查找表，使用拉链法解决哈希冲突。有空间换时间的思想体现(不同的 key 落到不同的 bucket，即定位bucket的过程)，也有 时间换空间 思想的体现(在一个 bucket 中，采用遍历的方式寻找 key 而不是再使用哈希)，同时渐进式扩容和等量扩容的思想也值得我们学习。\n","permalink":"http://localhost:1313/posts/golang-map%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一设计原理\"\u003e一、设计原理\u003c/h2\u003e\n\u003cp\u003e哈希表(也就是我们说的\u003ccode\u003emap\u003c/code\u003e)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是\u003ccode\u003eO(1)\u003c/code\u003e，是典型的 \u003cstrong\u003e以空间换时间\u003c/strong\u003e 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：\u003cstrong\u003e哈希函数\u003c/strong\u003e 和 \u003cstrong\u003e冲突解决方法\u003c/strong\u003e。\u003c/p\u003e","title":"Golang-map详解"},{"content":"一、概述 1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器 主要解决系统线程太重的问题：\n创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大； 系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。 goroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\ngoroutine 是用户态线程，其创建和切换等，都是在用户态完成而无需进入操作系统内核，其开销相比系统线程要小很多； goroutine 启动时默认栈大小只有 2k，可以根据实际情况进行自动伸缩。 2. Go scheduler Go 程序的执行由两部分组成：Go Program 和 runtime，即 用户代码 和 运行时。这里的 runtime 和 Java、Python 中的不一样，Java 的是虚拟机，而Go 的 runtime 和用户代码一起编译到一个可执行文件中。用户代码和 runtime 除了代码组织上有界限之外，运行的时候并没有明显的界限，用户代码中，一些常用的关键字(如 go, new 等)被编译成 runtime 包下的一些函数调用。用户程序进行的系统调用都会被 runtime 拦截，以此来帮助 runtime 进行调度方面以及垃圾回收其他方面的工作。\n一张关系图如下：\n为什么需要 scheduler 呢？runtime 维护所有的 goroutine，就是通过 scheduler 来进行调度。goroutine 和系统线程是独立的，但是 goroutine 需要依赖系统线程才能执行。\n可以用一句话概括 Go scheduler 的目标：\nFor scheduling goroutines onto kernel threads.\nGo scheduler 的核心思想是：\nreuser 系统线程，限制同时运行(不包括阻塞的)的线程数为 N，其中 N 为 CPU 的核心数； 线程使用私有的本地运行队列，并且为了更高地使用 CPU，某个线程可以从其他线程偷 goroutine 来帮助运行，也可以在 goroutine 阻塞的时候将其传递给其他线程。 3. M:N 模型 goroutine 建立在操作系统线程之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。M:N 是指 M 的 goroutine 运行在 N 的操作系统线程上，内核负责对这 N 的操作系统线程进行调度，而 Go runtime 则负责将这 M 个 goroutine 调度运用在这 N 个操作系统线程上。\n简单理解，对 goroutine 的调度，是指程序代码按照一定的算法，在适当的时候挑选出合适的 goroutine 然后放到真正的线程上去执行的过程。其实并没有一个调度器实体，它只是一段代码的抽象化表示，具体来说是 需要发生调度时由操作系统线程执行runtime.schedule方法进行的。\nGo runtime 负责 goroutine 的生老病死，从创建、切换、销毁都一手包办。runtime 在启动的时候，会创建 M 个操作系统线程(CPU 内核执行调度的基本单位)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行。在同一时刻，一个系统线程上只能执行一个 goroutine，当 goroutine 发生阻塞时，runtime 会将当前 goroutine 调走，让其他的 goroutine 继续执行。这样做的目的是尽量提升性能，尽量让所有的系统线程上面都有代码在执行。\n4. GPM 模型 我们观察调度过程的进化，从进程到线程再到协程，其实是一个不断共享、不断减少切换成本的过程。\n要理解调度，需要理解两个概念：运行和阻塞。这里提供两个角度：我们觉得自己就是线程或者协程，运行就是在低头不断做事，阻塞就是我们目前做的事需要等待别人，然后就一直等着，等其他人做完了，我们接着做，这里我们是站在线程或者协程的角度去看的；另一个角度是，我们站在 CPU 的角度看，我正在敲代码写需求(一个线程或者协程)，发现依赖别人的函数还没有提交，那就把敲代码这事放在一边，最小化 IDE 然后点开钉钉沟通下一个需求，等依赖的函数提交了，又打开 IDE 继续敲代码——在 Linux 中，线程对应的是一个叫做task_struct的结构体，从本质上来说，线程并不是一个实体，线程只是代表一个执行流和其状态。真正驱动流程的是 CPU，CPU 根据 PC 寄存器从程序中取指令和操作数，从 RAM 中取数据,，进行计算、 处理、 跳转、 驱动执行流往前。 CPU 并不关注处理的是线程还是协程,，只需要设置 PC 寄存器， 设置栈指针等(这些称为上下文),，那么 CPU 就可以运行这个线程或者协程了。\n所以，线程的运行，其实是被运行；线程的阻塞，其实是换出调度队列，不再去执行这个执行流。协程同理，协程也是一个类似于task_struct数据结构，其作用也是一个执行流或者状态，记录运行什么函数，运行到什么程度，也就是上下文。\nGo 在用户态实现调度，所以 Go 也需要有代表协程这种执行体的数据结构，也要有保存和恢复上下文的处理过程以及调度队列。\n在这些数据结果中，最主要的是一下几个(以下结构体均位于runtime包的runtime.go文件中)：\ng: 它保存了 goroutine 的所有信息，该结构体的每一个实例对象都代表了一个goroutine。调度器代码会通过 g 对象来对 goroutine 进行调度——当 goroutine 被调离系统线程时，调度器负责把 CPU 相关寄存器值等上下文信息保存在 g 对象的成员变量中；当 goroutine 被重新拉起运行时，调度器又负责把 g 对象成员变量中所保存的上下文信息恢复到相关寄存器，也就是恢复了执行上下文。 schedt：一方面保存调度器本身的状态信息，另一方面它拥有一个用来保存 goroutine 的运行队列。因为每个 Go 程序只有一个调度器，所以在每个 Go 程序中 schedt 结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的 goroutine 运行队列，我们称这个运行队列为全局运行队列(GRQ)。 p：表示执行所需要的资源，其最大数量同时也是 Go 代码的最大并行度。每一个运行着 go 代码的工作线程都会与一个 p 结构体的实例对象关联在一起。全局运行队列是每一个工作线程都可以读写的，因此为了并发安全，访问时需要加锁，但加锁势必耗费性能进而称为瓶颈。于是调度器为每一个工作线程引入了一个 私有的 goroutine 运行队列，我们称之为“局部队列(LRQ)”，工作线程优先使用局部队列的 goroutine，只有必要时才会去访问全局队列(后面还会了解到，当一个 p 的局部队列使用完时，还会去别的 p 偷几个 g 过来运行)，这大大减少了锁冲突，提高了工作线程的并发性。 m：代表实际工作线程，每一个工作线程都有唯一的m与之对应。m 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 p 结构体的实例对象之间的绑定关系。于是，通过 m 既可以找到与之对应的工作线程正在运行的 goroutine，又可以找到工作线程的局部运行队列等资源。 他们之间的关系，可以使用下图表示：\n另有一张图可能更清晰形象：\nGo scheduler 的职责就是将所有处于 可运行状态 的 goroutines 均匀分布到在 P 上运行的 M。\n当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。这被称为 Work-stealing，Go 从 1.1 开始实现。\nGo scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。\n实际上，Go scheduler 每一轮调度要做的工作就是找到处于 runnable 的 goroutines，并执行它。寻找的顺序如下：\nruntime.schedule() { // 检查全局队列，防止全局队列中的G被饿死 // if not found, 检查局部队列 // if not found, // 尝试从其他的P偷一些G过来 // if not found, 从全局队列中去一些 // if not found, poll network } 上述任何一步找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来一半的 G。\n这样做的好处是，有更多的 P 可以一起工作，加速执行完所有的 G。\n5. goroutine 的状态 如下图：\n6. Go scheduler 的调度时机 在以下四种情况下，scheduler 可能会发生调度——“可能”意味着，scheduler 只是有机会调度，但并不一定会发生。\n情形 说明 使用关键字 go 创建一个新的 goroutine，scheduler 会考虑调度 GC 肯定会发生调度，因为 GC 必须要在 M 上运行。 发生系统调用 当一个 goroutine 发生系统调用时，会阻塞 M，此时它会被调走，同时调用新的 goroutine 在 M 上运行 内存同步访问 atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 7. 同步/异步系统调用概览 当一个正在执行的 G(goroutine)需要进行系统调用时，根据调用类型，它所依附的 M 有两种情况：同步(系统调用等) 和 异步(网络请求等)。\n同步情况下，M1 会被阻塞，进而从 P 上调度下来，此时 G1 依然依附在 M1 上执行，之后会有一个新的 M2 被调用到 P 上，接着执行 P 的本地运行队列 LRQ 中的 G。一旦系统调用完成，G1 会再次加入 P 的 LRQ 等待被调度，而之前的 M1 则会被隐藏，等到需要的时候再次被使用。\n异步情况下，M1 不会被阻塞，G1 的异步请求会被另一个组件Network Poller接手，而 G1 本身也会被绑定到Network Poller上，等到系统调用结束，G1 会再次回到 P 上。由于 M 没有被阻塞，它可以继续执行当前被绑定的 P 的 LRQ 里面的 G。\n可以看到，在异步情况下，通过调度，Go scheduler 成功地将 IO 任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，极大地提高了效率。\n二、具体实现 有时间再细究。\n未完，待续…\n","permalink":"http://localhost:1313/posts/golang-gpm%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86/","summary":"\u003ch2 id=\"一概述\"\u003e一、概述\u003c/h2\u003e\n\u003ch3 id=\"1-为什么在内核的线程调度器之外go-还需要实现一个自己的调度器\"\u003e1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器\u003c/h3\u003e\n\u003cp\u003e主要解决\u003cstrong\u003e系统线程太重\u003c/strong\u003e的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大；\u003c/li\u003e\n\u003cli\u003e系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003egoroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\u003c/p\u003e","title":"Golang-GPM调度原理"},{"content":"1. Go语言指针的限制 go语言中也有指针，但相对C语言的指针来说，有了很多限制，但这也算是go的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\ngo中指针不能进行数学运算; func main() { num := 1 pNum := \u0026amp;num pNum++ // invalid operation: p++ (non-numeric type *int) } 不同类型的指针不能相互转换 func main() { var a int a = 10 var f *float32 f = \u0026amp;a // cannot use \u0026amp;a (type *int) as type *float32 in assignment } 不同类型的指针之间不能使用==或!=进行比较，也不能相互赋值 func main() { var a int var b float32 a = 1 b = 3.14 pa := \u0026amp;a pb := \u0026amp;b fmt.Println(pa == nil) fmt.Println(pa == pb) // invalid operation: pa == pb (mismatched types *int and *float32) pa = pb // cannot use pb (type *float32) as type *int in assignment } 只有在两个指针类型相同或者可以相互转换的情况下，才可以对两者进行比较。另外，指针可以通过 == 和 != 直接和 nil 作比较。\n2. unsafe包介绍 unsafe 包，“不安全”，为何不安全？是因为它可以使得用户绕过 go 的类型规范检查，能够对指针以及其指向的区域进行读写操作，即“允许程序无视 type 体系对任意类型内存进行读写”。因此使用时要格外小心。\nunsafe包中只有很简单的几个函数和定义:\npackage unsafe // 任意go表达式的类型。只是为了文档而声明的类型，实际上它并不是unsafe包的一部分 type ArbitraryType int // 任意类型代表的指针 type Pointer *ArbitraryType // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr // 返回x所在结构体的起始内存地址到x所对应属性两者距离，单位为byte，参数x的格式应该是structValue.field func Offsetof(x ArbitraryType) uintptr // 内存对齐时使用，这里暂时不研究 func Alignof(x ArbitraryType) uintptr 与此同时，unsafe包提供了两个很重要的功能：\n任何类型的指针 和 unsafe.Pointer 可以相互转换。 uintptr 类型和 unsafe.Pointer 可以相互转换。 即 任何数据类型的指针 \u0026lt;----\u0026gt; unsafe.Pointer \u0026lt;----\u0026gt; uintptr\n上述的功能有何用途？答： Pointer允许程序无视 type 体系对任意类型内存进行读写。\n如何理解这句话？因为unsafe.Pointer不能直接进行数学运算，但是我们可以将其转换成uintptr，对uintptr进行对应的数学运算(比如内存复制与内存偏移计算)，计算之后再转换成unsafe.Pointer类型。\n有了这个基础，我们可以干好多“见不得光”的事，比如 底层类型相同的数组之间的转换、使用 sync/atomic 包中的一些函数、访问并修改 Struct 的私有字段等场景。\n3. unsafe包的使用场景 场景一：访问并修改 struct 的私有属性 先从一个 demo 开始：\npackage main // unsafe修改struct私有属性 type user struct { name string age int company string } func main() { u := new(user) // A fmt.Println(*u) // { 0} uName := (*string)(unsafe.Pointer(u)) // B *uName = \u0026#34;Jemmy\u0026#34; fmt.Println(*u) // {Jemmy 0} uAge := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.age))) // C *uAge = 23 fmt.Println(*u) // {Jemmy 23} uCompany := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.company))) // D *uCompany = \u0026#34;吹牛逼技术有限公司\u0026#34; fmt.Println(*u) // {Jemmy 23 吹牛逼技术有限公司} } 在 A 处，我们新建一个user对象，使用new直接返回此类对象的指针。在这里要注意，在go中，对一个struct进行内存分配，实际上是分配的一块连续的空间，而new返回的指针，其实是struct中第一个元素的地址。\n通过上面的介绍我们知道，unsafe.Offsetof(x ArbitraryType) 返回 x 所在结构体的起始内存地址到 x 所对应属性两者距离，单位为 byte，参数 x 的格式应该是 structValue.field，那么unsafe.Offsetof(u.name)指的就是 u的起始地址，到属性name之间有多少个byte。\n在 C 处，因为unsafe.Pointer不能直接参与数学运算，所以我们先转换成uintptr类型，然后与unsafe.Offsetof(u.age)相加，就是u的属性age的地址，为uintptr类型，之后再转换为unsafe.Pointer，即可通过强制类型转换，直接去修改该属性的值。\n再来看 B 处，因为u的地址就是其第一个属性name的地址，可以直接获取到。其实我们可以改成和 C 处相似的结构：uName := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.name)))，效果一样。\n**注意!!!**上面 C 处的语句的加号两边的对象不能直接拆开去写，也就是说，不能写成:\ntmp := uintptr(unsafe.Pointer(u)) uAge := (*int)(unsafe.Pointer(tmp + unsafe.Offsetof(u.age))) 原因是，uintptr这个临时变量，本身就是一个很大的整数，而程序经过一些很大的计算之后，涉及到栈的扩容，扩容之后，原来的对象的内存位置发生了偏移，而 uintptr 所指的整数对应的地址也就发生了变化。这个时候再去使用，由于这个整数指的地址已经不是原来的地址了，会出现意想不到的 bug。\n场景二： 利用unsafe获取 slice 的长度 通过查看对应的源代码，我们知道slice header的结构体定义为：\ntype slice struct { array unsafe.Pointer // 元素指针 1字节 len int // 长度 1字节 cap int // 指针 1字节 } 当我们调用make函数创建一个新的slice后，底层调用的是makeslice，返回的是slice结构体:\nfunc makeslice(et *_type, len, cap int) slice 因此，我们可以通过unsafe.Pointer和uintptr进行转换，得到 slice 的字段值：\nfunc main() { s := make([]int, 10, 20) // slice结构体中，array类型为pointer，占1个字节8位，uintptr(unsafe.Pointer(\u0026amp;s))表示s的地址也是第一个属性array的地址，那么加上属性array的长度，就是下一个属性len的长度 var sLen = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(8))) fmt.Println(*sLen, len(s)) // 10 10 // 16的原因同上 var sCap = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(16))) fmt.Println(*sCap, cap(s)) // 20 20 } 场景三：实现string和[]byte 的零拷贝转换 一般的做法，都需要遍历字符串或 bytes 切片，再挨个赋值。\n在反射包src/reflect/value.go中，有下面的结构体定义：\ntype StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } 因此，只需共享底层的Data和Len即可：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } 4. unsafe.Sizeof(struct) 的本质 先看源码注释：\n// Sizeof takes an expression x of any type and returns the size in bytes // of a hypothetical variable v as if v was declared via var v = x. // The size does not include any memory possibly referenced by x. // For instance, if x is a slice, Sizeof returns the size of the slice // descriptor, not the size of the memory referenced by the slice. // The return value of Sizeof is a Go constant. // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr 这其中比较有意思的是 unsafe.Sizeof(a struct)的结果问题，即一个struct的 size 值为多少的问题。\n我们来观察一个有趣的事实：一个struct的 size 依赖于它内部的属性的排列顺序，即两个属性相同但排列顺序不同的struct的 size 值可能不同。\n比如，下面这个结构体 A 的 size 是 32：\ntype struct A{ a bool b string c bool } 而另一个和它有相同属性的结构体 B 的 size 是 24:\ntype struct B{ a bool c bool b string } 这都是 内存对齐在捣鬼。我们看一下 A 和 B 的内存位置：\n如上图所示，左边为struct A，右边为struct B。而Aligment可以使 1,2,4 或者 8。对 A 来说，a bool占一个 byte，而下一个属性是b string，占 16 个 byte(后面会说明为什么占 2 个字节)，因此无法进行内存对齐；而对 B 来说，a bool和c bool可以放在同一个 byte 中。\n在Golang中，各类型所占的 byte 如下\nbool,int8,uint8 \u0026ndash;\u0026gt; 1 byte int16,uint16 \u0026ndash;\u0026gt; 2 byte int32,uint32,float32 \u0026ndash;\u0026gt; 4 byte int,int64,uint64,float64,pointer \u0026ndash;\u0026gt; 8 byte string \u0026ndash;\u0026gt; 16 byte (两个字节) 任何 slice \u0026ndash;\u0026gt; 24 byte(3 个字节) 长度为 n 的 array \u0026ndash;\u0026gt; n*对应的 type 的长度 为什么string占到 2 个字节？因为 string 底层也是一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占 8 个字节；\n为什么任意类型的slice占到 3 个字节？同理，slice底层也是一个结构体，有三个域：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 1个字节 len int // 长度 8个byte 1个字节 cap int // 容量 8个byte 1个字节 } 说到这里，你也应该明白了，unsafe.Sizeof总是在编译期就进行求值，而不是在运行时，而且是根据类型来求值，而和具体的值无关。(这意味着，unsafe.Sizeof的返回值可以赋值给const即常量)\n可以通过下面的 demo 输出，判断你的掌握程度：\npackage main type user struct { name string // 2字节 age int // 1字节 company string // 2字节 } func main(){ fmt.Println(unsafe.Sizeof(user{})) // 输出40，5个字节，看 struct user 注释 fmt.Println(unsafe.Sizeof(10)) // 输出8，因为int占1字节 fmt.Println(unsafe.Sizeof([]bool{true, false})) // 输出24，任何slice都输出24 fmt.Println(unsafe.Sizeof([][]string{})) // 输出24，任何slice都输出24，即使是多维数组 } 5. 参考文献 码农桃花源—标准库\u0026ndash;unsafe sizeof-struct-in-go ","permalink":"http://localhost:1313/posts/golang-unsafe%E5%8C%85%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"1-go语言指针的限制\"\u003e1. \u003ccode\u003eGo\u003c/code\u003e语言指针的限制\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ego\u003c/code\u003e语言中也有指针，但相对\u003ccode\u003eC语言\u003c/code\u003e的指针来说，有了很多限制，但这也算是\u003ccode\u003ego\u003c/code\u003e的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\u003c/p\u003e","title":"Golang-unsafe包详解"},{"content":"在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\nGo 语言中数组、字符串和切片三者是密切相关的数据结构。这三种数据类型，在底层原始数据有着相同的内存结构，在上层，因为语法的限制而有着不同的行为表现。\n一、 数组(Array) 1. 概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存其中的元素，我们可以利用数组中元素的索引快速访问元素对应的存储地址。\n数组作为一种基本的数据类型，我们通常都会从两个维度描述数组：类型 和 大小(能够存储的最大元素个数)：\n// 源码位于 /usr/local/go/src/cmd/compile/internal/types/type.go // Array contains Type fields specific to array types. type Array struct { Elem *Type // element type 元素类型 Bound int64 // number of elements; \u0026lt;0 if unknown yet 最大元素个数，小于0表示未知 } // NewArray returns a new fixed-length array Type. func NewArray(elem *Type, bound int64) *Type { if bound \u0026lt; 0 { Fatalf(\u0026#34;NewArray: invalid bound %v\u0026#34;, bound) } t := New(TARRAY) t.Extra = \u0026amp;Array{Elem: elem, Bound: bound} t.SetNotInHeap(elem.NotInHeap()) return t } 从上述代码可以看出，类型Array包含两个属性，一个是数组类型Elem，另一个是数组大小Bound。另外需要注意的是：Go 语言中数组在初始化之后大小无法改变。\n2. 初始化 有两种初始化方式：\narray1 = [5]int{1, 2, 3, 4, 5} array2 = [...]int{1, 2, 3, 4, 5} 上述两种声明方式在运行期间得到的结果是完全相同的，后一种声明方式在编译期间就会被“转换”成为前一种，这也就是编译器对数组大小的推导。\n对第一种方式，那么变量的类型在编译进行到类型检查阶段就会被提取出来，随后会使用 NewArray函数创建包含数组大小的 Array 类型。\n对第二种方式，在第一步会创建一个Array{Elem: elem, Bound: -1}，即其大小会是-1，不过这里的-1只是一个占位符，编译器会在后面的 /usr/local/go/src/cmd/compile/internal/gc/typecheck.go 中对数组大小进行推导，并更新其 Bound 值：\n// The result of typecheckcomplit MUST be assigned back to n, e.g. // n.Left = typecheckcomplit(n.Left) func typecheckcomplit(n *Node) (res *Node) { ... // Need to handle [...]T arrays specially. if n.Right.Op == OTARRAY \u0026amp;\u0026amp; n.Right.Left != nil \u0026amp;\u0026amp; n.Right.Left.Op == ODDD { n.Right.Right = typecheck(n.Right.Right, ctxType) if n.Right.Right.Type == nil { n.Type = nil return n } elemType := n.Right.Right.Type // typecheckarraylit type-checks a sequence of slice/array literal elements. length := typecheckarraylit(elemType, -1, n.List.Slice(), \u0026#34;array literal\u0026#34;) n.Op = OARRAYLIT n.Type = types.NewArray(elemType, length) n.Right = nil return n } ... } 虽然在编译期这两种方式的实现方式不同，但在运行时这两中方式是完全等价的。事实上，[...]T 这种初始化方式也只是 Go 语言为我们提供的一种语法糖，当我们不想计算数组中的元素个数时可以偷个懒。\n另：变量初始化的位置：\n如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化；如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换之后代码才会继续进入 中间代码生成 和 机器码生成 两个阶段，最后生成可以执行的二进制文件。\n3. 赋值与访问 Go 语言中数组是值语义。一个数组变量即表示整个数组，它并不是隐式的指向第一个元素的指针（比如 C 语言的数组），而是一个完整的值。当一个数组变量被赋值或者被传递的时候，实际上会复制整个数组。如果数组较大的话，数组的赋值也会有较大的开销。为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。\nvar a = [...]int{1, 4, 3} // a 是一个数组 var b = \u0026amp;a // b 是指向数组的指针 fmt.Println(a[0], a[1]) // 打印数组的前2个元素 fmt.Println(b[0], b[1]) // 通过数组指针访问数组元素的方式和数组类似 for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v) } 我们可以用for循环来迭代数组。下面常见的几种方式都可以用来遍历数组：\nfmt.Println(\u0026#34;方式一：\u0026#34;) for i := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } fmt.Println(\u0026#34;方式二：\u0026#34;) for i, v := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, v) } fmt.Println(\u0026#34;方式三：\u0026#34;) for i := 0; i \u0026lt; len(a); i++ { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } // 输出 方式一： a[0]: 1 a[1]: 4 a[2]: 3 方式二： a[0]: 1 a[1]: 4 a[2]: 3 方式三： a[0]: 1 a[1]: 4 a[2]: 3 用for range方式迭代的性能可能会更好一些，因为这种迭代可以保证不会出现数组越界的情形，每轮迭代对数组元素的访问时可以省去对下标越界的判断。\n需要注意的是 长度为 0 的数组。长度为 0 的数组在内存中并不占用空间，有时候可以用于强调某种特有类型的操作时避免分配额外的内存空间，比如用于管道的同步操作：\nc1 := make(chan [0]int) go func() { fmt.Println(\u0026#34;c1\u0026#34;) c1 \u0026lt;- [0]int{} }() \u0026lt;-c1 在此场景下我们并不关心管道中的具体数据以及类型，我们需要的只是管道的接收和发送操作用于消息的同步，此时，空数组作为管道类型可以减少管道元素赋值时的开销。当然一般更倾向于用无类型的匿名结构体代替：\nc2 := make(chan struct{}) go func() { fmt.Println(\u0026#34;c2\u0026#34;) c2 \u0026lt;- struct{}{} // struct{}部分是类型, {}表示对应的结构体值 }() \u0026lt;-c2 注：本节参考自Go 语言高级编程 1.4\n二、切片(Slice) 切片和数组非常类似，可以用下标的方式访问，也会在访问越界时发生panic。但它比数组更加灵活，可以自动扩容。\n1. 内部实现 源代码位于： /usr/local/go/src/runtime/slice.go\ntype slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 长度(已经存放了多少个元素) cap int // 容量(底层数组的元素个数)，其中 cap\u0026gt;=len } 需要注意的是，底层的数组是可以被多个 slice 同时指向的，因此，对一个 slice 元素进行操作可能会影响其他指向对应数组的 slice。\n2. slice 的创建 方式 代码示例 说明 直接声明 var arr1 []int 其实是一个nil slice，array=nil,len=0,cap=0。此时没有开辟内存作为底层数组。 new arr2 := *new([]int) 也是一个nil slice，没有开辟内存作为底层数组。也没有设置元素容量的地方，此时只能通过append来添加元素，不能使用下标。 字面量 arr3 := []int{1,2,3} make arr4 := make([]int,2,5) 切片类型、长度、容量，其中容量可以不传，默认等于长度。 从切片或数组“截取” arr5 := arr4[1:2] 3. 关于 make 创建 slice Go 编译器会在编译期，根据以下两个条件来判断在哪个位置创建 slice：\n切片的大小和容量是否足够小 切片是否发生了逃逸 当要创建的切片非常小并且不会发生逃逸时，这部分操作会在编译期完成，并且创建在栈上或者静态存储区。如 n := make([]int,3,4) 会被直接转化成如下所示的代码：\nvar arr = [4]int n := arr[:3] 当发生逃逸或者比较大时，会在运行时调用 runtime.makeslice 函数在堆上初始化。而runtime.makeslice函数非常简单：\n// et是元素类型 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断len cap参数是否合法 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 在堆上申请一片连续的内存 return mallocgc(mem, et, true) } 这个函数的主要作用就是 计算当前切片所占用的内存空间并在堆上申请一段连续的内存，所需的内存空间采用以下的方式计算：\n内存空间 = 元素类型大小 * 切片容量cap 而元素类型的大小参照如下：\n类型 大小 bool, int8, uint8 1 bit int16, uint16 2 bit int32, uint32, float32 4 bit int, int64, uint64, float64, pointer 8 bit (1 个字节) string 16 bit (2 个字节) 长度为 n 的 array n * (对应的 type 的长度) TIPS：1 字节(Byte） = 8 位(bit)\nmallocgc 是专门用于内存申请的函数，后面会详细讲解。\n4. 切片截取 截取 是创建切片的一种方式，可以从数组或者切片直接截取，同时需要制定截取的起始位置。\n需要关注的是下面这种截取方式： arr1 = data[low : high : max]。这里的三个数字都是指原数组或切片的索引值，而非数量。\n这里的 low是最低索引值，是闭区间，也就是说第一个元素是位于data位于low索引处的元素；high是开区间，表示最后一个元素只能索引到 high - 1处；max也是开区间，表示容量为 max - 1。其中：len = high - low，cap = max - low，max \u0026gt;= high \u0026gt;= low。用下面的图来帮助说明：\n基于已有的数组或者切片创建新的切片，新 slice 和老 slice 会公用底层的数组，新老 slice 对底层数组的更改都会影响彼此。需要注意的是，如果某一方执行了append操作引起了 扩容 ，移动到了新位置，两者就不会影响了。所以关键问题在于二者是否会共用底层数组。\n我们通过一个例子来说明，该例子来自于雨痕 Go 学习笔记 P43，做了一些改造：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 55) s2 = append(s2, 77) s1[2] = 66 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } // 输出 [7 6 66] [5 4 3 2 100 200] [9 8 7 6 66 4 3 2 100 0] 让我们一步步来分析：\n首先，创建 slice、s1 和 s2：\nslice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] // len为3，cap默认到底层数组的结尾 s2 := s1[2:6:7] // len为4，cap为5 // 以上三个底层数组相同 之后，向 s2 尾部追加一个元素：\ns2 = append(s2, 55) s2的容量刚好还剩一个，直接追加，不会扩容。因为这三者此时还都共用同一个底层数组，所以这一改动，slice和s1都会受到影响：\n再次向 s2 追加一个元素：\ns2 = append(s2, 77) 此时，s2 的容量不够用，需要扩容。简单来说，扩容是新申请一块更大(具体多大，后面会说到，假设为原来的 2 倍)的内存块，将原来的数据 copy 过去，s2 的array指针指向新申请的那块内存。再次 append 之后：\n最后，修改 s1 索引为 2 处的元素：\ns1[2] = 66 此时 s2 已经使用了新开辟的内存空间，不再指向slice和s1指向的那个数组，因此 s2 不会受影响：\n后面打印 s1 的时候，只会打印出 s1 长度以内的元素。所以，只会打印出 3 个元素，虽然它的底层数组不止 3 个元素。\n5. append 扩容规则 之前说过，扩容是新申请一块更大的内存块，将原来的数据 copy 过去，原来切片的array指针指向新申请的那块内存。这里我们探讨这个“更大”到底是多大：\n第一步，预估扩容后的容量 newCap：\ndata = []int{1,2} data = appand(data,3,4,5) 扩容前的容量 oldCap = 2，新增 3 个元素，理论上应该扩容到 cap=5，之后会进行预估，求得 newCap 规则如下：\n如果 $oldCap * 2 \u0026lt; cap$，那么 newCap = cap；\n否则\n如果 扩容前元素个数oldLen \u0026lt; 1024​ ，那么直接翻倍，即 newCap = oldCap * 2； 否则(即 扩容前元素个数oldLen \u0026gt;= 1024 )，就先扩容 四分之一，也就是 1.25 倍，即 newCap = oldCap * 1.25。 即：\n这段规则的源码位于 /usr/local/go/src/runtime/slice.go：\nfunc growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { if old.len \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } ... } 上述例子中，oldCap=2，至少需要扩容到cap=5，根据预估规则，因为 oldCap*2=4 \u0026lt; 5，因此 newCap=cap=5，即预估结果为newCap=5。\n第二步，确定实际分配的内存，匹配到合适的内存规格\n理论上所需要内存 = 预估容量 * 元素类型大小，难道直接就会分配这么多的内存吗？并不是。\n首先元素类型大小已在 “一.3”中说明过，此处 int 类型的大小是 8bit(1 个字节)。接着看growslice函数：\nfunc growslice(et *_type, old slice, cap int) slice { ... var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) .... } 在这里，sys.PtrSize = 8，et类型是 int，所以 et.size == sys.PtrSize为 true，则 newcap * sys.PtrSize = 5 * 8 = 40。我们看看 roundupsize这个函数，位于 /usr/local/go/src/runtime/msize.go：\n// Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { // ... } } ... } 其中，_MaxSmallSize = 32768，smallSizeMax = 1024，smallSizeDiv = 8，而传进来的 size = 40。而：\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31} 所以上面roundupsize会返回：\nclass_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] = 48 在growslice中，capmem = 48，则最后计算得到的 newcap = int(capmem / sys.PtrSize) = int(48 / 8) = 6，即最终扩容后的容量为 6。而不是之前预估的 5。\n总结一下，首先使用预估规则预估一下需要的容量(本例中为 5)，然后用这个容量乘以 slice 元素的大小(单位是 bit，本例中 int 为 8)，之后根据在 class_to_size 中选择合适大小的值，比如 40，那应该选择比 40 大的更小的那个 48，这就是申请到的真正的容量内存，最后用真正的容量大小除以元素大小，即可得到真正的扩容后的 slice 的cap。\n6. slice 作为函数参数 函数调用处的参数称为 实参，函数定义处的参数称为 形参。形参是实参的拷贝，会生成一个新的切片，但二者指向底层数组的指针相同。\n当函数中没有出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,66,3,4,5,6] } func t1(s []int) { s[1] = 66 } 当函数中出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,2,3,4,5,6] } func t2(s []int) { s = append(s, 66) } 扩容后，指向的底层数组不同，互不影响。\n三、字符串(String) 字符串是 Go 语言中最常用的基础数据类型之一，虽然字符串往往被看做一个整体，但是实际上字符串是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组。\n在设计上，Go 语言中的string是一个只读的字节数组。当然，只读只意味着字符串会分配到只读的内存空间并且这块内存不会被修改，在运行时我们其实还是可以将这段内存拷贝到堆或者栈上，将变量的类型转换成 []byte 之后就可以进行，修改后通过类型转换就可以变回 string，Go 语言只是不支持直接修改 string 类型变量的内存空间。\nstring的底层结构如下：\n// /usr/local/go/src/runtime/string.go type stringStruct struct { str unsafe.Pointer len int } 可以看到和上面的切片结构非常相似，只是少了表示容量的cap。这是因为，字符串作为只读类型，我们并不会对齐进行扩容操作进而改变其自身的内存空间，所有在字符串上执行的写入操作都是通过拷贝实现的。\n关于字符串，讨论最多的是 string和[]byte互相转换的性能问题，在底层是通过 stringtoslicebyte 和 slicebytetostring两个函数实现的，其中出现了内存分配的情况，这里不做细究。\n在说unsafe 那篇文章里，提到了 实现string和[]byte 的零拷贝转换：这里再复习一下：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } ","permalink":"http://localhost:1313/posts/golang-%E6%95%B0%E7%BB%84-%E5%88%87%E7%89%87%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003cp\u003e在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\u003c/p\u003e","title":"Golang-数组,切片和字符串"},{"content":"一、 前言 我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\n最上面为高地址，最下面为低地址，分配时由高地址向低地址增长。函数的地址由低地址向高地址方向存放。\n从高地址到低地址依次为 栈空间、堆空间、全局静态变量区(数据区)、代码区。\n二、函数栈帧 函数执行时需要由足够的内存空间，用于存放 局部变量、返回值、参数等，这段空间对应内存中的栈。栈最上面是高地址，向下增长。\n分配给函数的栈空间，称为 函数栈帧(function stack frame)，栈底称为 栈基(bp)，栈顶称为 栈指针(sp)。函数调用结束后又会释放这个栈帧。bp 和 sp 始终指向正在执行的函数的栈帧。如果出现 A 调用 B，B 调用 C，C 调用 D，那么会出现由上到下分别为A的栈帧-\u0026gt;B的栈帧-\u0026gt;C的栈帧-\u0026gt;D的栈帧的情况:\n计算机执行函数时，会有专门的寄存器存放栈基 bp、栈指针 sp 和下一条要执行的指令 ip。\n所有的函数的栈帧布局都遵循统一的约定，所以被调用者是通过栈指针加上偏移量来定位到每个参数和返回值的。\nGo 在分配栈帧时是 一次性分配(主要是为了防止栈访问越界) ：(首先函数栈帧的空间在编译时期是可以确定的)确定栈基 bp，然后直接将栈指针 sp 移到所需最大栈空间的位置。之后通过栈指针 sp+偏移值这种相对寻址方式来使用函数栈帧。(例如需要将 3 和 4 依次入栈，则对应的指令分别是 sp+16 处存放 3，sp+8 处存放 4)\n由于函数栈帧的大小，可以在编译时期确定，对于栈消耗较大的函数，Go 编译器会在函数头部加上检测代码，如果发现需要进行栈增长，就会另外分配一块足够大的栈空间，并把原来栈上的数据拷过来，同时释放掉原来的栈空间。\n三、函数调用过程 有两个指令：call 和 ret。函数 call 指令实现跳转，而每个函数开始时都会分配栈帧，结束前又会释放自己的栈帧，ret 指令又会把栈恢复到之前的样子。\ncall的过程：\n将下一条指令的地址入栈，这就是返回地址，被调用函数执行结束后会回到这里； 跳转到被调用函数的入口处执行，这后面就是被调用函数的栈帧了。 ret过程：\n弹出返回地址； 跳转到这个返回地址 Go 与 C 语言不同的是，C 是通过寄存器和栈传递参数和返回值的，而 Go 是通过栈。下面通过举例说明 Go 中一个栈帧的结构以及函数调用过程中栈帧的变化：\n设有函数 A 和 B，在 A 内部调用了 B：\nfunc A() { x,y := 2,3 z := B(x,y) fmt.Println(x,y,z) } func B(m, n int) k int { return m + n } 首先需要了解的是，**被调用者的参数和返回值，都在调用者的函数栈帧中。**它们在栈中的顺序由上到下依次是：\nA 的局部变量 被调用函数 B 的返回值 传递给被调用函数 B 的参数(注意，参数顺序与实际书写书序相反) B 调用结束后的返回地址(A 中调用 B 之后要执行的命令，即 fmt.Println(x, y, z)) 调用者 A 的 bp 结构如下：\n而具体执行上述代码第 3 行也就是函数调用的详细过程如下：\n执行 call 函数：\na. 将调用者的下一条指令(第 4 行代码)入栈，这就是返回地址，被调用函数执行结束后会回到这里；\nb. 跳转到被调用者处(修改 ip 寄存器的值) 在被调用函数开始处有三步：\na. 将 sp 向下移动到足够的空间处(如 sp-24 处)；\nb. 调用者栈基(当前 bp 的值)入栈(调用者栈)(如存放到 sp+16 处)； 此时 bp 的值是被调用者 B 的栈基 结果是：bp 和 sp 始终指向正在执行的函数的栈帧； 接下来执行被调用函数剩下的部分；\na. 被调用者结束调用时，在 ret 函数前面还有两步：\n​ 1). 恢复调用者的栈基 bp 地址——第 2 步中的第 2 步，将栈该处的值赋给寄存器 bp\n​ 2). 释放自己的栈帧空间——第 2 步中的第 1 步，分配时向下移动了 24，则释放时向上移动多少 结果是：此时 bp 和 sp 已经恢复到调用者的栈帧了 执行 ret 步骤：\na. 弹出 call 指令的返回地址(对应过程 1 中的第 1 步)\nb. 跳转到弹出的这个地址(修改 ip 寄存器) 结果是：“被调用者”调用完毕，执行的是调用者的下一个指令，即调用完成(执行完被调用者)后，继续执行调用者函数。 如果在 B 中出现了defer操作，那么应该先执行defer，还是先执行return呢，还是先执行ret过程呢？\n答案是：Go 中的 return 并不是真正的返回，真正的返回操作是ret操作，return的作用仅仅是给返回值赋值，之后再执行defer操作，最后才是ret过程(释放自己的栈帧)。\n四、传参与返回值 理论部分已经全部说完了，下面通过一些实战来加深理解：\n为何有时通过函数交换变量位置却不成功？ func swap(a, b int) { a,b = b,a } func main() { a,b := 1,2 swap(a, b) fmt.Println(a,b) // 输出 1 2 // 交换失败 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2, a=1(入栈顺序与调用顺序相反)(没有返回值，对应3.传递给被调用函数 B 的参数) 执行 “a,b = b,a”，交换的是第 7 行入栈的两个变量而不是第 6 行入栈的调用者的局部变量 执行 ret 过程，返回之后，栈中 A 的局部变量并没有被改变，所以还是 a=1, b=2 再看下面的函数：\nfunc swap(a, b *int) { *a, *b = *b, *a } func main() { a,b := 1,2 swap(\u0026amp;a, \u0026amp;b) fmt.Println(a,b) // 输出 2 1 // 交换成功 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2 的地址, a=1 的地址(对应3.传递给被调用函数 B 的参数) 执行 “*a,*b = *b,*a”，传递的是 A 中变量的地址，实际上进行的是 A 中的变量的 b 和 A 中的变量的 a 交换 执行 ret 过程，返回之后，栈中 A 的局部变量被改变 有返回值，匿名返回值 func incr1(a int) int { var b int defer func() { a++ b++ }() a++ b = a return b } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 1 } 过程如下：前面说过，return 的作用相当于给返回值赋值，之后再执行 defer 函数，之后才是 ret 过程\n第 15 行，栈中从上到下为 a=0, b=0 第 16 行，incr1 的返回值，默认 0 值 第 2 行，incr1 的局部变量 b=0 第 9 行，incr1 的参数 a=0，自增后变成 2 第 10 行，incr1 的局部变量 b=1 第 11 行，incr1 的返回值被改变为 1 之后执行 defer 函数，incr1 的局部变量 a=3，incr1 的局部变量 b=1(注意，这里改变的是 incr1 的局部变量，而不是返回值) 返回，返回值依旧是 1 有返回值，非匿名返回值(命名返回值) func incr2(a int) (b int) { defer func() { a++ b++ }() a++ return a } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 2 } 过程与上述类似，只不过返回值变成了 incr1 中的 b，在第 8 步时首先被赋值 1，之后再 defer 中又自增，变成 2，因此返回值变成了 2。\n","permalink":"http://localhost:1313/posts/golang-%E5%85%B3%E4%BA%8E%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/","summary":"\u003ch2 id=\"一-前言\"\u003e一、 前言\u003c/h2\u003e\n\u003cp\u003e我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\u003c/p\u003e","title":"Golang-关于函数调用"},{"content":"选择优化的数据类型 MySQL 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\n更小的通常更好\n一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 0 ~ 200 ，那么字段类型设置为 unsigned tinyint 更好。\n简单就好\n简单数据类型的操作通常需要更少的 CPU 周期。例如整形比字符串的操作代价更低，因为字符串还要考虑 字符集 和 排序规则 ，使得字符串的比较比整形更加复杂。这里有两个例子：存储日期时，应该使用 MySQL 的内建类型( date 、 time 、 datetime 、 timestamp 等)而不是使用字符串；存储 IP 地址时，应该使用整型而非字符串， MySQL 中有专门的处理函数：\nmysql\u0026gt; select INET_ATON(\u0026#34;172.16.11.102\u0026#34;); +----------------------------+ | INET_ATON(\u0026#34;172.16.11.102\u0026#34;) | +----------------------------+ | 2886732646 | +----------------------------+ mysql\u0026gt; select INET_NTOA(2886732646); +-----------------------+ | INET_NTOA(2886732646) | +-----------------------+ | 172.16.11.102 | +-----------------------+ 行属性尽量避免 NULL\n一般情况下，某一行的默认属性是 NULL 。书中(《高性能 MySQL》)建议，最好指定列为 NOT NULL ，除非真的需要存储 NULL 值。这只是一个建议——如果计划在列上建索引，应该尽量避免设计成 可为 NULL 的列。\n1. 数字 1.1 整型(Whole Number) 可使用类型如下：\n类型 位数 范围 TINYINT 8 位（1 字节） -128~127 SMALLINT 16 位（2 字节） -32768~32767 MEDIUMINT 24 位（3 字节） -8388608~8388607（830 万多） INT 32 位（4 字节） -2147483648~2147483647（21 亿多） BIGINT 64 位（8 字节） -9223372036854775808~922, 3372, 0368, 5477, 5807（900 亿亿，反正很大啦） 整型有可选的 unsigned ，表示 非负 ，这大致可使正数的上限提高一倍。\n有符号和无符号整数使用相同的存储空间，有相同的性能，可根据实际情况选择以适合自己业务。\nMySQL 可以为整数类型指定宽度，例如 INT(11)， 但绝大多数情况下没有意义：对于存储和计算来说，**INT(11)**和 **INT(20)**是相同的，宽度不会限制值的合法范围，只是规定了 MySQL 的一些交互工具用来显示字符的个数。\n1.2 实数类型(Real Number) 实数是指 带有小部分的数字。我们能接触到的有 FLOAT 、 DOUBLE 和 DECIMAL 。这三个可以进一步划分： FLOAT 、 DOUBLE 称为浮点型， DECIMAL 就是 DECIMAL 类型。\n我们知道，标准的浮点运算由于硬件原因（篇幅所限具体原因请自行寻找），进行的是近似运算，如 Python 3.8 中 $0.1 + 0.2 = 0.30000000000000004$， Golang go1.13.4 darwin/amd64 中 fmt.Println(fmt.Sprintf(\u0026quot;%0.20f\u0026quot;, 0.1+0.2)) 输出$0.29999999999999998890 $ ，而 FLOAT 和 DOUBLE 所属的 浮点型 进行的就是这种运算。\n而 DECIMAL 用于存储精确的小数。因为 CPU 不支持对 DECIMAL 的直接计算，因此 在 MySQL 5.0及以后的版本 中， MySQL 服务器自身实现了 DECIMAL 的高精度计算。因此我们可以说，后期版本中，MySQL 既支持精确类型，也支持不精确类型。 相对而言， CUP 直接支持原生浮点运算，所以浮点运算明显更快。\nMySQL 使用二进制的形式存储 DECIMAL 类型。使用方式为 DECIMAL(总位数，小数点后位数) ，其中总位数最大为 65，小数点后位数最大为 30；并且位数与字节大小的对应关系为 9位/4字节 ，即每 9 位占 4 个字节，同时小数点占用一个字节。比如 DECIMAL(20, 9)共占用 5 个字节——小数点左边占用 3 个字节，小数点一个字节，小数点右边共占一个字节。\n浮点类型在存储同样范围的值时，通常比 **DECIMAL**使用更少的空间。 FLOAT 使用 4 个字节存储， DOUBLE 占用 8 个字节。需要注意的是，我们能选择的只是类型，即表示的范围大小，和整形一样，在 MySQL 底层进行计算的时候，所有的实数进行计算时都会转换成 DOUBLE 类型。\n2. 字符串 2.1 VARCHAR(变长字符串) VARCHAR 用于存储可变长字符串，是最常见的字符串数据类型。它比定长类型(CHAR)更加节省空间，因为它仅使用必要的空间。\n变长字符串 VARCHAR 需要使用额外的 1 个或 2 个字节记录字符串的长度：如果列的最大长度\u0026lt;=255 字节，则使用 1 个字节表示，否则使用 2 个字节。\nVARCHAR 节省空间，这对性能提升也有帮助，但由于行长是变的，如果通过 UPDATE 操作使得行长变得比原来更长，那就需要做一些额外的工作。不同引擎有不同的处理结果。\n当 VARCHAR 过长时，InnerDB 会将其保存为 BLOB，同时使用专门的外部区域来保存大文件，行中只保存对应的地址。\n2.2 CHAR(定长字符串) 当使用 CHAR(n) 时，会一次性分配足够的空间，注意这里的 n 指的是字符数而不是字节数。当存储 CHAR 时，会自动去掉末尾的空格，而 VARCHAR 不会。\nCHAR 非常适合存储很短的字符串，或者长度都很接近的字符串，例如密码的 MD5 值，因为这是一个定长的值。对于非常短的列， CHAR 比 VARCHAR 在存储空间上更有效率。\n关于“末尾空格截断”，通过下面的例子说明：\n\u0026gt; mysql\u0026gt; CREATE TABLE t1 (cl CHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t1(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t1; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3\u0026#39; | \u0026gt; +--------------------+ \u0026gt; ``` \u0026gt; \u0026gt; 我们再看下VARCHAR： \u0026gt; \u0026gt; ``` mysq \u0026gt; mysql\u0026gt; CREATE TABLE t2 (cl VARCHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t2(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t2; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3 \u0026#39; | \u0026gt; +--------------------+ 区别主要在 string3 后面的空格是否被截断。\n2.3 BLOB 和 TEXT BLOB 和 TEXT 都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。\n它们属于不同的数据类型：字符类型有 TINYTEXT, SMQLLTEXT, TEXT, MEDIUMTEXT, LONGTEXT，对应的二进制类型有 TINYBLOB, SMQLLBLOB, BLOB, MEDIUMBLOB, LONGBLOB。其中 BLOB 是 SMALLBLOB 的同义词，TEXT 是 SMALLTEXT 的同义词。\n当 BLOB 和 TEXT 的值太大时，InnerDB 会使用专门的“外部存储区域”进行存储实际内容，而行内使用 1~4 个字节存储一个外部内容的指针。\nBLOB 和 TEXT 家族之间仅有的不同是：BLOB 存储的是二进制的数据，没有排序规则和字符集，而 TEXT 有字符集和排序规则。\nMySQL 对 BLOB 和 TEXT 进行排序时与其他类型是不同的：它只针对没个列的最前 max_sort_length 字节而不是对整个字符串进行排序。如果需要排序的字符更少，可以尝试减小 max_sort_length ，或者使用 ORDER BY SUSTRING(column,length) 。\nMySQL 不能将 BLOB 或者 TEXT 列全部长度的字符串作为索引！\n3. 枚举、集合和位 3.1 枚举(ENUM) 枚举可以将一些不重复的字符串放到一个预定义的集合中，使用时也只能插入这个预定义集合中的某一个。\nMySQL 在存储枚举值时非常紧凑，在内部保存时，会将每个值在列表中的位置保存为整数(从 1 开始编号)，并在表的.frm 文件中保存“数字-字符串”映射关系的“查找表”；数据保存在两个字节中，因此枚举中可以有 $2^{16} - 1 = 65535$个。\nmysql\u0026gt; CREATE TABLE t2(e ENUM(\u0026#39;fish\u0026#39;,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;)); mysql\u0026gt; INSERT INTO t2(e) VALUES(\u0026#39;fish\u0026#39;),(\u0026#39;dog\u0026#39;),(\u0026#39;apple\u0026#39;),(1); # 注意，这里也可以世界使用枚举值对应的位置，如1对应\u0026#39;apple\u0026#39; # 查询枚举值，默认字符串表示 mysql\u0026gt; SELECT * FROM t2; +-------+ | e | +-------+ | fish | | dog | | apple | | fish | +-------+ # 使用数字形式表示枚举值 mysql\u0026gt; SELECT e+0 FROM t2; +------+ | e+0 | +------+ | 1 | | 3 | | 2 | | 1 | +------+ 尽量不要使用数字作为 ENUM 枚举常量，这种双重性很容易导致混乱，例如 ENUM('1','2','3') 。\n**注意：枚举字段是按照内部存储的整数而不是字符串顺序进行排序的。**一种绕过这种限制的方式是 刚开始就按照字典顺序来定义枚举值，另一中方式是使用 FIELD(列名，'arg1','arg2',…) 函数：\nmysql\u0026gt; SELECT e FROM t2 ORDER BY FIELD(e,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;,\u0026#39;fish\u0026#39;); +-------+ | e | +-------+ | apple | | dog | | fish | | fish | +-------+ 3.2 集合(SET) 如果说 ENUM 是单选的话，那 SET 就是多选。适合存储预定义集合中的多个值。同 ENUM 一样，其底层依旧通过整形存储。\n设定 set 的格式：\n字段名称 SET(\u0026#34;选项1\u0026#34;,\u0026#34;选项2\u0026#34;,...,\u0026#39;选项n\u0026#39;) 如 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); 同样的， SET 的每个选项值也对应一个数字，依次是 1，2，4，8，16...， 最多有 64 个选项。\n使用的时候，可以使用 set 选项的字符串本身（多个选项用逗号分隔），也可以使用多个选项的数字之和（比如：1+2+4=7）。\n通过实例来说明：\n# 建表 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); # 插入一个选项，字符串格式 INSERT INTO t3(hobby) VALUES(\u0026#39;swim\u0026#39;); # 插入多个选项，字符串格式，通过英文逗号分隔 INSERT INTO t3(hobby) VALUES(\u0026#39;swim,movie\u0026#39;); # 插入一个选项，数字格式 INSERT INTO t3(hobby) VALUES(1); # 等同于\u0026#39;swim\u0026#39; INSERT INTO t3(hobby) VALUES(4); # 等同于\u0026#39;movie\u0026#39; # 插入多个选项，数字格式 INSERT INTO t3(hobby) VALUES(7); # 等同于\u0026#39;swim,music,movie\u0026#39;，因为\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;分别为“1,2,4,8”，7=1+2+4. # 显示全部 mysql\u0026gt; SELECT * FROM t3; +------------------+ | hobby | +------------------+ | swim | | swim,movie | | swim | | movie | | swim,music,movie | +------------------+ # 查找包含movie的行 mysql\u0026gt; SELECT * FROM t3 WHERE FIND_IN_SET(\u0026#39;movie\u0026#39;,hobby) \u0026gt; 0; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 寻找包含排号为4的成员的行 mysql\u0026gt; SELECT * FROM t3 WHERE hobby \u0026amp; 4; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 直接使用字符串匹配 mysql\u0026gt; SELECT * FROM t3 WHERE hobby = \u0026#39;swim,movie\u0026#39;; +------------+ | hobby | +------------+ | swim,movie | +------------+ 3.3 位(BIT) NySQL 把 BIT 当成字符串类型而不是数字类型来存储。但是它的存储结果根据上下文会出现不同：\nmysql\u0026gt; CREATE TABLE t4(a BIT(8)); mysql\u0026gt; INSERT INTO t4(a) VALUES(b\u0026#39;00111001\u0026#39;); mysql\u0026gt; SELECT a, a+0 ,BIN(a) FROM t4; # bin()表示整数类型对应的二进制 +------+------+--------+ | a | a+0 | BIN(a) | +------+------+--------+ | 9 | 57 | 111001 | +------+------+--------+ 默认显示数字代表的 ASCII 码字符。\n","permalink":"http://localhost:1313/posts/mysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96/","summary":"\u003ch2 id=\"选择优化的数据类型\"\u003e选择优化的数据类型\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMySQL\u003c/code\u003e 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e更小的通常更好\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 \u003ccode\u003e0 ~ 200\u003c/code\u003e ，那么字段类型设置为 \u003ccode\u003eunsigned tinyint\u003c/code\u003e 更好。\u003c/p\u003e","title":"MySQL数据类型与优化"},{"content":"Docker 一、前言 Docker 是一个开源的应用容器引擎，可以让开发者将他们的应用以及依赖打包到一个可移植的容器中，这个容器可以发布并运行在任何流行的 Linux 环境下。\n理解：Docker 是什么？Docker 是一个容器，这个容器是可以随便移动的，就像一个箱子；箱子里是什么东西呢？箱子里是开发者写好的应用以及这个应用运行时的环境，即箱子里面是一个可以独立运行的沙盒应用；这个箱子有什么特点呢？可以随便搬动，并且能在任何 Linux 系统上直接运行（现在主流的服务器应用大多数都部署在 Linux 系统中）。\nDocker 的构想是实现Build, Ship, Run Anywhere，即通过对应用的 封装(Packaging) 、 分发(Distribution) 、 部署(Deployment) 、 运行(Runtime) 的生命周期进行管理，达到应用组件级别的“一次封装，到处运行”。这里的应用组件，既可以是一个 web 应用、一个编译环境，也可以是拥有运行环境的 web 服务，也可以是一套数据库平台服务，甚至是一个操作系统或者集群。\n二、Docker 架构 Docker 使用客户端-服务端架构。服务端负责构建、运行应用和分发容器（这个过程我是这样理解的：从上图可以看到有几个不同的角色：Client、daemon、registry、image 和 container，其中 registry 代表的是仓库，用来存储 image，同时我们也可以把 registry 中的 image（镜像）pull 到本地，进行修改之后 commit 回去，形成新的 image 存放在 registry，同时我们可以基于某个 image，在其中创建新的容器，这个容器中就是我们的应用和环境），客户端负责提供用户界面；Docker 客户端和守护进程之间使用 RESTful API，通过 unix 套接字或者网络接口进行通信，当我们使用 docker run 这样的命令时，客户端会将这些命令发送给他们的守护进程，然后守护进程执行这些命令；守护进程监听 Docker 客户端的请求并且管理服务端已有的 Docker 对象，如镜像、容器、网络。\n1. Registry（注册表） Docker Registry 用来存储 Docker 镜像。Docker Hub 是任何人都可以使用的公共注册中心，Docker 配置为默认在 Docker Hub 上查找镜像。当然你也可以运行自己的私人 Registry。\n当我们使用 docker pull 或者 docker run 的时候，将会从配置的 Registry 中提取所需要的镜像；使用 docker push 时，当前的镜像也将被推送到配置的 Registry 中。\n2. Image（镜像） 镜像是只读的，是用于创建一个容器的指令模板。通常情况下，一个镜像是基于另一个镜像，再加上自己的一些自定义配置形成的。举个例子，我们可以基于 Ubuntu 系统，在其基础上安装 nginx 以及其他 webserver 服务，以及这个服务运行时的各种配置信息，这样就行成了一个新的镜像。\n常见的虚拟机镜像，通常是由提供者打包成镜像文件，安装者从网上下载或是其他方式获得，恢复到虚拟机中的文件系统里；而 Docker 的镜像必须通过 Docker 打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。这样虽然失去了灵活性，但固定的格式意味着可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，使得在不同的机器中传递和共享 Docker 变得非常方便，这也是 Docker 能够提升工作效率的一处体现。\n通俗地讲，可以将 Docker 镜像理解为包含应用程序以及运行环境的基础文件系统，在容器启动的过程中，它以只读的方式被用于创建容器的运行环境。\nDocker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。\n对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，足以保证全球唯一性，这种编码（64 长度的字符串）的形式在 Docker 很多地方都有体现。由于镜像每层都有唯一的编码，就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，允许在镜像之间共享镜像层。举一个例子，由 Docker 官方提供的两个镜像 ElasticSearch 镜像和 Jenkins 镜像都是在 OpenJDK 镜像之上修改而得，实际使用的时候，这两个镜像是可以共用 OpenJDK 镜像内部的镜像层的。这带来的一项好处就是让镜像可以共用存储空间，达到 1+1\u0026lt;2 的效果，为在同一台机器里存放众多镜像提供了可能。\n2.1 镜像的命名 镜像的命名由三部分组成：username、repository 和 tag，他们的组织规则入下：\nusername 指上传镜像的用户；repository 表示镜像内容，形成对镜像的表意描述。有的镜像没有 username，这表明此镜像是由 Docker 官方进行维护的。\nrepository 表示镜像内容，形成对镜像的表意描述，通常采用的是软件名，这样的原因是，通常情况下，我们只在一个容器中运行一个应用，这样的命名可以更加方便的帮助我们识别镜像中的内容。\ntag 表示镜像版本，是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化，使用 tag 可以很好的区分和标识这些变化。tag 一般以版本号来命名。\n2.3 Container（容器） **容器是镜像的可运行实例。**默认情况下，一个容器和另外的容器机器主机相隔离，但是这都是可配置的。\n三、 概念理解 先说结论：一个”容器“，实际上是由 Linux Namespace 、 Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。\n1. LXC(Linux Container) Docker 其实是容器化技术的具体实现之一，采用 Golang 语言开发。很多人认为 Docker 是一种更轻量级的虚拟机，但事实上不是这样的，Docker 和虚拟机有本质的区别。容器在本质上讲，就是运行在操作系统上的一个进程，只不过加入了对资源的隔离和限制。Docker 正是基于容器的这个设计思想，采用 Linux Container 技术实现的核心管理引擎。\n为什么要进行这种设计呢？在默认情况下，一个操作系统里所有运行的进程共享 CPU 和内存资源，如果设计不当，在最极端的情况下，如果某进程出现死循环可能会耗尽所有的系统资源，其他的进程也会受到影响，这在企业级产品的场景下是不可接受的。\n不过，对资源进行隔离并不是新的发明，Linux 系统本身就支持操作系统级层面的虚拟化技术，叫做 Linux Container，即 LXC 的全称，它的作用是在操作系统的层次上为进程提供虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的 cpu 和 memory 节点，分配特定比例的 cpu 时间、IO 时间，限制可以使用的内存大小（包括内存和是 swap 空间），提供 device 访问控制，提供独立的 namespace（网络、pid、ipc、mnt、uts）。\nLXC，一种“操作系统层虚拟化”技术，为“linux 内核”容器功能的一个“用户空间接口”。LXC(LinuxContainer)是来自于 Sourceforge 网站上的开源项目，LXC 给 Linux 用户提供了用户空间的工具集，用户可以通过 LXC 创建和管理容器，在容器中创建运行操作系统就可以有效的隔离多个操作系统，实现操作系统级的虚拟化。最初的 Docker 容器技术基于 LXC 进行构建，后来 Docker 在自己的内核中刨除了 LXC。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。\n从前面的介绍中我们可以了解到，LXC 能够创建容器用于 Linux 系统的虚拟化，而 LXC 作为用户层管理工具主要提供了管理容器的接口，对实现容器的机制进行了封装隐藏，下面将对 LXC 容器的实现机制进行分析。LXC 有三大特色： cgroup 、 namespace 和 unionFS 。\nnamespace 这是另一个维度的资源隔离技术，与我们平常 C++程序开发中的 namespace 可以相类比。\n如果 cgroup 设计出来是为了隔离上面所描述的物理资源，那么 namespace 则用来隔离 PID、IPC、NETWORK 等系统资源。每一个 namespace 中的资源对其他 namespace 都是透明的，互不干扰。在每一个 namespace 内部，每一个用户都拥有属于自己的 init 进程，pid = 1，对于该用户来说，仿佛他独占了一台物理的 Linux 虚拟机。但是事实上，这个 namespace 中的 pid，只是其父容器的一个子进程而已。\n通过下图来加深理解：\n父容器有两个子容器，父容器的命名空间里有两个进程，id 分别为 3 和 4, 映射到两个子命名空间后，分别成为其 init 进程，这样命名空间 A 和 B 的用户都认为自己独占整台服务器。对于每一个命名空间，从用户看起来，应该像一台单独的 Linux 计算机一样，有自己的 init 进程(PID 为 1)，其他进程的 PID 依次递增，A 和 B 空间都有 PID 为 1 的 init 进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。从图中我们可以看到，进程 3 在父命名空间里面 PID 为 3，但是在子命名空间内，他就是 1. 也就是说用户从子命名空间 A 内看进程 3 就像 init 进程一样，以为这个进程是自己的初始化进程，但是从整个 host 来看，他其实只是 3 号进程虚拟化出来的一个空间而已。\n【参考】 DOCKER 基础技术：LINUX NAMESPACE（上）\nDOCKER 基础技术：LINUX NAMESPACE（下）\ncgroup（control group） 前面，我们介绍了 Linux Namespace，但是Namespace 解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。也就是说，虽然你通过 Namespace 把我 Jail 到一个特定的环境中去了，但是我在其中的进程使用用 CPU、内存、磁盘等这些计算资源其实还是可以随心所欲的。所以，我们希望对进程进行资源利用上的限制或控制。这就是 Linux CGroup 出来了的原因。\ncgroup 用来限定一个进程的资源使用，由 Linux 内核支持，可以限制和隔离 Linux 进程组（process groups）所使用的资源，比如 CPU、内存、磁盘和网络 IO，是 LXC 技术的物理基础。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。\nPrioritization: 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。\nAccounting: 一些审计或一些统计，主要目的是为了计费。\nControl: 挂起进程，恢复执行进程。\n使 ​​​ 用 ​​​ cgroup，系 ​​​ 统 ​​​ 管 ​​​ 理 ​​​ 员 ​​​ 可 ​​​ 更 ​​​ 具 ​​​ 体 ​​​ 地 ​​​ 控 ​​​ 制 ​​​ 对 ​​​ 系 ​​​ 统 ​​​ 资 ​​​ 源 ​​​ 的 ​​​ 分 ​​​ 配 ​​​、优先顺序、拒绝、监控和管理。可以更好地根据任务和用户分配硬件资源，提高总体效率。\n在实践中，系统管理员一般会利用 CGroup 做下面这些事（有点像为某个虚拟机分配资源似的）：\n隔离一个进程集合（比如：nginx 的所有进程），并限制他们所消费的资源，比如绑定 CPU 的核。\n为这组进程 分配其足够使用的内存\n为这组进程分配相应的网络带宽和磁盘存储限制\n限制访问某些设备（通过设置设备的白名单）\n【参考】DOCKER 基础技术：LINUX CGROUP\nunionFS unionFS 的含义是，可以把文件系统上多个目录内容联合挂载到同一个目录下，而目录的物理位置是分开的。\n我们来看一个例子(例子来自耗子叔的文章，但是原文中的不完善，我在这里补充一下)：\n首先我们建立两个目录(fruits 和 vegetables)，并在这两个目录中新建一些文件：\n# 创建目录 \u0026gt;\u0026gt;\u0026gt; mkdir fruits \u0026gt;\u0026gt;\u0026gt; mkdir vegetables \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;apple in fruits\u0026#34; \u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in fruits\u0026#34; \u0026gt; ./fruits/tomato \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;carrots in vegetables\u0026#34; \u0026gt; ./vegetables/carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in vegetables\u0026#34; \u0026gt; ./vegetables/tomato # 查看当前目录结构 \u0026gt;\u0026gt;\u0026gt; tree . . ├── fruits │ ├── apple │ └── tomato └── vegetables ├── carrots └── tomato 然后使用 aufs 进行 mount，注意 fruits 和 vegetables 的顺序：\n# 创建mount目录 \u0026gt;\u0026gt;\u0026gt; mkdir mnt # 把水果目录和蔬菜目录union mount到 ./mnt目录中 \u0026gt;\u0026gt;\u0026gt; sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt # 看一下当前的结构 \u0026gt;\u0026gt;\u0026gt; tree ./mnt ./mnt ├── apple ├── carrots └── tomato # 看一下mnt中的内容 \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables \u0026gt;\u0026gt;\u0026gt; cat ./mnt/tomato tomato in fruits 我们发现，fruits 和 vegetables 中的文件被 merge 到了一起，并且同名的文件只出现一次，默认以第一个文件夹为准。\n下面我们看一下 merge 后的文件和源文件之间的映射关系。第一步，修改源文件，merge 后的文件是否会受影响？\n# 修改fruits的apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 1 after fruits.apple\u0026#34; \u0026gt;\u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple # 查看mnt中的apple \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits append 1 after fruits.apple # 修改vevegtbles中的carrots echo \u0026#34;append 2 after vegetables.carrots\u0026#34; \u0026gt;\u0026gt; ./vevegtbles/carrots \u0026gt;\u0026gt;\u0026gt; cat ./vevegtbles/carrots carrots in vegetables append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots 由此可以得到：修改源文件，merge 后的文件也会同步改变。\n我们继续往下走：修改 mnt 中的文件，源文件会受到什么影响？\n\u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 3 after mnt.apple\u0026#34; \u0026gt;\u0026gt; ./mnt/apple # 查看源文件 \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple append 3 after mnt.apple # 重点来了，修改mnt.carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 4 in mnt.carrots\u0026#34; \u0026gt;\u0026gt; ./mnt/carrots tree . . ├── fruits │ ├── apple │ ├── carrots | └── tomato └── vegetables ├── carrots └── tomato \u0026gt;\u0026gt;\u0026gt; cat ./fruits/carrots append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots append 4 in mnt.carrots 我们 merge 后的第一个目录没有的文件，竟然将该文件复制进了第一个文件，然后进行了修改！\ndocker 通过一个叫做 copy-on-write (CoW) 的策略来保证 base 镜像的安全性，以及更高的性能和空间利用率。\nCopy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.\n当容器需要读取文件的时候: 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的 docker 容器共享运行时相同的文件)。 当容器需要添加文件的时候: 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候: 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候: 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 那么，这种 UnionFS 有什么用？\n历史上，有一个叫 Knoppix 的 Linux 发行版，其主要用于 Linux 演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把 CD/DVD 上的 image 运行在一个可写的存储设备上（比如一个 U 盘上），其实，也就是把 CD/DVD 这个文件系统和 USB 这个可写的系统给联合 mount 起来，这样你对 CD/DVD 上的 image 做的任何改动都会在被应用在 U 盘上，于是乎，你可以对 CD/DVD 上的内容进行任意的修改，因为改动都在 U 盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的 template，和另一个你的 working directory 给 union 在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个 ad hoc snapshot。\nDocker 把 UnionFS 的想像力发挥到了容器的镜像。你是否还记得我在介绍 Linux Namespace 上篇中用 mount namespace 和 chroot 山寨了一镜像。现在当你看过了这个 UnionFS 的技术后，你是不是就明白了，你完全可以用 UnionFS 这样的技术做出分层的镜像来。\n这就是 Docker 容器镜像分层实现的技术基础。所以我们说，Docker 中新的镜像并不是从头开始制作的，而是从一些 base 镜像的基础上创建并加上自定义修改而形成的，这些自定义的设置不会影响原来的 base 镜像。和 git 中的 commit 很像。这种设计的优点就是资源共享。试想一下，一台宿主机上运行 100 个基于 debian base 镜像的容器，难道每个容器中都保存一份重复的 debian 的拷贝吗？这显然不合理。借助 Linux 的 unionFS，宿主机只需要在磁盘上保存一份 base 镜像，内存中也加载一份，就能被所有基于这个 base 镜像的容器所共享。(举一个后面会遇到的例子：当我们使用 docker pull ubuntu:latest 这个命令的时候，可以看到如下的输出信息，从这个过程我们可以看出，镜像文件一般由若干层组成，使用 docker pull 下载中会获取并输出镜像的各层信息，当不同的镜像包括相同的层时，本地仅存了层的其中一份，减小了存储空间。)\n\u0026gt;\u0026gt;\u0026gt; docker pull ubuntu:latest latest: Pulling from library/ubuntu 35c102085707: Pull complete 251f5509d51d: Pull complete 8e829fe70a46: Pull complete 6001e1789921: Pull complete Digest: sha256:66cd4dd8aaefc3f19afd407391cda0bc5a0ade546e9819a392d8a4bd5056314e Status: Downloaded newer image for ubuntu:latest \u0026gt;\u0026gt;\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 5 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB 可以看到最新的 ubuntu 镜像只有 64M，而 centos 也只有 202M，是不是觉得太小了？这是因为 docker 在运行的时候直接使用了 docker 宿主机器的 kernel。\nLinux 操作系统由内核空间和用户空间组成。\n内核空间是 kernel，用户空间是 rootfs, 不同 Linux 发行版的区别主要是 rootfs. 比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。\n所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。\n需要注意的是，base 镜像只是用户空间和发行版一致。kernel 使用的是 docker 宿主机器的 kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。\nAUFS 有所有 Union FS 的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被 mount 好的目录。AUFS 的 whiteout 的实现是通过在上层的可写的目录下建立对应的 whiteout 隐藏文件来实现的。也就是说，如果我们想要删除某个地分支的文件，只需要在高分支的可写目录下，建立一个 whiteout的名字是’.wh.\u0026lt;filename\u0026gt;’ ，那么对应的下层的 \u0026lt;filename\u0026gt; 就会被删除，即使不被删除，也会不可见。\n当用 docker run 启动某个容器的时候，实际上容器的顶部添加了一个新的可写层，这个可写层也叫容器层。容器启动后，它里面的所有对容器的修改包括文件的增删改都只会发生在最顶部的容器层，而对下面的只读镜像层没有影响。\n【参考】DOCKER 基础技术：AUFS\n四、 Docker 镜像 刚开始学习时，很多人会分不清 镜像(image) 和 容器(container) 的区别。这里引用 Stackverflow：What is the difference between a Docker image and a container?的解释：\nAn instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.\nthe image is the recipe, the container is the cake ; -) you can make as many cakes as you like with a given recipe.\n镜像可以理解为一种 构建时(build-in)结构 ，而容器可以理解为一种 运行时(run-time)结构 。我们通常使用 docker service create 和 docker container run 从某个镜像启动一个或者多个容器。一旦容器从镜像启动之后，二者就变成了互相依赖的关系，并且在镜像启动的容器全部停止之前，镜像是无法被删除的。\n1. 镜像命名 docker pull DNS名称/用户名/镜像名:tag名 上述命令可以简写成 docker pull 镜像名 ，表示从 Docker 官方仓库中，默认拉取 tag 为 latest 的镜像。\n2. 常用命令 docker image pull xxx: 下载镜像 docker image ls: 列出当前主机上的所有镜像(-a 列出所有 -p只列出id) docker image inspect xxx: 查看当前image的详情 docker image rm xxx: 删除某个镜像(docker image rm $(docker image ls -a) -f 删除本机上所有的镜像) docker container rm $(docker container ls -a | awk \u0026#39;$1 !=\u0026#34;CONTAINER\u0026#34; {print $1}\u0026#39;) -f：删除所有的container 四、 Dockerfile 在实际开发中，几乎都是采用 Dockerfile 来制作镜像，而很少会采用将容器整个提交的方式。Dockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件。在 Dockerfile 中，包含了构建一个镜像过程中需要执行的命令以及其他操作。常见的 Docker 命令如下：\nFROM 之前提到过，我们不会从 0 开始构建一个镜像，而是会选择一个已经存在的镜像作为 base。FROM 用于指定一个 base 镜像，之后的所有操作都是基于这个 base 镜像来执行的，Docker 会先获取这个给出的 base 镜像，然后在这个 base 镜像上进行后面的构建操作。FROM 支持三种格式：\nFROM \u0026lt;image\u0026gt; [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] [AS \u0026lt;name\u0026gt;] 一般使用第二种，当 tag 不写时，默认为 latest。除了选择现有的镜像之外，Docker 还存在一个特殊的镜像，叫 scratch，它表示一个空白的镜像。如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。\nRUN RUN 用来在构建 docker 镜像的过程中执行命令行命令。但是并不建议一条 shell 命令一个 RUN。为什么呢？之前说过，Dockerfile 中的每一条指令都会建立一层，RUN 也不例外。每一个 RUN 行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这条命令，执行结束后，commit 这一层的修改，构成新的镜像。如果有很多 RUN，会出现很多运行时不需要的东西，结果就是产生了非常臃肿、非常多层的镜像, 不仅增加了构建部署的时间，也很容易出错。正确的做法是将这些命令通过\u0026amp;\u0026amp;符号串起来，如果需要换行就是用“\\”来连接两行，简化为一层，并且及时删除下载的 tgz 文件等。因此，在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\nENV 用于设置环境变量。例如：\nENV VERSION=1.0 DEBUG=on \\ NAME=\u0026#34;Happy Feet\u0026#34; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。\nWORKDIR Dockerfile 中的 WORKDIR 指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。相当于设置根目录。当使用相对目录的情况下，采用上一个 WORKDIR 指定的目录作为基准，相当与 cd 命令，但不同的是指定了 WORKDIR 后，容器启动时执行的命令会在该目录下执行。\nCMD 与 ENTRYPOINT 之前了解到，Docker 不是虚拟机，容器就是进程。既然是进程，那么启动容器的时候，需要指定所运行的程序以及参数。CMD 就是用于默认的容器主进程的启动命令的。当然 Dockerfile 中也可以没有 CMD，在运行时指定也可以。\n另外需要注意的是，容器中运行一个服务没有前后台的概念。为什么呢？对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。举个例子，我们使用了\nCMD service nginx start 然后发现容器执行后就立即退出了，甚至在容器内去使用 systemctl 命令发现根本执行不了。原因是使用“service nginx start”，则是希望 upstart 以后以后台守护进程的形式启动 nginx 服务，但是“CMD service nginx start”会被理解成 CMD [ \u0026ldquo;sh\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;service nginx start\u0026rdquo;]，因此主进程实际上是 sh，那么当 service nginx start 命令结束以后，sh 也就消失了，sh 作为主进程退出了，自然就会使容器退出。正确做法是直接执行 nginx 可执行文件，并且要以前台的形式运行，如\nCMD nginx -g \u0026#39;daemon off;\u0026#39; ENTRYPOINT 的目的和 CMD 一样，都是指定容器启动程序以及参数。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为\n\u0026lt;ENTRYPOINT\u0026gt; \u0026#34;\u0026lt;CMD\u0026gt;\u0026#34; COPY 与 ADD COPY 指令将从构建上下文目录中 \u0026lt;源路径\u0026gt; 的文件/目录复制到新的一层的镜像内的 \u0026lt;目标路径\u0026gt; 位置。\u0026lt;源路径\u0026gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath. Match 规则，比如：\nCOPY package.json /usr/src/app/ \u0026lt;目标路径\u0026gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。\n在使用该指令的时候还可以加上 \u0026ndash;chown=: 选项来改变文件的所属用户及所属组。\nCOPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。使用 ADD 时，如果原路径是一个 url 或者压缩包，Docker 引擎会将这个 url 下载或者将压缩包解压之后再复制。看情况使用即可。\nEXPOSE 声明运行时容器提供服务的端口，这只是一个声明（即打算、推荐用这个端口），在运行是并不会因为这个声明而开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处：\n帮助镜像使用者理解这个镜像服务推荐使用的端口，以方便配置映射；\n在运行时使用端口映射，也就是 docker run -P 时( -P 表示随机映射)，会自动映射 EXPOSE 的端口。\n需要区分 docker run -P 和 docker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; ：\ndocker run -P 会随机映射宿主端口到 Dockerfile 中的 EXPOSE ，如： \u0026gt;\u0026gt;\u0026gt; cat Dockerfile FROM nginx:latest EXPOST 80 90 \u0026gt;\u0026gt;\u0026gt; docker build -t nginx-test . \u0026gt;\u0026gt;\u0026gt; docker run -d -P nginx-test \u0026gt;\u0026gt;\u0026gt; docker container ls # 输出 9e3f0b2d6569 nginx-test \u0026#34;/docker-entrypoint.…\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:32769-\u0026gt;80/tcp, 0.0.0.0:32768-\u0026gt;90/tcp compassionate_pascal 这其中会将本机的 32769 和 32768 暴露出来，同时映射到容器中的 80 和 90 。\ndocker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; 指定宿主机和容器的端口： \u0026gt;\u0026gt;\u0026gt; docker run -d -p 8080:80 nginx-test 此时访问宿主机的 curl 宿主机IP:8080 会映射到容器内的 80 端口。\nVOLUMN docker 提供一种机制，可以将宿主机上的某个目录与容器的某个目录(称为挂载点，或者卷)关联起来，容器挂载点下的内容就是宿主机对应目录下的内容，可以有以下效果：\n容器基于镜像创建，容器的文件系统包括镜像的只读层+可写层，容器进程所产生的的数据均保存在可写层上，一旦容器删除，上面的数据就没有了，除非手动备份下来。而 卷挂载 机制可以让我们把容器中的某个目录和宿主机关联，让容器中的数据持久保存在宿主机上，即使容器删除，产生的数据仍在。 当我们开发一个应用时，开发环境在本机，运行环境启动在一个 docker 容器中，当我们修改一处之后想看到效果，需要重启容器，这显然比较麻烦。此时可以设置容器与本机的某个目录同步，当我们修改主机上的内容是，不需要同步容器，对容器来说是自动生效的，比如一个 web 应用，修改 index.html 后，刷新之后马上就能看到效果。 多个容器运行一组关联服务，共享一些数据。 通过一个 nginx 实例加深理解：\n1. 指明宿主机的目录\n# 拉取nginx镜像 docker pull nginx:latest # 创建宿主机目录 mkdir -p /Users/hujiaming/Downloads/nginx_test/index # 自定义欢迎页内容 cat \u0026#34;\u0026lt;h1\u0026gt; Hello World \u0026lt;/h1\u0026gt;\u0026#34; \u0026gt;\u0026gt;\u0026gt; /Users/hujiaming/Downloads/nginx_test/index/index.html # 将宿主机端口8080映射到容器端口80，将宿主机目录 /Users/hujiaming/Downloads/nginx_test/index 映射到容器目录 /usr/share/nginx/html(这个目录中存放nginx默认的欢迎页index.html) docker run -d -p 8080:80 -v /Users/hujiaming/Downloads/nginx_test/index:/usr/share/nginx/html --name nginx nginx 此时访问 宿主机 IP:8080，会出现 Hello World 而不是 nginx 的默认欢迎页，当我们修改 nginx_test/index/index.html 内容时，刷新浏览器发现也会同步刷新。\n2. 未指定关联的主机目录\ndocker run -d -p 8080:80 -v /data --name nginx nginx 上述命令只设置了容器的挂载点，并没有指定关联的主机目录。这时候 docker 会自动绑定主机上的一个目录。可以通过 docker inspect \u0026lt;name\u0026gt; 查看:\n\u0026gt;\u0026gt;\u0026gt; docker run -d -it -v /data nginx # 查看得到Container ID为： a369cc1f6efa \u0026gt;\u0026gt;\u0026gt; docker inspect a369cc1f6efa # 输出 ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/data\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ], ... 上面 Mounts 下的每条信息记录了容器上一个挂载点的信息，\u0026ldquo;Destination\u0026rdquo; 值是容器的挂载点，\u0026ldquo;Source\u0026quot;值是对应的主机目录。可以看出这种方式对应的主机目录是自动创建的，其目的不是让在主机上修改，而是让多个容器共享。\n此外还可以使用 --volumn-from 参数指定和某个已经存在的容器共享挂载点。\n五、 实战 1. 在 Ubuntu19 中安装 docker # 旧版本中docker叫做 docker , docker.io , docker-engine，如果这些旧版本已经安装，先卸载掉他们 sudo apt-get remove docker docker-engine docker.io containerd runc # 添加依赖 sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 添加GPG curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 在 /etc/apt/sources.list中添加依赖 sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # 更新 sudo apt-get update # 安装docker服务 sudo apt-get install docker-ce 2. 启动和关闭容器 # 查看当前已有的image \u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 10 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB nginx latest 53f3fd8007f7 3 months ago 109MB centos 7 9f38484d220f 5 months ago 202MB jenkins latest cd14cecfdb3a 13 months ago 696MB # 启动(-it 告诉docker，开启容器的交互模式并将读者当前的shell连接到容器的终端；/bin/bash 是说用户在容器内部想运行bash这个进程) \u0026gt;\u0026gt;\u0026gt; docker run -it ubuntu:latest /bin/bash # 不关闭容器而退出容器 \u0026gt;\u0026gt;\u0026gt; 组合键 ctrl + PQ # 在宿主机器上查看运行的机器 \u0026gt;\u0026gt;\u0026gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a847b8ed22b4 ubuntu:latest \u0026#34;/bin/bash\u0026#34; 41 seconds ago Up 40 seconds dreamy_bardeen 6ccf082c4be6 centos:7 \u0026#34;/bin/bash\u0026#34; 4 hours ago Up 4 hours heuristic_tu # 连接到运行中的容器(记得将下面的dreamy_bardeen换成你自己的容器名称，在docker container ls结果最后一列) \u0026gt;\u0026gt;\u0026gt; docker container exec -it dreamy_bardeen bash # 停止容器 \u0026gt;\u0026gt;\u0026gt; docker container stop dreamy_bardeen # 杀死容器 \u0026gt;\u0026gt;\u0026gt; docker container rm dreamy_bardeen 3. 多阶段构建 编写如下 go 文件：\n# main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { engine := gin.Default() engine.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { name := c.Query(\u0026#34;name\u0026#34;) fmt.Println(\u0026#34;hello \u0026#34; + name) c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hello \u0026#34; + name}) }) engine.Run(\u0026#34;:8899\u0026#34;) } 使用 go mod :\ngo mod init demo_go go mod tidy 对于 Dockerfile 的编写，有三种方案：\n方案一：直接使用 golang 全镜像\nFROM golang:1.14-alpine EXPOSE 8899 WORKDIR /go/src/demo_go COPY . /go/src/demo_go RUN GOPROXY=https://goproxy.cn,direct go build -v -o main *.go ENTRYPOINT [ \u0026#34;./main\u0026#34; ] 方案二：使用两个 Dockerfile，第一个编译出可执行二进制，第二个直接将二进制复制进去执行\n# cat Dockerfile.build FROM golang:1.14-alpine WORKDIR /apps/demo_go COPY . . RUN go build -v -o app *.go # cat Dockerfile.copy FROM golang:1.14-alpine WORKDIR /root/ COPY app /root/app RUN chmod a+x /root/app EXPOSE 8899 ENTRYPOINT [\u0026#34;/root/app\u0026#34;] # 这二者通过一个build.sh文件组合在一起 # cat build.sh #!/bin/bash echo \u0026#34;start build demo_go:stage1\u0026#34; docker build -t demo_go:build . -f Dockerfile.build docker create --name extract demo_go:build docker cp extract:/apps/demo_go/app ./app docker rm -f extract echo \u0026#34;start build demo_go:stage2\u0026#34; docker build --no-cache -t demo_go:install . -f Dockerfile.copy rm -rf ./app 方案三：多阶段构建\n# 第一阶段，编译出可执行文件 FROM golang:1.14-alpine as builder WORKDIR /apps COPY . . RUN CGO_ENABLED=0 GOOS=linux GOPROXY=https://goproxy.cn,direct go build -v -a -o app *.go # 第二阶段，将第一阶段编译好的二进制复制进最后一个阶段的容器即可 FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /apps/app . EXPOSE 8899 CMD [\u0026#34;./app\u0026#34;] 分别使用不同的执行构建 image：\n# 第一种 docker build -t demo_go:source -f Dockerfile . # 第二种 bash build.sh # 第三种 docker build -t demo_go:multi -f Dockerfile.multi . 这三种方案有什么区别？我们看一下各自 image 的大小：\n\u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID SIZE demo_go copy ab80d3d110b6 401MB demo_go source 274bf686025c 474MB demo_go app 7e8207b60f07 394MB demo_go multi 62b316cc49bd 21.1MB 看出差距了？\n","permalink":"http://localhost:1313/posts/%E5%85%B3%E4%BA%8Edocker/","summary":"这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要","title":"关于docker"},{"content":" 关于我 你好！我是 hujm2023，欢迎来到我的个人技术博客。\n关于本站 这里是我分享技术经验、学习心得和编程实践的地方。主要内容包括：\n技术栈 编程语言: Golang、Python、Java 数据库: MySQL、Redis 工具: Git、Docker、Kubernetes 系统: Linux 博客内容 算法与数据结构: LeetCode 题解、经典算法实现 后端开发: Go 语言深入解析、并发编程、性能优化 数据库技术: MySQL 底层原理、Redis 源码分析 系统架构: 分布式系统设计、微服务架构 开发工具: 效率工具使用技巧、最佳实践分享 技术理念 追求代码质量和工程实践 重视基础理论与实际应用的结合 持续学习，保持技术敏感度 乐于分享，共同进步 联系方式 如果你对文章内容有疑问，或者想要技术交流，欢迎通过以下方式联系我：\n邮箱: hujm.net@gmail.com GitHub: github.com/hujm2023 声明 本博客所有文章均为个人原创（除特别注明外），转载请注明出处。文章中的观点仅代表个人看法，如有错误欢迎指正。\n感谢你的访问，希望这些内容对你有所帮助！\n","permalink":"http://localhost:1313/about/","summary":"关于本站和作者","title":"关于"},{"content":"前言 堆，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作 根节点（root node），根节点本身没有 父节点（parent node）。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\n优先级队列 是计算机科学中的一类抽象数据类型。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。优先队列往往用堆来实现。\nGolang实现一：根据原理简单实现 package minheap import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; ) /* * @CreateTime: 2021/7/6 21:57 * @Author: hujiaming * @Description: Golang实现最小堆 */ var ErrMinHeapEmpty = errors.New(\u0026#34;minHeap is empty\u0026#34;) const HeapHeadTag int64 = math.MinInt64 type MinHeap struct { elements []int64 } // NewMinHeap 创建一个最小堆实例 func NewMinHeap() *MinHeap { return \u0026amp;MinHeap{elements: []int64{HeapHeadTag}} } /* Add 将一个元素添加到最小堆中，并且添加后要使其满足最小堆的特性 首先将该元素插入到数组最后，然后对这最后一个元素进行 “上浮” 操作： 该元素与父元素进行大小比较，如果小于父元素，则和父元素交换位置，如此循环，直到 到达堆顶 或 子元素小于父元素。 */ func (mh *MinHeap) Add(v int64) { // 1. 先将元素插在数组最后面 mh.elements = append(mh.elements, v) // 2. 将最后一个元素上浮，使其符合最小堆的性质。其实是为 v 找位置 i := len(mh.elements) - 1 for ; mh.elements[i/2] \u0026gt; v; i /= 2 { mh.elements[i] = mh.elements[i/2] } mh.elements[i] = v } /* PopMin 弹出堆中最小的元素 对最小堆而言，移除元素，只能移除堆顶(最小值)的元素。 首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作： 将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。 */ func (mh *MinHeap) PopMin() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } res := mh.elements[1] last := mh.elements[len(mh.elements)-1] // idx 表示最后一个元素应该在的位置 var idx int for idx = 1; idx*2 \u0026lt; len(mh.elements); { // 找出子节点中较小的元素的 index minChildIdx := idx * 2 if minChildIdx \u0026lt; len(mh.elements)-1 \u0026amp;\u0026amp; mh.elements[minChildIdx+1] \u0026lt; mh.elements[minChildIdx] { minChildIdx++ } // 当前结点 大于 较小子节点，和这个较小子节点交换位置，继续循环 if last \u0026gt; mh.elements[minChildIdx] { mh.elements[idx] = mh.elements[minChildIdx] idx = minChildIdx continue } break } mh.elements[idx] = last mh.elements = mh.elements[:len(mh.elements)-1] return res, nil } // PeekHead 只返回堆顶元素(最小值)，不进行下沉操作 func (mh *MinHeap) PeekHead() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } return mh.elements[1], nil } // IsEmpty 最小堆是否是空的 func (mh *MinHeap) IsEmpty() bool { if len(mh.elements) == 0 || (len(mh.elements) == 1 \u0026amp;\u0026amp; mh.elements[0] == HeapHeadTag) { return true } return false } // Length 返回最小堆中的元素个数 func (mh *MinHeap) Length() int { return len(mh.elements) - 1 } // Print 打印代表最小堆的数组 func (mh *MinHeap) Print() { fmt.Println(mh.elements[1:]) } Test 如下：\nfunc TestMinHeap(t *testing.T) { mh := NewMinHeap() mh.Add(4) mh.Add(2) mh.Add(7) mh.Add(9) mh.Add(1) mh.Add(5) mh.Add(10) mh.Add(3) mh.Add(2) mh.Print() for !mh.IsEmpty() { fmt.Println(mh.PopMin()) } assert.Equal(t, mh.Length(), 0) } // 输出 /* [1 2 5 2 4 7 10 9 3] 1 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 3 \u0026lt;nil\u0026gt; 4 \u0026lt;nil\u0026gt; 5 \u0026lt;nil\u0026gt; 7 \u0026lt;nil\u0026gt; 9 \u0026lt;nil\u0026gt; 10 \u0026lt;nil\u0026gt; */ Golang 实现二：实现标准库 heap.Interface 接口 先看下标准库中的 Interface，位置在 container/heap/heap.go：\n// The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // An implementation of Interface can be sorted by the routines in this package. // The methods refer to elements of the underlying collection by integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the \u0026lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } 我们以此为基础，实现一个 优先级队列:\npackage priorityqueen type Item struct { value int64 // 实际值 priority int64 // 优先级 index int // 当前 item 在数组中的 index } // PriorityQueen 表示优先级队列 type PriorityQueen []*Item func (mh2 PriorityQueen) Len() int { return len(mh2) } func (mh2 PriorityQueen) Less(i, j int) bool { return mh2[i].priority \u0026lt; mh2[j].priority } func (mh2 PriorityQueen) Swap(i, j int) { mh2[i], mh2[j] = mh2[j], mh2[i] mh2[i].index = i mh2[j].index = j } // Push 将 x 添加到数组最后 func (mh2 *PriorityQueen) Push(x interface{}) { l := len(*mh2) c := cap(*mh2) if l+1 \u0026gt; c { cmh2 := make([]*Item, l, c/2) copy(*mh2, cmh2) *mh2 = cmh2 } *mh2 = (*mh2)[:l+1] item := (x).(*Item) item.index = l (*mh2)[l] = item } // Pop 返回数组最后一个元素 func (mh2 *PriorityQueen) Pop() interface{} { l := len(*mh2) c := cap(*mh2) if l \u0026lt; c/2 \u0026amp;\u0026amp; c \u0026gt; 25 { cmh2 := make([]*Item, l, c/2) copy(cmh2, *mh2) *mh2 = cmh2 } item := (*mh2)[l-1] item.index = -1 // for safety *mh2 = (*mh2)[:l-1] return item } // PopHead 弹出堆顶元素 func (mh2 *PriorityQueen) PopHead() *Item { if mh2.Len() == 0 { return nil } item := (*mh2)[0] heap.Remove(mh2, 0) return item } // PopWithPriority 弹出优先级小于 maxP 的堆顶元素，如果没有，返回 nil 和 当前堆顶和maxP的距离 func (mh2 *PriorityQueen) PopWithPriority(maxP int64) (*Item, int64) { if mh2.Len() == 0 { return nil, 0 } item := (*mh2)[0] if item.priority \u0026gt; maxP { return nil, item.priority - maxP } heap.Remove(mh2, 0) return item, 0 } // PeekHead 显示堆顶元素 func (mh2 *PriorityQueen) PeekHead() *Item { if mh2.Len() == 0 { return nil } heap.Init(mh2) item := (*mh2)[0] return item } 测试一下：\nfunc TestPriorityQueen(t *testing.T) { items := make([]*Item, 0) rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 10; i++ { v := rand.Int63n(100) items = append(items, \u0026amp;Item{ value: v, priority: v, index: i, }) } q := PriorityQueen(items) heap.Init(\u0026amp;q) fmt.Println(q.PeekHead()) maxP := int64(50) for _, i := range q { if i.priority \u0026lt; maxP { fmt.Println(fmt.Sprintf(\u0026#34;p: %d, v: %d\u0026#34;, i.priority, i.value)) } } fmt.Println(\u0026#34;====\u0026#34;) for i := 0; i \u0026lt; 10; i++ { item, _ := q.PopWithPriority(maxP) if item != nil { fmt.Println(item) } } fmt.Println(\u0026#34;====\u0026#34;) for { item := q.PopHead() if item == nil { break } fmt.Println(item) } } // 输出 /* \u0026amp;{5 5 0} p: 5, v: 5 p: 11, v: 11 p: 6, v: 6 p: 33, v: 33 ==== \u0026amp;{5 5 -1} \u0026amp;{6 6 -1} \u0026amp;{11 11 -1} \u0026amp;{33 33 -1} \u0026amp;{50 50 -1} ==== \u0026amp;{52 52 -1} \u0026amp;{73 73 -1} \u0026amp;{85 85 -1} \u0026amp;{97 97 -1} \u0026amp;{99 99 -1} */ Golang 标准库 heap.Interface 源码解析 整个包的实现非常简洁，加上注释以及空行，整个文件才只有120 行：\n// Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package heap provides heap operations for any type that implements // heap.Interface. A heap is a tree with the property that each node is the // minimum-valued node in its subtree. // // The minimum element in the tree is the root, at index 0. // // A heap is a common way to implement a priority queue. To build a priority // queue, implement the Heap interface with the (negative) priority as the // ordering for the Less method, so Push adds items while Pop removes the // highest-priority item from the queue. The Examples include such an // implementation; the file example_pq_test.go has the complete source. // package heap import \u0026#34;sort\u0026#34; // The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // Init establishes the heap invariants required by the other routines in this package. // Init is idempotent with respect to the heap invariants // and may be called whenever the heap invariants may have been invalidated. // The complexity is O(n) where n = h.Len(). func Init(h Interface) { // heapify n := h.Len() // (n/2 - 1) 处的结点是最后一棵子树(没有孩子结点)的根节点 for i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) } } // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 h.Swap(0, n) down(h, 0, n) return h.Pop() } // Remove removes and returns the element at index i from the heap. // The complexity is O(log n) where n = h.Len(). func Remove(h Interface, i int) interface{} { n := h.Len() - 1 if n != i { h.Swap(i, n) if !down(h, i, n) { up(h, i) } } return h.Pop() } // Fix re-establishes the heap ordering after the element at index i has changed its value. // Changing the value of the element at index i and then calling Fix is equivalent to, // but less expensive than, calling Remove(h, i) followed by a Push of the new value. // The complexity is O(log n) where n = h.Len(). func Fix(h Interface, i int) { if !down(h, i, h.Len()) { up(h, i) } } func up(h Interface, j int) { for { i := (j - 1) / 2 // parent if i == j || !h.Less(j, i) { break } h.Swap(i, j) j = i } } func down(h Interface, i0, n int) bool { i := i0 for { j1 := 2*i + 1 if j1 \u0026gt;= n || j1 \u0026lt; 0 { // j1 \u0026lt; 0 after int overflow break } j := j1 // left child if j2 := j1 + 1; j2 \u0026lt; n \u0026amp;\u0026amp; h.Less(j2, j1) { j = j2 // = 2*i + 2 // right child } if !h.Less(j, i) { break } h.Swap(i, j) i = j } return i \u0026gt; i0 } 我们关注其中几个核心实现：\ndown(h Interface, idx, heapLen int) 下沉操作：\n首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作：\n将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。\n为什么元素 i 比它的两个子节点都小，就可以跳出循环，不再继续下去呢？这是由于，在 Init 函数中，第一个开始 down 的元素是第 n/2 - 1 个，可以保证总是从最后一棵子树开始 down，因此可以保证 Init-\u0026gt;down 时，如果元素 i 比它的两个子节点都小，那么该元素对应的子树，就是最小堆。\nup(h Interface, curIdx int) 上浮操作：\n主要用在 Push 中，当我们向最小堆插入一个元素时，现将其插入到数组最后，之后进行上浮操作，此时的 curIdx 就是数组最后一个元素的 index，即 h.Len() - 1。当前元素与其父元素进行比较，如果当前元素小于父元素，则与父元素交换位置，如此往复，直到堆顶或者当前元素大于父元素。\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E5%B0%8F%E5%A0%86%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E7%9A%84golang%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/%E5%A0%86%E7%A9%8D\"\u003e堆\u003c/a\u003e，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为\u003cstrong\u003e最小堆（min heap）\u003c/strong\u003e；反之，若母节点的值恒大于等于子节点的值，此堆称为\u003cstrong\u003e最大堆（max heap）\u003c/strong\u003e。在堆中最顶端的那一个节点，称作 \u003cstrong\u003e根节点（root node）\u003c/strong\u003e，根节点本身没有 \u003cstrong\u003e父节点（parent node）\u003c/strong\u003e。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\u003c/p\u003e","title":"最小堆以及优先级队列的Golang实现"},{"content":"select 的缺陷 目前对于高并发的解决方案是 一个线程处理所有连接，在这一点上 select 和 epoll 是一样的。但 当大量的并发连接存在、但短时间内只有少数活跃的连接时，select 的表现就显得捉襟见肘了。\n首先，select 用在有活跃连接时，所以，在高并发的场景下 select 会被非常频繁地调用。当监听的连接以数万计的时候，每次返回的只是其中几百个活跃的连接，这本身就是一种性能的损失。所以内核中直接限定死了 select 可监听的文件句柄数：\n// include/uapi/linux/posix_types.h #define __FD_SETSIZE 1024 其次，内核中实现 select 的方式是 轮询，即每次检测都会遍历所有的 fd_set 中的句柄，时间复杂度为 O(n)，与 fd_set 的长度呈线性关系，select 要检测的句柄数越多就会越费时。\npoll 和 select 的实现机制没有太大差异，相比 select，poll 只是取消了最大监控文件描述符的限制，并没有从根本上解决 select 的缺陷。\n下面这张图中所表达的信息中，当并发连接较小时，select 和 epoll 差距非常小，当并发数逐渐变大时，select 性能就显得非常乏力：\n需要注意的是，这个前提是 保持大量连接，但是只有少数活跃连接，如果活跃连接也特别多，那 epoll 也会有性能问题。\nepoll 相关的数据结构与方法 与 epoll 相关的系统调用有以下三个：\n这三个方法可以在 Linux 系统的机器上通过 man 2 xxx 的方式查看具体用法\n/* 返回 epoll 实例的文件句柄，size 没有实际用途，传入一个大于 0 的数即可。 */ int epoll_create(int size); /* 让 epoll(epfd)实例 对 目标文件(fd) 执行 `ADD | DEL | MOD` 操作，并指定”关心“的事件类型 */ int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); /* 阻塞等待所”关心“的事件发生 */ int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 与 select 相比，epoll 分清了 频繁调用 和 不频繁调用 的操作。例如，epoll_ctl 是不太频繁调用的，而 epoll_wait 是非常频繁调用的。\n这是 epoll 最常见的 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; int main(void) { int epfd,nfds; struct epoll_event ev; // ev用于注册事件，表示自己关心的事哪些事件 struct epoll_event events[5]; // events 用于接收从内核返回的就绪事件 epfd = epoll_create(1); // 创建一个 epoll 实例 ev.data.fd = STDIN_FILENO; // 我们关心的是命令行输入 ev.events = EPOLLIN|EPOLLET; //监听读状态同时设置ET模式(这个后面会讲，可以简单理解成：文件内容发生变化时才会触发对应的事件) epoll_ctl(epfd, EPOLL_CTL_ADD, STDIN_FILENO, \u0026amp;ev); // 注册epoll事件 for(;;) { nfds = epoll_wait(epfd, events, 5, -1); // 进入死循环，最后的 -1 表示无限期阻塞，直到有事件发生 // epoll_wait 返回，表示有对应的事件发生，事件的信息存储在 events 数组中。nfds 表示数组的长度。接下来逐个处理事件 for(int i = 0; i \u0026lt; nfds; i++) { if(events[i].data.fd==STDIN_FILENO) printf(\u0026#34;welcome to epoll\u0026#39;s word!\\n\u0026#34;); } } } 接下来我们看看 epoll 相关的数据结构。\neventpoll /* * This structure is stored inside the \u0026#34;private_data\u0026#34; member of the file * structure and represents the main data structure for the eventpoll * interface. */ struct eventpoll { // 保护 rbr(红黑树) 和 rdllist(等待队列) struct mutex mtx; // 等待队列，用来保存对一个 epoll 实例调用 epoll_wait() 的所有进程。 // 当调用 epoll_wait 的进程发现没有就绪的事件需要处理时，就将当前进程添加到此队列中，然后进程睡眠；后续事件发生，就唤醒这个队列中的所有进程(也就是出现了惊群效应) wait_queue_head_t wq; // 当被监视的文件是一个 epoll 类型时，需要用这个等待队列来处理递归唤醒。 // epoll 也是一种文件类型，因此一个 epoll 类型的 fd 也是可以被其他 epoll 实例监视的。 // 而 epoll 类型的 fd 只会有“读就绪”的事件。当 epoll 所监视的非 epoll 类型文件有“读就绪”事件时，当前 epoll 也会进入“读就绪”状态。 // 因此如果一个 epoll 实例监视了另一个 epoll 就会出现递归。如 e2 监视了e1，e1 上有读就绪事件发生，e1 就会加入 e2 的 poll_wait 队列中。 wait_queue_head_t poll_wait; // 就绪列表(双链表)，产生了用户注册的 fd读写事件的 epi 链表。 struct list_head rdllist; // 保护 rdllist 和 ovflist 。 rwlock_t lock; /* RB tree root used to store monitored fd structs */ // 红黑树根结点，管理所有\u0026#34;关心\u0026#34;的 fd struct rb_root_cached rbr; // 单链表，当 rdllist 被锁定遍历向用户空间发送数据时，rdllist 不允许被修改，新触发的就绪 epitem 被 ovflist 串联起来， // 等待 rdllist 被处理完了，重新将 ovflist 数据写入 rdllist struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ // 创建 eventpoll 的用户结构信息。 struct user_struct *user; // eventpoll 对应的文件结构，Linux 中一切皆文件，epoll 也是一个文件。 struct file *file; /* used to optimize loop detection check */ u64 gen; struct hlist_head refs; }; 如上面 demo 中所示，\nepitem // 红黑树用于管理所有的要监视的文件描述符 fd。当我们向系统中添加一个 fd 时，就会对应地创建一个 epitem 结构体。 // epitem 可以添加到红黑树，也可以串联成就绪列表或其它列表。 struct epitem { union { /* RB tree node links this structure to the eventpoll RB tree */ // 所在的红黑树 struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; }; /* List header used to link this structure to the eventpoll ready list */ // 所在的 eventpoll 的就绪列表 struct list_head rdllink; /* Works together \u0026#34;struct eventpoll\u0026#34;-\u0026gt;ovflist in keeping the single linked chain of items. */ // 关联的 eventpoll 中的 ovflist struct epitem *next; /* The file descriptor information this item refers to */ // 为最开始的 fd 创建 epitem 时的文件描述符信息 struct epoll_filefd ffd; /* List containing poll wait queues */ // poll 等待队列 struct eppoll_entry *pwqlist; /* The \u0026#34;container\u0026#34; of this item */ // 所在的 eventpoll struct eventpoll *ep; /* List header used to link this item to the \u0026#34;struct file\u0026#34; items list */ struct hlist_node fllink; /* wakeup_source used when EPOLLWAKEUP is set */ struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ struct epoll_event event; }; epoll 工作流程 epoll 是有状态的, 内核中维护了一个数据结构用来管理所要监视的 fd，这个数据结构是 eventpoll；\n在 eventpoll 中有一颗红黑树, 用来快速的查找和修改要监视的 fd，每个节点被封装成 epitem 结构；\n在 eventpoll 中有一个列表, 用来收集已经发生事件的 epitem , 这个 list 叫 ready list(rdllist)。\n通过 epoll_ctl 函数添加进来的事件都会被放在红黑树的某个节点内，所以，重复添加是没有用的。当把事件添加进来的时候会完成关键的一步——该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数，该回调函数在内核中被称为：ep_poll_callback。这个回调函数其实就所把这个事件添加到rdllist这个双向链表中——一旦有事件发生，epoll就会将该事件添加到双向链表中。那么当我们调用 epoll_wait 时，epoll_wait 只需要检查 rdlist 双向链表中是否有存在注册的事件，有则返回，效率非常可观。\nepoll_create 细节 // 创建一个 eventpoll 对象，并且关联文件资源 static int do_epoll_create(int flags) { int error, fd; struct eventpoll *ep = NULL; struct file *file; // ... // 创建并初始化核心结构 eventpoll，赋值给 ep error = ep_alloc(\u0026amp;ep); if (error \u0026lt; 0) return error; // 创建一个文件(文件句柄 fd 和 file结构) fd = get_unused_fd_flags(O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (fd \u0026lt; 0) { error = fd; goto out_free_ep; } // 注意，在这里将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象 file = anon_inode_getfile(\u0026#34;[eventpoll]\u0026#34;, \u0026amp;eventpoll_fops, ep, O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (IS_ERR(file)) { error = PTR_ERR(file); goto out_free_fd; } // 绑定 fd 和 file，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程。 ep-\u0026gt;file = file; fd_install(fd, file); return fd; // ... } 这个函数很简单，主要做以下几件事：\n创建并初始化核心结构 eventpoll，赋值给变量 ep； 创建一个 文件句柄fd 和 文件 file结构体，并绑定 fd 和 file、绑定 file 和 eventpoll(将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象)，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程，这也间接说明 epoll 也是一种文件。 关于绑定 fd 和 file，参考：彻底理解 Linux 中的 文件描述符(fd)\nepoll_ctl 细节 // epoll_ctl 的详细实现 int do_epoll_ctl( int epfd/*epoll 文件描述符*/, int op /*操作类型*/, int fd /*要监控的目标文件描述符*/, struct epoll_event *epds/*要监视的事件类型*/, bool nonblock, ) { int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct eventpoll *tep = NULL; // epoll 对应的文件 f = fdget(epfd); // fd 对应的文件 tf = fdget(fd); /* The target file descriptor must support poll */ // epoll 并不能监控所有的文件描述符，只能监视支持 poll 方法的文件描述符 // 其实是检查对应的 file 中的 file_operations 中是否有 poll 方法，即当前文件类型是否实现了 poll 方法(普通文件没有实现，socket 或者 epoll 类型等都实现了，所以可以被 epoll 监控) if (!file_can_poll(tf.file)) goto error_tgt_fput; /* Check if EPOLLWAKEUP is allowed */ // 检查是否允许 EPOLLWAKEUP if (ep_op_has_event(op)) ep_take_care_of_epollwakeup(epds); // epoll 监视的不是自己 error = -EINVAL; if (f.file == tf.file || !is_file_epoll(f.file)) goto error_tgt_fput; // 在 do_epoll_create 实现里 anon_inode_getfile 已经将 private_data 与 eventpoll 关联。 ep = f.file-\u0026gt;private_data; // 当我们添加进来的 file 是一个 epoll 类型的文件时，有可能造成循环引用的死循环。在这里提前检查避免这种情况 error = epoll_mutex_lock(\u0026amp;ep-\u0026gt;mtx, 0, nonblock); if (error) goto error_tgt_fput; if (op == EPOLL_CTL_ADD) { if (READ_ONCE(f.file-\u0026gt;f_ep) || ep-\u0026gt;gen == loop_check_gen || is_file_epoll(tf.file)) { // ... } } // 查找 要添加的 fd 是否已经在红黑树上了，如果是，返回对应的 epitem 结构，否则返回 NULL epi = ep_find(ep, tf.file, fd); error = -EINVAL; switch (op) { case EPOLL_CTL_ADD: // 增加fd if (!epi) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; // fd 不在红黑树上，就将此 fd 添加到红黑树上管理。默认关注的事件是 EPOLLERR | EPOLLHUP error = ep_insert(ep, epds, tf.file, fd, full_check); } else error = -EEXIST; break; case EPOLL_CTL_DEL: // 删除fd if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: // 修改fd事件类型 if (epi) { if (!(epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE)) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; error = ep_modify(ep, epi, epds); } } else error = -ENOENT; break; } mutex_unlock(\u0026amp;ep-\u0026gt;mtx); // ... } 在 do_epoll_ctl() 的参数中，操作类型有三种：\nEPOLL_CTL_ADD： 往事件表中注册fd上的事件； EPOLL_CTL_DEL：删除fd上的注册事件； EPOLL_CTL_MOD：修改fd上的注册事件。 而 struct epoll_event 结构表示事件类型，常见的有：\n// eventpoll.h #define EPOLLIN (__force __poll_t)0x00000001 // 有可读数据到来 #define EPOLLPRI (__force __poll_t)0x00000002 // 有紧急数据可读：1. TCP socket 上有外带数据；2. 分布式环境下状态发生改变；3. cgroup.events类型的文件被修改 #define EPOLLOUT (__force __poll_t)0x00000004 // 有数据要写 #define EPOLLERR (__force __poll_t)0x00000008 // 文件描述符上发生错误(不管有没有设置这个 flag，epoll_wait 总是会检测并返回这样的错误) #define EPOLLHUP (__force __poll_t)0x00000010 // 该文件描述符被挂断。常见 socket 被关闭（read == 0） #define EPOLLRDHUP (__force __poll_t)0x00002000 // 对端已关闭链接，或者用 shutdown 关闭了写链 /* Set the Edge Triggered behaviour for the target file descriptor */ #define EPOLLET ((__force __poll_t)(1U \u0026lt;\u0026lt; 31)) // ET 工作模式 /* Set the One Shot behaviour for the target file descriptor */ /* 一般情况下，ET 模式只会触发一次，但有可能出现多个线程同时处理 epoll，此标志规定操作系统最多触发其上注册的一个可读或者可写或者异常事件，且只触发一次，如此无论线程再多，只能有一个线程或进程处理同一个描述符 */ #define EPOLLONESHOT ((__force __poll_t)(1U \u0026lt;\u0026lt; 30)) /* Set exclusive wakeup mode for the target file descriptor */ /* 唯一唤醒事件，主要为了解决 epoll_wait 惊群问题。多线程下多个 epoll_wait 同时等待，只唤醒一个 epoll_wait 执行。 该事件只支持 epoll_ctl 添加操作 EPOLL_CTL_ADD */ #define EPOLLEXCLUSIVE ((__force __poll_t)(1U \u0026lt;\u0026lt; 28)) 关于什么是 “ET(边缘触发)” 和 “LT(水平触发)”，后面会详细说。\nep_insert static int ep_insert(struct eventpoll *ep, const struct epoll_event *event, struct file *tfile, int fd, int full_check) { // ep_insert(ep, epds, tf.file, fd, full_check); // tf 表示 fd 对应的 file 结构 int error, pwake = 0; __poll_t revents; long user_watches; // epoll 文件对象中所监视的 fd 数量 struct epitem *epi; struct ep_pqueue epq; struct eventpoll *tep = NULL; // 当 fd 类型是 epoll 时，tep 用来保存 fd 对应的 eventpoll 结构 // 要监视的文件也是 epoll 类型，用 tep 保存对应的 eventepoll 结构 if (is_file_epoll(tfile)) tep = tfile-\u0026gt;private_data; lockdep_assert_irqs_enabled(); // 判断 epoll 监视的文件个数是否超出系统限制 user_watches = atomic_long_read(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); if (unlikely(user_watches \u0026gt;= max_user_watches)) return -ENOSPC; if (!(epi = kmem_cache_zalloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ // 创建一个双链表，头和尾都是它自己 INIT_LIST_HEAD(\u0026amp;epi-\u0026gt;rdllink); epi-\u0026gt;ep = ep; ep_set_ffd(\u0026amp;epi-\u0026gt;ffd, tfile, fd); // epitem 与 fd 绑定 epi-\u0026gt;event = *event; epi-\u0026gt;next = EP_UNACTIVE_PTR; // 目标文件是 epoll 类型 if (tep) mutex_lock_nested(\u0026amp;tep-\u0026gt;mtx, 1); /* Add the current item to the list of active epoll hook for this file */ if (unlikely(attach_epitem(tfile, epi) \u0026lt; 0)) { kmem_cache_free(epi_cache, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); return -ENOMEM; } if (full_check \u0026amp;\u0026amp; !tep) list_file(tfile); // 当前进程的用户的 epoll_watches 加一 atomic_long_inc(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); // 将初始化后的 epitem 添加到红黑树中 ep_rbtree_insert(ep, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); // 不允许递归监视太多的 epoll if (unlikely(full_check \u0026amp;\u0026amp; reverse_path_check())) { ep_remove(ep, epi); return -EINVAL; } if (epi-\u0026gt;event.events \u0026amp; EPOLLWAKEUP) { error = ep_create_wakeup_source(epi); if (error) { ep_remove(ep, epi); return error; } } /* Initialize the poll table using the queue callback */ epq.epi = epi; // 注册回调函数，作用：add our wait queue to the target file wakeup lists. 在tcp_sock-\u0026gt;sk_sleep中插入一个等待者 // 不同的系统实现 poll 的方式不同，如socket的话, 那么这个接口就是 tcp_poll() init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc); // 可能此时已经有事件存在了, revents返回这个事件 revents = ep_item_poll(epi, \u0026amp;epq.pt, 1); // ... // 如果此时就有关注的事件发生，我们将其放到就绪队列中 if (revents \u0026amp;\u0026amp; !ep_is_linked(epi)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); // 唤醒等待的线程，告诉他们有活干了 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) wake_up(\u0026amp;ep-\u0026gt;wq); if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; } // ... } ep_insert 先申请一个 epitem 对象 epi，并初始化 epitem 的两个 list 的头指针：rdllink(指向 eventpoll 的 rdllist)、pwqlist(指向包含此 epitem 的所有 poll wait queue)，通过 fs 将 epitem、fd 和 file 绑定，通过 epitem.ep 将此 epitem 和 传入的 eventpoll 对象绑定，通过传入的 event 对 epitem.events 赋值，紧接着，将这个 epitem 加入到 eventpoll 的 红黑树中。整个过程结束后，epitem 本身就完成了和 eventpoll 以及 被监视文件fd 的关联。但还要做一件事：将 epitem 加入目标文件的 poll 等待队列并注册对应的回调函数。\n在 ep_insert() 中有一行是 init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc);，这其实是注册了一个回调函数——将文件的 poll() 方法与此方法绑定，当文件就绪，就会调用此方法。\n关于 等待队列 的实现，参考：理解 Linux 等待队列\n我们知道，当一个进程加入等待队列之后，需要将设置对应的唤醒函数，当资源就绪的时候调用这个设置好的唤醒函数：\n// 链表中的一个结点 struct wait_queue_entry { unsigned int flags; // 标志，如 WQ_FLAG_EXCLUSIVE，表示等待的进程应该独占资源（解决惊群现象） void *private; // 等待进程相关信息，如 task_struct wait_queue_func_t func; // 唤醒函数 struct list_head entry; // 前后结点 }; 我们再来看下 init_waitqueue_func_entry 这个方法：\nstatic inline void init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func) { wq_entry-\u0026gt;flags = 0; wq_entry-\u0026gt;private = NULL; wq_entry-\u0026gt;func = func; } 正是将等待队列中的结点的唤醒函数设置为 ep_ptable_queue_proc ！\n我们来详细看看 ep_ptable_queue_proc 的实现：\n/* // 当该文件描述符对应的文件有事件到达后，回调用这个函数 // 首先根据pt拿到对应的epi。然后通过pwq将三者关联。 // @file: 要监听的文件 // @whead: 该fd对应的设备等待队列，每个设备的驱动都会带 // @pt: 调用文件的poll传入的东西。 */ static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct ep_pqueue *epq = container_of(pt, struct ep_pqueue, pt); struct epitem *epi = epq-\u0026gt;epi; struct eppoll_entry *pwq; // epitem 的私有项，为每一个 fd 保存内核的 poll。 // 这个结构体主要完成 epitem 和 epitem事件发生时 callback 函数的关联，将唤醒回调函数设置为 ep_poll_callback，然后加入设备等待队列 // ... // 将pwq的等待队列和回调函数ep_poll_callback关联 // ep_poll_callback 才是真正意义上的 poll() 醒来时的回调函数，当设备就绪，就会唤醒设备的等待队列中的进程，此时 ep_poll_callback 会被调用 init_waitqueue_func_entry(\u0026amp;pwq-\u0026gt;wait, ep_poll_callback); pwq-\u0026gt;whead = whead; pwq-\u0026gt;base = epi; // 将 进程对应的等待双链表结点 放入等待队列whead // 将eppoll_entry挂在到fd的设备等待队列上。也就是注册epoll的回调函数 ep_poll_callback if (epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, \u0026amp;pwq-\u0026gt;wait); else add_wait_queue(whead, \u0026amp;pwq-\u0026gt;wait); pwq-\u0026gt;next = epi-\u0026gt;pwqlist; epi-\u0026gt;pwqlist = pwq; } 我们来看看 ep_poll_callback 干了什么：\n/* * This is the callback that is passed to the wait queue wakeup * mechanism. It is called by the stored file descriptors when they * have events to report. * * This callback takes a read lock in order not to contend with concurrent * events from another file descriptor, thus all modifications to -\u0026gt;rdllist * or -\u0026gt;ovflist are lockless. Read lock is paired with the write lock from * ep_scan_ready_list(), which stops all list modifications and guarantees * that lists state is seen correctly. */ static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key) { int pwake = 0; struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-\u0026gt;ep; __poll_t pollflags = key_to_poll(key); unsigned long flags; int ewake = 0; // ... /* * If we are transferring events to userspace, we can hold no locks * (because we\u0026#39;re accessing user memory, and because of linux f_op-\u0026gt;poll() * semantics). All the events that happen during that period of time are * chained in ep-\u0026gt;ovflist and requeued later on. */ // 因为要访问用户空间，所以此时对 rdllist 的访问不应该加锁。如果恰巧这个时候有对应的 // 事件发生，应该将其放到 ovflist 中之后再调度。 if (READ_ONCE(ep-\u0026gt;ovflist) != EP_UNACTIVE_PTR) { if (chain_epi_lockless(epi)) ep_pm_stay_awake_rcu(epi); } else if (!ep_is_linked(epi)) { // 将当前的 epitem 添加到 eventpool 的就绪队列中 /* In the usual case, add event to ready list. */ if (list_add_tail_lockless(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist)) ep_pm_stay_awake_rcu(epi); } /* * Wake up ( if active ) both the eventpoll wait list and the -\u0026gt;poll() * wait list. */ // 同时唤醒 eventpool 和 poll 的等待的进程 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) { if ((epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) \u0026amp;\u0026amp; !(pollflags \u0026amp; POLLFREE)) { switch (pollflags \u0026amp; EPOLLINOUT_BITS) { case EPOLLIN: if (epi-\u0026gt;event.events \u0026amp; EPOLLIN) ewake = 1; break; case EPOLLOUT: if (epi-\u0026gt;event.events \u0026amp; EPOLLOUT) ewake = 1; break; case 0: ewake = 1; break; } } wake_up(\u0026amp;ep-\u0026gt;wq); } if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; // ... return ewake; } ep_wait 细节 入口在\nSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { struct timespec64 to; return do_epoll_wait(epfd, events, maxevents, ep_timeout_to_timespec(\u0026amp;to, timeout)); } 实际调用的是 do_epoll_wait：\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). * * @epfd: 对应的 eventpoll 文件描述符 * @events: 用于接收已经就绪的事件 * @maxevents：所监听的最大事件个数 * @to：超时事件(-1表示无限制等待) */ // epoll_wait 的具体实现 static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, struct timespec64 *to) { int error; struct fd f; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents \u0026lt;= 0 || maxevents \u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ // 确保用户传进来的地址空间是可写的 if (!access_ok(events, maxevents * sizeof(struct epoll_event))) return -EFAULT; /* Get the \u0026#34;struct file *\u0026#34; for the eventpoll file */ // 获取 epoll 实例 f = fdget(epfd); if (!f.file) return -EBADF; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; // 确保传进来的 epfd 是 epoll 类型 if (!is_file_epoll(f.file)) goto error_fput; /* * At this point it is safe to assume that the \u0026#34;private_data\u0026#34; contains * our own data structure. */ ep = f.file-\u0026gt;private_data; /* Time to fish for events ... */ // 执行具体的 poll，如果有事件产生，返回的 error 就是对应的事件个数，对应的事件也会同时从 eventpoll 对应的 rdllist(就绪队列) 中写入到传进来的 events 数组中 error = ep_poll(ep, events, maxevents, to); error_fput: fdput(f); return error; } 我们看下 ep_poll 的实现细节：\n/** * ep_poll - 检索已经就绪的事件，并将其从内核空间传送到用户空间传进来的events 列表中 * * @ep: eventpoll 实例指针 * @events: 存放就绪事件的用户空间的数组的指针 * @maxevents: events 数组的长度 * @timeout: 获取就绪事件操作的最大超时时间。如果是 0，表示不阻塞；如果是负数，表示一直阻塞 * * Return: 成功收到的事件的个数，或者失败时对应的错误码。 */ static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 设置超时 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { // 有具体的超时时长 slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. */ // 用户设置不阻塞。 timed_out = 1; } // 检查 ep.rdllist 或 ep.ovflist 中是否有就绪的事件，如果有返回就绪事件的个数。否则返回 0 eavail = ep_events_available(ep); while (1) { if (eavail) { // rdllist 中已经有事件了，将其传送到用户空间。 // 如果没有对应的事件并且也没到超时时间，就再等等，直到超时 res = ep_send_events(ep, events, maxevents); if (res) return res; } // 走到这一步，说明没有就绪事件 // 用户设置不阻塞，直接返回 if (timed_out) return 0; // always false eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查当前进程是否有信号处理，返回不为0表示有信号需要处理。 if (signal_pending(current)) return -EINTR; init_wait(\u0026amp;wait); write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有就绪事件，如果没有，让当前进程睡眠(然后进程就阻塞在这里了...) eavail = ep_events_available(ep); if (!eavail) __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 重新计算超时时间 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 进程被唤醒了，说明有事件发生！ __set_current_state(TASK_RUNNING); /* * We were woken up, thus go and try to harvest some events. * If timed out and still on the wait queue, recheck eavail * carefully under lock, below. */ eavail = 1; if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); /* * If the thread timed out and is not on the wait queue, * it means that the thread was woken up after its * timeout expired before it could reacquire the lock. * Thus, when wait.entry is empty, it needs to harvest * events. */ if (timed_out) // list_empty 检查 list 是否为空 eavail = list_empty(\u0026amp;wait.entry); // 将 wait 从 ep 的等待队列中删除 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 我们再来看 ep_send_events的实现：\nstatic int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) { struct epitem *epi, *tmp; LIST_HEAD(txlist); poll_table pt; int res = 0; if (fatal_signal_pending(current)) return -EINTR; init_poll_funcptr(\u0026amp;pt, NULL); mutex_lock(\u0026amp;ep-\u0026gt;mtx); // 将 rdllist 中的元素全部添加到 txlist 中，并清空 ep.rdllist ep_start_scan(ep, \u0026amp;txlist); // 迭代器，逐个处理从 ep-\u0026gt;rdllist 中取出后放在 txlist 中的 epitem // epi 表示正在处理的对象(cursor) list_for_each_entry_safe(epi, tmp, \u0026amp;txlist, rdllink) { struct wakeup_source *ws; __poll_t revents; if (res \u0026gt;= maxevents) break; ws = ep_wakeup_source(epi); if (ws) { if (ws-\u0026gt;active) __pm_stay_awake(ep-\u0026gt;ws); __pm_relax(ws); } // 重置 epitem 中的 rdllink list_del_init(\u0026amp;epi-\u0026gt;rdllink); // 检查就绪事件的 flag 是否是调用方需要的 revents = ep_item_poll(epi, \u0026amp;pt, 1); if (!revents) continue; // 内核向用户态复制数据 if (__put_user(revents, \u0026amp;events-\u0026gt;events) || __put_user(epi-\u0026gt;event.data, \u0026amp;events-\u0026gt;data)) { list_add(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;txlist); ep_pm_stay_awake(epi); if (!res) res = -EFAULT; break; } res++; events++; // 处理水平触发和边缘触发的场景 if (epi-\u0026gt;event.events \u0026amp; EPOLLONESHOT) epi-\u0026gt;event.events \u0026amp;= EP_PRIVATE_BITS; else if (!(epi-\u0026gt;event.events \u0026amp; EPOLLET)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); } } ep_done_scan(ep, \u0026amp;txlist); mutex_unlock(\u0026amp;ep-\u0026gt;mtx); return res; } 而其中的 ep_item_poll，不同的驱动程序，都会有自己的 poll 方法，如果是 TCP套接字，这个poll方法就是 tcp_poll。在 TCP 中，会周期性的调用这个方法调用频率取决于协议栈中断频率的设置。一旦有事件到达后，对应的 tcp_poll 方法被调用，tcp_poll 方法会回调用 sock_poll_wait()，该方法会调用这里注册的 ep_ptable_queue_proc 方法。epoll 其实就是通过此机制实现将自己的回调函数加入到文件的 waitqueue 中的。这也是 ep_ptable_queue_proc 的目的。\nstatic __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt, int depth) { struct file *file = epi-\u0026gt;ffd.file; __poll_t res; pt-\u0026gt;_key = epi-\u0026gt;event.events; if (!is_file_epoll(file)) // 非 epoll 类型的 fd，检查 socket 的就绪事件，fd 关联回调函数 ep_poll_callback。最终执行的 poll 是 tcp_poll res = vfs_poll(file, pt); else res = __ep_eventpoll_poll(file, pt, depth); return res \u0026amp; epi-\u0026gt;event.events; } 再谈 epoll 和 select 从更高的角度看，epoll 和 select 都是 I/O 多路复用，当我们在调用这类函数时，我们传入的是 关心的socket，接收到的返回是 就绪的 socket。那为何会有性能差距呢？我们尝试找出他们的不同点：\n对比 select epoll 连接数限制 1024 理论上无限制 内在处理机制 现行轮训 callback TODO TODO TODO 再回头看看 select 的 demo:\nint main(){ int fds[] = ...; // 关心的 socket 数组 fd_set source_fds; // 将我们关心的 socket 保存到 fd_set 中 fd_set temp_fds; // 临时变量，作为 select 的返回值 // 初始化 source_fds FD_ZERO(\u0026amp;source_fds); for (int i=0; i\u0026lt;fds.length; i++) { FD_SET(fds[i], \u0026amp;source_fds); } while(1) { // select 将一个 fd_set 作为入参，将就绪的 socket 又填充如这个入参中作为出参返回 // 因此，为了快速重置，设置一个临时变量，避免每次都要进行 source_fds 的重置 temp_fds = source_fds; // select 会阻塞，直到关心的 socket 上有事件发生 int n = select(..., \u0026amp;temp_fds, ...); // 在用户态遍历 socket，检查是否有我们关心的事件发生 for (int i=0; i \u0026lt; fds.length; i++) { if (FD_ISSET(fds[i], \u0026amp;temp_fds)) { // ... 进行对应的逻辑处理 FD_CLR(fds[i], \u0026amp;temp_fds); } } } return 0; } select 主要有两点限制：\n所能关注的 socket 太少，只能有 1024 个，对于一些大型 web 应用来说有点捉襟见肘； 尽管 FD_SET 是 O(1) 的操作，但返回后还要在用户态遍历一次整个 fd_set，这是一个线性操作 再回过头来看 epoll:\nint main() { int fds[] = ...; // 关心的 socket 数组 int epfd = epoll_create(...); // 创建 epoll 实例 // 将关心的 socket 添加到 epoll 中(红黑树等) for (int i=0; i \u0026lt; fds.length; i++){ epoll_ctl(epfd,EPOLL_CTL_ADD, fds[i], ...); } // 定义一个结构，用来接收就绪的事件 struct epoll_event events[MAX_EVENTS]; while(1){ // 如果无事件发生，那么进程将阻塞在这里 // 如果有事件发生，则返回就绪的事件个数，同时事件被存储在 events 中 int n = epoll_wait(epfd, \u0026amp;events,...); for (int i=0; i \u0026lt; n; i++) { // 通过下标取到返回的就绪事件，进行对应的逻辑处理 new_event = events[i]; } } return 0; } 每次epoll_wait 返回的都是活跃的 socket，根本不用全部遍历一遍 epoll 底层使用到了 红黑树 来存储所关心的 socket，查找效率有保证；注册的对应的事件通知是通过回调的方式执行的，这种解耦、相互协作的方式更有利于操作系统的调度。 ","permalink":"http://localhost:1313/posts/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/","summary":"\u003ch2 id=\"select-的缺陷\"\u003eselect 的缺陷\u003c/h2\u003e\n\u003cp\u003e目前对于高并发的解决方案是 \u003cstrong\u003e一个线程处理所有连接\u003c/strong\u003e，在这一点上 \u003ccode\u003eselect\u003c/code\u003e 和 \u003ccode\u003eepoll\u003c/code\u003e 是一样的。但 \u003cstrong\u003e当大量的并发连接存在、但短时间内只有少数活跃的连接时，\u003ccode\u003eselect\u003c/code\u003e 的表现就显得捉襟见肘了。\u003c/strong\u003e\u003c/p\u003e","title":"I/O多路复用之 epoll"},{"content":"看 select 源码，fd_set 这个结构体实际上是一个 long 型的数组，但是数组的长度依赖于系统中 typedef long int __fd_mask 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\n本文旨在抛开 select 相关的功能，彻底搞明白 fd_set 的存储原理、FD_SET() 等函数到底实现了什么效果。\n本次调试机器：\n$ uname -a Linux localhost 4.15.0-52-generic #56-Ubuntu SMP Tue Jun 4 22:49:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux fd_set 的源码中有非常多的预编译指令：\n// /usr/include/x86_64-linux-gnu/sys/select.h /* The fd_set member is required to be an array of longs. */ typedef long int __fd_mask; /* Some versions of \u0026lt;linux/posix_types.h\u0026gt; define this macros. */ #undef __NFDBITS /* It\u0026#39;s easier to assume 8-bit bytes than to get CHAR_BIT. */ #define __NFDBITS (8 * (int) sizeof (__fd_mask)) #define __FD_MASK(d) ((__fd_mask) (1UL \u0026lt;\u0026lt; ((d) % __NFDBITS))) /* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 我简单整理一下，去掉和本系统无关的，结果如下：\ntypedef long int __fd_mask; // 8 #define __NFDBITS (8 * (int) sizeof (__fd_mask) // 64 #define __FD_SETSIZE 1024 typedef struct { __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; // 长度为 1024/64=16，类型为 long } fd_set; 接着，我们看一个 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; void print_set1(fd_set *fdset); void print_set2(fd_set *fdset); int main() { fd_set fdset; FD_ZERO(\u0026amp;fdset); printf(\u0026#34;sizeof long int: %ld\\n\u0026#34;, sizeof(long int)); // 8 printf(\u0026#34;sizeof int: %ld\\n\u0026#34;, sizeof(int)); // 4 printf(\u0026#34;sizeof short: %ld\\n\u0026#34;, sizeof(short)); // 2 FD_SET(1, \u0026amp;fdset); FD_SET(2, \u0026amp;fdset); FD_SET(3, \u0026amp;fdset); FD_SET(7, \u0026amp;fdset); print_set1(\u0026amp;fdset); // 10001110 -\u0026gt; 第 1 2 3 7 位分别设置成了 1 FD_SET(15, \u0026amp;fdset); FD_SET(16, \u0026amp;fdset); FD_SET(31, \u0026amp;fdset); // 10000000000000011000000010001110 -\u0026gt; 长度为 32 FD_SET(32, \u0026amp;fdset); FD_SET(33, \u0026amp;fdset); FD_SET(62, \u0026amp;fdset); // 100000000000000000000000000001110000000000000011000000010001110 0-\u0026gt;长度为 63 print_set2(\u0026amp;fdset); FD_SET(63, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 0 -\u0026gt; 长度为 64 print_set2(\u0026amp;fdset); FD_SET(64, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 -\u0026gt; 长度还是 64，但产生了进位 print_set2(\u0026amp;fdset); FD_SET(128, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 1-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(129, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 3-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(1023, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1024, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1025, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 print_set2(\u0026amp;fdset); int isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 1，代表第 7 位被设置 FD_CLR(7, \u0026amp;fdset); print_set2(\u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000000001110 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 -\u0026gt; 第 7 位的 1 变成了 0 isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 0，代表第 7 位没有被设置 return 0; } void print_set2(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%llu \u0026#34;, (unsigned long long)fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } void print_set1(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%ld \u0026#34;,fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } print_set() 函数是我自己添加的，用于打印出 fd_set 中的 __fds_bits 数组中的内容。需要注意两点：\n数组长度是 16，是如何确定的？答：在处理过预编译指令之后，__FD_SETSIZE 的值是 1024，__NFDBITS 的值是 64，计算得到数组长度为 16；\n类型的长度如何确定？答：在最开始使用了 typedef long int __fd_mask，long int 其实就是 long，即 long signed integer type。熟悉 C语言的同学都知道，当我们描述 short、int 和 long 的长度时，只有对 short 的长度是肯定的，而对后两者都使用了 可能 的说法：可能长度为 8。这是因为 C语言 没有对其做出严格的规定，只做了宽泛的限制：short 占 2字节；int 建议为机器字长，64 位机器下占4字节；2 ≤ short ≤ int ≤ long，如上述代码中打印结果所示，在我测试的这台机器上，long 占 8字节 即 64位。\n接下来我们看 main() 中的代码：\n在调用 FD_SET() 设置 1 2 3 7 后，我们调用print_set1()打印结果，输出：142 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，数组第一位竟然是 142？！哪来的？但我们将 142 转成二进制就一下子了然了：10001110， 总共占 8 位，从右往左从 0 开始数，只有第 1 2 3 7 位被设置成了 1， 这个二进制对应的数就是 142，因为 142 完全在一个 long 的范围(64位)内，所以正常表示了。那如果我们对一个超过 long 范围的数调用 FD_SET()，会是什么效果？\n代码继续走到 FD_SET(62, \u0026amp;fdset)，我们调用 print_set1()，输出 4611686033459871886 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，4611686033459871886 转成二进制为 100000000000000000000000000001110000000000000011000000010001110，字符串长度为 63，可以看到，依旧在 long 的范围之内；执行到 FD_SET(63,\u0026amp;fdset) 呢，调用 print_set1()，输出 -4611686003394903922 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，出现了负数。我们想一下原因。只执行FD_SET(62,\u0026amp;fdset) 会将第 63 位处设置为 1，对应的二进制为 100000000000000000000000000000000000000000000000000000000000000(长度为 63)；根据 FD_SET() 的功能，我们可以猜测，FD_SET(63,\u0026amp;fdset) 会将第 64 位设置为 1，其对应的二进制应该是 1000000000000000000000000000000000000000000000000000000000000000(长度为 64)。\n在这里我们补充一个知识：参考这里 Wiki-无符号数，在计算机底层，有符号数可以表示特定范围内的整数(包括负数)，无符号数只能表示非负数(0 以及正数)，有符号数能够表示负数的原因是，最高位被用来当做符号位，1 表示负数，0 表示正数，代价就是所表示的数的范围少了一半，举个例子，8 位可以表示无符号数 [0,255](最小00000000；最大11111111，对应的十进制就是 255)，对应的有符号数范围就是 [-127,127]。\n再回头看 1000000000000000000000000000000000000000000000000000000000000000，__fd_mask 的类型是 long，是一个有符号数，最高位的 1 表示负数，后面的才是真正的值，于是这个二进制转成有符号十进制的结果就是 0，而且还是个 -0。为了验证我们的想法，我们将 print_set1() 换成 print_set2()，这两个函数唯一的不同是，将数组中的每一位的类型强转成了无符号数，这下结果就成了 9223372036854775808，符合我们的预期。 所以后面的调试，我们都使用 print_set2() 这个函数。\n刚才的 FD_SET(63,\u0026amp;fdset) 已经到达一个 long 的最大可 表示范围了，如果再多一位，会发生什么？我们看下 FD_SET(64, \u0026amp;fdset)，输出 13835058070314647694 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0，13835058070314647694 转换成二进制后为 1100000000000000000000000000001110000000000000011000000010001110(长度为 64)，和 设置 63 时的一样，但数组的第二位变成了 1。按照前面的推测，单独执行 FD_SET(64, \u0026amp;fdset)，应该将第 65 位设置成 1，长度为 65，但是 65 显然超过了 long 的可表示的长度(64位)，于是，产生了“进位”，这个进位的基本单位就是 64位，即 __NFDBITS 的值。于是，可以用如下 python 代码表示(python 对大数处理非常好，一般不会出现溢出)：\n#!/usr/local/env python3 # coding:utf-8 # get_fd_set_bin 返回 fd_set 表示的真实二进制(从右往左方向) # every_fd_bits 表示数组中每个元素代表多少位 # set_array 表示 fd_set 的 long 数组 def get_fd_set_bin(every_fd_bits, set_array): int_value = 0 for idx in range(len(set_array)): int_value = int_value | (set_array[idx] \u0026lt;\u0026lt; every_fd_bits * idx) return bin(int_value)[2:] # 输出 \u0026#34;0bxxxxxx\u0026#34;，为了方便展示，去掉前缀 # print_bin 将二进制按照 step 为一组打印 def print_bin(output, step=64): le = len(output) m = le % step padding = step - m if m != 0 else 0 output = output.zfill(le + padding) print(\u0026#39; \u0026#39;.join(\u0026#39;\u0026#39;.join(output[idx * step:(idx + 1) * step]) for idx in range((le + padding) // step))) 在我们当前的例子中，every_fd_bits = 64, set_array 的长度为 16。测试一下我们的代码：\n# 输入(相当于设置了 1 2 3 7) get_fd_set_bin(64, [142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000010001110 # 输入(相当于设置了 1 2 3 7 64) get_fd_set_bin(64, [142,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000000000001 0000000000000000000000000000000000000000000000000000000010001110 我用 Golang 做了简单实现：\npackage main import ( \u0026#34;math/big\u0026#34; \u0026#34;strings\u0026#34; ) type FdSet interface { FD_CLR(fd int) error FD_ISSET(fd int) (bool, error) FD_SET(fd int) error FD_ZERO() error FdSetString() string } type fdType uint64 const ( maxFdSetSize = 1024 fdMask = 8 // sizeof long int in c fdBits = 8 * fdMask ) type FdSetGolang struct { data [maxFdSetSize / fdBits]fdType } func NewGdSetGolang() *FdSetGolang { return \u0026amp;FdSetGolang{data: [maxFdSetSize / fdBits]fdType{}} } func (fs *FdSetGolang) FD_CLR(fd int) error { fs.clear(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ISSET(fd int) (bool, error) { return fs.isSet(fs.getMask(fd)), nil } func (fs *FdSetGolang) FD_SET(fd int) error { fs.set(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ZERO() error { for i := range fs.data { fs.data[i] = 0 } return nil } func (fs *FdSetGolang) FdSetString() string { tmp := make([]string, 0, len(fs.data)) for i := len(fs.data) - 1; i \u0026gt;= 0; i-- { if v := fs.uintBin(uint64(fs.data[i])); v != \u0026#34;\u0026#34; { tmp = append(tmp, v) } } // 最左边的那个，可以将前面的 0 全部去掉 if len(tmp) \u0026gt; 0 { t := tmp[0] if t != \u0026#34;\u0026#34; { for i := 0; i \u0026lt; len(t); i++ { if t[i] != \u0026#39;0\u0026#39; { tmp[0] = t[i:] break } } } } return \u0026#34;--\u0026gt;\u0026#34; + strings.Join(tmp, \u0026#34; \u0026#34;) + \u0026#34;\u0026lt;--\u0026#34; } func (fs *FdSetGolang) getMask(fd int) (idx int, n int) { return fd / fdBits, fd % fdBits } // set 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 1 func (fs *FdSetGolang) set(idx int, n int) { old := fs.data[idx] fs.data[idx] = 1\u0026lt;\u0026lt;n | old } // clear 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 0 func (fs *FdSetGolang) clear(idx int, n int) { if fs.isSet(idx, n) { fs.data[idx] ^= 1 \u0026lt;\u0026lt; n } } func (fs *FdSetGolang) isSet(idx, n int) bool { old := fs.data[idx] this := 1 \u0026lt;\u0026lt; n if int(old)\u0026amp;this == this { return true } return false } // uintBin 输出 n 的二进制表示 func (fs *FdSetGolang) uintBin(n uint64) string { if n == 0 { return \u0026#34;\u0026#34; } s := big.NewInt(0).SetUint64(n).Text(2) return strings.Repeat(\u0026#34;0\u0026#34;, fdBits-len(s)) + s } ","permalink":"http://localhost:1313/posts/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3linux-select%E4%B8%AD%E7%9A%84fd_set/","summary":"\u003cp\u003e看 \u003ccode\u003eselect\u003c/code\u003e 源码，\u003ccode\u003efd_set\u003c/code\u003e 这个结构体实际上是一个 \u003ccode\u003elong\u003c/code\u003e 型的数组，但是数组的长度依赖于系统中 \u003ccode\u003etypedef long int __fd_mask\u003c/code\u003e 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\u003c/p\u003e","title":"彻底理解Linux Select中的FD_SET"},{"content":"关于事务 事务的特性 原子性(Atomic, A)：要么全部执行，要么全部不执行； 一致性(Consistent, C)：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态； 隔离性(Isolation, I)：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务； 持久性(Durability, D)：事务提交后，其结果永久保存在数据库中。 事务ACID特性的实现思想\n原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 并发操作带来的问题 脏读(Dirty Reads)：一个事务在处理的过程中读取到了另一个未提交事务中的事务； 不可重复读(Non-Reapeatable Reads)：一个事务在读取某些数据后的某个时间再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了； 幻读(Phantom Reads)：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据。 不可重复读 和 幻读 区别是什么？\n不可重复读 的重点是 修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）\n幻读 的重点是 新增/删除：在同一事务中，同样的条件，第一次和第二次读出来的 记录数不一样。（因为中间有其他事务提交了插入/删除）\n事务的隔离级别 读未提交(Read UnCommitted)：所有的事务都可以看到其他事务未提交的修改(很少用到业务中)。(脏读：Y，不可重复读：Y，幻读：Y，) 读已提交(Read Committed)：只能看到其他已经提交的事务。(脏读：N，不可重复读：Y，幻读：Y) 可重复读(Reapeatable Read)：确保同一个事务在并发读取时数据一致(MySQL 默认的事务级别)。(脏读：N，不可重复读：N，幻读：Y) 可串行化(Serializable)：串行化读取数据(最高隔离级别，锁竞争激烈)。(脏读：N，不可重复读：N，幻读：N) 不同的数据库支持的隔离级别不同。在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据库中，只支持 Serializable (串行化)级别和 Read committed (读已提交)这两种级别，其中默认的为 Read committed 级别。\nMySQL 中有哪几种锁？ 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 什么是 MVCC？ 多版本并发控制(MultiVersion Concurrency Control) 是一种并发控制的方法，一般用在数据库管理系统中，实现对数据库的并发访问。\n为什么需要 MVCC？ 主要实现对数据的隔离，解决读写之间的阻塞问题，提高读写并发度。\n最原生的锁，锁住一个资源之后禁止其他任何线程访问。但是很多应用的场景都是 读多写少，很多数据的读取次数远远大于修改的次数，而这种读数据的操作之间进行排斥就显得很没必要； 所以出现了 读写锁，读锁与读锁不互斥，而写锁与写锁、写锁与读锁之间互斥，这样已经很大地提升了系统的并发能力。 后来人们发现并发读还是不够，又提出了一种让读写之间也不冲突的方法：快照读。就是读取数据的时候通过一种类似于 “快照” 的方式将第一眼看到的数据保存下来，这样读锁和写锁就不冲突了，不同的事务会看到自己特定版本的数据。当然，“快照”是一种概念模型，不同的数据库实现方式可能不太一样。 所以我们可以看到这样的“提高并发”的演进思路：\n普通锁，串行执行 \u0026ndash;\u0026gt; 读写锁，实现读读并发 \u0026ndash;\u0026gt; MVCC，实现读写并发。\nMVCC 解决了哪些问题？ 读写之间的阻塞问题：可以实现并发读写； 降低了死锁的概率：MySQL 的 InnoDB 的 MVCC 使用了乐观锁，读数据时并不需要加锁；对于写操作，也只锁定必要的行； 解决一致性读的问题：一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。 MVCC 只在 可重复读(REPEATABLE READ) 和 提交读(READ COMMITTED) 两个隔离级别下工作。其他两个隔离级别都和 MVCC 不兼容，因为 未提交读 总是读取最新的数据行，而不是符合当前事务版本的数据行。而 可串行化则会对所有读取的行都加锁。\nMVCC 如何实现的？ Innodb 中使用 B+树 作为索引的数据结构，并且主键所在的索引称为 聚簇索引(ClusterIndex)，聚簇索引的叶子结点保存了完整的一条数据。一张表只能有一个主键，所以也只能有一个聚簇索引，如果没有定义主键，InnoDB 将使用一个隐藏列作为聚簇索引。除了 聚簇索引，还有 二级索引(SecondaryIndex)，它的叶子结点中保存的是主键。\nInnoDB 的叶子段中保存了数据页，数据页中保存了行记录，而在行记录中有三个个重要的隐藏记录：\nDB_ROW_ID(隐藏行 ID)：隐藏的行 ID，用来生成默认的聚簇索引。如果我们创建表时没有指定聚簇索引，那么 InnoDB 会使用这个隐藏 ID来创建聚簇索引。 DB_TRX_ID(行的事务ID)：操作这行数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。新增一个事务时事务ID会增加，DB_TRX_ID 能够表示事务开始的先后顺序。 DB_ROLL_PT(行的回滚指针)：回滚指针，指向这行记录的 Undo Segment 中的 undo log。 MVCC 在 MySQL 中的实现依赖的是 undo log 和 ReadView。\nundo log：\n除了记录 redo log 之外，当进行数据修改时还会记录 undo log。undo log 用于数据的撤回操作，它记录修改的反向操作，比如插入对应删除，修改对应修改为原来的数据。undo log 分为两种：Insert 和 Update，Delete 可以看做是一种特殊的 Update，即在记录上修改删除标记。而 Insert undo log 在事务提交之后可以删除，因为用不到。所以我们可以理解为：update undo log记录了数据之前的数据信息，通过这些信息可以还原到之前版本的状态。\nReadView：\n也称为 一致性读视图。它并不实际存在，只是一个概念，通过 undo log 和版本计算出来，用以决定当前事务能看到哪些数据。\n对于 READ UNCOMMITTED 隔离级别，所有事务直接读取数据库的最新值即可；SERIALIZABLE 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 ReadView 的版本控制。\n所以我们才说 MVCC 只支持 Read Committed 以及 Repeated Read 隔离级别的实现，而核心逻辑就是依赖 undo log 以及版本控制。针对这个问题 InnoDB 在设计上增加了ReadView 的设计，ReadView 中主要包含当前聚簇索引对应的、当前系统中还有哪些活跃的读写事务，把它们的 事务ID 放到一个列表中，我们把这个列表命名为为 m_ids。对于查询时版本数据能否被看到的判断依据是：\n如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问； 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问； 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 先说结论：Read Committed 和 Repeatable Read 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同：\n在 Read Committed 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态； 在 Repeatable Read 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证 可重复读(Repeatale Read)。 腾讯面试：MySQL事务与MVCC如何实现的隔离级别？ 中有一个例子特别好，以截图方式展示：\nRead Committed 下的 ReadView：\nRepeatable Read 下的 ReadView：\nMySQL 中哪些存储引擎支持事务？ MySQL 服务器层不管理事务，事务是由下层的存储引擎实现的。支持事务的存储引擎有InnoDB 和 NDB Cluster。\n什么是自动提交？ MySQL 默认使用 InnoDB 引擎，并且默认采用 自动提交(AUTOCOMMITTED) 模式。也就是说，如果不是显式地开启一个事务，则每一个查询都被当成一个事务执行提交操作。\nMySQL 支持的存储引擎 我们主要关注三个：InnoDB、MyISAM 和 Memory。\nInnoDB MySQL 的默认事务型引擎，支持事务和外键。在你增删改查时匹配的条件字段带有索引时，InnoDB 使用 行级锁；在你增删改查时匹配的条件字段不带有索引时。InnoDB 使用的将是 表级锁。\nMyISAM 旧版本MySQL 的默认存储引擎。主要特点是快，不支持事务，也不支持外键。\nMemory 使用内存空间来创建表。Memory 类型的表访问非常快，因为它的数据是放在内存中的，并且默认使用 Hash 索引，但是一旦服务关闭，表中的数据就会丢失掉。\n关于索引 按照数据结构分：哈希索引、B+树索引 和 全文索引。\n按物理存储方式分：聚簇索引 和 二级索引。\nInnoDB到底支不支持哈希索引？\nInnoDB 用户无法手动创建哈希索引，这一层上说，InnoDB 确实不支持哈希索引; InnoDB 会 自调优(self-tuning)，如果判定建立 自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB 自己会建立相关哈希索引，这一层上说，InnoDB 又是支持哈希索引的。 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 B+树索引 所有的数据都在叶子节点，非叶子结点只存储叶子结点的索引，且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序的链表，这样就可以实现范围查询。优势：\nB+Tree 它的非叶子节点不存储数据，只存储索引，而数据会存放在叶子节点中。非叶子结点存储的索引越多，叶子结点能表示的数据就越多，同样数量情况下，树的高度越小，查找数据时进行的 IO 次数就越少。 全文索引 只支持英文，实现方式为 倒排索引：先分词，再建立对应的B+树索引。\nInnoDB 中的索引策略 覆盖索引 最左前缀原则 索引下推 索引下推优化是 MySQL 5.6 引入的，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 InnoDB 中创建索引有什么原则 最左前缀匹配原则 频繁作为查询条件的字段才去创建索引 频繁更新的字段不适合创建索引 索引列不能参与计算，不能有函数操作 优先考虑扩展索引，而不是新建索引，避免不必要的索引 在order by或者group by子句中，创建索引需要注意顺序 区分度低的数据列不适合做索引列(如性别） 定义有外键的数据列一定要建立索引。 对于定义为text、image数据类型的列不要建立索引。 删除不再使用或者很少使用的索引 MySQL 分库分表 分库分表方案 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。 分库分表可能遇到的问题 事务问题：需要用分布式事务啦 跨节点Join的问题：解决这一问题可以分两次查询实现 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。 数据迁移，容量规划，扩容等问题 ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID 跨分片的排序分页问题（后台加大pagesize处理？） MySQL InnoDB 索引为什么使用 B+树？ 可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？\n为什么不是一般二叉树？ 如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。\n为什么不是平衡二叉树呢？ 我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。\n那为什么不是B树而是B+树呢？ B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。 B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。 ","permalink":"http://localhost:1313/posts/mysql%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch3 id=\"关于事务\"\u003e关于事务\u003c/h3\u003e\n\u003ch4 id=\"事务的特性\"\u003e事务的特性\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e原子性(Atomic, A)\u003c/code\u003e：要么全部执行，要么全部不执行；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e一致性(Consistent, C)\u003c/code\u003e：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e隔离性(Isolation, I)\u003c/code\u003e：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e持久性(Durability, D)\u003c/code\u003e：事务提交后，其结果永久保存在数据库中。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e事务ACID特性的实现思想\u003c/p\u003e","title":"MySQL面试汇总"},{"content":"当我们谈论 Redis 时，应该谈论什么？ Redis 基本数据类型有哪些？以及他们各自的使用场景是什么？ 常见的有五种：字符串、哈希、列表、集合、有序集合。5.0 版本中新添加了 Stream 类型。\n字符串 String: 就是常规的 GET/SET 操作。是 Redis 最基本的数据类型，一个键最大能存储 512MB(底层数据结构：SDS)； 哈希 Hash：可以理解成一个键值对的集合，十分适合存储结构化数据。比如 MySQL 中有一条记录：id=1, name=demo, age=18，那么可以使用 hash 将其存到 Redis 中：HSET user:1 name demo age 18(数据结构：ZipList 或 HashTable)； 列表 List：就是简单的字符串列表，按照插入顺序排序。比较常见的场景是当做队列或者栈使用(数据结构：QuickList，是 ZipList 和 双向链表 的组合)。 集合 Set：存放的是一堆不重复值的集合，通常用来做去重，同时还提供了不同 Set 之间求交集、并集、合集等功能，业务上也能使用的到。它底层也是通过哈希表去实现的，可以做到增删改查都是 O(1) 的复杂度(数据结构：HashTable)。 有序集合 Sorted Set：跟 Set 一样，也是一堆不重复值的集合，不同的是每一个元素都会关联一个 float64 类型的分数，而 Redis 正是基于这个分数为集合中的成员进行排序的。比较常见的使用场景是存排行榜数据，去 Top N 会非常方便(数据结构：跳表SkipList)。 流式数据 Stream：这是 V5.0 版本引入的新的数据类型，用来弥补 Pub/Sub 的不足，工作模式类似于 kafka，可以使用 XADD 往一个 stream 中发送消息，而消费者可以是单个，也可以是消费者集群，并且任意一个消费者消费之后，必须手动调用 XACK 才会完全标志这条消息被处理，特别适合做消息队列。 Redis 使用场景 热数据存储：当成缓存中间件来使用，以缓解 DB 的压力。 做消息队列：我们可以使用它的 List 或 Stream 或 Pub/Sub 来实现一个消息队列，完成业务逻辑上的数据解耦； 排行榜：利用 Redis Sorted Set 实现； 限流器：利用单线程、原子递增等特性，可以记录某个用户在某段时间内的访问量，结合业务逻辑做到限流效果； 分布式锁：setnx 命令，设置成功表示拿到锁，不成功表示没拿到锁。 Redis 是单线程还是多线程？为什么这么快？ 4.0 以前，不管是主业务逻辑还是持久化，都是单线程； 4.0 版本，引入了多线程处理 AOF 等不太核心的操作，但主 Reactor 模型依旧使用单线程。主要是体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等; 6.0 版本，主 Reactor 真正引入多线程处理用户逻辑。 既然是单线程，为什么还这么快？\n官方的 QA 里说过，Redis 是基于内存的操作，CPU 并不是 Redis 的瓶颈，最大的瓶颈可能来自于机器内存大小以及网络带宽。快的原因：\n基于内存操作，并且有许多非常优秀的的数据结构为数据存储和处理做支撑； 单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能损失； 基于 I/O 多路复用 实现了自己类似于 Reactor 模型的事件库，大大提高网络处理能力。 Redis 是如何实现分布式锁的？ 主要利用 Redis 的 SETNX 命令实现：SETNX k v，当 k 不存在时，k v 设置成功并返回成功，表示拿到锁；k 已经存在则返回失败，加锁失败。操作结束后，可以使用 del k 删除，表示释放锁；也可以在加锁的同时，给这个锁一个过期时间，避免锁没有被显式释放而造成永久锁住。\n但上述方式也存在一些问题：\nSETNX 和 EXPIRE 并不是原子性操作，如果我 SET 之后因为网络原因没有 EXPIRE，锁因为没有设置超时时间而永远无法释放。很多开源的解决方案是 通过 lua 脚本同时设置过期时间，也可以 使用原生的 SET 命令，加上 nx 选项以及对应的过期时间，都可以解决没有 没有expire造成的锁不释放 问题。 使用了 expire，但有可能出现新的问题：就是加锁的一方的执行时间超过了 expire，此时锁自动过期释放，另一个线程获得锁，此时两个线程并发运行，就会出问题，而且如果当前线程处理完后调用 expire 也会将另一个线程的锁解除；而且这个锁也不是可重入锁。 针对这个问题，Redis 作者提出了在基于分布式环境下提出了更高级的分布式锁的实现：RedLock。(不过也并不是完美的，而且实际使用时也不会给你 5 个独立的 redis master)\n结论：Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。\n缓存雪崩、缓存穿透、缓存击穿等问题 缓存雪崩 现象：大量的热 key 设置了相同的过期时间，在该时刻这些热 key 全部失效，所有的请求铺天盖地都打到了 DB。\n解决方案：不要设置相同的过期时间，可以在一个 baseDuration 上加减一个随机数。\n缓存穿透 现象：一般的逻辑都是在 redis 中找不到，就会去 DB 查，然后将结果缓存到 Redis。但是如果某些 Key 在 DB 中也不存在(如小于 0 的用户 ID)，这类 Key 每次都会进行两次无用的查询。\n解决方案：\n加强非法参数的逻辑校验，提前返回失败； 将不存在的 Key 也缓存下来； 使用布隆过滤器，可以帮助识别：哪些数据一定不存在和可能存在，提前过滤一定不存在的数据。 缓存击穿 现象：某一个热点 key 扛着非常大的并发，某一时刻这个热点 key 失效，所有请求全部打到 DB 上，像是在墙上穿了一个洞。\n解决方案：1. 设置这个热点 key 永不过期；2. 如果非要更新，那么在这个热点 key 为空的时候，设置一个锁(比如 SETNX)，只让一个请求去数据库拉取数据，取完之后释放锁，恢复正常缓存逻辑。\nRedis 持久化方式以及实现细节 Redis 是在内存中处理数据的，但断电后内存数据会消失，因此需要将内存数据通过某种方式存储到磁盘上，以便服务器重启后能够恢复原有数据，这就是 Redis 的持久化。有三种方式：\nAOF日志(Append Only File)：文件追加方式，并且以文本的形式追加到文件中； RDB快照(Redis DataBase)：将某一时刻的内存数据，以二进制的形式全部存到磁盘中； 混合持久方式：v4.0 增加了混合持久化方式，集成了 RDB 和 AOF 的优点。 AOF AOF 采用的是写后日志的方式，现将数据写入内存，再记录到日志文件中。AOF 记录的是实际的操作命令和数据，即我们在终端输入的命令。等到重启恢复时，只需要将 AOF 文件中的命令重复执行一遍(涉及到 AOF 重写)。\n命令同步到 AOF 需要经历三个阶段：\n命令追加：Redis 将执行完的命令、命令的参数等信息“传播” AOF 程序中： 缓存追加：AOF 程序根据接收到的命令数据，将命令编码为自己的网络通信协议，然后将内容追加到服务器的 AOF 缓存中(redisServer 中有一个字段叫 sds aof_buf)； 文件写入和保存：缓存数据到一定条件，在事件处理器之后，会调 flushAppendOnlyFile 函数，这个函数会执行两个操作： WRITE：将 aof_buf 中的数据缓存写入 AOF 文件中； SAVE：调用 fsync 或者 fdataasync函数，将AOF 文件保存到磁盘中； 而 AOF 的文件保存模式有三种：\n不保存：WRITE 会被执行，SAVE 只会在服务关闭等常见会被执行一次，平常会被略过。这个时候，这两个操作都是由主线程来完成的，会阻塞主线程； 每秒保存一次：WRITE 每次都被执行，SAVE 启动子线程每秒执行一次。WRITE 操作由主进程执行，阻塞主进程；SAVE 操作由子线程执行，不直接阻塞主进程，但 SAVE 完成的快慢会影响 WRITE 的阻塞时长。 每执行一个命令保存一次：每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。这两个动作都由主线程执行，会阻塞主线程。 文件重写(bgrewriteaof):\n当开启的AOF时，随着时间推移，AOF文件会越来越大,当然redis也对AOF文件进行了优化，即触发AOF文件重写条件（后续会说明）时候，redis将使用bgrewriteaof对AOF文件进行重写。这样的好处在于减少AOF文件大小，同时有利于数据的恢复。常见的重写策略：\n重复或无效的命令不写入文件； 过期的数据不再写入文件； 多条命令合并写入。 RDB 按照指定时间间隔对你的数据集生成的时间点快照。它是 Redis 数据库中数据的内存快照，它是一个二进制文件（默认名称为：dump.rdb，可修改），存储了文件生成时 Redis 数据库中所有的数据内容。在 Redis Server 重启时可以通过加载 RDB 文件来还原数据库状态。 可用于 Redis 的数据备份、转移与恢复。\nrdbSave 负责将内存中的数据以 RDB 的格式保存到磁盘中，如果 RDB 文件已经存在，那么旧的文件会被新的文件替换。\n而 SAVE 和 BGSAVE 都会调用 rdbSave 函数，但他们的执行方式不同：\nSAVE 直接调用 rdbSave，阻塞 Redis 主进程，直到保存完为止。在主进程阻塞期间，服务器不能处理任何客户端请求； BGSAVE 则会 folk 出一个子进程，子进程调用 rdbSave，并在结束后向主进程发送信号通知。因为 rdbSave 是在子进程运行的，所以并不会阻塞主进程，在此期间服务器仍旧可以继续处理客户端的请求。 其他需要注意的：\n为了避免产生竞争条件， BGSAVE 执行时， SAVE 命令不能执行。 调用 rdbLoad 函数载入 RDB 文件时，不能进行任何和数据库相关的操作，不过订阅与发布方面的命令可以正常执行，因为它们和数据库不相关联。 AOF 文件的保存频率通常要高于 RDB 文件保存的频率， 所以一般来说， AOF 文件中的数据会比 RDB 文件中的数据要新。因此， 如果服务器在启动时， 打开了 AOF 功能， 那么程序优先使用 AOF 文件来还原数据。 只有在 AOF 功能未打开的情况下，Redis 才会使用 RDB 文件来还原数据。 混合持久化 混合持久化就是 同时结合 RDB 持久化以及 AOF 持久化混合写入 AOF文件。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据，缺点是 AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性差，并且 4.0 之前的版本并不识别；\n混合持久化同样也是通过 bgrewriteaof 完成的，不同的是当开启混合持久化时，fork 出的子进程先将共享的内存副本全量的以 RDB 方式写入 AOF文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有 RDB 格式和 AOF 格式的 AOF文件 替换旧的的 AOF文件。\n总结 RDB 优点：\n是一个非常紧凑的问题，特别适合文件备份以及灾难恢复； 节省性能。开启子进程不影响主进程功能。 RDB 缺点：\nRDB 是某一时刻的快照，无法保存全部数据，在请求较大时，丢失的数据会更多。 AOF 优点：\n数据更完整，秒级数据丢失(取决于设置fsync策略)； 文件内容可读性高，方便 debug。 AOF 缺点：\n文件体积更大，且恢复速度慢于 RDB。 Redis 如何实现高可用 Redis 实现高可用主要有三种方式：主从复制、哨兵模式，以及 Redis 集群。\n主从复制 在 主从复制 中，Redis server 分为两类：主库 master 和 从库 slave。主库可以进行读写操作，当写操作导致数据变化时会自动同步到从库。而从库一般是只读的，并接受来自主库的数据，一个主库可拥有多个从库，而一个从库只能有一个主库。\n哨兵模式 哨兵(sentinel) 是官方推荐的的 高可用(HA) 解决方案。Redis 的主从高可用解决方案，这种方案的缺点在于当 master 故障时候，需要手动进行故障恢复，而 sentinel 是一个独立运行的进程，它能监控一个或多个主从集群，并能在 master 故障时候自动进行故障转移，更为理想的是 sentinel 本身是一个分布式系统，其分布式设计思想有点类似于 zookeeper，当某个时候 Master 故障后，sentinel集群 采用一致性算法来选取Leader，故障转移由 Leader 完成。而对于客户端来说，操作 Redis 的主节点，我们只需要询问 sentinel，sentinel 返回当前可用的 master，这样一来客户端不需要关注的切换而引发的客户端配置变更。\nRedis 集群 从最开始的 一主N从，到 读写分离，再到 Sentinel 哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。为什么还需要 Redis 集群？这是因为某些场景下，单实例会存在一下几个问题：\n写并发：读操作可以通过负载均衡由诸多从节点分担，但所有的写操作只能由主节点完成，在海量数据高并发场景下，主节点压力也会飙升； 海量数据的存储压力：单实例本质上是只有一台主节点作为存储，其他从结点都是复制主节点的数据，也就是说，Redis 服务的存储能力取决于主节点所能承载的上线。 为了扩展写能力和存储能力，Redis引入集群模式。\nRedis3.0 加入了 集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的 master 节点上面，从而解决了海量数据的存储问题。\n同时 Redis集群 采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。\nRedis 也内置了高可用机制，支持 N 个 master节点 ，每个 master节点 都可以挂载多个slave节点，当 master节点 挂掉时，集群会提升它的某个slave节点 作为新的master节点。\nRedis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点(其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用)。\n问：集群中那么多 master节点，集群在存储的时候如何确定选择哪个节点呢？\n采用 类一致性哈希算法 实现节点选择。\n首先，集群将自己分成 16384 个 slot(槽位)，然后让每个节点分别负责一部分槽位(范围固定)。当某个 key 到来时，某个集群的 master 会先计算这个 key 应该被分配到哪个槽位(CRC16后的哈希值与 16384 取模的结果就是应该放入的槽位号)，如果这个槽位刚好是自己负责，那么开始处理并返回；如果不属于当前节点负责的范围，那么会返回一个 moved error，并告诉你应该去哪个节点指定这个写入命令。\n问：那集群如何实现扩容？\n通过 reshard(重新分片)来实现。它可以将已经分配给某个节点的任意数量的 slot 迁移给另一个节点，同时将对应 slot 的数据也全部迁移值新的节点。\nRedis 的过期策略以及内存淘汰机制 过期策略 定期随机检测删除：Redis 默认每隔 xxx ms就随机抽取设置了过期时间的 key，检测这些 key 是否过期，如果过期就删除。\n惰性删除：不再是 Redis主动去删除，而是在客户端获取某个 key 时，先检查是否过期，没过期则正常返回，如果过期则删除并且返回 nil。\n内存淘汰机制 惰性删除可以解决一些过期了，但没被定期删除随机抽取到的 key。但有些过期的 key 既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以 Redis 提供了内存淘汰机制来解决这个问题。\nRedis 在使用内存达到某个阈值(通过 maxmemory 配置)的时候，就会触发内存淘汰机制，选取一些 key 来删除。当内存不足以容纳新写入的数据时，内存淘汰有以下几种策略：\nnoeviction：报错。默认策略。 allkeys-lru：在所有的 key 中，删除最近最少使用的 key； allkeys-random：在所有的 key 中，随机移除某个 key； volatile-lru：在所有设置了过期时间的 key中，删除最近最少使用的 key； volatile-random：在所有设置了过期时间的 key中，随机移除某个 key； volatile-ttl：在所有设置了过期时间的 key中，有更早过期时间的 key 优先移除。 Redis 中 大key 和 热key 问题 大Key 问题 现象：\n什么是大 Key：\n单个简单的 key 存储的 value 很大：会导致网络拥塞，内存使用不均(集群模式下)； hash、set、zset 以及 list 结构中存储过多的元素：单个命令耗时太长容易阻塞其他命令，严重会引起集群发生故障切换，循环故障从而整个集群宕机。 如何发现：\nRedis 监控对超多 xxx 的 kv 报警； 定时脚本不断去 scan 拿到结果进而报警然后处理优化； 利用 redis-cli --bigkeys 命令行工具分析； 使用 redis-rdb-tools 工具对 RDB 文件进行分析 如何解决：\n删除：4.0 以后有 lazy delete，不会阻塞主线程。但这只是临时方案； hash： 使用 hscan + hdel set ： 使用 sscan + srem zset ： 使用 zremrangebyrank list ： 使用 scan + ltrim 拆分，然后使用 multiGet 获取; 热Key 问题 现象：\n突然有非常大的请求去访问 Redis 上的某个特定的key，流量过于集中，甚至达到物理网卡的上限，导致这台 Redis 服务器宕机。此时，这台Redis上的其他读写请求都变得不可用；热 key 会落到同一个 Redis 实例上，无法通过扩容解决；所有的请求都打在 DB 上，Redis 都扛不住，DB 大概率会挂掉。\n如何发现：\n业务经验预估 对用户行为数据分析，如点击、加购行为都会有打点数据 如果是集群，可以利用集群 proxy 统计分析 Redis v4.3 的 redis-cli 有一个 --hotkeys 选项，可以在命令行直接获取当前 namespace 中的热点 key(实现上是通过 scan + object freq 完成的)。 利用 redis-cli monitor 抓取数据，利用现有开源工具如 redis-faina 进行分析，统计出热 key。 怎么解决：\n增加 Redis 副本数量，将读请求的压力分配到不同的副本节点上； 业务上缓存(本地缓存)：比如使用一个大小限定的 map，每次去 Redis 查询前先检查内存中是否存在，如果存在就直接返回了。 集群条件下热key 备份：在集群条件下，一个 key 会被放入指定的实例的 slot，增加集群的节点数是没有用的。为了将针对某一个 key 的请求打散到不同的实例上，可以给对应的 key 增加前缀或者后缀，这样就可以实现将热key的流量让整个集群来分担，而不是某个节点。不过整个方案需要进行一定的业务开发，比如 key 前后缀的生成方式。 Redis 通信协议简单介绍 简称 RESP(Redis Serilization Protocol)，是 Redis 自定义的用于服务端和客户端之间的通信协议。特点是：实现简单、可读性强、快速解析。\n间隔符号，在 类Unix 下是 \\r\\n，在 Windows 是 \\n。\n+：简单字符串：\u0026quot;+OK\\r\\n\u0026quot; -：错误信息：\u0026quot;-Error unknow command 'foobar'\\r\\n\u0026quot; :：整数：\u0026quot;:1000\\r\\n\u0026quot; $：批量字符串：\u0026quot;$6\\r\\nfoobar\\r\\n\u0026quot;，前面的数组表示字符串长度 *：数组：\u0026quot;\\*2\\\\r\\\\n$2\\\\r\\\\nfoo\\\\r\\\\n$3\\\\r\\\\nbar\\\\r\\\\n\u0026quot;，数组包含2个元素，分别是字符串foo和bar。 ","permalink":"http://localhost:1313/posts/redis-%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch2 id=\"当我们谈论-redis-时应该谈论什么\"\u003e当我们谈论 Redis 时，应该谈论什么？\u003c/h2\u003e\n\u003ch3 id=\"redis-基本数据类型有哪些以及他们各自的使用场景是什么\"\u003eRedis 基本数据类型有哪些？以及他们各自的使用场景是什么？\u003c/h3\u003e\n\u003cp\u003e常见的有五种：\u003ccode\u003e字符串\u003c/code\u003e、\u003ccode\u003e哈希\u003c/code\u003e、\u003ccode\u003e列表\u003c/code\u003e、\u003ccode\u003e集合\u003c/code\u003e、\u003ccode\u003e有序集合\u003c/code\u003e。\u003ccode\u003e5.0\u003c/code\u003e 版本中新添加了 \u003ccode\u003eStream\u003c/code\u003e 类型。\u003c/p\u003e","title":"Redis 面试汇总"},{"content":"一、原理 0. 简介 channel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 容量capacity。\n在 runtime 中是通过 hchan 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\ntype hchan struct { qcount uint // 环形队列中已经有的元素个数 dataqsiz uint // 环形队列容量，就是用户创建时指定的 capacity buf unsafe.Pointer // 环形队列所在的地址 elemsize uint16 // channal 中元素类型的大小 closed uint32 // channel 是否关闭 elemtype *_type // channel 元素类型 sendx uint // 环形队列中已经发送的 index recvx uint // 环形队列中已经接受的 index recvq waitq // 等待接受 channel 中消息的 goroutine 队列 sendq waitq // 等待向 channel 中发送消息的 goroutine 队列 lock mutex } 1. 用法以及常见问题汇总 已经关闭的 channel，再次关闭会 panic 向已经关闭的 channel 发送数据会造成 panic 如果从 channel 中取出元素的方式是 for-range，则在 channel 关闭时会自动退出循环 func main() { ch := make(chan int, 10) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } // 注意这里的 close，如果没有，将会出现死锁 panic close(ch) }() for j := range ch { fmt.Println(j) } } close 一个 channel 时，如果还有 sender goroutine 挂在 channel 的发送队列中，则会引起 panic。首先 close 会唤醒所有在此 channel 等待队列中的 goroutine，使其状态变为 Grunable，再看下文 3 中的 sendchan 源码就知道，当 goroutine 被唤醒之后，还会去检查 channel 是否已经被关闭，如果被关闭则会 panic。\n从已经 close 的 channel 中取值(说明已经正常关闭，channel 是空的)，会返回 channel 元素的零值。区分零值还是真实值，可以使用 comma, ok 的语法：\nx, ok := \u0026lt;- ch if !ok{ // channel 已经被关闭 // ..... } If the receiving goroutine queue of the channel is not empty, in which case the value buffer of the channel must be empty, all the goroutines in the receiving goroutine queue of the channel will be unshifted one by one, each of them will receive a zero value of the element type of the channel and be resumed to running state.\n没有通过 make 来初始化的 channel 被称为 nil channel，关闭一个 nil channel 会直接 panic 2. 创建 channel // 初始化 channel func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // 如果 hchan 中的元素不包含指针，那么也就不需要 GC var c *hchan switch { case mem == 0: /* channel 中缓冲区大小是 0(ch := make(chan int, 0)) 或者 元素类型的大小是 0(ch := make(chan struct{})) 此时所需的空间只有 hchan 这一个元素的 */ // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: /* channel 中元素的类型不是指针。 此时所需要的空间除了 hchan 的，还有对应元素的：uintptr(size)*elem.size + hchanSize 因为不是指针，GC 也不会对channel中的元素进行 scan */ // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: /* channel 中的元素包含指针。 注意，这里进行了两次空间分配，一次是给 hchan，第二次是给 channel 中的元素 */ // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } 3. 向 channel 发送 // select {case \u0026lt;-xxx} 的入口 func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } // entry point for c \u0026lt;- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } // 向一个 channel 发送数据的具体实现 // c 就是 channel 实体，ep 表示要发送的数据，block 表示是否阻塞(正常业务逻辑中是 true，如果是 select 则是 false) func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { /* 应用层的 channel 是空的，如 var ch chan int ch \u0026lt;- 1 如果非阻塞，则直接返回； 如果阻塞，也就是向一个 nil channel 发送数据，那么将永久阻塞下去 需要注意的是，空的channel 和 已经关闭的channel是不同的。向空 channel 发送将永久阻塞，向 closed channel 发送将 panic。 */ if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 数据竞争相关的检测，后面专门说明 if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread\u0026#39;s view of c.closed and full(). /* 这里的 FastPath 其实是对 非阻塞channel(select) 操作判断的一种优化：已经要求不要在 channel 上发生阻塞， 那么这里迅速做一个判断，“能失败则立刻失败”——如果 非阻塞 \u0026amp;\u0026amp; 未关闭 \u0026amp;\u0026amp; 已经满了，那就不往后面走了。 // 检查 channel 是否已经满了 func full(c *hchan) bool { // 无缓冲的 channel if c.dataqsiz == 0 { // 如果等待队列中有 goroutine 等待，那么就返回 channel 未满，可以进行后续的处理 return c.recvq.first == nil } // 有缓冲的 channel，看环形链表中的元素数量是否已经到达容量 return c.qcount == c.dataqsiz } 如何理解这个 full？ 答：For a zero-capacity (unbuffered) channel, it is always in both full and empty status. */ if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 向一个已经关闭的 channel 发送数据，会造成 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). /* 这里也是一个 FastPath： 通常情况下往一个 channel 中发送数据，会先将数据复制到环形链表中，然后 等待接受的 goroutine 来取，再讲数据从唤醒链表中拷贝到 goroutine 中。 但是考虑一种情况，等待接收的 goroutine 早就在等了(等待队列不为空)， 这个时候发送过来一个数据，就没必要再先放进 buffer、再拷贝给等待 goroutine 了， 直接将数据从发送 goroutine 的栈拷贝到接受者 goroutine 的栈中，节省资源。 */ send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. /* 如果是有缓冲的 channel 并且 buffer 中空间足够，那么就将数据拷贝到 buffer 中。 同时更新 */ qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将数据从发送 goroutine 拷贝到 buffer 中 typedmemmove(c.elemtype, qp, ep) // 发送 index++ c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } // buffer 中 已有元素数量++ c.qcount++ unlock(\u0026amp;c.lock) return true } // 如果是非阻塞的 channel(select)，发送的工作已经走完了，可以返回了，后面的都是阻塞 channel 要做的事 if !block { unlock(\u0026amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. // 在 channel 上阻塞，receiver 会帮我们完成后续的工作 // 将当前的发送 goroutine 打包成一个 sudog 结构 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 将打包好的 sudog 入队到 channel 的 sendq(发送队列)中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 将这个发送 g 的状态改变：Grunning -\u0026gt; Gwaiting，之后进入休眠 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren\u0026#39;t considered as roots of the // stack tracer. KeepAlive(ep) // 后面的是当前 goroutine 被唤醒后的逻辑 // 醒来后检查一下状态，才会返回成功 // someone woke us up. if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 醒来后发现 channel 已经被关闭了，直接 panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } 4. 从 channel 中接收 func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } // entry points for \u0026lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller\u0026#39;s stack. // 从 hchan 中接收数据，并将数据拷贝到 ep 对应的空间中。ep 可以是 nil，这种情况下数据会被丢弃； // 如果 ep 不为 nil，那么必须指向 堆 或者 调用者g的栈地址 // 这里的返回值 selected 表示是否被 select 到，received 表示是否成功接收到数据 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 从一个阻塞的 nil channel 中接收数据，则会永久阻塞 if c == nil { if !block { return } // 这种情况其实就是 goroutine 泄露 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // FastPath: 如果不阻塞并且没有内容可接收，直接返回 false false if !block \u0026amp;\u0026amp; empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026#34;open and empty\u0026#34;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026amp;c.closed) == 0 { // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. // 走到这里，说明 channel 是非阻塞的，并且已经关闭了，而且 channel 中没有数据留下，此时会返回对应值的零值 if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 当前 channel 中没有数据可读，直接返回 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { // 将 ep 设置成对应元素的零值 typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). /* 这里也是一个 FastPath：如果我们去接收的时候，发现 buffer 是空的，但是 发送等待队列不为空，那么直接从这个等待的 goroutine 中拷贝数据。 如果 buffer 不为空，那么需要先从 buffer 中拿，然后将等待队列中的元素再放到 buffer 中 */ recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } if c.qcount \u0026gt; 0 { // Receive directly from queue // 如果 buffer 中有数据可取，直接从 buffer 中拿 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 将 buffer 中的数据拷贝到目标地址 if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 清空 buffer 中取出的元素的内容 typedmemclr(c.elemtype, qp) // 接收 index++ c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // buffer 中 总数-- c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 如果非阻塞，返回 false if !block { unlock(\u0026amp;c.lock) return false, false } // no sender available: block on this channel. // 如果是阻塞的 channel，那么接收的 goroutine 将阻塞在这里 // 将等待的 goroutine 打包成 sudog，并将其放到等待队列中，之后休眠 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // 被唤醒 // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 如果 channel 没有被关闭，那就是真的 receive 到数据了 return true, success } 5. 关闭 channel func closechan(c *hchan) { // close 一个 nil channel 将 panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) // close 一个已经 closed 的 channel，将 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } // 明确关闭 channel c.closed = 1 var glist gList // release all readers /* 将所有的接收等待队列中的 goroutine 全部弹出， 每一个 goroutine 将会收到 channel 中元素类型的零值， 并且恢复到 Grunning 状态 */ for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { // 这一步设置零值 typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) /* 将所有发送队列中的 goroutine 全部弹出，并恢复到 Grunning 状态。 恢复到后将继续进行“往 channel buffer 中发送数据”操作 但这个方法中已经将 closed 设置成 1，恢复运行后会检查，如果已经 closed，则会直接 panic */ for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 二、使用 如何正确关闭 channel 不同的场景介绍几种建议方案，尤其是生产-消费模型相关的。\n1. M receivers, one sender, the sender says \u0026ldquo;no more sends\u0026rdquo; by closing the data channel 一个生产者、多个消费者，由 producer 来关闭 channel，通知数据已经发送完毕。\nfunc main(){ consumerCnt := 10 // 这里可以是缓冲的，也可以是非缓冲的 taskChan := make(chan int, consumerCnt) wg := \u0026amp;sync.WaitGroup{} go func() { for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for data := range taskChan { fmt.Printf(\u0026#34;consumer %d received: %d\\n\u0026#34;, idx, data) } }(i) } }() for i := 0; i \u0026lt; consumerCnt * 2; i++ { taskChan \u0026lt;- i } close(taskChan) wg.Wait() } 2. One receiver, N senders, the only receiver says \u0026ldquo;please stop sending more\u0026rdquo; by closing an additional signal channel 一个 consumer、多个 producer 场景，多添加一个用于 通知 的 channel，由其中一个消费者告诉生产者“已经够了，不要再发了”。\nfunc main(){ rand.Seed(time.Now().UnixNano()) producerCnt := 10 taskChan := make(chan int) wg := \u0026amp;sync.WaitGroup{} // 用于信号通知 stopChan := make(chan struct{}) // 多个 producer 一直在生产消息，直到收到停止的信号 for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { // 这是一个 try-receive 操作，尝试能否快速退出 select { case \u0026lt;-stopChan: return default: } // 即使上面刚进行了判断没有退出，但到这一步的过程中 stopChan 可能就有数据 或者 被close了 select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- rand.Intn(1000): } } }(i) } // 一个消费者 wg.Add(1) go func() { defer wg.Done() for value := range taskChan { // 在这里确定要退出的逻辑 if value%7 == 0 { fmt.Println(value) fmt.Printf(\u0026#34;%d is times of 7, bye \\n\u0026#34;, value) // 在这里使用 close(stopChan) 和 stopChan \u0026lt;- struct{}{} 都能达到同样的效果 close(stopChan) // stopChan \u0026lt;- struct{}{} return } fmt.Println(value) } }() wg.Wait() } 3. M receivers, N senders, any one of them says \u0026ldquo;let\u0026rsquo;s end the game\u0026rdquo; by notifying a moderator to close an additional signal channel 多个 producer、多个 consumer 的场景下，当其中任何一个发生异常时，全部退出。这种场景下，不能让任何一个 producer 或者 consumer 来关闭 taskChan，也不能让任何一个 consumer 来关闭 stopChan 进而通知所有的 goroutine 退出。这个时候，我们可以再添加一个类似于主持人角色的 channel，让它来做 close stopChan 这个操作。\nfunc main(){ rand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int, consumerCnt) stopChan := make(chan struct{}) // 这里必须使用有缓冲的 buffer，主要是为了避免 moderator 还没启动时就已经有一个 toStop 消息到达导致它没收到 toStop := make(chan string, 1) var stoppedBy string // moderator go func() { stoppedBy = \u0026lt;-toStop close(stopChan) }() // producer for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { value := rand.Intn(10000) if value == 0 { // 达到退出的条件 /* 注意这里的用法，直接换成 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) 是否可行？ 答案是不行，会造成死锁。 */ select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx): default: } return } // 剩下的逻辑和前一个 demo 一样 select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- value: } } }(i) } wg := \u0026amp;sync.WaitGroup{} // consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case value := \u0026lt;-taskChan: // 达到 consumer 的退出条件 if value%7 == 0 { select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, value): default: } return } fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;exit by\u0026#34;, stoppedBy) } 注意当 producer 或者 consumer 达到退出的条件时，往 toStop channel 发送数据的方式。因为 toStop 的容量只有 1，直接使用 toStop \u0026lt;- fmt.Sprintf(\u0026quot;consumer-%d\u0026quot;, value) ，当 toStop 满了塞不下了，那么所有的往里面塞的 goroutine 都将被阻塞挂起，而这些 goroutine 还在等 stopChan 通知退出，而 moderator 的实现里，只接收一个，这就造成了死锁。所以正确做法是，通过 select 尝试往 toStop 中发送，成功还好，不成功(说明已经有其他的 goroutine 通知了)直接 return。\n也可以不使用“通过 select 尝试发送”的方式，那就是让 toStop 的容量变成容纳所有可能发送的 goroutine 的数量，这个时候就可以放心直接往 toStop 里灌数据了：\n// ... toStop := make(chan string, producerCnt + consumerCnt) // ... // producer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) // ... // consumer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, idx) 4. A variant of the \u0026ldquo;N sender\u0026rdquo; situation: the data channel must be closed to tell receivers that data sending is over 上面三个 demo 中，我们都没有对 tashChan 进行明确的 close，close 操作交给了 GC。但是有些场景下，会要求没数据时一定要关闭 taskChan，然后通知调用consumer明确告知“数据已经发送完了”。但是当有多个 producer 时，直接关闭肯定行不通。再这样的场景下，可以引入一个 middle channel ，producer 的数据不再直接发给 consumer，而是先发给middle channel，这个 middle channel 只有一个 sender，可以做到 close taskChan 了。\nrand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int) middleChan := make(chan int) closing := make(chan string) done := make(chan struct{}) var stoppedBy string stop := func(by string) { select { case closing \u0026lt;- by: \u0026lt;-done case \u0026lt;-done: } } // 多个 producer，将数据发送给 middle channel for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { select { case \u0026lt;-done: return default: } value := rand.Intn(10000) if value%7 == 0 { fmt.Println(value, \u0026#34; will stop\u0026#34;) stop(\u0026#34;producer-\u0026#34; + strconv.Itoa(idx)) return } select { case \u0026lt;-done: return case middleChan \u0026lt;- value: } } }(i) } // middle channel go func() { exit := func(v int, needSend bool) { close(done) if needSend { taskChan \u0026lt;- v } close(taskChan) } for { select { case stoppedBy = \u0026lt;-closing: exit(0, false) return case v := \u0026lt;-middleChan: select { case stoppedBy = \u0026lt;-closing: exit(v, true) return case taskChan \u0026lt;- v: } } } }() wg := \u0026amp;sync.WaitGroup{} // 多个 consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-done: return default: } for value := range taskChan { fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;stopped by\u0026#34;, stoppedBy) ","permalink":"http://localhost:1313/posts/golang-channel%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一原理\"\u003e一、原理\u003c/h2\u003e\n\u003ch3 id=\"0-简介\"\u003e0. 简介\u003c/h3\u003e\n\u003cp\u003echannel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 \u003ccode\u003e容量capacity\u003c/code\u003e。\u003cbr /\u003e\n在 \u003ccode\u003eruntime\u003c/code\u003e 中是通过 \u003ccode\u003ehchan\u003c/code\u003e 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\u003cbr /\u003e\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\u003cbr /\u003e\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\u003c/p\u003e","title":"Golang Channel详解"},{"content":" Redis 设计与实现\u0026ndash;事件 中有很清晰的说明。\nredis 要处理的事件有两种类型：\n文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发； 时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。 一、时间事件 时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\n每个时间事件主要由三个属性组成：\nwhen ：以毫秒格式的 UNIX 时间戳为单位，记录了应该在什么时间点执行事件处理函数。 timeProc ：事件处理函数。 next 指向下一个时间事件，形成链表。 根据 timeProc 函数的返回值，可以将时间事件划分为两类：\n如果事件处理函数返回 ae.h/AE_NOMORE ，那么这个事件为单次执行事件：该事件会在指定的时间被处理一次，之后该事件就会被删除，不再执行。 如果事件处理函数返回一个非 AE_NOMORE 的整数值，那么这个事件为循环执行事件：该事件会在指定的时间被处理，之后它会按照事件处理函数的返回值，更新事件的 when 属性，让这个事件在之后的某个时间点再次运行，并以这种方式一直更新并运行下去。 这些常规操作主要包括：\n更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 对不合理的数据库进行大小调整。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主节点的话，对附属节点进行定期同步。 如果处于集群模式的话，对集群进行定期同步和连接测试。 二、文件事件 Redis 服务器通过在多个客户端之间进行多路复用， 从而实现高效的命令请求处理： 多个客户端通过套接字连接到 Redis 服务器中， 但只有在套接字可以无阻塞地进行读或者写时， 服务器才会和这些客户端进行交互。\nRedis 将这类因为对套接字进行多路复用而产生的事件称为文件事件（file event）， 文件事件可以分为读事件和写事件两类。\n1. 读\u0026ndash;标志着客户端命令请求的发送状态 当一个新的客户端连接到服务器时， 服务器会给为该客户端绑定读事件， 直到客户端断开连接之后， 这个读事件才会被移除。\n有两种状态：\n等待：客户端只是连接到服务器，并没有发送命令； 就绪：客户端给服务端发送命令请求、并且请求已经到达(相应的套接字可以无阻塞地执行读操作)时，读事件状态更新为“就绪”。 当一个新的客户端连接到服务器\n2. 写\u0026ndash;标志着客户端对命令结果的接受状态 服务器只会在有命令结果要传回给客户端时， 才会为客户端关联写事件， 并且在命令结果传送完毕之后， 客户端和写事件的关联就会被移除。\n也只有两种状态：\n等待：有结果返回，但客户端还未能执行无阻塞写时； 就绪：有结果返回，并且能无阻塞写时。 当客户端向服务器发送命令请求， 并且请求被接受并执行之后， 服务器就需要将保存在缓存内的命令执行结果返回给客户端， 这时服务器就会为客户端关联写事件。\n3.读 和 写的关系 读事件只有在客户端断开和服务器的连接时，才会被移除。这也就是说，当客户端关联写事件的时候，实际上它在同时关联读/写两种事件。因为在同一次文件事件处理器的调用中， 单个客户端只能执行其中一种事件（要么读，要么写，但不能又读又写）， 当出现读事件和写事件同时就绪的情况时，事件处理器优先处理读事件————也就是说， 当服务器有命令结果要返回客户端， 而客户端又有新命令请求进入时， 服务器先处理新命令请求。\n4. 常见的文件事件 为Server端的接口（TCP Socket，Unix Socket，管道）客户端连接的可读事件（在server.c的initServer()函数中） 为各个客户端连接的Socket添加读/写事件（在networking.c中） AOF的管道（Pipe）添加读/写事件（在aof.c中） Cluster集群连接的读/写事件（在cluster.c中） 主从复制连接的读/写事件（在replication.c中） Redis哨兵模式连接的读/写事件（在sentinel.c中） ","permalink":"http://localhost:1313/posts/redis%E4%BA%8C-%E4%BB%80%E4%B9%88%E6%98%AF-redis-%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://redisbook.readthedocs.io/en/latest/internal/ae.html\"\u003eRedis 设计与实现\u0026ndash;事件\u003c/a\u003e 中有很清晰的说明。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eredis 要处理的事件有两种类型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发；\u003c/li\u003e\n\u003cli\u003e时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"一时间事件\"\u003e一、时间事件\u003c/h3\u003e\n\u003cp\u003e时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\u003cbr /\u003e\n每个时间事件主要由三个属性组成：\u003c/p\u003e","title":"Redis(二): 什么是 Redis 中的事件"},{"content":"一、前言 在关注 redis 单线程/多线程 时，有几个重要的时间节点：\nBefore Redis v4.0，真正的单线程； Redis v4.0，引入多线程处理 AOF 等任务，但核心的网络模型中依旧使用单线程； Redis v6.0，正式在网络模型中实现 I/O多线程。 从 Redis v1.0 到 Redis v6.0以前，Redis 的核心网络模型一直都是一个典型的 单Reactor模型，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 单Reactor模型 的所有运作细节，为以后更好地理解新的 Multi-Reactors/Master-Workers 模型做准备。\n注：本文基于 Redis v5.0.0 版本分析。\n二、概览 Reactor 模式本质上指的是使用 I/O多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O) 的模式。传统的 单Reactor 模型中有三种角色：\nReactor：主线程，模型核心，通过事件循环不断处理事件，如果是新的连接事件，则交给 Acceptor，如果是已经连接的 I/O 事件，则交给 Handler； Acceptor：负责 server 和 client 的连接。Reactor 模式一条最重要的原则就是：I/O 操作不能阻塞主线程循环，所以对于阻塞的网络 I/O，一般都是通过 I/O 多路复用实现的，如 Linux 上的epoll，这样可以最大程度地满足“一个线程非阻塞地监听多个 I/O 事件”。当有新的连接到来是，Acceptor 创建一个新的 socket，并将这个 socket添加到 epoll 的监听队列中，指定事件类型(读事件 或 写事件)，指定对应事件发生时的回调函数，这样当此客户端的请求到来时，epoll 会调用设定好的回调函数(可以理解成 Handler)； Handler：真正的业务处理逻辑。已经建立连接的客户端请求到来后，触发 epoll 的读事件，调用 Handler 执行具体的业务逻辑。 Redis v6.0 之前的网络模型就是一个典型的 单Reactor 模型：\n我们先逐一认识一下对应的角色概念：\naeEventLoop：这是 Redis 自己实现的一个高性能事件库，里面封装了适配各个系统的 I/O多路复用(I/O multiplexing)，除了 socket 上面的事件以外，还要处理一些定时任务。服务启动时就一直循环，调用 aeProcessEvent 处理事件； client ：代表一个客户端连接。Redis 是典型的 CS 架构（Client \u0026lt;---\u0026gt; Server），客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。Redis 使用结构体 client 存储客户端的所有相关信息，包括但不限于封装的套接字连接 \u0026ndash; *conn，当前选择的数据库指针 \u0026ndash;*db，读入缓冲区 \u0026ndash; querybuf，写出缓冲区 \u0026ndash; buf，写出数据链表 \u0026ndash; reply等； acceptTcpHandler：角色 Acceptor 的实现，当有新的客户端连接时会调用这个方法，它会调用系统 accept 创建一个 socket 对象，同时创建 client 对象，并将 socket 添加到 EventLoop 的监听列表中，并注册当对应的读事件发生时的回调函数 readQueryFromClient，即绑定 Handler，这样当该客户端发起请求时，就会调用对应的回调函数处理请求； readQueryFromClient：角色 Handler 的实现，主要负责解析并执行客户端的命令请求，并将结果写到对应的 client-\u0026gt;buf 或者 client-\u0026gt;reply 中； beforeSleep：事件循环之前的操作，主要执行一些常规任务，比如将 client 中的数据写会给客户端、进行一些持久化任务等。 有了这写概念，我们可以试着描绘一下 客户端client 与 Redis server 建立连接、发起请求到接收到返回的整个过程：\nRedis 服务器启动，开启主线程事件循环 aeMain，注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来； 客户端和服务端建立网络连接，acceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上作为对应事件发生时的回调函数，并初始化一个 client 绑定这个客户端连接； 客户端发送请求命令，触发读就绪事件，主线程调用 readQueryFromClient 通过 socket 读取客户端发送过来的命令存入 client-\u0026gt;querybuf 读入缓冲区； 接着调用 processInputBuffer，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 根据 Redis 协议解析命令，最后调用 processCommand 执行命令； 根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族的一系列函数将响应数据写入到对应 client 的写出缓冲区：client-\u0026gt;buf 或者 client-\u0026gt;reply ，client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client 添加进一个 LIFO 队列 clients_pending_write； 在事件循环 aeMain 中，主线程执行 beforeSleep --\u0026gt; handleClientsWithPendingWrites，遍历 clients_pending_write 队列，调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 sendReplyToClient 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。 三、事件库 aeEventLoop 实现细节 先来看核心数据结构：\n/* State of an event based program */ typedef struct aeEventLoop { int maxfd; // 当前已经注册在此的最大文件描述符 int setsize; // 可“关心”的文件描述符数量 long long timeEventNextId; // 下一个 timer 的id time_t lastTime; // 上一轮事件循环时的系统事件，用来诊断系统时间偏差 aeFileEvent *events; // 注册的文件事件 aeTimeEvent *timeEventHead; // 注册的时间事件 aeFiredEvent *fired; // 就绪的事件 int stop; // 事件轮询是否停止 void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; // 下一次事件轮训之前的钩子函数 aeBeforeSleepProc *aftersleep; // 事件轮询结束后的钩子函数 } aeEventLoop; /* File event structure */ typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE) */ aeFileProc *rfileProc; // 读事件就绪时的回调函数 aeFileProc *wfileProc; // 写事件就绪时的回调函数 void *clientData; // fd 对应的 client 实例 } aeFileEvent; /* Time event structure */ typedef struct aeTimeEvent { long long id; /* time event identifier. */ long when_sec; /* seconds */ long when_ms; /* milliseconds */ aeTimeProc *timeProc; aeEventFinalizerProc *finalizerProc; void *clientData; struct aeTimeEvent *next; } aeTimeEvent; /* A fired event */ typedef struct aeFiredEvent { int fd; int mask; } aeFiredEvent; 关于 时间事件 和 文件事件，可参考：redis 中的事件(时间事件和文件事件)到底是什么？\naeEventLoop 的 Prototypes 有很多，我们关注几个重要的：\n1. aeEventLoop *aeCreateEventLoop(int setsize) 创建一个 aeEventLoop 实例 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; int i; if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;lastTime = time(NULL); eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; if (aeApiCreate(eventLoop) == -1) goto err; /* Events with mask == AE_NONE are not set. So let\u0026#39;s initialize the * vector with it. */ for (i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } 这个方法的实现很简单，就是一些成员变量的初始化。需要注意的是 aeApiCreate，在 src/ae.c 的最开始，有下面的代码：\n/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \u0026#34;ae_evport.c\u0026#34; #else #ifdef HAVE_EPOLL #include \u0026#34;ae_epoll.c\u0026#34; #else #ifdef HAVE_KQUEUE #include \u0026#34;ae_kqueue.c\u0026#34; #else #include \u0026#34;ae_select.c\u0026#34; #endif #endif #endif 这段代码的意思是，根据当前的系统类型，选择性能最好的 I/O多路复用 库，比如当前系统是 Linux，那么应该使用 ae_epoll，Mac 下使用 ae_kqueue等，ae_select 是保底方案。而 ae_xxx 是对不同系统下的 I/O多路复用 的封装，将底层的不同系统调用都通过统一的 API接口 和 数据结构 aeApiStates 暴露出去，供上层调用。我们看下 Linux 系统中 aeApiCreate 的实现：\ntypedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } // 创建 epoll 实例 state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 而 Mac 下的实现又是这样的：\ntypedef struct aeApiState { int kqfd; struct kevent *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct kevent)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;kqfd = kqueue(); if (state-\u0026gt;kqfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 2. aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) 监听文件事件 int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) { if (fd \u0026gt;= eventLoop-\u0026gt;setsize) { errno = ERANGE; return AE_ERR; } aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; if (aeApiAddEvent(eventLoop, fd, mask) == -1) return AE_ERR; fe-\u0026gt;mask |= mask; if (mask \u0026amp; AE_READABLE) fe-\u0026gt;rfileProc = proc; if (mask \u0026amp; AE_WRITABLE) fe-\u0026gt;wfileProc = proc; fe-\u0026gt;clientData = clientData; if (fd \u0026gt; eventLoop-\u0026gt;maxfd) eventLoop-\u0026gt;maxfd = fd; return AE_OK; } 同样，aeApiAddEvent 在不同系统下有不同的实现，在 Linux 系统中，会调用 epoll_ctl ，将 fd 添加到 epoll 实例的监听列表中，同时指定对应事件触发时的回调函数为 *proc。\n3. aeProcessEvents(aeEventLoop *eventLoop, int flags) 事件轮训处理的核心逻辑 /* The function returns the number of events processed. */ int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; // 只处理时间事件和文件事件 if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; // 先处理文件事件 if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { // 计算下一次时间事件到来之前应该阻塞等待的时长 // 调用底层的 poll 函数，获取已经就绪的事件 numevents = aeApiPoll(eventLoop, tvp); // 如果设置了 aftersleep 钩子函数，那应该在 poll 之后调用 if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); // 调用对应事件的回调函数 for (j = 0; j \u0026lt; numevents; j++) { aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[eventLoop-\u0026gt;fired[j].fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fd = eventLoop-\u0026gt;fired[j].fd; int rfired = 0; // 读事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { rfired = 1; fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } // 写事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!rfired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } processed++; } } // 最后再处理时间事件 if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; /* return the number of processed file/time events */ } 四、Redis 单线程流程详解 在这个 section，我们将通过源码的角度，看看 section 1 中的 Redis 的 单Reactor 网络模型中的实现细节，我们对照这张图开始：\n1. server 启动，创建 EventLoop 在 src/server.c 中的 main 方法中，当服务器启动时，会调用 initServer方法，在这个方法中，Redis 会创建全局唯一的 aeEventLoop 实例，并注册 Server socket 到对应的多路复用组件上，同时指定回调函数为 acceptTcpHandler，意思是服务器接收到新的连接时，应该调用 acceptTcpHandler 这个回调函数。\nvoid initServer(void) { ... // 创建全局唯一的 EventLoop 实例 server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } ... /* Create an event handler for accepting new connections in TCP and Unix * domain sockets. */ // ipfd 表示服务启动是监听的 socket 对应的 fd，epoll 监听此 fd，有读事件发生(新连接到来)时调用回调函数 acceptTcpHandler for (j = 0; j \u0026lt; server.ipfd_count; j++) { if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL) == AE_ERR) { serverPanic( \u0026#34;Unrecoverable error creating server.ipfd file event.\u0026#34;); } } } .... 2. 新连接到来时创建连接以及 client 实例 在前面我们将 server 对应的 socket 添加到 epoll 的监听队列，当有新的连接到来时，会触发读事件就绪，此时回调函数 acceptTcpHandler 就会被调用：\nvoid acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 创建 connect fd，代表 Redis Server 和客户端的一个连接(socket) cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), \u0026amp;cport); if (cfd == ANET_ERR) { if (errno != EWOULDBLOCK) serverLog(LL_WARNING, \u0026#34;Accepting client connection: %s\u0026#34;, server.neterr); return; } serverLog(LL_VERBOSE, \u0026#34;Accepted %s:%d\u0026#34;, cip, cport); acceptCommonHandler(cfd, 0, cip); } static void acceptCommonHandler(int fd, int flags, char *ip) { client *c; // 1. 为 connect fd 创建一个 Client 对象 if ((c = createClient(fd)) == NULL) { serverLog(LL_WARNING, \u0026#34;Error registering fd event for the new client: %s (fd=%d)\u0026#34;, strerror(errno), fd); close(fd); /* May be already closed, just ignore errors */ return; } // 2. 检查是否超过了最大连接数 if (listLength(server.clients) \u0026gt; server.maxclients) { char *err = \u0026#34;-ERR max number of clients reached\\r\\n\u0026#34;; /* That\u0026#39;s a best effort error message, don\u0026#39;t check write errors */ if (write(c-\u0026gt;fd, err, strlen(err)) == -1) { /* Nothing to do, Just to avoid the warning... */ } server.stat_rejected_conn++; freeClient(c); return; } // 3. 检查 protect mode 是否开启，如果开启，不允许远程登录 if (server.protected_mode \u0026amp;\u0026amp; server.bindaddr_count == 0 \u0026amp;\u0026amp; server.requirepass == NULL \u0026amp;\u0026amp; !(flags \u0026amp; CLIENT_UNIX_SOCKET) \u0026amp;\u0026amp; ip != NULL) { ... } server.stat_numconnections++; c-\u0026gt;flags |= flags; } client *createClient(int fd) { client *c = zmalloc(sizeof(client)); ... // 1. 标记 fd 为非阻塞 anetNonBlock(NULL, fd); // 2. 设置不开启 Nagle 算法 anetEnableTcpNoDelay(NULL, fd); // 3. 设置 KeepAlive if (server.tcpkeepalive) anetKeepAlive(NULL, fd, server.tcpkeepalive); // 4. 为 fd 创建对应的文件事件监听对应 socket 的读事件，并指定对应事件发生之后的回调函数为 readQueryFromClient if (aeCreateFileEvent(server.el, fd, AE_READABLE, readQueryFromClient, c) == AE_ERR) { close(fd); zfree(c); return NULL; } // 5. 默认使用 0 号 db selectDb(c, 0); uint64_t client_id; // 6. 设置 client 其他默认属性 atomicGetIncr(server.next_client_id, client_id, 1); c-\u0026gt;id = client_id; c-\u0026gt;fd = fd; ... return c; } 在这个方法中，主要做了以下几件事：\n为新连接创建一个 socket，并将这个 socket 添加到 epoll 的监听队列中，注册读事件，并指定对应读事件触发后的回调函数为 readQueryFromClient； 创建一个 client 对象，将 client、socket 等互相绑定，建立联系。 3. 客户端请求到来，执行具体的 handler 在 createClient 中我们知道对应客户端的 socket 上有事件发生时，回调函数是 readQueryFromClient。这个方法主要做一件事：将客户端的请求读取到 client 对象的 querybuf 中。之后再调用 processInputBufferAndReplicate 进一步处理请求。\nvoid readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 调用 read 从 socket 中读取客户端请求数据到 client-\u0026gt;querybuf c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); nread = read(fd, c-\u0026gt;querybuf+qblen, readlen); ... // 如果 client-\u0026gt;querybuf 的大小超过 client_max_querybuf_len，直接返回错误，并关闭连接 if (sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClient(c); return; } // 处理客户端请求 processInputBufferAndReplicate(c); } 再来看 processInputBufferAndReplicate 的实现，它其实是 processInputBuffer 的封装，多加了一层判断：如果是普通的 server，则直接调用 processInputBuffer ；如果是主从客户端，还需要将命令同步到自己的从服务器中。\nvoid processInputBufferAndReplicate(client *c) { if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) { processInputBuffer(c); } else { size_t prev_offset = c-\u0026gt;reploff; processInputBuffer(c); size_t applied = c-\u0026gt;reploff - prev_offset; if (applied) { replicationFeedSlavesFromMasterStream(server.slaves, c-\u0026gt;pending_querybuf, applied); sdsrange(c-\u0026gt;pending_querybuf,applied,-1); } } } processInputBuffer 会试着先从缓冲区中解析命令类型，判断类型，之后调用 processCommand 执行：\nvoid processInputBuffer(client *c) { // 设置 server 的当前处理 client 为c，可以理解为获得了 server 这把锁 server.current_client = c; // 不断从 querybuf 中取出数据解析成成对的命令，直到 querybuf 为空 while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { // 进行一些 flags 的判断 ... // 根据命令类型判断是 单条指令 还是 多条指令一起执行 if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); } // 参数个数为 0 时重置客户端，可以接收下一个命令 if (c-\u0026gt;argc == 0) { resetClient(c); } else { // 执行命令 if (processCommand(c) == C_OK) { // 集群信息同步 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MULTI)) { /* Update the applied replication offset of our master. */ c-\u0026gt;reploff = c-\u0026gt;read_reploff - sdslen(c-\u0026gt;querybuf) + c-\u0026gt;qb_pos; } // 如果不是阻塞状态，则重置client，可以接受下一个命令 if (!(c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) || c-\u0026gt;btype != BLOCKED_MODULE) resetClient(c); } // 释放“锁” if (server.current_client == NULL) break; } } // 重置 querybuf if (c-\u0026gt;qb_pos) { sdsrange(c-\u0026gt;querybuf,c-\u0026gt;qb_pos,-1); c-\u0026gt;qb_pos = 0; } server.current_client = NULL; } 我们再来看 processCommand，在真正执行命令之前，会进行非常多的校验，校验通过后才会真正执行对应的命令。\nint processCommand(client *c) { // 1. 如果命令是 quit，则直接退出 if (!strcasecmp(c-\u0026gt;argv[0]-\u0026gt;ptr, \u0026#34;quit\u0026#34;)) { addReply(c, shared.ok); c-\u0026gt;flags |= CLIENT_CLOSE_AFTER_REPLY; return C_ERR; } // 2. 在 command table 寻找对应命令的处理函数， c-\u0026gt;cmd = c-\u0026gt;lastcmd = lookupCommand(c-\u0026gt;argv[0]-\u0026gt;ptr); ... // 3. 用户权限校验 if (server.requirepass \u0026amp;\u0026amp; !c-\u0026gt;authenticated \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand) { flagTransaction(c); addReply(c, shared.noautherr); return C_OK; } // 4. 如果是集群模式，还需要处理集群 node 重定向 if (server.cluster_enabled \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_LUA \u0026amp;\u0026amp; server.lua_caller-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;getkeys_proc == NULL \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;firstkey == 0 \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand)) { ... } // 5. 处理 maxmemory 情形 if (server.maxmemory \u0026amp;\u0026amp; !server.lua_timedout) { ... } // 6. 非 master 或者 磁盘有问题是，不要进行 AOF 等持久化操作 int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE \u0026amp;\u0026amp; server.masterhost == NULL \u0026amp;\u0026amp; (c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE || c-\u0026gt;cmd-\u0026gt;proc == pingCommand)) { flagTransaction(c); if (deny_write_type == DISK_ERROR_TYPE_RDB) addReply(c, shared.bgsaveerr); else addReplySds(c, sdscatprintf(sdsempty(), \u0026#34;-MISCONF Errors writing to the AOF file: %s\\r\\n\u0026#34;, strerror(server.aof_last_write_errno))); return C_OK; } // 7. 当此服务器时master时：如果配置了 repl_min_slaves_to_write，当slave数目小于时，禁止执行写命令 if (server.masterhost == NULL \u0026amp;\u0026amp; server.repl_min_slaves_to_write \u0026amp;\u0026amp; server.repl_min_slaves_max_lag \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE \u0026amp;\u0026amp; server.repl_good_slaves_count \u0026lt; server.repl_min_slaves_to_write) { flagTransaction(c); addReply(c, shared.noreplicaserr); return C_OK; } // 8. 当只读时，除了 master 的命令，不执行任何其他指令 if (server.masterhost \u0026amp;\u0026amp; server.repl_slave_ro \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE) { addReply(c, shared.roslaveerr); return C_OK; } // 9. 当客户端处于 Pub/Sub 时，只处理部分命令 if (c-\u0026gt;flags \u0026amp; CLIENT_PUBSUB \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != pingCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != subscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != unsubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != psubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != punsubscribeCommand) { addReplyError(c, \u0026#34;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\u0026#34;); return C_OK; } // 10. 服务器为slave，但是没有连接 master 时，只会执行带有 CMD_STALE 标志的命令，如 info 等 if (server.masterhost \u0026amp;\u0026amp; server.repl_state != REPL_STATE_CONNECTED \u0026amp;\u0026amp; server.repl_serve_stale_data == 0 \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_STALE)) { flagTransaction(c); addReply(c, shared.masterdownerr); return C_OK; } // 11. 正在加载数据库时，只会执行带有 CMD_LOADING 标志的命令，其余都会被拒绝 if (server.loading \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_LOADING)) { addReply(c, shared.loadingerr); return C_OK; } // 12. 当服务器因为执行lua脚本阻塞时，只会执行部分命令，其余都会拒绝 if (server.lua_timedout \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != replconfCommand \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == shutdownCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;n\u0026#39;) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == scriptCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;k\u0026#39;)) { flagTransaction(c); addReply(c, shared.slowscripterr); return C_OK; } // 13. 真正执行命令 if (c-\u0026gt;flags \u0026amp; CLIENT_MULTI \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != discardCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != multiCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != watchCommand) { // 如果是事务命令，则开启事务，命令进入等待队列 queueMultiCommand(c); addReply(c, shared.queued); } else { // 否则调用 call 直接执行 call(c, CMD_CALL_FULL); c-\u0026gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); } return C_OK; } 最后就是 call 函数，这是 Redis 执行命令的核心函数，它会处理通用的执行命令的前置和后续操作：\n如果有监视器 monitor，则需要将命令发送给监视器； 调用 redisCommand 的 proc 方法，执行对应具体的命令逻辑； 如果开启了 CMD_CALL_SLOWLOG，则需要记录慢查询日志； 如果开启了 CMD_CALL_STATS，则需要记录一些统计信息； 如果开启了 CMD_CALL_PROPAGATE，则当 dirty 大于0时，需要调用 propagate 方法来进行命令传播(命令传播就是将命令写入 repl-backlog-buffer 缓冲中，并发送给各个从服务器中。)。 void call(client *c, int flags) { .... start = ustime(); c-\u0026gt;cmd-\u0026gt;proc(c); duration = ustime() - start; .... } 经过上面的过程，命令执行结束，对应的结果已经写在了 client-\u0026gt;buf缓冲区 或者 client-\u0026gt;reply链表中：client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client添加进一个 LIFO 队列 server.clients_pending_write。\n4. 在下一次事件循环之前，将写缓冲区中的数据发送给客户端 这个过程在主事件循环之前的钩子函数 beforeSleep 中，这个函数在 main 中指定，在 aeMain 中执行：\nint main(int argc, char **argv) { ... aeSetBeforeSleepProc(server.el, beforeSleep); aeSetAfterSleepProc(server.el, afterSleep); aeMain(server.el); // 启动单线程网络模型 .... } void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; // 这是一个死循环，一直到 redis-server 停止 while (!eventLoop-\u0026gt;stop) { if (eventLoop-\u0026gt;beforesleep != NULL) eventLoop-\u0026gt;beforesleep(eventLoop); aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP); // 处理三个事件：time file call_after_sleep } } 再具体的实现中，我们只关注如何将写缓冲区的数据写回给客户端：\nvoid beforeSleep(struct aeEventLoop *eventLoop) { ... /* Handle writes with pending output buffers. */ handleClientsWithPendingWrites(); .... } int handleClientsWithPendingWrites(void) { listIter li; listNode *ln; int processed = listLength(server.clients_pending_write); // clients_pending_write 是一个 client 队列，listRewind 获取一个用于迭代的游标 listRewind(server.clients_pending_write,\u0026amp;li); // 当队列不为空时，持续进行下面的逻辑处理 while((ln = listNext(\u0026amp;li))) { client *c = listNodeValue(ln); c-\u0026gt;flags \u0026amp;= ~CLIENT_PENDING_WRITE; // 将遍历过 client 从队列中删除 listDelNode(server.clients_pending_write,ln); /* If a client is protected, don\u0026#39;t do anything, * that may trigger write error or recreate handler. */ if (c-\u0026gt;flags \u0026amp; CLIENT_PROTECTED) continue; // 将 client 的数据写回 client 对应的s ocket if (writeToClient(c-\u0026gt;fd,c,0) == C_ERR) continue; // 这次一次性没发完，那就给对应 socket 创建额外的写事件 if (clientHasPendingReplies(c)) { int ae_flags = AE_WRITABLE; /* For the fsync=always policy, we want that a given FD is never * served for reading and writing in the same event loop iteration, * so that in the middle of receiving the query, and serving it * to the client, we\u0026#39;ll call beforeSleep() that will do the * actual fsync of AOF to disk. AE_BARRIER ensures that. */ if (server.aof_state == AOF_ON \u0026amp;\u0026amp; server.aof_fsync == AOF_FSYNC_ALWAYS) { ae_flags |= AE_BARRIER; } if (aeCreateFileEvent(server.el, c-\u0026gt;fd, ae_flags, sendReplyToClient, c) == AE_ERR) { freeClientAsync(c); } } } return processed; } 对 client-\u0026gt;buf 和 client-\u0026gt;reply 的处理在 writeToClient 方法中：\n/* Write data in output buffers to client. Return C_OK if the client * is still valid after the call, C_ERR if it was freed. */ int writeToClient(int fd, client *c, int handler_installed) { ssize_t nwritten = 0, totwritten = 0; size_t objlen; clientReplyBlock *o; while(clientHasPendingReplies(c)) { // 优先处理 buf，先发送一批。在执行之前会判断如果 client-\u0026gt;buf 中有数据，则发送 client-\u0026gt;buf 中的 if (c-\u0026gt;bufpos \u0026gt; 0) { nwritten = write(fd,c-\u0026gt;buf+c-\u0026gt;sentlen,c-\u0026gt;bufpos-c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If the buffer was sent, set bufpos to zero to continue with * the remainder of the reply. */ if ((int)c-\u0026gt;sentlen == c-\u0026gt;bufpos) { c-\u0026gt;bufpos = 0; c-\u0026gt;sentlen = 0; } } else { // client-\u0026gt;buf 中没数据了，则处理 client-\u0026gt;reply 链表中剩下的 o = listNodeValue(listFirst(c-\u0026gt;reply)); objlen = o-\u0026gt;used; if (objlen == 0) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); continue; } nwritten = write(fd, o-\u0026gt;buf + c-\u0026gt;sentlen, objlen - c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If we fully sent the object on head go to the next one */ if (c-\u0026gt;sentlen == objlen) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); c-\u0026gt;sentlen = 0; /* If there are no longer objects in the list, we expect * the count of reply bytes to be exactly zero. */ if (listLength(c-\u0026gt;reply) == 0) serverAssert(c-\u0026gt;reply_bytes == 0); } } if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } server.stat_net_output_bytes += totwritten; if (nwritten == -1) { if (errno == EAGAIN) { nwritten = 0; } else { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, strerror(errno)); freeClient(c); return C_ERR; } } if (totwritten \u0026gt; 0) { /* For clients representing masters we don\u0026#39;t count sending data * as an interaction, since we always send REPLCONF ACK commands * that take some time to just fill the socket output buffer. * We just rely on data / pings received for timeout detection. */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } // 数据全部发送完毕了，那么前一步因为没发完而创建的文件监听事件可以从 EventLoop 中删除了 if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; if (handler_installed) aeDeleteFileEvent(server.el,c-\u0026gt;fd,AE_WRITABLE); /* Close connection after entire reply has been sent. */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClient(c); return C_ERR; } } return C_OK; } ","permalink":"http://localhost:1313/posts/redis%E4%B8%80-redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e在关注 \u003cstrong\u003eredis 单线程/多线程\u003c/strong\u003e 时，有几个重要的时间节点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBefore \u003ccode\u003eRedis v4.0\u003c/code\u003e，真正的单线程；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v4.0\u003c/code\u003e，引入多线程处理 \u003ccode\u003eAOF\u003c/code\u003e 等任务，但\u003cstrong\u003e核心的网络模型中依旧使用单线程\u003c/strong\u003e；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v6.0\u003c/code\u003e，正式在网络模型中实现 \u003ccode\u003eI/O多线程\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e从 \u003ccode\u003eRedis v1.0\u003c/code\u003e 到 \u003ccode\u003eRedis v6.0以前\u003c/code\u003e，Redis 的核心网络模型一直都是一个典型的 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e 的所有运作细节，为以后更好地理解新的 \u003cstrong\u003eMulti-Reactors/Master-Workers\u003c/strong\u003e 模型做准备。\u003c/p\u003e","title":"Redis系列(一): Redis 单线程事件循环"},{"content":"题目描述 使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\n1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z 思路 使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\n代码参考 func printEach() { letter, number := make(chan bool), make(chan bool) wait := sync.WaitGroup{} go func() { i := 1 for { select { case \u0026lt;-number: fmt.Print(i) i++ letter \u0026lt;- true } } }() wait.Add(1) go func(wait *sync.WaitGroup) { str := \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34; i := 0 for { select { case \u0026lt;-letter: if i \u0026gt;= len(str) { wait.Done() return } fmt.Print(str[i : i+1]) i++ if i \u0026gt;= len(str) { wait.Done() return } number \u0026lt;- true } } }(\u0026amp;wait) // 让数字先开始打印 number \u0026lt;- true // 等待循环结束，表示整个打印可以结束了 wait.Wait() // 最后关闭 channel，防止内存泄露 close(letter) close(number) } 代码解释：\nletter 用于通知打印字母，number 用于通知打印数字。\nsync.Waitgroup{} 用于阻塞主线程等待整个打印过程结束。\n倒数第 4 行中的 number \u0026lt;- true 表示让数字先开始打印。\n结束后记得关闭 channel，防止内存泄露\n扩展 有三个函数，分别可以打印 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo;，要求每个函数都起一个 goroutine，并按照 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo; 的顺序打印在屏幕上，5 次。\nfunc printCatDogFish(){ cat, dog, fish := make(chan struct{}), make(chan struct{}), make(chan struct{}) wg := \u0026amp;sync.WaitGroup{} target := 100 go func() { // cat for { select { case \u0026lt;-cat: fmt.Println(\u0026#34;cat\u0026#34;) dog \u0026lt;- struct{}{} } } }() go func() { // dog for { select { case \u0026lt;-dog: fmt.Println(\u0026#34;dog\u0026#34;) fish \u0026lt;- struct{}{} } } }() wg.Add(1) go func(w *sync.WaitGroup) { // fish defer w.Done() i := 0 for { select { case \u0026lt;-fish: fmt.Println(\u0026#34;fish\u0026#34;) i++ if i \u0026gt;= target { return } cat \u0026lt;- struct{}{} } } }(wg) cat \u0026lt;- struct{}{} wg.Wait() close(cat) close(dog) close(fish) } ","permalink":"http://localhost:1313/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003ch3 id=\"题目描述\"\u003e题目描述\u003c/h3\u003e\n\u003cp\u003e使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"思路\"\u003e思路\u003c/h3\u003e\n\u003cp\u003e使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\u003c/p\u003e","title":"面试题:交替打印数字和字符串"},{"content":" 本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\n一、介绍 当我们谈论加解密方式时，通常有两种情形：对称加密 和 非对称加密。\n对于 对称加密，加密和解密使用同一份秘钥，加密者必须将加密方式告知使用者，否则使用者无法解密，这就面临着 “秘钥配送问题”。\n而在 非对称加密 中，有公钥和私钥加密使用公钥，解密使用私钥；公钥是公开的，任何人都可以获得，私钥则是保密的。只有持有私钥的人才能解开被对应公钥加密的数据。因此非对称加密算法，也称公钥加密算法。\n如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。\n1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做 RSA算法。从那时直到现在，RSA 算法一直是最广为使用的\u0026quot;非对称加密算法\u0026quot;。毫不夸张地说，只要有计算机网络的地方，就有 RSA 算法。\n这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA 密钥是 768 个二进制位。也就是说，长度超过 768 位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024 位的 RSA 密钥 基本安全，2048 位的密钥极其安全。\n二、使用 Golang 的标准库中已经对 RSA 相关的加密算法进行了实现，这里展示基本用法 以及 使用自定义密码 的场景。\n对 RSA 的使用大致分为三个步骤：\nRSAGenKey 生成公钥和私钥； RSAEncrypt 加密数据，传入 待加密数据 和 公钥，返回 加密后的数据； RSADecrypt 解密数据，传入 被加密的数据 和 私钥，返回 解密后的数据。 1. RSA 加密的基本用法 // RSAGenKey 生成公私钥 func RSAGenKey(bits int) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥（bits=1024基本安全，2048 极其安全） privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 4、通过pem将设置的数据进行编码，并写入磁盘文件 // fPrivate, err := os.Create(\u0026#34;privateKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPrivate.Close() // err = pem.Encode(fPrivate, block1) // if err != nil { // return err // } // 4. 有两种方式，一种是将秘钥写入文件，一种是当成返回值返回，由使用者自行决定 prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } // fPublic, err := os.Create(\u0026#34;publicKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPublic.Close() // pem.Encode(fPublic, \u0026amp;block2) // 同样，可以将公钥写入文件，也可以直接返回 pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // RSAEncrypt 对数据进行加密操作 func RSAEncrypt(src []byte, pubKey []byte) (res []byte, err error) { block, _ := pem.Decode(pubKey) // 使用X509将解码之后的数据 解析出来 keyInit, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return } publicKey := keyInit.(*rsa.PublicKey) // 使用公钥加密数据 res, err = rsa.EncryptPKCS1v15(rand.Reader, publicKey, src) return } // 对数据进行解密操作 func RSADecrypt(src []byte, prvKey []byte) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo:\nfunc main() { sourceData := \u0026#34;我的头发长，天下我为王\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKey(2048) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecrypt(encryptData, prvKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 我的头发长，天下我为王 after encrypt: [153 1 185 195 ...(很长的字节数组)] after decrypt: 我的头发长，天下我为王 equal? true 2. 使用自定义密码的 RSA 算法 有时候我们想在随机生成的基础上加上自定义的密码，可以使用下面的方式：\n// RSAGenKeyWithPwd generate rsa pair key with specified password func RSAGenKeyWithPwd(bits int, pwd string) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥 privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 通过自定义密码加密 if pwd != \u0026#34;\u0026#34; { block1, err = x509.EncryptPEMBlock(rand.Reader, block1.Type, block1.Bytes, []byte(pwd), x509.PEMCipherAES256) if err != nil { return nil, nil, err } } prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // 加密方式与 RSAEncrypt 没有区别，可以共用 // RSADecryptWithPwd decrypt src with private key and password func RSADecryptWithPwd(src []byte, prvKey []byte, pwd string) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes if pwd != \u0026#34;\u0026#34; { blockBytes, err = x509.DecryptPEMBlock(block, []byte(pwd)) if err != nil { return nil, err } } privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo：\nfunc main() { sourceData := \u0026#34;好的代码本身就是最好的说明文档\u0026#34; pwd := \u0026#34;123456\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKeyWithPwd(2048, pwd) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecryptWithPwd(encryptData, prvKey, pwd) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 好的代码本身就是最好的说明文档 after encrypt: [136 134 26 233 ...(很长的字节数组)] after decrypt: 好的代码本身就是最好的说明文档 equal? true 参考文章： golang 使用 RSA 生成公私钥，加密，解密，并使用 SHA256 进行签名，验证 GO 语言 RSA 加密解密 go - 如何在 golang 中使用密码创建 rsa 私钥 RSA 算法原理（一） ","permalink":"http://localhost:1313/posts/golang%E4%B8%AD%E4%BD%BF%E7%94%A8rsa%E8%BF%9B%E8%A1%8C%E5%8A%A0%E8%A7%A3%E5%AF%86/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003e本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\u003c/p\u003e\n\u003ch2 id=\"一介绍\"\u003e一、介绍\u003c/h2\u003e\n\u003cp\u003e当我们谈论加解密方式时，通常有两种情形：\u003cstrong\u003e对称加密\u003c/strong\u003e 和 \u003cstrong\u003e非对称加密\u003c/strong\u003e。\u003c/p\u003e","title":"Golang中使用RSA进行加解密"},{"content":"介绍 boltdb 是一个使用 Go 编写的键值对数据库，它的目标是 简单、快速和稳定的轻型数据库，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\n使用 1. 安装 go get github.com/boltdb/bolt/... 2. 打开(Open)一个数据库文件连接 func main() { dbPath := \u0026#34;./data.db\u0026#34; // 指定你的数据库文件要存储的地方 db, err := bolt.Open(dbPath, os.ModePerm, nil) if err != nil { panic(err) } ... } bolt 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 Open 操作添加超时：\ndb, err := bolt.Open(dbPath, os.ModePerm, \u0026amp;bolt.Options{Timeout: time.Second * 5}) 运行如上代码，如果 5 秒内未能成功打开文件，会返回一个 timeout 错误。\n3. 事务(Transaction) 在某一时刻， bolt 只允许有一个读写事务 或者 允许多个只读事务。其事务的隔离级别对应 MySQL 中的 可重复读，即每一个事务在 commit 之前，多次读库多看到的信息视图是一致的。\n3.1 读写事务(Read-write Transactions) 启动一个 读写事务，可以通过下面的方式：\nerr := db.Update(func(tx *bolt.Tx) error { ... return nil }) if err != nil { log.Fatal(err) } 或者：\n// open a Read-write transaction with the first argument `true` tx,err := db.Begin(true) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } Update 中的函数就是一个 可重复读 的事务，在这个函数里面可以进行任何的数据库操作。最后需要通过 return nil 来提交修改；如果提交一个 error，那么整个修改会进行 Rollback，回到最初的状态，不会产生任何改变。注意，在 Update 中手动进行 Rollback，会造成 panic。\n3.2 只读事务(Read-only Transactions) 通过下面的方式打开一个只读事务：\nerr := db.View(func(tx *bolt.Tx) error { ... return nil }) 或者：\n// open a Read-only transaction with the first argument `false` tx,err := db.Begin(false) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } 需要注意的是，在 View 只读事务中，无法做一些“写入”操作，能做的可以是：读一个 bucket，读对应 bucket 中的值，或者复制整个 db。注意，在 View 中手动进行 Rollback，会造成 panic。\n3.3 批量读写事务(Batch read-write transactions) 通过以下方式使用 Batch：\nerr := db.Batch(func(tx *bolt.Tx) error { b := tx.Bucket(bucketName) for i := 0; i \u0026lt; 100; i++ { if err := b.Put([]byte(fmt.Sprintf(\u0026#34;name-%d\u0026#34;, i+1)), []byte(fmt.Sprintf(\u0026#34;%d\u0026#34;, rand.Int31n(math.MaxInt32)))); err != nil { return err } } return nil }) Batch 和 Update 相似，以下情形除外：\nBatch 中的操作可以被合并成一个 transaction； 传给 Batch 的函数可能被执行多次，不管返回的 error 是否为 nil 这也就意味着，Batch 里面的操作必须是幂等的，这似乎会带来一些额外的工作，因此之建议在 多个 goroutine 同时调用的时候使用。\n创建一个 DB 对象是线程安全的，但一个事务里面的操作并不是线程安全的。另外，读写事务 和 只读事务 不应该相互依赖，或者不应该同时在同一个 goroutine 中被长时间打开，因为 读写事务 需要周期性地 re-map 数据，但是当 只读事务 打开时，这个操作会造成死锁。\n4. bolt 的读与写 首先，不管是读还是写，都需要先指定一个 bucket，这个概念类似于关系型数据库中的 table。对于 bucket 的操作，有以下几种：\nCreateBucket 创建一个 bucket ，但当 bucket 已经存在时，会返回错误 bucket already exists；如果成功，会返回一个 Bucket对象： bucketName := \u0026#34;my-bucket\u0026#34; _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，当 bucket 已经存在时，会返回错误 b, err := tx.CreateBucket([]byte(bucketName)) if err != nil { return err } // ... do some thing return nil }) CreateBucketIfNotExists 创建一个 bucket，创建成功 或 bucket已经存在时，返回 Bucket 对象： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // ... return nil }) Bucket 选择一个已经存在的 bucket，bucket 不存在时不会报错，但返回的 Bucket 对象为 nil，后续所有对 b 的操作都会造成空指针错误： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式选择一个已经存在的 bucket b, err := tx.Bucket([]byte(bucketName)) if err != nil { return err } fmt.Println(b == nil) // 如果 bucket 不存在，则 b 为 nil，后面所有对 b 的操作都会造成空指针错误 return nil }) DeleteBucket 删除一个已经存在的 bucket，如果 bucket 不存在会返回 bucket not found 错误。 _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式删除一个已经存在的 bucket，如果 bucket 不存在会返回 `bucket not found` 错误 err := tx.DeleteBucket([]byte(bucketName)) if err != nil { return err } return nil }) 4.1 写 或 修改 只有一种方式：使用 Put(k,v []byte) 方法。\n_ = db.Update(func (tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // set name = Jemmy err = b.Put([]byte(\u0026#34;name\u0026#34;),[]byte(\u0026#34;Jemmy\u0026#34;)) if err != nil { return err } }) Value 不一定是一个字符串，你可以存储整个序列化后的对象：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket111\u0026#34; err = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } u := \u0026amp;User{ ID: 1, Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) err = b.Put([]byte(key), data) if err != nil { return err } fmt.Printf(\u0026#34;%s\\n\u0026#34;, b.Get([]byte(key))) return nil }) if err != nil { log.Fatal(err) } } 输出：\n{\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 比较有用的一个技巧：可以使用 NextSequence() 得到一个递增的 unique identifier，你可以把它理解成 MySQL 中的递增主键：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket222\u0026#34; err = db.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } for i:=0;i\u0026lt;5;i++ { u := \u0026amp;User{ Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } // 获取一个主键值。只有当 Tx被关闭 或者 b不可写 时，才会返回错误。在 Update() 函数中不可能发生 id, err := b.NextSequence() if err != nil { return err } u.ID = id // 将 user 序列化成 []byte data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) // 使用 Put 保存 err = b.Put([]byte(key), data) if err != nil { return err } } return nil }) if err != nil { log.Fatal(err) } _ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) } 输出：\nkey=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 4.2 读取 正如上面代码所示，你可以使用 func (b *Bucket) Get(key []byte) []byte 。下面介绍一些更高阶的用法：\n遍历整个 bucket: bolt 通过 byte-sorted 的顺序在 bucket 中存储键值对，这个设计使得对 key 的迭代遍历非常方便也非常快：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 使用 游标 cursor 可以非常方便地移动，类似的函数还有：\nFirst() Move to the first key. Last() Move to the last key. Seek() Move to a specific key. Next() Move to the next key. Prev() Move to the previous key. 所以你可以使用下面的方式进行倒序遍历：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.Last(); k != nil; k, v = c.Prev() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 当然，如果你明确知道你要遍历整个 bucket，并且是正序输出，也可以通过 ForEach：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) err := b.ForEach(func(k, v []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) return nil }) if err != nil { return err } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 前缀匹配搜索，可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() prefix := []byte(\u0026#34;1\u0026#34;) for k, v := c.Seek(prefix); k != nil \u0026amp;\u0026amp; bytes.HasPrefix(k, prefix); k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 范围搜索，也可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() min := []byte(\u0026#34;1\u0026#34;) max := []byte(\u0026#34;3\u0026#34;) for k, v := c.Seek(min); k != nil \u0026amp;\u0026amp; bytes.Compare(k, max) \u0026lt;= 0; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} ","permalink":"http://localhost:1313/posts/boltdb%E4%BD%BF%E7%94%A8%E4%B8%80%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/boltdb/bolt\"\u003eboltdb\u003c/a\u003e 是一个使用 Go 编写的键值对数据库，它的目标是 \u003cstrong\u003e简单、快速和稳定的轻型数据库\u003c/strong\u003e，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\u003c/p\u003e\n\u003ch2 id=\"使用\"\u003e使用\u003c/h2\u003e\n\u003ch3 id=\"1-安装\"\u003e1. 安装\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ego get github.com/boltdb/bolt/...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-打开open一个数据库文件连接\"\u003e2. 打开(Open)一个数据库文件连接\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;./data.db\u0026#34;\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 指定你的数据库文件要存储的地方\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edb\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebolt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eOpen\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eos\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eModePerm\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tpanic(\u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003ebolt\u003c/code\u003e 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 \u003ccode\u003eOpen\u003c/code\u003e 操作添加超时：\u003c/p\u003e","title":"Boltdb使用(一)基本用法"},{"content":" 实验机器：MacBook Pro (Retina, 15-inch, Mid 2015)\nGolang 版本：go version go1.14.6 darwin/amd64\n一、前言 网卡 也称 网络适配器，是电脑与局域网进行相互连接的设备，在 OSI 七层模型中，工作在 物理层 和 数据链路层，其作用可以简单描述为：\n将本机的数据封装成帧，通过网线发送到网络上去； 接收网络上其他设别传过来的帧，将其重新组合成数据，向上层传输到本机的应用程序中。 这里的网卡指的是真实的网卡，是一个真实的物理设备。今天我们要了解的是一个叫 虚拟网卡 的东西。\n在当前的云计算时代，虚拟机和容器的盛行离不开网络管理设备，即 虚拟网络设备，或者说是 虚拟网卡。虚拟网卡有以下好处：\n对用户来说，虚拟网卡和真实网卡几乎没有区别。我们对虚拟网卡的操作不会影响到真实的网卡，不会影响到本机网络； 虚拟网卡的数据可以直接从用户态读取和写入，这样方便我们在用户态进行一些额外的操作(比如截包、修改后再发送出去) Linux 系统中有众多的虚拟网络设备，如 TUN/TAP 设备、VETH 设备、Bridge 设备、Bond 设备、VLAN 设备、MACVTAP 设备 等。这里我们只关注 TUN/TAP 设备。\ntap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。\n二、理解 tun/tap 数据传输过程 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备(OSI 模型的第三层：网络层，即IP 层),也就是说，通过它可以处理来自网络层的数据，更通俗一点的说，通过它，通过它我们可以处理 IP 数据包。\n先看一下正常情况下的物理设备是如何工作的：\n这里的 ethx 表示的就是一台主机的真实的网卡接口，一般一台主机只会有一块网卡，像一些特殊的设备，比如路由器，有多少个口就有多少块网卡。\n我们先看一下 ifconfig 命令的输出：\n$ ifconfig ... en0: flags=8863\u0026lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST\u0026gt; mtu 1500 options=400\u0026lt;CHANNEL_IO\u0026gt; ether ac:bc:32:96:86:01 inet6 fe80::456:7cb8:3dc5:2722%en0 prefixlen 64 secured scopeid 0x4 inet 10.0.0.176 netmask 0xffffff00 broadcast 10.0.0.255 nd6 options=201\u0026lt;PERFORMNUD,DAD\u0026gt; media: autoselect status: active ... 可以看到 etho 这个网卡接口分配到的 IP 地址是 10.0.0.176，这是一块物理网卡，它的两端分别是 内核协议栈 和 外面的网络，从物理层收到的数据，会被转发给内核进而通过某种接口被应用层的用户程序读到；应用程序要想和网络中的另一个进程进行数据通信，会先将数据发送给内核，然后被网卡发送出去。\n接下来我们看一看 tun/tap 设备的工作方式：\n上图中应用层有两个应用程序，而 网络协议栈 和 网络设备(eth0 和 tun0) 都位于内核层，对于 socket，可以这么理解：socket 就像是一组 接口(interface)，它将更复杂的 TCP/IP 协议簇隐藏在 socket 接口后面，只对用户暴露更简单的接口，就像操作系统隐藏了底层的硬件操作细节而只对用户程序暴露接口一样，它是 应用层 与 TCP/IP协议簇 通信的中间软件抽象层。\ntun0 就是一个 tun/tap 虚拟设备，从上图中就可以看出它和物理设备 eth0 的区别：虽然它们的一端都是连着网络协议栈，但是 eth0 另一端连接的是物理网络，而 tun0 另一端连接的是一个 应用层程序，这样协议栈发送给 tun0 的数据包就可以被这个应用程序读取到，此时这个应用程序可以对数据包进行一些自定义的修改(比如封装成 UDP)，然后又通过网络协议栈发送出去——这就是目前大多数 代理 的工作原理。\n假如 eth0 的 IP 地址是 10.0.0.176，而 tun0 配的 IP 为 192.168.1.2。上图是一个典型的使用 tun/tap 进行 VPN 工作的原理，发送给 192.168.1.0/24 的数据通过 应用程序 B 这个 隧道 处理(隐藏一些信息)之后，利用真实的物理设备 10.0.0.176 转发给目的地址(假如为 49.233.198.76)，从而实现 VPN。我们看下每一个流程：\nApplication A 是一个普通的应用程序，通过 Socket A 发送了一个数据包，这个数据包的目的地址是 192.168.1.2； Socket A 将这个数据包丢给网络协议栈； 协议栈根据数据包的目的地址，匹配本地路由规则，得知这个数据包应该由 tun0 出去，于是将数据包丢给了 tun0； tun0 收到数据包之后，发现另一端被 Application B 打开，于是又将数据包丢给了 Application B； Application B 收到数据包之后，解包，做一些特殊的处理，然后构造一个新的数据包，将原来的数据嵌入新的数据包中，最后通过 Socket B 将数据包转发出去，这个时候新数据包的源地址就变成了 eth0 的地址，而目的地址就变成了真正想发送的主机的地址，比如 49.233.198.76； Socket B 将这个数据包丢给网络协议栈； 协议栈根据本地路由得知，这个数据包应该从 eth0 发送出去，于是将数据包丢给 eth0； eth0 通过物理网络将这个数据包发送出去 简单来说，tun/tap 设备的用处是将协议栈中的部分数据包转发给用户空间的特殊应用程序，给用户空间的程序一个处理数据包的机会，比较常用的场景是 数据压缩、加密等，比如 VPN。\n三、使用 Golang 实现一个简易 VPN 先看客户端的实现：\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; \u0026#34;github.com/songgao/water\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; ) /* * @CreateTime: 2020/11/16 11:08 * @Author: hujiaming * @Description: 数据传输过程： 用户数据，如ping --\u0026gt; 协议栈conn --\u0026gt; IfaceWrite --\u0026gt; IfaceRead --\u0026gt; 协议栈conn --\u0026gt; 网线 */ var ( serviceAddress = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;10.0.0.245:9621\u0026#34;, \u0026#34;service address\u0026#34;) tunName = flag.String(\u0026#34;dev\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;local tun device name\u0026#34;) ) func main() { flag.Parse() // create tun/tap interface iface, err := water.New(water.Config{ DeviceType: water.TUN, PlatformSpecificParams: water.PlatformSpecificParams{ Name: *tunName, }, }) if err != nil { color.Red(\u0026#34;create tun device failed,error: %v\u0026#34;, err) return } // connect to server conn, err := net.Dial(\u0026#34;tcp\u0026#34;, *serviceAddress) if err != nil { color.Red(\u0026#34;connect to server failed,error: %v\u0026#34;, err) return } // go IfaceRead(iface, conn) go IfaceWrite(iface, conn) sig := make(chan os.Signal, 3) signal.Notify(sig, syscall.SIGINT, syscall.SIGABRT, syscall.SIGHUP) \u0026lt;-sig } /* IfaceRead 从 tun 设备读取数据 */ func IfaceRead(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 在这里你可以对拿到的数据包做一些数据，比如加密。这里只对其进行简单的打印 color.Cyan(\u0026#34;get data from tun: %v\u0026#34;, packet[:n]) // 通过物理连接，将处理后的数据包发送给目的服务器 err = forwardServer(conn, packet[:n]) if err != nil { color.Red(\u0026#34;forward to server failed\u0026#34;) } } } /* IfaceWrite 从物理连接中读取数据，然后通过 tun 将数据发送给 IfaceRead */ func IfaceWrite(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 从物理请求中读取数据 nr, err := conn.Read(packet) if err != nil { color.Red(\u0026#34;WRITE: read from tun failed\u0026#34;) break } // 将处理后的数据通过 tun 发送给 IfaceRead _, err = iface.Write(packet[4:nr]) if err != nil { color.Red(\u0026#34;WRITE: write to tun failed\u0026#34;) } } } // forwardServer 通过物理连接发送一个包 func forwardServer(conn net.Conn, buff []byte) (err error) { output := make([]byte, 0) bsize := make([]byte, 4) binary.BigEndian.PutUint32(bsize, uint32(len(buff))) output = append(output, bsize...) output = append(output, buff...) left := len(output) for left \u0026gt; 0 { nw, er := conn.Write(output) if er != nil { err = er } left -= nw } return err } 再看服务端的实现：\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; ) /* * @CreateTime: 2020/11/16 11:39 * @Author: hujiaming * @Description: */ var clients = make([]net.Conn, 0) func main() { listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:9621\u0026#34;) if err != nil { color.Red(\u0026#34;listen failed,error: %v\u0026#34;, err) return } color.Cyan(\u0026#34;server start...\u0026#34;) for { // 对客户端的每一个连接，都起一个 go 协程去处理 conn, err := listener.Accept() if err != nil { color.Red(\u0026#34;tcp accept failed,error: %v\u0026#34;, err) break } clients = append(clients, conn) color.Cyan(\u0026#34;accept tun client\u0026#34;) go handleClient(conn) } } func handleClient(conn net.Conn) { defer conn.Close() buff := make([]byte, 65536) for { n, err := conn.Read(buff) if err != nil { if err != io.EOF { color.Red(\u0026#34;read from client failed\u0026#34;) } break } // broadcast data to all clients for _, c := range clients { if c.RemoteAddr().String() != conn.RemoteAddr().String() { c.Write(buff[:n]) } } } } 在这里，我们把 网络协议栈 抽象成了一个黑盒。在接下来的步骤中，我们将逐渐抽丝剥茧，一步步了解网络协议栈的工作原理，以及用 Golang 去实现它。\n四、参考 原创 详解云计算网络底层技术——虚拟网络设备 tap/tun 原理解析 TUN/TAP概述及操作 TUN/TAP设备浅析 https://github.com/ICKelin/article/issues/9 ","permalink":"http://localhost:1313/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tuntap/","summary":"\u003cblockquote\u003e\n\u003cp\u003e实验机器：\u003ccode\u003eMacBook Pro (Retina, 15-inch, Mid 2015)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eGolang 版本：\u003ccode\u003ego version go1.14.6 darwin/amd64\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e网卡\u003c/strong\u003e 也称 \u003cstrong\u003e网络适配器\u003c/strong\u003e，是电脑与局域网进行相互连接的设备，在 \u003ccode\u003eOSI\u003c/code\u003e 七层模型中，工作在 \u003cstrong\u003e物理层\u003c/strong\u003e 和 \u003cstrong\u003e数据链路层\u003c/strong\u003e，其作用可以简单描述为：\u003c/p\u003e","title":"虚拟网络设备tuntap"},{"content":"一、前言 公司后端服务已经全部微服务化，想要调试某个服务可以使用 grpcui，但要对某个接口进行压测，grpcui 还做不到。诸多努力之后找到本次主角：https://github.com/bojand/ghz，官网：ghz.sh。\n推荐理由：简洁！可以一次性解决掉 proto 文件相互之间引用的烦心事！\n二、使用 这里只介绍在 Mac 环境下的用法，其他环境请参阅官网。\n另：我们仍旧使用 GOPATH 方式来管理包，我的： export GOPATH=/Users/hujiaming/go ，本次测试目录为：/Users/hujiaming/go/src/hujm.net。\n1. 安装 直接使用 brew 来安装：\nbrew install ghz 如果不成功，可以直接去 https://github.com/bojand/ghz/releases 下载二进制，下载后放在 PATH 中即可。\n注：还需要有 protoc 工具。\n2. 生成 protoset 文件 如果你的 proto 文件中还引用了其他文件，强烈建议使用 protoset 方式。\n假如我在如下的 proto 中定义一个 GRPC服务：\n/** * @filename: api.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/offer.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/association.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; service ApiService { rpc CreateSKUAssociations(CreateSKUAssociationsReq) returns (CreateSKUAssociationsReply) {}; } message CreateSKUAssociationsReq { repeated Association associations = 1 [ (validator.field) = {repeated_count_min : 1} ]; } message CreateSKUAssociationsReply {} 而 Association 是定义在 \u0026quot;xxx/cm/fulfillment/offermanager/offerpb/association.proto” 文件中的：\n/** * @filename: association.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; message Association { int64 offer_id = 1 [ (validator.field) = {int_gt : 1000000000} ]; string sku_code = 2 [ (validator.field) = {string_not_empty : true} ]; string author = 3 [ (validator.field) = {string_not_empty : true} ]; } 如果采用非 protoset 方式，可能要先生成 association.pb.go，再生成 api.pb.go 文件。这里我们采用 protoset 方式，一步到位：\nprotoc \\ --include_imports \\ -I. -I/usr/local/include \\ -I/usr/local/go \\ -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \\ -I$GOPATH/src \\ --proto_path=. \\ --descriptor_set_out=api.bundle.protoset \\ api.proto 需要注意的点如下：\n如果你的 proto 文件中有引用，上述命令中一定要有 include_imports 参数； 在后面运行时如果出现 no descriptor found for \u0026quot;xxxxxx\u0026quot;，可能是某个文件没有通过 -I 引用进来，记得加上重新执行。 不出意外，会在当前目录下生成 api.bundle.protoset 文件。\n3. 执行压测任务 可以看一下 ghz 的用法：\n$ ghz --help usage: ghz [\u0026lt;flags\u0026gt;] [\u0026lt;host\u0026gt;] Flags: -h, --help Show context-sensitive help (also try --help-long and --help-man). --config= Path to the JSON or TOML config file that specifies all the test run settings. --proto= The Protocol Buffer .proto file. --protoset= The compiled protoset file. Alternative to proto. -proto takes precedence. --call= A fully-qualified method name in \u0026#39;package.Service/method\u0026#39; or \u0026#39;package.Service.Method\u0026#39; format. -i, --import-paths= Comma separated list of proto import paths. The current working directory and the directory of the protocol buffer file are automatically added to the import list. --cacert= File containing trusted root certificates for verifying the server. --cert= File containing client certificate (public key), to present to the server. Must also provide -key option. --key= File containing client private key, to present to the server. Must also provide -cert option. --cname= Server name override when validating TLS certificate - useful for self signed certs. --skipTLS Skip TLS client verification of the server\u0026#39;s certificate chain and host name. --skipFirst=0 Skip the first X requests when doing the results tally. --insecure Use plaintext and insecure connection. --authority= Value to be used as the :authority pseudo-header. Only works if -insecure is used. -c, --concurrency=50 Number of requests to run concurrently. Total number of requests cannot be smaller than the concurrency level. Default is 50. -n, --total=200 Number of requests to run. Default is 200. -q, --qps=0 Rate limit, in queries per second (QPS). Default is no rate limit. -t, --timeout=20s Timeout for each request. Default is 20s, use 0 for infinite. -z, --duration=0 Duration of application to send requests. When duration is reached, application stops and exits. If duration is specified, n is ignored. Examples: -z 10s -z 3m. -x, --max-duration=0 Maximum duration of application to send requests with n setting respected. If duration is reached before n requests are completed, application stops and exits. Examples: -x 10s -x 3m. --duration-stop=\u0026#34;close\u0026#34; Specifies how duration stop is reported. Options are close, wait or ignore. -d, --data= The call data as stringified JSON. If the value is \u0026#39;@\u0026#39; then the request contents are read from stdin. -D, --data-file= File path for call data JSON file. Examples: /home/user/file.json or ./file.json. -b, --binary The call data comes as serialized binary message or multiple count-prefixed messages read from stdin. -B, --binary-file= File path for the call data as serialized binary message or multiple count-prefixed messages. -m, --metadata= Request metadata as stringified JSON. -M, --metadata-file= File path for call metadata JSON file. Examples: /home/user/metadata.json or ./metadata.json. --stream-interval=0 Interval for stream requests between message sends. --reflect-metadata= Reflect metadata as stringified JSON used only for reflection request. -o, --output= Output path. If none provided stdout is used. -O, --format= Output format. One of: summary, csv, json, pretty, html, influx-summary, influx-details. Default is summary. --connections=1 Number of connections to use. Concurrency is distributed evenly among all the connections. Default is 1. --connect-timeout=10s Connection timeout for the initial connection dial. Default is 10s. --keepalive=0 Keepalive time duration. Only used if present and above 0. --name= User specified name for the test. --tags= JSON representation of user-defined string tags. --cpus=8 Number of cpu cores to use. --debug= The path to debug log file. -e, --enable-compression Enable Gzip compression on requests. -v, --version Show application version. Args: [\u0026lt;host\u0026gt;] Host and port to test. 需要关注的几个参数：\n--skipTLS --insecure：如果服务不支持 HTTPS 的话，可以使用此参数跳过 TLS 验证；\n--protoset：指定本次运行的 protoset 文件路径，即上面生成的 api.bundle.protoset；\n--call：需要调用的方法名，格式为：包名.服务名.方法名。比如我要调用 offerpb 包下的 ApiService 服务的 CreateSKUAssociations 方法，那么 call 参数应该是： --call offerpb.ApiService.CreateSKUAssociations；\n--data：本次请求的参数，通过 jsonString 的格式传入；\n--data-file：本次请求的参数，只不过通过文件的形式传入，文件中是标准的通过 json 序列化后的数据；\n--metadata：metadata 参数，通过 jsonString 的格式传入；\n-c：并发数，默认 50(这里有坑，具体参照官网解释：-c。虽然会其多个 goroutine，但是所有的 goroutine 会公用一个连接)；\n-n：请求数，默认 200。n 不能小于 c。\n假设 ApiService服务的地址是：localhost:58784。我们执行下面的命令，发起一次压测任务：\n$ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data \u0026#39;{\u0026#34;associations\u0026#34;:[{\u0026#34;sku_code\u0026#34;: \u0026#34;test:6985079117562211244\u0026#34;,\u0026#34;offer_id\u0026#34;: 8629237865019910744,\u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34;}]}\u0026#39; \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 当你的请求参数比较多时，将他们放在一个文件中、然后使用 --data-file 参数是更好的选择：\n$ cat test_data.json { \u0026#34;associations\u0026#34;: [ { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6237052533738512496\u0026#34;, \u0026#34;offer_id\u0026#34;: 5655307241153104444, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:2156276639623439583\u0026#34;, \u0026#34;offer_id\u0026#34;: 6360134836979240095, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:8361104385030719827\u0026#34;, \u0026#34;offer_id\u0026#34;: 3705044490439993926, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6023087259299523902\u0026#34;, \u0026#34;offer_id\u0026#34;: 3776027093787512475, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:9196748606623463644\u0026#34;, \u0026#34;offer_id\u0026#34;: 1506864634761125694, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; } ] } $ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data-file /Users/hujiaming/go/src/hujm.net/test_data.json \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 看下输出：\nSummary: Count:\t1000 Total:\t743.17 ms Slowest:\t194.74 ms Fastest:\t37.67 ms Average:\t69.32 ms Requests/sec:\t1345.59 Response time histogram: 37.670 [1]\t| 53.377 [384]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 69.084 [349]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 84.791 [138]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 100.498 [26]\t|∎∎∎ 116.205 [2]\t| 131.912 [0]\t| 147.619 [16]\t|∎∎ 163.326 [33]\t|∎∎∎ 179.033 [17]\t|∎∎ 194.739 [34]\t|∎∎∎∎ Latency distribution: 10 % in 46.59 ms 25 % in 49.94 ms 50 % in 57.28 ms 75 % in 69.51 ms 90 % in 102.33 ms 95 % in 163.38 ms 99 % in 183.99 ms Status code distribution: [OK] 1000 responses Summary 的参数：\nCount：完成的请求总数，包括成功的和失败的； Total：本次请求所用的总时长，从 ghz 启动一直到结束； Slowest：最慢的某次请求的时间； Fastest：最快的某个请求的时间； Average：(所有请求的响应时间) / Count。 Requests/sec：RTS，Count / Total 的值。 三、参考资料 https://github.com/bojand/ghz Simple gRPC benchmarking and load testing tool ","permalink":"http://localhost:1313/posts/%E4%BD%BF%E7%94%A8ghz%E5%8E%8B%E6%B5%8Bgrpc%E6%8E%A5%E5%8F%A3/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e公司后端服务已经全部微服务化，想要调试某个服务可以使用 \u003ca href=\"https://github.com/fullstorydev/grpcui\"\u003e\u003ccode\u003egrpcui\u003c/code\u003e\u003c/a\u003e，但要对某个接口进行压测，\u003ccode\u003egrpcui\u003c/code\u003e 还做不到。诸多努力之后找到本次主角：\u003ca href=\"https://github.com/bojand/ghz\"\u003ehttps://github.com/bojand/ghz\u003c/a\u003e，官网：\u003ca href=\"https://ghz.sh\"\u003eghz.sh\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e推荐理由：简洁！可以一次性解决掉 \u003ccode\u003eproto\u003c/code\u003e 文件相互之间引用的烦心事！\u003c/p\u003e","title":"使用ghz压测GRPC接口"},{"content":"一、简介 默克尔树是一种典型的二叉树结构，由一个根节点、一组中间节点 和 一组叶节点 组成。默克尔树最早由 Merkle Ralf 在 1980 年提出，曾广泛用于 文件系统 和 P2P 系统中，比如 Git、区块链、IPFS 等大名鼎鼎的项目或技术。\n他又被称为 哈希树，即存储哈希值的树。树的叶子结点是 数据块(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\n最下面的叶节点包含存储数据或其哈希值。 非叶子节点（包括中间节点和根节点）都是它的两个孩子节点内容的哈希值。 如果是奇数个叶子结点，那么其父节点保存的哈希值就是它本身或者复制一份自己凑成对再进行哈希的结果(具体实现取决于实际情况) 当然，默克尔树可以推广到多叉树的情形，此时非叶子节点的内容为它所有的孩子节点的内容的哈希值。\n二、原理与用途 最开始，我们有一组已经准备好的数据块(比如文件)，他们根据某个标准有序(比如根据文件名字典排序)，而每一个文件都有唯一的哈希值与之对应。这是最底层的情况，当我们向上走的时候，每两个当前层的节点(左右孩子结点)的哈希值可以重新组合，形成一个新的节点(父节点)，这个新的结点中不存储数据，其哈希值为左右孩子结点组合后再次使用预设的哈希函数求哈希值。如此以往，直到生成树根，这个树根我们称为 Merkel Root。有一个特殊情况需要注意，有可能某一层的节点数是奇数，这样就会剩下最后一个结点，再没有结点与其组队生成父节点，这种情况下有两种解决方案：一种是复制一份自己；另一种是不复制，让其父节点只有它一个子节点，而且是左孩子结点。\n目前，默克尔树的典型应用场景包括如下几种。\n快速比较大量数据 对每组数据排序后构建默克尔树结构。当两个默克尔树根相同时，则意味着所代表的两组数据必然相同。否则，必然不同。\n由于 Hash 计算的过程可以十分快速，预处理可以在短时间内完成。利用默克尔树结构能带来巨大的比较性能优势。\n快速定位修改 假如我们基于文件 D0~D3 构建如上的默克尔树，如果 D2 被修改，那么会影响到结点 N2、N2 和 Root。此时我们可根据发生变化的节点，沿着 Root -\u0026gt; N5 -\u0026gt; N2， 通过 O(logN) 的时间复杂度快速定位到哪个结点发生了变化。\n零知识证明 它指的是证明者能够在不向验证者提供任何有用的信息的情况下(没有泄露信息)，使验证者相信某个论断是正确的。有一个很简单的例子：A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法：\nA 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。\nB 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。\n后面的第二种方法属于零知识证明。它的好处在于，在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。\n在默克尔树中，我们仍旧以上图为例，如何向他人证明我拥有 D0 这个数据，而不用暴露更多系统的信息呢？模仿上面的例子，验证者随机提供数据 D1、D2 和 D3，证明者构造如图的默克尔树，并公布 N1 、N5 和 Root。验证者自行计算 Root 值，看是否一致，从而检验 D0 是否存在，因为如果存在，N0 一定相同，那么 N4(N0-N1) 也一定相同、Root(N4-N5)也一定相同。整个过程中验证着没有得到任何除了 D0 外的敏感信息(其他的 D)。\n三、Golang 实现 首先，我们定义需要的结构：\n// Node 表示默克尔树中的 叶结点、非叶结点 或者 Root type Node struct { Tree *MerkleTree // 所在的 Merkle Tree Parent *Node // 父节点 Left *Node // 左孩子 Right *Node // 右孩子 leaf bool // 是否叶子结点 Hash []byte // 如果是叶子结点，则为叶子结点数据的哈希值；如果是非叶子结点，则为左右孩子哈希值组合后的哈希值 C Content // 叶子结点存储的数据块 } // Content 代表一个数据块 type Content interface { CalculateHash() ([]byte, error) Equals(other Content) (bool, error) } // MerkleTree 默克尔树 type MerkleTree struct { Root *Node // Merkle Root 树根 merkleRoot []byte // 树根的哈希值 Leafs []*Node // 所有的叶子结点 hashStrategy func() hash.Hash // 计算哈希的方法 } 需要注意的是，hashStrategy 是一个函数，其返回 type hash.Hash interface，目前最常见的实现是 sha256.New 等，这里为了说明清楚原理，我们自己实现一个，计算 hash 时，只是简单将其转化为 []byte 即可：\ntype myHash struct { hash []byte data []byte blockSize int } func newMyHash() hash.Hash { h := \u0026amp;myHash{ data: make([]byte, 0), blockSize: 64, } return h } // Write 将 p 中的数据更新进 m func (m *myHash) Write(p []byte) (n int, err error) { nn := 0 if len(m.data) == 0 { m.data = p nn = len(p) } else { m.data = append(m.data, 38) m.data = append(m.data, p...) nn = len(m.data) + 1 + len(p) } return nn, nil } // Sum 后面追加 func (m *myHash) Sum(b []byte) []byte { m.data = append(m.data, b...) return m.data } func (m *myHash) Reset() { m.data = make([]byte, 0) m.blockSize = 64 } func (m *myHash) Size() int { return len(m.data) } func (m *myHash) BlockSize() int { return m.blockSize } func newMyHashFunc() hash.Hash { return newMyHash() } 另外，对于 type Content interface，我们也简单实现一个：\ntype myContent string func newMyContent(s string) myContent { return myContent(s) } func (c myContent) CalculateHash() ([]byte, error) { //hash := md5.New() //hash.Write(c.ToBytes()) //return hash.Sum(nil), nil return []byte(c), nil } func (c myContent) Equals(other merkletree.Content) (bool, error) { return reflect.DeepEqual(c, other), nil } 创建 接下来我们提供一个构造方法：\n//NewTree creates a new Merkle Tree using the content cs. func NewTree(cs []Content) (*MerkleTree, error) { var defaultHashStrategy = sha256.New // 默认使用 sha256.New 进行哈希 t := \u0026amp;MerkleTree{ hashStrategy: defaultHashStrategy, } root, leafs, err := buildWithContent(cs, t) // 逐层构建结点 if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } // NewTreeWithHashStrategy 效果同 NewTree，不过使用自定义的哈希函数 func NewTreeWithHashStrategy(cs []Content, hashStrategy func() hash.Hash) (*MerkleTree, error) { t := \u0026amp;MerkleTree{ hashStrategy: hashStrategy, } root, leafs, err := buildWithContent(cs, t) if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } 接着我们来看 buildWithContent 做了什么：\n// buildWithContent 主要将 Content 转变成 Node，为下一步的逐层构建做好准备 func buildWithContent(cs []Content, t *MerkleTree) (*Node, []*Node, error) { if len(cs) == 0 { return nil, nil, errors.New(\u0026#34;error: cannot construct tree with no content\u0026#34;) } var leaves []*Node // 将当前的所有 Content 转化成 Node，放在数组 leaves 中 for _, c := range cs { hash, err := c.CalculateHash() if err != nil { return nil, nil, err } leaves = append(leaves, \u0026amp;Node{ Hash: hash, C: c, leaf: true, Tree: t, }) } root, err := buildIntermediate(leaves, t) // 逐层构建默克尔树，最后返回树根 if err != nil { return nil, nil, err } return root, leaves, nil } 再看 buildIntermediate 如何逐层构建：\nfunc buildIntermediate(nl []*Node, t *MerkleTree) (*Node, error) { var nodes []*Node // 如果是单数，不复制自己以凑成对，而是使自己的父节点只有一个左孩子结点(自己)，没有右孩子结点 for i := 0; i \u0026lt; len(nl); i += 2 { h := t.hashStrategy() left, right := i, i+1 var chash []byte if right == len(nl) { // 单数个，父节点计算哈希时只计算左孩子的 chash = nl[left].Hash } else { // 双数个，父节点从左右子孩子的哈希计算得到自己的哈希 chash = append(nl[left].Hash, nl[right].Hash...) } if _, err := h.Write(chash); err != nil { return nil, err } // 生成父节点 node := \u0026amp;Node{ Left: nl[left], Hash: h.Sum(nil), Tree: t, } if right \u0026lt; len(nl) { node.Right = nl[right] } nodes = append(nodes, node) if right \u0026lt; len(nl) { node.Right.Parent = node } nl[left].Parent = node // 如果只有两个，说明当前构造的 node 就是根节点，结束递归 if len(nl) == 2 { return node, nil } } // 递归调用 return buildIntermediate(nodes, t) } 打印 为了方便调试，我们先实现反序列化默克尔树——逐层遍历二叉树。逐层遍历二叉树是数据结构课程中的基础操作，需要用到一个队列，我们先实现一个简单的队列：\ntype queue struct { data []*Node } func newQueue() queue { q := queue{data: make([]*Node, 0)} return q } // 入队 func (q *queue) enqueue(c *Node) { q.data = append(q.data, c) } // 出队 func (q *queue) dequeue() *Node { if len(q.data) == 0 { return nil } data := q.data[0] q.data = q.data[1:] return data } // 是否为空 func (q *queue) isEmpty() bool { return len(q.data) == 0 } // 队列中元素个数 func (q *queue) len() int { return len(q.data) } 借助队列实现默克尔树的打印：\n// Print 打印默克尔树 func (m *MerkleTree) Print() { if len(m.Leafs) == 0 { fmt.Println(\u0026#34;empty tree\u0026#34;) return } q := newQueue() q.enqueue(m.Root) for !q.isEmpty() { size := q.len() for i := 0; i \u0026lt; size; i++ { tmp := q.dequeue() if tmp == nil { break } if !tmp.leaf { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } else { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } if tmp.Left != nil { q.enqueue(tmp.Left) } if tmp.Right != nil { q.enqueue(tmp.Right) } } fmt.Print(\u0026#34;\\n\u0026#34;) } } 查找 先看实现：\n// 查找 content 对应的从上到下的路径，index 表示是否为左孩子 func (m *MerkleTree) GetMerklePath(content Content) ([][]byte, []int64, error) { for _, current := range m.Leafs { ok, err := current.C.Equals(content) if err != nil { return nil, nil, err } if ok { currentParent := current.Parent var merklePath [][]byte var index []int64 for currentParent != nil { // 当前节点是父节点的右孩子 if bytes.Equal(currentParent.Right.Hash, current.Hash) { merklePath = append(merklePath, currentParent.Right.Hash) index = append(index, 1) } else { merklePath = append(merklePath, currentParent.Left.Hash) index = append(index, 0) } current = currentParent currentParent = currentParent.Parent } // 添加 root if len(merklePath) \u0026gt; 0 { if bytes.Equal(m.Root.Left.Hash, merklePath[0]) { index = append(index, 0) } else { index = append(index, 1) } merklePath = append(merklePath, m.Root.Hash) } return merklePath, index, nil } } return nil, nil, nil } 验证(证明) 首先验证一棵默克尔树是否是有效的：\nfunc (m *MerkleTree) VerifyTree() (bool, error) { calculatedMerkleRoot, err := m.Root.verifyNode() if err != nil { return false, err } // 重新根据各个结点构建一棵默克尔树，并得到其 root，看是否与已存在的相同 if bytes.Compare(m.merkleRoot, calculatedMerkleRoot) == 0 { return true, nil } return false, nil } func (n *Node) verifyNode() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } var ( rightBytes []byte leftBytes []byte err error ) // 递归处理 if n.Right != nil { rightBytes, err = n.Right.verifyNode() if err != nil { return nil, err } } if n.Left != nil { leftBytes, err = n.Left.verifyNode() if err != nil { return nil, err } } h := n.Tree.hashStrategy() if _, err := h.Write(append(leftBytes, rightBytes...)); err != nil { return nil, err } return h.Sum(nil), nil } 再次验证某个 Content 是否属于这棵树(零知识证明)：\nfunc (m *MerkleTree) VerifyContent(content Content) (bool, error) { for _, l := range m.Leafs { ok, err := l.C.Equals(content) if err != nil { return false, err } // 存在于已知的节点中 if ok { // 逐层计算 hash，并比较 currentParent := l.Parent for currentParent != nil { h := m.hashStrategy() var allBytes []byte leftBytes, err := currentParent.Left.calculateNodeHash() if err != nil { return false, err } allBytes = leftBytes if currentParent.Right != nil { rightBytes, err := currentParent.Right.calculateNodeHash() if err != nil { return false, err } allBytes = append(allBytes, rightBytes...) } if _, err := h.Write(allBytes); err != nil { return false, err } if bytes.Compare(h.Sum(nil), currentParent.Hash) != 0 { return false, nil } currentParent = currentParent.Parent } return true, nil } } return false, nil } // calculateNodeHash 计算当前 node 的哈希(左右孩子哈希值组合后，再求哈希) func (n *Node) calculateNodeHash() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } h := n.Tree.hashStrategy() var allBytes []byte allBytes = n.Left.Hash if n.Right != nil { allBytes = append(allBytes, n.Right.Hash...) } if _, err := h.Write(allBytes); err != nil { return nil, err } return h.Sum(nil), nil } 重建 // RebuildTree 根据保存的文件块(leaves)重新构建默克尔树 func (m *MerkleTree) RebuildTree() error { var cs []Content for _, c := range m.Leafs { cs = append(cs, c.C) } root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 也可以根据提供的 []Content 重新构建：\n// RebuildTreeWith 根据提供的 content 完全重建一棵树 func (m *MerkleTree) RebuildTreeWith(cs []Content) error { root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 四、参考文档 Merkle 树结构 Merkle Tree（默克尔树）算法解析 go 语言实现的 merkle 树 我修改了部分实现 ","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%BB%98%E5%85%8B%E5%B0%94%E6%A0%91/","summary":"\u003ch2 id=\"一简介\"\u003e一、简介\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Merkle_tree\"\u003e默克尔树\u003c/a\u003e是一种典型的二叉树结构，由\u003cstrong\u003e一个根节点\u003c/strong\u003e、\u003cstrong\u003e一组中间节点\u003c/strong\u003e 和 \u003cstrong\u003e一组叶节点\u003c/strong\u003e 组成。默克尔树最早由 \u003ccode\u003eMerkle Ralf \u003c/code\u003e在 1980 年提出，曾广泛用于 \u003cstrong\u003e文件系统\u003c/strong\u003e 和 \u003cstrong\u003eP2P\u003c/strong\u003e 系统中，比如 \u003ccode\u003eGit\u003c/code\u003e、区块链、\u003ccode\u003eIPFS\u003c/code\u003e 等大名鼎鼎的项目或技术。\u003c/p\u003e\n\u003cp\u003e他又被称为 \u003cstrong\u003e哈希树\u003c/strong\u003e，即存储哈希值的树。树的叶子结点是 \u003cstrong\u003e数据块\u003c/strong\u003e(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\u003c/p\u003e","title":"优秀数据结构--默克尔树"},{"content":"一、前言 前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\n有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\n这道题本质上是解决 判断数据是否存在于一个大集合中。我当时的回答大致是：前面设置一个 布隆过滤器，可以判断哪些 key 一定不存在、哪些可能存在；通过布隆过滤器的检测之后，后面再设置 n 个 redis 数据库(桶)，通过一个 hash 函数进行分桶操作，之后在某个桶中判断某个 key 是否存在就是 O(1) 的时间复杂度。\n需要注意的是，在计算机中，判断一个元素是不是在一个集合中，通常是用 hash 来解决，这在数据量不大的时候是可以的，但是当数据量很大的时候存储空间就会爆炸。\n当时面试官并没有表示满意或者不满意，毕竟这和其他众多更加底层的面试题比起来，只是冰山一角。最后的面试结果是通过，但因为薪资没有达到我的期望，因此也就没有后续了。\n正好国庆假期有时间，系统总结一下 布隆过滤器 的原理，介绍现有的 Redis 实现，并希望通过 Golang 简单实现，算是学习与总结。\n二、原理 布隆过滤器(Bloom Filter) 由 布隆 于 1970 年提出，在这里可以看到原论文：Space/time Trade-offs in Hash Coding with Allowable Errors。从论文标题可以看出，布隆过滤器在时空复杂度方面有着非常大的优势，同时使用到了哈希，但是存在误算率。实际上，布隆过滤器由 一个很长的二进制数组 和 一系列哈希函数 组成，它的作用是 可以检索一个元素是否存在于一个集合中，优点是 插入与查询的时空效率都远超一般的算法，缺点是 存在一定的误识别率 和 删除困难。\n下面我们看一下布隆过滤器的工作流程：\n布隆过滤器本质上是由长度为 m 的 位向量 或者 位列表 (仅包含 0 或者 1 的列表)组成，并且列表的所有元素被初始化为 0：\n当然还会有一系列哈希函数：\n当我们插入一个 key 时，先通过几个哈希函数得到各自的哈希值，然后将位列表对应位设置为 1：\n再插入元素时，继续将对应位设置为 1 即可，而不用担心之前的值是否为 1：\n当我们查询 another_key 是否在上面的位列表中时，还是经过同样的哈希函数，得到各个列表索引值，进而得到位列表处的值，之后进行判断：如果全为 1，则表示可能存在，如果出现一个为 0，则表明一定不存在。\n为什么说当 结果全为 1 时可能存在，而不是 一定存在？假设我们要查一个单词 test 是否存在，其计算的哈希索引值分别为 [2, 5, 14]，位列表中对应的值也全是 1，但是三个 1 是由 hu 和 Jemmy 两个单词插入的结果，原来并没有 test，这种情况下就会出现误判。\n你可以在这个在线网站 Bloom Filters 上自己体会一下这个过程。\n我们假设位列表的长度为 m，有 k 个哈希函数，那么其误判率大概为：\n对于给定的 m 和 n，当\n的时候，误差率取得最小值。具体的推导过程可参考这篇文章：布隆过滤器的误判率该如何计算？ - Xdims 的回答 - 知乎。我们只需要记住结论即可：\n不要让实际元素数量远大于初始化数量； 如果实际元素数量超过初始化数量，则应该选择更大的 m 重建布隆过滤器，将之前的元素进行批量 add。 三、在 Redis 中使用 在低版本需要安装插件并且重新启动：\n下载插件并安装 cd ~/Documents \u0026amp;\u0026amp; git clone https://github.com/RedisBloom/RedisBloom \u0026amp;\u0026amp; cd RedisBloom \u0026amp;\u0026amp; make # 会得到一个 redisbloom.so 文件 重启 redis-server： # 在redis-cli中关闭服务器，其他方法比如 命令行下 kill -9 (redis-server的pid)是没用的 shutdown # 之后退出 # 重启 redis-server /usr/local/etc/redis.conf --loadmodule ~/Documents/RedisBloom/redisbloom.so \u0026amp; 重新进入 redis-cli 即可。 常用命令如下：\nbf.add name key ：往名为 name 的布隆过滤器中添加一个 key bf.madd name key1 key2 ... keyn: 往名为 name 的布隆过滤器中批量添加多个 key bf.exists name key：检查 key 是否存在于名为 name 的布隆过滤器中 bf.mexists name key1 key2 ... keyn：查询多个 key 是否存在于布隆过滤器中。 五、使用 Golang 实现 package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;github.com/spaolacci/murmur3\u0026#34; \u0026#34;hash\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;unsafe\u0026#34; ) /* * @CreateTime: 2020/10/7 17:28 * @Author: Jemmy(hujm20151021@gmail.com) * @Description: 布隆过滤器 实现 */ // BloomFilter 布隆过滤器的struct type BloomFilter struct { m uint8 // 位数组长度为 2^m n uint64 // 已有元素 k uint32 // 哈希函数的个数 hashFunc []hash.Hash64 // 哈希函数，使用 murmur3 算法，性能好实现简单，但是易于遭受DDoS攻击 data []byte sync.RWMutex // 读写锁 } // NewBloomFilter 初始化一个布隆过滤器 // m 表示位数组长度为 2的m次方 // k 表示哈希函数的个数 func NewBloomFilter(m uint8, k int) *BloomFilter { if k \u0026lt;= 0 { panic(\u0026#34;invalid number k for hashFunc num \u0026#34;) } hashFunc := make([]hash.Hash64, k) // 初始化哈希函数 for i := 0; i \u0026lt; k; i++ { hashFunc[i] = murmur3.New64WithSeed(uint32(i)) } filter := \u0026amp;BloomFilter{ m: m, n: 0, k: uint32(k), hashFunc: hashFunc, data: make([]byte, 1\u0026lt;\u0026lt;m), } // 防止创建数组越界 if len(filter.data) == 0 { panic(\u0026#34;m is too big to make slice\u0026#34;) } return filter } // exists 检查元素是否存在于集合中 // true: 可能存在 // false: 一定不存在 func (b *BloomFilter) exists(data []byte) bool { b.RLock() defer b.RUnlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) f.Reset() if b.data[position] == 0 { return false } } return true } func (b *BloomFilter) add(data []byte) { b.Lock() defer b.Unlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) b.data[position] = 1 f.Reset() } b.n++ } // Reset 清空布隆过滤器中的所有元素 func (b *BloomFilter) Reset() { b.Lock() defer b.Unlock() b.data = make([]byte, 1\u0026lt;\u0026lt;b.m) b.n = 0 } // Number 返回过滤器中的元素个数 func (b *BloomFilter) Number() uint64 { b.RLock() defer b.RUnlock() return b.n } // AddString 向布隆过滤器中添加字符串对象 func (b *BloomFilter) AddString(s string) { b.add(stringToBytes(s)) } // ExistsString 检查s是否存在于集合中 func (b *BloomFilter) ExistsString(s string) bool { return b.exists(stringToBytes(s)) } // AddNumber 添加数字m func (b *BloomFilter) AddNumber(m uint64) { b.add(uint64ToBytes(m)) } // ExistsNumber 检查数字m是否存在于集合中 func (b *BloomFilter) ExistsNumber(m uint64) bool { return b.exists(uint64ToBytes(m)) } // AddBytes 添加 序列化后的对象 func (b *BloomFilter) AddBytes(data []byte) { b.add(data) } // ExistsBytes 检查对象data是否存在 func (b *BloomFilter) ExistsBytes(data []byte) bool { return b.exists(data) } /* ********************************************* 辅助函数 ***************************************************** */ // stringToBytes 将string转换成byte数组，零拷贝 func stringToBytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } // bytesToString byte数组转换成string，零拷贝 func bytesToString(b []byte) string { return *(*string)(unsafe.Pointer(\u0026amp;b)) } // uint64ToBytes 将uint64转为byte数组 func uint64ToBytes(num uint64) []byte { data := make([]byte, 8) binary.LittleEndian.PutUint64(data, num) return data } 写一个测试一下：\nfunc main() { filter := NewBloomFilter(10, 3) filter.AddNumber(1) filter.AddNumber(2) filter.AddNumber(3) filter.AddNumber(4) filter.AddNumber(5) filter.AddNumber(7) filter.AddString(\u0026#34;hu\u0026#34;) filter.AddString(\u0026#34;Jemmy\u0026#34;) fmt.Println(filter.Number()) // 8 fmt.Println(filter.ExistsNumber(3)) fmt.Println(filter.ExistsNumber(5)) fmt.Println(filter.ExistsNumber(6)) fmt.Println(filter.ExistsString(\u0026#34;Jemmy\u0026#34;)) fmt.Println(filter.ExistsString(\u0026#34;jemmy\u0026#34;)) } // 输出 8 true true false true false 【参考资料】\n布隆过滤器论文\n维基百科 布隆过滤器\n在线演示\n","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E7%BB%84%E4%BB%B6-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\u003c/p\u003e","title":"优秀组件-布隆过滤器"},{"content":"一、前言 大家应该对 二分查找算法 不陌生，二分查找之所以能达到 O(logN) 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 随机访问数据 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\n事实上，对于一个有序的链表，我们可以通过建索引的方式，做到类似二分查找的效果。\n假设我们有一个已经排好序的链表(其实是一个双链表，这里为了方便，看待成单链表)：\n如果要对这个链表进行查找，那将是 O(n) 的时间复杂度，我们做一些额外的工作：先对链表中每两个结点建一个索引构成一级索引，再对一级索引进行同样的操作得到二级索引：\n当我们要查找元素 20 时，从最高层开始查，则查找路线应该是 1(向右)-\u0026gt;8(向右)-\u0026gt;14(向下)-\u0026gt;14(向右)-\u0026gt;20，经过了 5 个结点；如果直接在原始链表中查找，需要经过 11 个结点，速度有很明显的提升。不过你也发现了，这是典型的 空间换时间 ，虽然查找速度提升了，但是需要花费空间去存储每一层的索引，占用了更大的空间。\n这种带多级索引的链表结构，就是我们今天要详细学习的 跳表。许多开源软件中都有使用到 跳表 这种数据结构，比如 Redis 中的 zset ，我也是最近看 redis 源码才发现对 skiplist 了解甚少，才决定专门学习一遍。\n二、跳表的性质 跳表 可以视为一个 水平排列(Level)、垂直排列(Tower) 的位置(position，对具体结点 Entry 访问的抽象) 的二维集合。跳表具有如下性质：\n由多层(Level)组成，最底层为第 1 层，向上一层为第 2 层，以此类推。层数不会超过规定的一个最大值 LMAX；\n每一层都是一个拥有头结点的有序列表，第 1 层的链表包含所有的元素；\n如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。 这也是 “第 k 层是第 k-1 层的索引” 描述的体现。\n为了节省空间，第一层之上都不存储实际数据，只有指针，包含同层下一个元素的指针 和 同列下一个元素的指针。\n当查找元素时，会从最顶层链表的头节点开始遍历。以升序跳表为例，如果当前节点的下一个节点包含的值比目标元素值小，则继续向右查找。如果下一个节点的值比目标值大，就转到当前层的下一层去查找。重复向右和向下的操作，直到找到与目标值相等的元素为止。以下为找到元素 20 的路径：\n三、跳表的 Golang 实现 跳表首先由 William Pugh 在其 1990 年的论文《Skip lists: A probabilistic alternative to balanced trees》中提出。由该论文的题目可以知道两点：\n跳表是概率型数据结构。 跳表是用来替代平衡树的数据结构。准确来说，是用来替代自平衡二叉查找树（self-balancing BST）的结构。 在这里我们用 Golang 具体实现一遍。\n首先定义需要的结构体：\ntype Node struct { Value int // 某个结点的值，为了方便理解，这里暂时使用 int forward []*Node // 存储该节点所有层的下一个节点的信息，纵向观察，数组的长度是固定的，为 maxLevel。 curLevel int // 本节点最高层 } type SkipList struct { head *Node // 当前结点 length int // (最后一层)总结点长度 maxLevel int // 跳表的最大层 } 这里最让人疑惑的是 forward []*Node 这个属性，它用来存储该结点所有层的下一个节点。怎么理解呢？看上图，对于结点 8 来说，第一层该结点的下一个节点是 9，第二层该结点的下一个节点是 10，第三层该结点的下一个节点是 14，当 maxLevel = 3(代表forward数组长度为 3) 时，结点 8 的 forward 的应该是 [9, 10, 14]。\n当我们要定位一个元素时，从最顶层 先行后列、从上到下 进行对比。怎么个先行后列？从最顶层开始，如上图，这就选定了第一个元素 1，如果当前的元素比要定位的元素小并且后面的元素不为空时，将当前的位置水平向右移动(p = p.forward[i])，否则，向下移动。重复这个动作，直到找到合适的位置。\n接下来我们还要有一个初始化 SkipList 的操作：\n// CreateSkipList 初始化一个 SkipList func CreateSkipList(base,maxLevel int) *SkipList { s := new(SkipList) s.head = new(Node) s.maxLevel = maxlevel // 第一列默认全都为 base ，并且不计算在 length 中 s.head.curLevel = maxlevel - 1 // 计算层数的时候，为了和 forward 数组保持一致，从第 0 层开始计数 s.head.forward = make([]*Node, maxlevel) s.head.Value = base s.length = 0 return s } 我们先看插入一个元素：\n1. 插入新元素 第一步，确定这个元素的位置；第二步，确定这个元素应该有的层数。\n参考之前的性质：如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。这个概率我们可以通过一个函数来解决：\n// func (s *SkipList) getNodeLevel() int { var level int = 0 // 根据性质 第1层包含所有的元素，所以第一层肯定包含这个新元素，所以默认在第一层 rand.Seed(time.Now().UnixNano()) for { // 第 k 层 有 1/2 的概率成为 k-1 层的索引，并且不会超过最大层 if rand.Intn(2) == 1 || level \u0026gt;= s.maxLevel-1 { break } level++ } return level } 接下来我们看插入的过程：\nfunc (s *SkipList) Insert(value int) (bool, error) { v, err := checkSkipListValid(s) if v == false { return false, err } p := s.head newNode := new(Node) newNode.Value = value newNode.forward = make([]*Node, s.maxLevel) level := s.getNodeLevel() // 当前节点所包含的层数 // forward []*Node 存储该节点所有层的下一个节点的信息 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从最高层开始，向下移动 for { // 找到应该插入的位置 if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; value { p = p.forward[i] // 不为空且插入的值比当前值大，向右移动 } else { // 当前值的当前行的后继为空或者大于插入值，应该向下走，即 i-1 break } } //find the last Node which match user defined IsLess() condition in i level //insert new Node after the node // 在第i层找到应该插入的最佳位置，然后在该位置插入新的节点 // level层以下都有这个节点 if i \u0026lt;= level { // 相当于链表的插入操作，新节点在当前层的下一个节点就是当前节点的后一个节点 newNode.forward[i] = p.forward[i] p.forward[i] = newNode // 当前节点的后一个节点就是新节点 } } newNode.curLevel = level s.length++ // 更新节点长度加一 return true, nil } 我们通过一组图来说明这个情况：\n加入我们设定 maxLevel = 5、插入节点 10 时得到的 level = 1，那么效果如下：\n当我们继续 插入元素 20 时，假如计算得到 level = 2，从上述代码第 15 行开始进去循环，从节点 p = base 开始遍历，在第二个 for 循环，也就是第 17 行里面，base 的 forward = [10, 10, nil, nil, nil] ，第 4 层和第 3 层都直接跳过。\n当 i = 2 也就是第 2 层时，base.forward[2] = nil，所以不会走到第 20 行，但是此时 i \u0026lt;= level，于是有 newNode.forward[2] = p.forward[2] = base.forward[2] = nil，也就是第 2 层的下一个结点，p.forward[2] = base.forward[2] = newNode(结点 20)：\n当 i = 1 也就是第 1 层时，在第 19 行处，base.forward[1] = 10 != nil，并且 10 \u0026lt; 20，因此会走到底 20 行，p = p.forward[i] = base.forward[1] = 10，之后跳出内层循环，来到第 30 行，同样执行赋值操作：\n同样，当 i = 0 即最底下一层时，操作步骤和 i=1 时一样，最终效果为：\n再比如我们 插入元素 15。假如得到的 level = 0，即只出现在最底层。i \u0026gt;= 1 这个过程和插入 20 时没多大区别：\n当 i = 0 时，第 19 行代码中，base.forward[0] = 10 != nil，并且 ·10 \u0026lt; 15，因此 p = p.forward[0] = 10，继续内层循环，此时发现虽然 p.forward[0] = 结点10.forward[0] = 20 != nil，但是 20 \u0026gt; 15，因此跳出内层循环，在下面第 30 行，将 结点 15 插在了结点 10 和结点 20 的中间，效果如下：\n2. 查找元素 查找元素 value 是否在跳表中，如果存在返回对应的 Node，否则返回 nil。\n还是固定的遍历策略，先看代码：\n//try to find the first node which not match the user defined IsLess() condition func (s *SkipList) Search(value int) *Node { p := s.head // 从最高层开始 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从左往右 for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i] \u0026lt; value { p = p.forward[i] // 当前节点的 next 不空，且当前值小于待查找值，则向右移动 } else { break } } } // 假如我们需要查找 value=14，此时已经定位到第一层的10 p = p.forward[0] // 还是要再判断一下p的 value，比如我们要查找14，那 p=15 就不符合，应该返回 nil if p.Value != value { return nil } return p } 3. 删除元素 假设我们已经有了如下的跳表：\n代码如下：\nfunc (s *SkipList) RemoveNode(obj int) bool { var update []*Node = make([]*Node, s.maxLevel) // 用来存储被删除结点每一层的前缀 p := s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; obj { p = p.forward[i] } else { break } } update[i] = p } p = p.forward[0] // 删除的节点不存在 if p == nil || p.Value \u0026lt; obj || obj \u0026lt; p.Value { return false } for i := p.curLevel; i \u0026gt;= 0; i-- { // 将被删除结点的前缀，指向删除结点的 next update[i].forward[i] = p.forward[i] } s.length-- return true } 现在我们想 删除结点 20。运行到第 16 行时，update = [15, 10, base, base, base]。p = p.forward[0] = 20，即此时 p 指向被删除的节点。在第 23 行，从 结点 20 的最高层开始，逐层替换掉被删除结点的前缀结点的后缀结点。\n4. 逐层打印跳表 直接看代码：\nfunc (s *SkipList) Traverse() { var p *Node = s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p != nil { fmt.Print(\u0026#34;%d\u0026#34;,p.Value) if p.forward[i] != nil { fmt.Print(\u0026#34;--\u0026gt;\u0026#34;) } p = p.forward[i] } else { break } } fmt.Println() p = s.head } } 四、时空复杂度分析 都是 O(logn)。具体证明方法请阅读 【参考文献】中 2 跟 3 。\n五、总结 跳表 是一个非常优秀的数据结构，在 Redis 中被用来作为 zset 的底层实现，但是 Redis 的实现比上述设计要复杂的多，比如其引入了 span 表示当前节点到下一个 forward 跨过了几个元素，用来快速计算排名等。\n不过有一点，二叉平衡树也能用来做排序查找，为什么 Redis 不采用树形结构呢？其实 Redis 的作者已经在 这里 说出了原因：\nThere are a few reasons:\nThey are not very memory intensive. It\u0026rsquo;s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.\nA sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.\nThey are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.\n大致意思就是：\n跳表更加节省内存，并且计算随机层数的函数，可以由自己随意更改来获得更多或者更少的索引；\nzset 经常用来实现整体遍历操作，这一点上二者相差无几；\n跳表在调试的时候更容易操作一些。\n【参考文献】\n1. Golang 跳表的实现 https://github.com/GrassInWind2019/skipList/blob/master/src/skipList/skipList.go 2. 跳表时空复杂度分析 https://lotabout.me/2018/skip-list/ 3. 一文彻底搞懂跳表的各种时间复杂度、适用场景以及实现原理 ","permalink":"http://localhost:1313/posts/%E8%B7%B3%E8%A1%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e大家应该对 \u003cstrong\u003e二分查找算法\u003c/strong\u003e 不陌生，二分查找之所以能达到 \u003ccode\u003eO(logN)\u003c/code\u003e 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 \u003cstrong\u003e随机访问数据\u003c/strong\u003e 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\u003c/p\u003e","title":"跳表原理以及Golang实现"},{"content":"首先明确，Redis 是一个使用 C 语言编写的键值对存储系统。Redis 是众所周知的 “快”，一方面，它是一个内存数据库，所有的操作都是在内存中完成的，内存的访问速度本身就很快；另一方面，得益于它底层的数据结构。Redis 的常见类型可在这个网页找到：Redis 命令参考简体中文版，其使用到的底层数据结构有如下六种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和 整数数组。本篇文章，将具体了解这些底层数据结构的实现。\n本文所涉及源码位于：https://github.com/redis/redis，所选版本为 6.0.8。\n绘图工具为 draw.io\n涉及到内存操作的函数：\nvoid *zmalloc(size_t size); // 调用zmalloc函数，申请size大小的空间 void *zcalloc(size_t size); // 调用系统函数calloc申请内存空间 void *zrealloc(void *ptr, size_t size); // 原内存重新调整为size空间的大小 void zfree(void *ptr); // 调用zfree释放内存空间 char *zstrdup(const char *s); // 字符串复制方法 size_t zmalloc_used_memory(void); // 获取当前以及占用的内存空间大小 void zmalloc_enable_thread_safeness(void); // 是否设置线程安全模式 void zmalloc_set_oom_handler(void (*oom_handler)(size_t)); // 可自定义设置内存溢出的处理方法 float zmalloc_get_fragmentation_ratio(size_t rss); // 获取所给内存和已使用内存的大小之比 size_t zmalloc_get_rss(void); // 获取RSS信息(Resident Set Size) size_t zmalloc_get_private_dirty(void); // 获得实际内存大小 size_t zmalloc_get_smap_bytes_by_field(char *field); // 获取/proc/self/smaps字段的字节数 size_t zmalloc_get_memory_size(void); // 获取物理内存大小 void zlibc_free(void *ptr); // 原始系统free释放方法 一、底层数据结构 1. 简单动态字符串 源码文件：sds.h\n1.1 数据结构 SDS（Simple Dynamic Strings, 简单动态字符串）是 Redis 的一种基本数据结构，主要是用于存储字符串和整数。 在 Redis 3.2 版本以前，SDS 的实现如下：\nstruct sdshdr { // 记录 buf 数组中已使用字节的数量，等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; 比如，字符串 Redis6.0 的结构如下：\nSDS 遵循 C 字符串以空字符结尾的惯例， 但保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面， 并且为空字符分配额外的 1 字节空间， 以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的， 所以这个空字符对于 SDS 的使用者来说是完全透明的——这样做的好处是，SDS 可以直接使用 C 库中的有关字符串的函数。\n但是在 Redis 3.2 以后，为了提高效率以及更加节省内存，Redis 将 SDS 划分成一下五种类型：\nsdshdr5 sdshdr8 sdshdr16 sdshdr32 sdshdr64 先看 sdshdr5，增加了一个 flags 字段来标识类型，用一个字节(8 位)来存储：\n// Note: sdshdr5 is never used, we just access the flags byte directly. struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 前 3 位表示类型, 后 5 为表示长度 */ char buf[]; }; 对于 sdshdr5 ，因为其可存储长度最大为 2^5 - 1 = 31，当字符串长度超过 31 时，仅靠 flag 的后 5 为表示长度是不够的，这时需要使用其他的四个结构来保存：\nstruct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; // 已使用长度 1字节 uint8_t alloc; // 总长度 1字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; // 已使用长度 2字节 uint16_t alloc; // 总长度 2字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; // 已使用长度 4字节 uint32_t alloc; // 总长度 4字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; // 已使用长度 8字节 uint64_t alloc; // 总长度 8字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; C/C++ 中 __packed 的作用：\n假设有以下结构体：\nstruct { char a; // 1 字节 int b; // 4 字节 char c[2]; // 2 字节 double d; // 8 字节 }Struct_A; 在计算机内存中，结构体变量的存储通常是按字长对齐的，比如在 8 位机上，就按照 1 字节(8 位)对齐，上述结构体占用 1+4+2+8=15​ 字节的内存；在 16 位机上，按照 2 字节对齐，则该结构体占用 2+4+2+8=16​ 字节。也就是说，在更高位的机器中，如果按照默认的机器字长做内存对齐的标准，那总会有一些空间是浪费的，比如上面 16 位时，为了对齐，使用了 2 字节来存储一个char类型的变量。为什么要对齐？这是因为对内存操作按照整字存取会有更高的效率，是 “以空间换时间” 的思想体现。当然，在空间更优先的情况下，也可以不使用默认的机器字长做内存对齐，这个时候，使用 __packed___关键字，可以强制使编译器将结构体成员按照 1 字节进行内存对齐，可以得到非对齐的紧凑型结构体。\n1.2 API 创建 SDS /* Create a new sds string starting from a null terminated C string. */ sds sdsnew(const char *init) { size_t initlen = (init == NULL) ? 0 : strlen(init); // 拿到要创建的字符串的长度 return sdsnewlen(init, initlen); // 传入字符串、字符串长度，调用 sdsnewlen 动态分配内存 } sds sdsnewlen(const void *init, size_t initlen) { void *sh; sds s; char type = sdsReqType(initlen); // 根据字符串长度得到合适的类型 // 一般情况下，创建一个空字符串的目的都是为了后面的append操作，因此，空字符串的情况下，直接创建SDS_TYPE_8，减少后面的扩容操作 if (type == SDS_TYPE_5 \u0026amp;\u0026amp; initlen == 0) type = SDS_TYPE_8; // 计算类型对应的结构体头部长度(len alloc flags的长度) int hdrlen = sdsHdrSize(type); // 指向flag的指针 unsigned char *fp; // 申请内存，内存大小为 结构体头部长度+字符串长度(buf)+1，这里+1是因为要考虑 \u0026#39;\\0\u0026#39; 字符 sh = s_malloc(hdrlen+initlen+1); if (sh == NULL) return NULL; if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); // 将s指向buf s = (char*)sh+hdrlen; // 将 s-1 指向flag fp = ((unsigned char*)s)-1; // 对sds结构体变量进行赋值 switch(type) { case SDS_TYPE_5: { *fp = type | (initlen \u0026lt;\u0026lt; SDS_TYPE_BITS); break; } case SDS_TYPE_8: { SDS_HDR_VAR(8,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = initlen; *fp = type; break; } ... } if (initlen \u0026amp;\u0026amp; init) memcpy(s, init, initlen); // 在s的最后添加\u0026#39;\\0\u0026#39; s[initlen] = \u0026#39;\\0\u0026#39;; // 返回指向 buf 数组的指针s return s; } 注意，创建 SDS 时返回给上层的是指向 buf 数组的指针 s，而不是结构体的指针，那如何找到结构体中的其他元素呢？上面提到了 __packed__ 关键字，使用 1 字节进行内存对齐，那么知道了 buf 的地址，将其减去对应类型的长度(偏移量)，就能得到结构体中其他类型的地址。\n清空 SDS 清空一个 SDS 有两个途径：\n第一种是直接调用 s_free() 函数：\n/* Free an sds string. No operation is performed if \u0026#39;s\u0026#39; is NULL. */ void sdsfree(sds s) { if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1])); } 另一种方式是 重置 len 为 0 的方式，这种情况下 buf 所占用的空间并没有被清除掉，新的数据会直接覆盖 buf 中的原有数据而无需再申请新的内存空间：\n/* Modify an sds string in-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */ void sdsclear(sds s) { sdssetlen(s, 0); s[0] = \u0026#39;\\0\u0026#39;; } 拼接 SDS 拼接使用的是 sds sdscatsds(sds s, sds t)，但最终调用的还是 sdscatlen：\n// 将 t 拼接到 s 后面。调用此方法之后，sds底层的buf可能经过了扩容迁移了原来的位置，注意更新原来变量中对应的指针 sds sdscatsds(sds s, const sds t) { return sdscatlen(s, t, sdslen(t)); } sds sdscatlen(sds s, const void *t, size_t len) { size_t curlen = sdslen(s); // 计算当前s的长度 s = sdsMakeRoomFor(s,len); // 空间不够的话扩容，确保s的剩余空间足够放得下t if (s == NULL) return NULL; // 扩容失败 memcpy(s+curlen, t, len); // 拼接 sdssetlen(s, curlen+len); // 更新s的属性len s[curlen+len] = \u0026#39;\\0\u0026#39;; // 给s最后加上 \u0026#39;\\0\u0026#39; return s; } 接下来我们详细看一下扩容规则，在函数 sdsMakeRoomFor 中：\n// 将sds s的 buf 的可用空间扩大，使得调用此函数之后的s能够再多存储 addlen 长度的字符串。 // 注意：此方法并未改变 sds 的len属性，仅仅改变的是 sds 的 buf 数组的空间。 sds sdsMakeRoomFor(sds s, size_t addlen) { void *sh, *newsh; size_t avail = sdsavail(s); // 当前的可用空间长度：s.alloc - s.len size_t len, newlen; char type, oldtype = s[-1] \u0026amp; SDS_TYPE_MASK; int hdrlen; // 情况1：剩余长度大于所需要长度，没必要扩容，直接返回 if (avail \u0026gt;= addlen) return s; len = sdslen(s); // 当前字符串长度 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 新字符串长度 // 情况2：扩容 // 情况2.1： 如果 新长度 \u0026lt; 1MB，则按 新长度的2倍 扩容 // 否则，就按 新长度+1MB 扩容 if (newlen \u0026lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; // 计算新长度的类型 type = sdsReqType(newlen); // 还是为了后续使用减少扩容次数的原因，将 sdshdr5 变为 sdshdr8 if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) { // 如果新长度对应的类型没变，则直接调用 s_realloc 扩大动态数组即可 newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; } else { /* Since the header size changes, need to move the string forward, * and can\u0026#39;t use realloc */ // 类型发生了改变，意味着sds结构体头部的三个属性的类型也要跟着变化，此时直接重新申请一块内存 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; // 原s的数据拷贝到新的内存上 memcpy((char*)newsh+hdrlen, s, len+1); // 释放掉原来的s的空间，并将其更新为刚才新申请的 s_free(sh); s = (char*)newsh+hdrlen; // 更新 flag s[-1] = type; // 更新 len sdssetlen(s, len); } // 更新 alloc sdssetalloc(s, newlen); return s; } 代码中注释已经很清楚了，这里再总结一下扩容策略：如果 剩余长度 avail \u0026gt;= 新增长度 addlen ，则无需扩容；否则，如果 avail + addlen \u0026lt; 1MB，按照 2 * (avail + addlen)扩容，否则按照 avail + addlen + 1MB 扩容。\n1.3 总结 创建 SDS 时返回的是指向 buf 数组的指针，而不是 SDS 类型的对象，这样的好处是兼容了已有的 C 语言中的相关函数； 读取内容时，先通过类对应类型计算偏移量，再通过 len 属性来限制读取的长度，杜绝了缓冲区溢出，二进制安全； 根据字符串的长度，定义了五种不同的类型，节省了空间； 进行字符串拼接时，会通过 sdsMakeRoomFor 函数来决定是否有底层 buf 数组的扩容操作。 2. 双端链表 源码文件：adlist.h\n2.1 数据结构 当我们使用 lpush 或者 rpush 的时候，其实底层对应的数据结构就是一个双端链表。\n首先我们来了解结点 listNode：\ntypedef struct listNode { struct listNode *prev; // 头指针 struct listNode *next; // 尾指针 void *value; // 具体的值，因为值的类型不确定，此处使用万能指针 } listNode; 虽然使用多个 listNode就已经足够表示一个双端链表，但是为了更方便，Redis 还有如下结构：\ntypedef struct list { listNode *head; // 头指针 listNode *tail; // 尾指针 void *(*dup)(void *ptr); // 拷贝结点函数 void (*free)(void *ptr); // 释放结点值函数 int (*match)(void *ptr, void *key); // 判断两个结点是否相等的函数 unsigned long len; // 链表长度 } list; 他们的关系可用如下图表示：\n2.2 API 创建 list 对象 创建的是一个 list 对象，首先会尝试申请分配空间，失败返回 NULL ：\n// 创建的只是一个 list 对象，这个对象可以被 AlFreeList() 释放掉，但是仅仅释放的是这个 list 对象，其上面的 listNode 对象还需要另外手动释放 list *listCreate(void) { struct list *list; // 申请分配内存，失败返回 NULL if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 给其他属性赋值 list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; list-\u0026gt;dup = NULL; list-\u0026gt;free = NULL; list-\u0026gt;match = NULL; // 最终返回 list 对象 return list; } 添加元素 listNode 到 list 给一个带头的双向链表添加元素，有三种添加方法：头插入 、 尾插入 和 指定位置，分别对应的操作为 lpush 、rpush 和 linsert。对于 lpush 和 rpush 的实现如下，本质上就是对双端链表的基础操作：\nlist *listAddNodeHead(list *list, void *value) { listNode *node; // 申请分配内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; // 将 listNode 插入到 list 的元素中 if (list-\u0026gt;len == 0) { // 如果之前 list 没有元素，那么 list 的 head 和 tail 均指向当前的 listNode list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { // 链表的头插入 node-\u0026gt;prev = NULL; node-\u0026gt;next = list-\u0026gt;head; list-\u0026gt;head-\u0026gt;prev = node; list-\u0026gt;head = node; } // 更新 len list-\u0026gt;len++; // 返回的是传进来的 list ，失败返回的是 NULL return list; } // 尾插入，过程和头插入类似 list *listAddNodeTail(list *list, void *value) { listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (list-\u0026gt;len == 0) { list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { node-\u0026gt;prev = list-\u0026gt;tail; node-\u0026gt;next = NULL; list-\u0026gt;tail-\u0026gt;next = node; list-\u0026gt;tail = node; } list-\u0026gt;len++; return list; } 关于 linsert ，其用法如下：\nLINSERT key BEFORE|AFTER pivot value\n将值value插入到列表key当中，位于值pivot之前或之后。\n当pivot不存在于列表key时，不执行任何操作。\n当key不存在时，key被视为空列表，不执行任何操作。\n如果key不是列表类型，返回一个错误。\n在 Redis 底层，对应的方法为 listInsertNode，当然，为了找到 old_node，前面还需要遍历 list，这个操作的时间复杂度是 O(n)，我们这里只关注如何插入元素：\n// 在 list 的 old_node 的前或后(after\u0026lt;0,在前面增加；after\u0026gt;0，在后面增加)新增值为 value 的新listNode list *listInsertNode(list *list, listNode *old_node, void *value, int after) { listNode *node; // 为新增的 listNode 申请内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (after) { // after\u0026gt;0，在后面插入 node-\u0026gt;prev = old_node; node-\u0026gt;next = old_node-\u0026gt;next; if (list-\u0026gt;tail == old_node) { list-\u0026gt;tail = node; } } else { // after\u0026lt;0，在前面插入 node-\u0026gt;next = old_node; node-\u0026gt;prev = old_node-\u0026gt;prev; if (list-\u0026gt;head == old_node) { list-\u0026gt;head = node; } } if (node-\u0026gt;prev != NULL) { node-\u0026gt;prev-\u0026gt;next = node; } if (node-\u0026gt;next != NULL) { node-\u0026gt;next-\u0026gt;prev = node; } // 更新 len list-\u0026gt;len++; // 成功 返回传进来的 list return list; } 删除元素 删除元素的情况有以下几种：清空整个 list ，删除某个 listNode。\n我们先看清空整个 list ，它只是释放掉了这个 list 上连的所有的 listNode ，而 list 对象并没有被销毁：\n/* Remove all the elements from the list without destroying the list itself. */ void listEmpty(list *list) { unsigned long len; listNode *current, *next; current = list-\u0026gt;head; len = list-\u0026gt;len; // 遍历整个链表，逐个释放空间，直到为空 while(len--) { next = current-\u0026gt;next; if (list-\u0026gt;free) list-\u0026gt;free(current-\u0026gt;value); zfree(current); current = next; } list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; } 而下面这个 listRelease 方法，会释放所有：\n/* Free the whole list. * * This function can\u0026#39;t fail. */ void listRelease(list *list) { listEmpty(list); // 先清空所有的 listNode zfree(list);\t// 再释放 list } 然后看删除某个具体的 listNode：\nvoid listDelNode(list *list, listNode *node) { // 是否是 list 中的第一个元素 if (node-\u0026gt;prev) node-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; else list-\u0026gt;head = node-\u0026gt;next; // 是否是 list 中的最后一个元素 if (node-\u0026gt;next) node-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; else list-\u0026gt;tail = node-\u0026gt;prev; // 释放当前节点的值 if (list-\u0026gt;free) list-\u0026gt;free(node-\u0026gt;value); // 释放内存 zfree(node); // 更新 len list-\u0026gt;len--; } 2.3 总结 Redis 基于双端链表，可以提供各种功能：列表键、发布订阅功能、监视器等；\n因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表；\n仔细看过源代码后会发现，这是一个典型的双端链表，其底层实现与我在《数据结构》中遇到的如出一辙，这也从侧面说明了熟悉基本的数据结构的重要性。\n3. 字典 字典，由一个个键值对构成，首先想一下，一个字典应该提供什么样的功能？键值对用来存储数据，之后还要能插入数据、修改数据、删除数据、遍历(读取)数据，字典最大的特点就是上面这些所有的操作都可以在 O(1) 的时间复杂度里完成。\n比如在 redis-cli 中，我输入如下命令：\nredis\u0026gt; set name Jemmy 这条命令在 redis 的内存中生成了一个键值对(key-value)，其中 key 是 name，value 是 Jemmy的字符串对象，\nRedis 的字典采用 哈希表 来实现。一个哈希表，你可以简单把它想成一个数组，数组中的每个元素称为一个桶，这也就对应上我们经常所说，一个哈希表由多个桶组成，每个桶中保存了键值对的数据(哈希桶中保存的值其实并不是值本身，而是一个指向实际值的指针)。\n提到哈希，首先要关注的是哈希算法以及解决哈希冲突的方式。哈希算法的具体实现我们暂时不关心，只需要知道 Redis 使用的是 MurmurHash2，“这个算法的优点在于：即使输入的键是有规律的，算法仍能够给出一个很好的随机分布性，计算速度也很快”；对于解决哈希冲突的方法，最常见的是 开放地址法 和 拉链法。二者实现原理在 Golang-map 详解 中已经说过，这里不再细讲，目前只需要知道，Redis 采用拉链法解决哈希冲突。\n在 Redis 中，有以下几个概念：哈希表、哈希表结点和字典，他们的关系大致可以描述为：字典是一个全局的字典，一个字典中包含两个哈希表，一个正在使用，另一个用作扩容用；哈希表中包含多个哈希表结点。接下来我们详细看下每个结构的具体实现：\n源码文件：dict.h\n3.1 数据结构 哈希表结点 哈希表节点使用 dictEntry 结构表示， 每个 dictEntry 结构都保存着一个键值对：\ntypedef struct dictEntry { // key void *key; // value，可以是指针 uint64_t int64_t double中的某一个 union { void *val; uint64_t u64; int64_t s64; double d; } v; // 指向另一个哈希表结点的指针，连接哈希值相同的键值对，用来解决哈希冲突 struct dictEntry *next; } dictEntry; 哈希表 typedef struct dictht { dictEntry **table; // dictEntry数组，dictEntry代表一个键值对 unsigned long size; // 哈希表大小(容量) unsigned long sizemask; // 值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 unsigned long used; // 哈希表已有结点的数量 } dictht; 下图可以表示 哈希表 dictht 和 哈希表结点 dictEntry 之间的关系：\n字典 typedef struct dict { dictType *type; // 类型对应的特定函数 void *privdata; // 私有数据 dictht ht[2]; // 两个哈希表，一个正常使用，另一个用于扩容 long rehashidx; // rehash 索引值，扩容时使用，正常时为-1 unsigned long iterators; // 正在运行的迭代器的数量 } dict; 这里的 type 是一个指向 dictType 结构体的指针，而每一个 dictType 结构体保存了 一组用于操作特定类型键值对的函数，不同的类型有不同的操作函数，privdata 保存了需要传递给特定类型函数的可选参数：\ntypedef struct dictType { // 计算哈希值的函数 uint64_t (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键是否相同的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj); } dictType; ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。\n除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。\n下图展示了一个普通状态(没有进行 rehash )的字典：\n3.2 哈希冲突的解决方式 当两个以上的键经过哈希函数计算之后，落在了哈希表数组的同一个索引上面，我们就称这些键发生了 哈希冲突(hash collision)。\nRedis 的哈希表使用 链接法来解决键冲突： 每个哈希表节点(dictEntry)都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。写入时，因为没有直接指向链的最后一个元素的指针，因此为了更少的时间复杂度， Redis 采用的是在链表头部插入；读取时，先定位到链头，之后逐个比较值是否与所求相同，直到遍历完整个链。\n比如上图中，在 dictht.table 的 3 号桶中已经存在一个键值对 k1-v1，此时又新加入一个键值对 k2-v2，经过哈希计算后正好也落在 3 号桶中，经过插入后结果如下：\n3.4 rehash 细节 当哈希表的键值对数量太多或者太少时，需要根据实际情况对哈希表的大小进行扩大或者缩小，这个过程通过 rehash(重新散列) 来完成。 而判断是否进行 rehash ，是在向哈希表插入一个键值对的时候，接下来我们通过分析源代码的方式，详细了解 rehash 的细节。\n首先，添加一个新键值对，用到的是 dictAdd 方法：\n/* Add an element to the target hash table */ int dictAdd(dict *d, void *key, void *val) { dictEntry *entry = dictAddRaw(d,key,NULL); // 将键值对封装成dictEntry if (!entry) return DICT_ERR; // 如果创建dictEntry，返回失败 dictSetVal(d, entry, val); // 键不存在，则设置dictEntry结点的值 return DICT_OK; } 我们接着看 dictAddRaw，这一步主要将键值对封装成一个 dictEntry 并返回 ：\n// 将 key 插入哈希表中 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing) { long index; dictEntry *entry; dictht *ht; // 如果哈希表正在rehash，则向前 rehash一步(渐进式rehash的体现) // 是否正在进行 rehash，是通过 dict.rehashidx == -1 来判断的 if (dictIsRehashing(d)) _dictRehashStep(d); // 调用_dictKeyIndex() 检查键是否存在，如果存在则返回NULL if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; // 获取当前正在使用的ht，如果正在 rehash，使用 ht[1]，否则使用 ht[0] ht = dictIsRehashing(d) ? \u0026amp;d-\u0026gt;ht[1] : \u0026amp;d-\u0026gt;ht[0]; // 为新增的节点分配内存 entry = zmalloc(sizeof(*entry)); // 将结点插入链表头部 entry-\u0026gt;next = ht-\u0026gt;table[index]; ht-\u0026gt;table[index] = entry; // 更新结点数量 ht-\u0026gt;used++; // 设置新节点的键，使用的是 type 属性中的 keyDup 函数 dictSetKey(d, entry, key); return entry; } 我们再看 _dictKeyIndex 这个方法，作用是计算某个 key 应该存储在哪个空的 bucket ，即需要返回这个 key 应该存储在 dictEntry 数组的 index，如果已经存在，返回 -1。需要注意的是，当哈希表正在 rehash 时，返回的 index 应该是要搬迁的 ht：\n// 传进来的 existing 是 NULL, hash是通过 type 中的哈希函数计算的 static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing) { unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; // 检查是否需要扩展哈希表，如果需要则进行扩展 if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table \u0026lt;= 1; table++) { idx = hash \u0026amp; d-\u0026gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-\u0026gt;ht[table].table[idx]; while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (existing) *existing = he; return -1; } he = he-\u0026gt;next; } if (!dictIsRehashing(d)) break; } return idx; } 最后，我们关注 检查是否需要 rehash，需要则启动 的 _dictExpandIfNeeded：\nstatic int _dictExpandIfNeeded(dict *d) { // 如果正在 rehash，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果哈希表中是空的，则将其收缩为初始化大小 DICT_HT_INITIAL_SIZE=4 if (d-\u0026gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // 在 (ht[0].used/ht[0].size)\u0026gt;=1前提下，如果 系统允许扩容 或者 ht[0].used/t[0].size\u0026gt;5 时，容量扩展为原来的2倍 if (d-\u0026gt;ht[0].used \u0026gt;= d-\u0026gt;ht[0].size \u0026amp;\u0026amp; (dict_can_resize || d-\u0026gt;ht[0].used / d-\u0026gt;ht[0].size \u0026gt; dict_force_resize_ratio)) { return dictExpand(d, d-\u0026gt;ht[0].used * 2); // 扩容至原来容量的2倍 } return DICT_OK; } 仔细看看 dictExpand 是如何扩展哈希表容量的，这个函数中，判断是否需要扩容，如果需要，则新申请一个 dictht ，赋值给 ht[0]，然后将字典的状态设置为 正在 rehash(rehashidx \u0026gt; -1)，需要注意的是，这个方法中并没有实际进行键值对的搬迁：\n// 扩容 或者 新建一个 dictht int dictExpand(dict *d, unsigned long size) { /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 如果正在 reahsh 或者 传进来的size不合适(size比当前已有的容量小，正常情况下这是不可能的)，直接返回错误 if (dictIsRehashing(d) || d-\u0026gt;ht[0].used \u0026gt; size) return DICT_ERR; dictht n; // 新哈希表 // 计算 扩展或缩放新哈希表容量 的大小，必须是2的倍数 unsigned long realsize = _dictNextPower(size); // 如果计算扩容后的新哈希表的容量，和原来的相同，就没必要扩容，直接返回错误 if (realsize == d-\u0026gt;ht[0].size) return DICT_ERR; // 为新哈希表申请内存，并将所有的指针初始化为NULL n.size = realsize; n.sizemask = realsize - 1; n.table = zcalloc(realsize * sizeof(dictEntry *)); n.used = 0; /* Is this the first initialization? If so it\u0026#39;s not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果原来的哈希表是空的，意味着这是在新建一个哈希表，将新申请的 dictht 赋值给 ht[0]，直接返回创建成功 if (d-\u0026gt;ht[0].table == NULL) { d-\u0026gt;ht[0] = n; return DICT_OK; } // 如果不是新建哈希表，那就是需要实打实的扩容，此时将刚才新申请的 哈希表 赋值给 ht[1]，并将当前字典状态设置为\u0026#34;正在rehash\u0026#34;(rehashidx \u0026gt; -1) d-\u0026gt;ht[1] = n; d-\u0026gt;rehashidx = 0; return DICT_OK; } // 哈希表的容量必须是 2的倍数 static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size \u0026gt;= LONG_MAX) return LONG_MAX + 1LU; while (1) { if (i \u0026gt;= size) return i; i *= 2; } } 什么时候进行 桶 的搬迁呢？这里涉及到一个名词：渐进式扩容。我们知道，扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面，如果哈希表中的键值对数量少，那么一次性转移过去不是问题；但是键值对的数量很大，几百万几千万甚至上亿，那么一次性搬完的计算量+单线程很有可能使 redis 服务停止一段时间。因此，为了避免 rehash 对服务造成影响，服务不是一次性 rehash 完成的，而是 分多次、渐进式地将 ht[0] 中的键值对搬迁到 ht[1] 中。\n源码中真正执行搬迁的函数是 _dictRehashStep：\n// _dictRehashStep 让 rehash 的动作向前走一步(搬迁一个桶)，前提是当前字典没有被遍历，即iterators==0，iterators表示当前正在遍历此字典的迭代器数目 static void _dictRehashStep(dict *d) { if (d-\u0026gt;iterators == 0) dictRehash(d, 1); } 再看 dictRehash ：\n// dictRehash 向前 rehash n步。如果还没有搬迁完，返回 1，搬迁完成返回0 int dictRehash(dict *d, int n) { // 当dictRehash时，rehashidx指向当前正在被搬迁的bucket，如果这个bucket中一个可搬迁的dictEntry都没有，说明就没有可搬迁的数据。 // 这个时候会继续向后遍历 ht[0].table 数组，直到找到下一个存有数据的bucket位置，如果一直找不到，则最多向前走 empty_visits 步，本次搬迁任务结束。 int empty_visits = n * 10; // 整个dict的 rehash 完成了，返回0 if (!dictIsRehashing(d)) return 0; // 外层大循环，确保本次最多向前走n步 以及 ht[0].table中还有值 while (n-- \u0026amp;\u0026amp; d-\u0026gt;ht[0].used != 0) { dictEntry *de, *nextde; // 确保 rehashidx 不会超过 ht[0].table 的长度，因为 rehashidx 指向当前正在被搬迁的bucket，其实就是 ht[0].table 数组的下标，这里保证数组下标访问不会越界 assert(d-\u0026gt;ht[0].size \u0026gt; (unsigned long)d-\u0026gt;rehashidx); // 当前的bucket搬迁完了，继续寻找下一个bucket，知道全部为空 或者 向前走的步数超过了限定值 while (d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] == NULL) { d-\u0026gt;rehashidx++; if (--empty_visits == 0) return 1; } // 终于找到了可搬迁的某个bucket中的 dictEntry de = d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx]; // 将这个 bucket 中的所有 dictEntry 包括链表上的，前部搬迁到新的 ht[1] 中 while (de) { uint64_t h; nextde = de-\u0026gt;next; // 获取当前键值对在新的哈希表中的桶的序号，这里进行取模的是 ht[1]的sizemask，所以 h 很大概率会与在 ht[0] 中的不一样 h = dictHashKey(d, de-\u0026gt;key) \u0026amp; d-\u0026gt;ht[1].sizemask; // 更新 新桶与旧桶 中的属性 de-\u0026gt;next = d-\u0026gt;ht[1].table[h]; d-\u0026gt;ht[1].table[h] = de; d-\u0026gt;ht[0].used--; d-\u0026gt;ht[1].used++; de = nextde; } // 搬迁完成，将原来的ht[0]中的bucket置空 d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] = NULL; // rehashidx 自增，表示又搬完了一个桶 d-\u0026gt;rehashidx++; } // 检查是否搬完了整张表 if (d-\u0026gt;ht[0].used == 0) { // 全部完成搬迁，则释放掉ht[0]的内存，将ht[1]的内容放到ht[0]中，重置ht[1]，并标志rehash完成(rehashidx=-1) zfree(d-\u0026gt;ht[0].table); d-\u0026gt;ht[0] = d-\u0026gt;ht[1]; _dictReset(\u0026amp;d-\u0026gt;ht[1]); d-\u0026gt;rehashidx = -1; return 0; } // 否则后面的动作还要继续搬迁 return 1; } 那什么时候会进行渐进式rehash呢？在源码中搜索 _dictRehashStep：有以下几处出现了：\ndictAddRaw ：向字典增加一个键值对时； dictGenericDelete：查找并移除某个键值对时； dictFind ：根据 key 查找对应的 dictEntry 时； dictGetRandomKey：返回一个随机的 dictEntry 时； dictGetSomeKeys：随机返回指定 count 个 dictEntry 时，会进行 count 次 _dictRehashStep 总结一下：\n为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。\n3.5 API 添加键值对 dictAdd 在上面讲 rehash 时，使用的例子，就是 添加键值对，这里不再赘述。\n删除键值对 dictDelete 其底层调用的是 dictGenericDelete：\n// 找到key对应的键值对，并移除它。此处dictDelete 调用时传入 nofree=0 static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) { uint64_t h, idx; dictEntry *he, *prevHe; int table; // 如果字典中键值对数量为0，返回 未找到 if (d-\u0026gt;ht[0].used == 0 \u0026amp;\u0026amp; d-\u0026gt;ht[1].used == 0) return NULL; // 如果当前处于 rehash 阶段，则往前进行一步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table \u0026lt;= 1; table++) { // 获取桶的索引 idx = h \u0026amp; d-\u0026gt;ht[table].sizemask; // 获取桶中的第一个 dictEntry he = d-\u0026gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表，找到之后将其从链表中删除 while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (prevHe) prevHe-\u0026gt;next = he-\u0026gt;next; else d-\u0026gt;ht[table].table[idx] = he-\u0026gt;next; if (!nofree) { dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } d-\u0026gt;ht[table].used--; return he; } prevHe = he; he = he-\u0026gt;next; } // 如果没有再 rehash，就没必要再去 ht[1] 中寻找了 if (!dictIsRehashing(d)) break; } return NULL; // 没找到，返回 NULL } 查找键值对 dictFind 过程跟 dictGenericDelete 一模一样， dictGenericDelete 还多了一个删除操作。\n4. 跳表 会有专门的一篇文章来讲。看这里：跳表原理以及 Golang 实现\n5. 整数集合 当一个集合中只包含整数，并且元素的个数不是很多的话，redis 会用整数集合作为底层存储，它的一个优点就是可以节省很多内存，虽然字典结构的效率很高，但是它的实现结构相对复杂并且会分配较多的内存空间。当然，当整数集合中的 元素太多(redis.conf 中 set-max-intset-entries=512) 或者 添加别的类型的元素是，整个整数集合会被转化成 字典。\n源码文件：intset.h\n5.1 数据结构 整数集合（intset） 是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。\ntypedef struct intset { // 编码方式 uint32_t encoding; // 集合中包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; } intset; contents 数组中的元素按照从小到大的顺序排列，并且保证没有重复值；length 表示整数集合中包含的元素数量，即 contents 数组的长度。虽然 contents 数组的类型是 int8_t，但实际上并不保存 int8_t 类型的值，而是会根据实际 encoding 的值做出判断，比如 encoding = INTSET_ENC_INT16，那么数组的底层类型均为 int16_t ，整个数组中的元素类型都是 int16_t：\n/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 \u0026lt; INTSET_ENC_INT32 \u0026lt; INTSET_ENC_INT64. */ #define INTSET_ENC_INT16 (sizeof(int16_t)) // int16 16位 #define INTSET_ENC_INT32 (sizeof(int32_t)) // int32 32位 #define INTSET_ENC_INT64 (sizeof(int64_t)) // int64 64位 // 返回 v 对应的 encoding 值 static uint8_t _intsetValueEncoding(int64_t v) { if (v \u0026lt; INT32_MIN || v \u0026gt; INT32_MAX) return INTSET_ENC_INT64; else if (v \u0026lt; INT16_MIN || v \u0026gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16; } 下面是一个使用 INTSET_ENC_INT16 编码的、长度为 6 的整数集合：\n5.2 API 初始化 intset // 创建一个空的 intset intset *intsetNew(void) { // 为 intset 对象申请空间 intset *is = zmalloc(sizeof(intset)); // 默认使用 INTSET_ENC_INT16 作为存储大小 is-\u0026gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 数组长度为0，因为没有初始化的操作 is-\u0026gt;length = 0; return is; } 这里有一点需要注意，创建 intset 的时候并没有初始化 contents 数组，应为没必要。在常规情况下，访问数组是根据数组第一个元素地址加上类型大小作为偏移值读取，但是 intset 的数据类型依赖于 encoding，读取的时候通过 memcpy 按照 encoding 的值重新计算偏移量暴力读取的，属于 非常规操作数据，因此，刚开始没必要申请数组的空间，等添加一个元素时，动态扩容该元素的大小的内存即可。\n添加元素 我们先看代码：\n// 在 intset 中添加一个整数 intset *intsetAdd(intset *is, int64_t value, uint8_t *success) { uint8_t valenc = _intsetValueEncoding(value); // 根据要插入的 value 的类型 获取对应的 encoding uint32_t pos; if (success) *success = 1; // success = NULL if (valenc \u0026gt; intrev32ifbe(is-\u0026gt;encoding)) { // 插入元素的 encoding 值大于 intset 当前的，升级 return intsetUpgradeAndAdd(is,value); } else { // 插入元素的 encoding 值小于等于当前 intset 的，则找到这个 value 应该插入的位置，赋值给 pos，已经存在的话直接返回 if (intsetSearch(is,value,\u0026amp;pos)) { if (success) *success = 0; return is; } // 动态扩容 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 将 pos 位置后面的元素整体向后挪一位，给 pos 腾位置 if (pos \u0026lt; intrev32ifbe(is-\u0026gt;length)) intsetMoveTail(is,pos,pos+1); } // 将 pos 位置设置为 value _intsetSet(is,pos,value); // 更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } // 动态扩容，即将原来数组的容量 (is.length*encoding) 调整为 ((is.length+1)*encoding) static intset *intsetResize(intset *is, uint32_t len) { uint32_t size = len*intrev32ifbe(is-\u0026gt;encoding); is = zrealloc(is,sizeof(intset)+size); return is; } // 暴力迁移pos位置之后的数据，为pos位置挪出位置 static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) { // from = pos, to = pos+1 // src 表示 pos 相对于数组头部的迁移量 // dst 表示 pos下一个元素相对于数组头部的偏移量 void *src, *dst; // pos位置 距离数组末尾的元素个数，bytes*类型大小 即是pos后面的所有元素的总长度 uint32_t bytes = intrev32ifbe(is-\u0026gt;length)-from; // encoding uint32_t encoding = intrev32ifbe(is-\u0026gt;encoding); if (encoding == INTSET_ENC_INT64) { src = (int64_t*)is-\u0026gt;contents+from; dst = (int64_t*)is-\u0026gt;contents+to; bytes *= sizeof(int64_t); } else if (encoding == INTSET_ENC_INT32) { src = (int32_t*)is-\u0026gt;contents+from; dst = (int32_t*)is-\u0026gt;contents+to; bytes *= sizeof(int32_t); } else { src = (int16_t*)is-\u0026gt;contents+from; dst = (int16_t*)is-\u0026gt;contents+to; bytes *= sizeof(int16_t); } // 从 src 复制 bytes 个字符到 dst memmove(dst,src,bytes); } 整个过程可以简单总结为：先判断当前插入值的 encoding 是否超过了 intset 的，如果超过了，进行升级，升级 操作我们待会儿再看。没超过的话，需要找到当前元素应该插入的位置 pos ，查找 操作我们还是待会儿再看。之后是动态扩容，动态扩容的过程有：先将数组容量增加，之后将 pos 后面的元素整体移一位，最后将 value 值写入 pos 处。特别需要注意的是，将 pos 后面的元素整体后移一位 这一步，没有逐个移动元素，而是计算好 src 和 dst，直接调用 memmove 将 src 处的 bytes 个字符复制到 dst 处，这正是利用了 intset 数组非常规读取数组的特点。下面通过一个例子看一下插入的过程：\n升级 当插入的元素的类型比集合中现有所有元素的类型都要长时，需要先将数组整个升级之后，才能继续插入元素。升级 指的是 将数组类型变成和插入值类型相同的过程。\n升级过程大致可分为三个步骤：\n根据新元素类型，扩展底层数组的大小，并为新元素分配空间； 将底层数组的所有元素都转化成与新元素相同，并将转换后的元素放在合适的位置上，并且在防止的过程中，需要维持底层数组中数组顺序不变； 将新元素添加到新数组中 下面我们直接看代码：\nstatic intset *intsetUpgradeAndAdd(intset *is, int64_t value) { uint8_t curenc = intrev32ifbe(is-\u0026gt;encoding); // 当前 encoding uint8_t newenc = _intsetValueEncoding(value); // 插入元素的 encoding int length = intrev32ifbe(is-\u0026gt;length); // 插入到 数组最左边 还是 数组最右边。为什么会是最值？因为要升级，所以插入值肯定超出了现有 encoding 对应类型的最值，要么是负数越界，要么是正数越界 int prepend = value \u0026lt; 0 ? 1 : 0; // 首先，设置 intset 的 encoding 为插入元素的 encoding(更大的那个) is-\u0026gt;encoding = intrev32ifbe(newenc); // 根据新元素类型 扩展数组大小 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 从数组最后一个元素开始遍历，将其放入合适的位置。prepend 的作用就是确保我们能给待插入值留下最左边的位置 或 最右边的位置 while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); // 在数组头部或者数组尾部插入 value if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-\u0026gt;length),value); // 最后更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } 通过一个例子说明升级的过程：\n注意：整数集合没有降级操作！一旦对数组进行了升级， 编码就会一直保持升级后的状态。\n查找 在 intset 中查找 value 是否存在，如果存在，返回 1，同时将 pos 值设置为数组的索引值；如果不存在，返回 0，同时将 pos 设置成应该存放的位置的索引值：\nstatic uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) { int min = 0, max = intrev32ifbe(is-\u0026gt;length)-1, mid = -1; int64_t cur = -1; // 当 intset 中没有元素时，直接返回 if (intrev32ifbe(is-\u0026gt;length) == 0) { if (pos) *pos = 0; return 0; } else { // 大于当前数组中最大值 或 小于最小值，也是直接返回 if (value \u0026gt; _intsetGet(is,max)) { if (pos) *pos = intrev32ifbe(is-\u0026gt;length); return 0; } else if (value \u0026lt; _intsetGet(is,0)) { if (pos) *pos = 0; return 0; } } // 因为数组有序，所以采用二分法查找位置是一个非常正确的选择 while(max \u0026gt;= min) { mid = ((unsigned int)min + (unsigned int)max) \u0026gt;\u0026gt; 1; cur = _intsetGet(is,mid); if (value \u0026gt; cur) { min = mid+1; } else if (value \u0026lt; cur) { max = mid-1; } else { break; } } if (value == cur) { // value 已经存在 if (pos) *pos = mid; return 1; } else { // value 不存在 if (pos) *pos = min; return 0; } } 5.3 总结 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 整数集合中的元素不能太对，当超过配置值后，会被转化成字典。 6. 压缩列表 压缩列表 是 Redis 自己实现的一个数据存储结构，有点类似数组，通过一片连续的空间存储数据，只不过数组的每个元素大小都相同，压缩列表允许每个元素有自己的大小。其核心思想，就是在一个连续的内存上，模拟出一个链表的结构。\n在源代码中有这么一段描述：\nThe ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist.\n大致意思是：ziplist 是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist 可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以 O(1) 的时间复杂度在表的两端提供 push 和 pop 操作。但由于每次操作都需要重新分配 ziplist 使用的内存，所以实际的复杂度与 ziplist 使用的内存量有关。\n源码文件：ziplist.h\n6.1 数据结构 ziplist 并没有实际的 struct 表示，但在 ziplist.c 中有如下描述：\nThe general layout of the ziplist is as follows:\n\u0026lt;zlbytes\u0026gt; \u0026lt;zltail\u0026gt; \u0026lt;zllen\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;entry\u0026gt; \u0026hellip; \u0026lt;entry\u0026gt; \u0026lt;zlend\u0026gt;\nzlbytes：本身占用 4 字节，整个压缩列表占用的总字节数(包括他自己) zltail：本身占用 4 字节，起始位置到最后一个结点的偏移量，用来快速定位最后一个元素，在反向输出压缩列表时会有用 zllen：本身占用 2 字节，压缩列表包含的元素个数 entry：元素内容。用数组存储，内存上紧挨着 zlend：本身占用 1 字节，压缩列表结束的标志位，一般为常量 0xFF 接下来看 entry 这个结构：\n\u0026lt;prevlen\u0026gt; \u0026lt;encoding\u0026gt; \u0026lt;entry-data\u0026gt;\nprevlen：1 字节或者 5 字节，表示前一个 entry 长度，在反向遍历的时候会有用 encoding：1、2 或 5 字节，表示当前 entry 的编码方式，表示当前 entry 的类型，integer 或 string entry-data：实际所需的字节数，结点真正的值，可以是 integer 或 string。它的类型和长度由 encoding 来决定 接下来我们详细关注这三个参数：\nprevlen 以字节为单位，记录前一个 entry 的长度。prevlen 的长度可以是 1 字节 或者 5 字节：\n当前一个结点的长度小于 254 字节时，prevlen 的长度为 1 字节，前一个 entry 的长度就保存在这一个字节中； 当前一个结点的长度大于等于 254 字节时，prevlen 的长度为 5 字节，其中第一个字节会被设置成 0xFE(十进制的 254)，表示这是一个 5 字节长 的 prevlen，后面的四个字节则保存前一个 entry 的长度。 prevlen 的作用是：在反向遍历压缩数组时，可以通过当前元素的指针，减去 prevlen ，就能得到前一个元素的地址。\nencoding 节点的 encoding 属性记录了节点的 entry-data 属性所保存 数据的类型 以及 长度：\n一字节、两字节或者五字节长， 值的最高位为 00 、 01 或者 10 的是字节数组编码： 这种编码表示节点的 content 属性保存着 字符串(字节数组)， 数组的长度由编码除去最高两位之后的其他位记录： 编码 编码长度 content 中保存的值 00bbbbbb 1 字节 长度小于等于 63 字节的字节数组(6 位分辨位，2^6 = 64，除去全 0 的) 01bbbbbb | xxxxxxxx 2 字节 长度小于等于 16383 字节的字节数组(14 位分辨位，2^14 = 16384，除去全 0 的) 10000000 | xxxx…xxxx(32 位) 5 字节 长度小于等于 4294967295 字节的字节数组(32 位分辨位，2^32 = 4294967296) 一字节长， 值的最高位以 11 开头的是整数编码： 这种编码表示节点的 entry-data 属性保存着整数值， 整数值的类型和长度由编码除去最高两位之后的其他位记录: 编码 编码长度 entry-data 中保存的值 11000000 1 字节 int16_t 类型整数 11010000 1 字节 int32_t 类型整数 11100000 1 字节 int64_t 类型整数 11110000 1 字节 24 位有符号整数 11111110 1 字节 8 位有符号整数 1111xxxx 1 字节 使用这一编码的节点没有相应的 entry-data 属性， 因为编码本身的 xxxx 四个位已经保存了一个介于 0 和 12 之间的值， 所以它无须 entry-data 属性。 entry-data 节点的 entry-data 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。\n6.2 API 创建ziplist 返回一个只包含 \u0026lt;zlbytes\u0026gt;\u0026lt;zltail\u0026gt;\u0026lt;zllen\u0026gt;\u0026lt;zlend\u0026gt; 的 ziplist：\nunsigned char *ziplistNew(void) { unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; // 头部的 4+4+2 和 尾部的1 总共 11 字节 unsigned char *zl = zmalloc(bytes); // 这里的ziplist类型是一个 char 数组，而不是某个具体的结构体 ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); // 设置 zlbytes 为 初始分配的值，即 bytes ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); // 设置 zltail 为 header 结束的地方 ZIPLIST_LENGTH(zl) = 0; // 设置 zllen 为 0 zl[bytes-1] = ZIP_END; // 最后一个字节存储常量 255 ，表示 ziplist 结束 return zl; } 插入ziplistInsert 这个函数的作用是 在 ziplist 的任意数据项前面插入一个新的数据项：\nunsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { return __ziplistInsert(zl,p,s,slen); } // 在 p 处 插入 s，s 的长度为 slen；插入后s占据p的位置，p及其后面的数据整体后移。其中 p 指向 ziplist 中某一个 entry 的起始位置，或者 zlend(当向尾部插入时) unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { // reqlen 表示 将 s 变成一个 entry 所需要的总字节数，即 prevlen,encoding,entry-data 的总长度 size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; // 随便使用一个一眼就能看出来的值表示当前变量未被逻辑初始化，避免 warning zlentry tail; if (p[0] != ZIP_END) { // 如果不是插入尾部，则根据p获取 p所在的 entry 的前一个 entry 的 prevlen，需要保存 prevlen的字节数保存在 prevlensize(1字节或者5字节，前面有介绍) ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); } else { // p 指向的是 尾部标志 unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) { // 获取 ziplist 最后一个 entry 的长度，保存在 prevlen 中 prevlen = zipRawEntryLength(ptail); } } // 尝试能否转化成整数 if (zipTryEncoding(s,slen,\u0026amp;value,\u0026amp;encoding)) { // 可以转化成 int，则 reqlen 即为存储此 int 所需的字节数，即 entry-data 的长度 reqlen = zipIntSize(encoding); } else { // 无法转换成 int，那就是字节数组，reqlen 就是要存入的字符串的长度，即 entry-data 的长度 reqlen = slen; } // reqlen reqlen += zipStorePrevEntryLength(NULL,prevlen); // 再加上 prevlen 的长度 reqlen += zipStoreEntryEncoding(NULL,encoding,slen); // 再加上 encoding 的长度 // 当不是向尾部插入时，我们必须确保下一个 entry 的 prevlen 等于当前 entry 的长度 int forcelarge = 0; // 【1】nextdiff 存储的是p的prevlen的变化值(新元素长度reqlen - p之前entry的prelen)，具体解释看代码后面【1】处的解释 nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 \u0026amp;\u0026amp; reqlen \u0026lt; 4) { nextdiff = 0; forcelarge = 1; // 这种情况下意味着，本来可以用 1 字节的，却使用了 5 个字节 } /* Store offset because a realloc may change the address of zl. */ // 存储 p 相对于 ziplist 的偏移量，因为 resize 可能改变 ziplist 的起始地址 offset = p-zl; // 到这一步已经能确定 ziplist 需要的总的容量了，调用 resize 调整 ziplist 的大小 zl = ziplistResize(zl,curlen+reqlen+nextdiff); // 重新定位 p p = zl+offset; // 将 p 以及其后面的数据移动为 s 挪地方，别忘了更新 zltail 的值 if (p[0] != ZIP_END) { // 在p前面腾出reqlen字节给新entry使用（将p move到p+reqlen，考虑了prelen缩减或增加） memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); // 更新 s 的后一个 entry（p+reqlen即p的新地址）的prevlen； if (forcelarge) // 【2】强制使用 5 字节存储，避免连锁更新时的大量重新分配空间操作，不进行缩容 zipStorePrevEntryLengthLarge(p+reqlen,reqlen); else // 计算 reqlen 进而判断使用 1 字节 还是 5 字节 zipStorePrevEntryLength(p+reqlen,reqlen); // 更新 zltail ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); // 更新zltail zipEntry(p+reqlen, \u0026amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); } } else { // 如果是在尾部插入，则直接修改 zltail 为 s ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); } // 如果 nexydiff 不等于0，整个 s 后面的 ziplist 的 prevlen 都可能发生变化，这里尝试进行维护 if (nextdiff != 0) { offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; // 改变的只是 p 后面的，前面的没变，因此 s 插入的位置没变 } // 存入 s 这个 entry p += zipStorePrevEntryLength(p,prevlen); p += zipStoreEntryEncoding(p,encoding,slen); if (ZIP_IS_STR(encoding)) { memcpy(p,s,slen); } else { zipSaveInteger(p,value,encoding); } // ziplist 的长度加 1 ZIPLIST_INCR_LENGTH(zl,1); return zl; } // 将 ziplist 的长度变成 len unsigned char *ziplistResize(unsigned char *zl, unsigned int len) { zl = zrealloc(zl,len); ZIPLIST_BYTES(zl) = intrev32ifbe(len); zl[len-1] = ZIP_END; return zl; } 解释【1】：这种情况发生在 插入的位置不是尾部 的情况，我们假设 p 的前一个元素为 p0，此时 p 的 prevlen 存储的是 p0 的长度。但是由于要将 s 插入到 p 之前，那么 p 的 prevlen 的值就应该变成 s 的长度，这样 p 本身的长度也就发生了变化，有可能变大也有可能变小。这个变化了多少的值就是 nextdiff，如果变大了，nextdiff 是正数，否则是负数。如果是负数，只有一种情况，那就是 p0 的长度大于 254，用 5 个字节存；而 s 的长度小于 254，用 1 个字节存就够了。\n解释【2】：关于 forcelarge，这是一个已经被修改后的 bug，大致意思是，这种操作发生在 连锁更新(90 行) 的时候，为了防止大量的重新分配空间的动作，如果一个 entry 的长度只需要 1 个字节就能够保存,但是连锁更新时如果原先已经为 prevlen 分配了 5 个字节,则不会进行缩容操作。关于为何，可以参考这篇文章：Redis 的一个历史 bug 及其后续改进，作者对这个 bug 进行了复现，以及提到了 Redis 对此作出的更新(提出了更优化的结构 listpack)。\n我们接着说 连锁更新。回忆一个 entry 的结构，其中 prevlen 表示前一个 entry 的长度：如果前一个结点长度小于 254，则 prevlen 占用 1 字节，否则占用 5 字节。现在， 考虑这样一种情况： 在一个压缩列表中， 有多个连续的、长度介于 250 字节到 253 字节之间的节点 e1 至 eN 。因为 e1 至 eN 的所有节点的长度都小于 254 字节， 所以记录这些节点的长度只需要 1 字节长的 prevlen 属性， 换句话说， e1 至 eN 的所有节点的 prevlen 属性都是 1 字节长的。此时，如果我们在 e1 前面插入一个长度大于 254 的元素 m，因为 e1 的 prevlen 仅为 1 字节，无法保存大于 254 的数，因此，我们还要对 ziplist 进行空间重分配操作，使得 e1 能够保存 m 的长度，即将 ziplist 的大小再增加 4 字节，让 e1 的 prevlen 大小由 1 字节变为 5 字节，这种操作我们称为 m 对 e1 发生了 扩展。回到刚才的情况，现在麻烦来了，e1 大小发生了变化，肯定超过了原来的 254，此时 e1 需要对 e2 进行扩展，又到后面，e2 需要对 e3 进行扩展……程序需要不断地对压缩列表执行空间重分配操作， 直到 eN 为止。\nRedis 将这种在特殊情况下产生的连续多次空间扩展操作称之为 “连锁更新”（cascade update）。我们看看 连锁更新 的具体实现：\n// p 指向第一个不需要更新的 entry unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) { size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; // 当 p 是 ziplist 的”尾巴“时停止更新 while (p[0] != ZIP_END) { zipEntry(p, \u0026amp;cur); // 【1】将 entry 解码称为一个易于操作的 entry 结构体，细节见代码后解释 rawlen = cur.headersize + cur.len; // 当前节点的长度 rawlensize = zipStorePrevEntryLength(NULL,rawlen); // 存储当前节点所需要的 prevlen 大小 // 没有下一个节点，直接返回 if (p[rawlen] == ZIP_END) break; // 获取 p 的下一个节点 zipEntry(p+rawlen, \u0026amp;next); // 如果下一个节点的 prevlen 等于当前节点的 长度，则没必要更新，直接退出循环 if (next.prevrawlen == rawlen) break; // 下一个节点的 prevlen 小于当前节点的长度(当前节点长度为 5 字节，next 的 prevlen 为1 字节) if (next.prevrawlensize \u0026lt; rawlensize) { // ziplist的地址可能发生改变，先记录 p 相对于zl起始位置的偏移量 offset = p-zl; // 额外需要申请的空间 5 - 1 = 4 extra = rawlensize-next.prevrawlensize; // 改变 ziplist 的容量 zl = ziplistResize(zl,curlen+extra); // 重新计算 p 的位置 p = zl+offset; /* Current pointer and offset for next element. */ np = p+rawlen; // next 的新地址 noffset = np-zl; // next新地址相对于 ziplist 头部的偏移量 // 更新 zltail if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra); } // 扩展 next 的 prevlen，并将数据拷贝 memmove(np+rawlensize, np+next.prevrawlensize, curlen-noffset-next.prevrawlensize-1); // 在扩展后的 next 的 prevlen 中重新记录 p 的长度 zipStorePrevEntryLength(np,rawlen); /* Advance the cursor */ // 更新 p 为下一个 entry p += rawlen; // 更新 p 的长度(需要加上扩展的 prevlen 的 extra 个字节) curlen += extra; } else { // 这种情况下，next 的 prevlen 足够表示 当前 p 的长度 if (next.prevrawlensize \u0026gt; rawlensize) { // next 的 prevlen \u0026gt; p 的长度(next.prevlen = 5 结点，p的长度小于 5 个结点)，此时应该 缩容，但出于性能以及操作的方便性(减少后续连锁更新的可能性)，我们通常不进行缩容，这个时候，直接将 next 的 prevlen 设置为 5 个结点 zipStorePrevEntryLengthLarge(p+rawlen,rawlen); } else { // 相等 zipStorePrevEntryLength(p+rawlen,rawlen); } // next 的长度并没有发生变化(没有缩容)，终止循环 break; } } return zl; } 解释【1】：“辅助结构体” zlentry，这个结构体与 ziplist 中的一个实际 entry 相对应，其作用是为了更加方便地操作一个 实际的 entry：\ntypedef struct zlentry { unsigned int prevrawlensize; // 存储 prevrawlen 所需要的字节数，同样也有 1字节 和 5字节之分 unsigned int prevrawlen; // 对应 prevlen unsigned int lensize; // 存储 len 所需要的字节数 unsigned int len; // 当前 entry 的长度 unsigned int headersize; // ziplist头部大小: prevrawlensize + lensize unsigned char encoding; // 编码方式 unsigned char *p; // 指向某个实际 entry 的地址 } zlentry; 其他的一些操作，比如删除、查找，过程与插入类似，无非就是各个 entry 地址的计算，删除时还有可能涉及到连锁更新。 这里不再描述，想了解的可以根据上面的思路自己研究源代码。\n6.3 总结 ziplist是 redis 为了节省内存，提升存储效率自定义的一种紧凑的数据结构，每一个 entry 都保存这上一个 entry 的长度，可以很方便地进行反向遍历； 添加和删除节点可能会引发连锁更新，极端情况下会更新整个ziplist，但是概率很小； 在 Redis 中，当元素个数较少时，哈希表(hset 等操作) 和 列表(lpush 等操作) 的底层结构都是 ziplist。 7. 紧凑列表 源码文件：listpack.h\n实现文档：Listpack specification\n紧凑列表是 压缩列表 的升级版，目的是在未来代替 ziplist。\n有时间再完善。\n二、 Redis 对象对应的数据结构 前面大致介绍了 简单动态字符串 sds、双端链表 adlist、字典 dict、跳表 skiplist、整数集合 intset 和 压缩列表 ziplist 等基础数据结构，同时我们知道 Redis 中有 字符串对象(string)、列表对象(list)、哈希对象(hash)、集合对象(set) 和 有序集合对象(zset) 等五种对象，他们都至少用了上面一种基础数据结构来实现。在 Redis 中，客户端的一条命令以及参数会被解释成一个 robj 结构体：\n源码文件： server.h\ntypedef struct redisObject { unsigned type : 4; // 类型 unsigned encoding : 4;\t// 编码 unsigned lru : LRU_BITS; // 对象最后被访问的时间，我们暂时不关注 LRU int refcount;\t// 引用次数 void *ptr;\t// 指向实现对象的数据结构 } robj; /* Object types */ #define OBJ_STRING 0 /* String object. */ #define OBJ_LIST 1 /* List object. */ #define OBJ_SET 2 /* Set object. */ #define OBJ_ZSET 3 /* Sorted set object. */ #define OBJ_HASH 4 /* Hash object. */ /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The \u0026#39;encoding\u0026#39; field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 // 简单动态字符串 sds #define OBJ_ENCODING_INT 1 // long 类型 #define OBJ_ENCODING_HT 2 // 字典 dict #define OBJ_ENCODING_ZIPMAP 3 // zipmap(弃用) #define OBJ_ENCODING_LINKEDLIST 4 // 双端链表 adlist #define OBJ_ENCODING_ZIPLIST 5 // 压缩列表 ziplist #define OBJ_ENCODING_INTSET 6 // 整数集合 intset #define OBJ_ENCODING_SKIPLIST 7 // 跳表 skiplist #define OBJ_ENCODING_EMBSTR 8 // 采用embstr编码的sds #define OBJ_ENCODING_QUICKLIST 9 // qunicklist，用于列表 #define OBJ_ENCODING_STREAM 10 // 紧凑列表 listpack #define LRU_BITS 24 obj 的作用大致为：\n为多种数据类型提供一种统一的表示方式。 允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。 支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。 说到底， robj 所表示的就是 五种 Object types 和 11 中 Object encoding 之间的对应方式，起到一个桥梁作用。这种对应关系可用如下的图来表示：\n","permalink":"http://localhost:1313/posts/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-1-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","summary":"\u003cp\u003e首先明确，\u003ccode\u003eRedis\u003c/code\u003e 是一个\u003cstrong\u003e使用 C 语言编写的键值对存储系统\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 是众所周知的 “\u003cstrong\u003e快\u003c/strong\u003e”，一方面，它是一个内存数据库，所有的操作都是在\u003cstrong\u003e内存\u003c/strong\u003e中完成的，内存的访问速度本身就很快；另一方面，得益于它\u003cstrong\u003e底层的数据结构\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 的常见类型可在这个网页找到：\u003ca href=\"https://redis.readthedocs.io/en/2.4/index.html\"\u003eRedis 命令参考简体中文版\u003c/a\u003e，其使用到的底层数据结构有如下六种：\u003cstrong\u003e简单动态字符串\u003c/strong\u003e、\u003cstrong\u003e双向链表\u003c/strong\u003e、\u003cstrong\u003e压缩列表\u003c/strong\u003e、\u003cstrong\u003e哈希表\u003c/strong\u003e、\u003cstrong\u003e跳表\u003c/strong\u003e和 \u003cstrong\u003e整数数组\u003c/strong\u003e。本篇文章，将具体了解这些底层数据结构的实现。\u003c/p\u003e","title":"Redis源码阅读--1.基础数据结构与对象"},{"content":"一、常见的索引类型 1. 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 创建自定义的哈希索引：\n通过一个实例来说明：\n提出问题：假如我们要存储大量的URL，同时还有通过 URL 查询该条记录的需求，应该如何建立索引？ 调研：如果直接在 URL 上建立索引，那么索引会很长，并且很大 解决方案：删除原来 URL 上的索引，新增一个被索引的 url_crc 列，存储 URL 列被 CRC32 之后的值，之后的查询可通过这个索引来查。缺点是还要花时间维护这个索引列。 # 建表 CREATE TABLE url_demo ( id int unsigned NOT NULL auto_increment, url varchar(255) NOT NULL, url_crc int unsigned NOT NULL DEFAULT 0, PRIMARY KEY(id) ); # 为了减少维护工作，可以创建一个触发器 DELIMITER // CREATE TRIGGER url_demo_crc_ins BEFORE INSERT ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; CREATE TRIGGER url_demo_crc_upd BEFORE UPDATE ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; // DELIMITER ; # 之后可验证增删改查 INSERT INTO url_deml(url) VALUES(\u0026#34;https://www.baidu.com\u0026#34;); SELECT * FROM url_demo; +----+-----------------------+------------+ | id | url | url_crc | +----+-----------------------+------------+ | 1 | https://www.baidu.com | 3010065587 | +----+-----------------------+------------+ UPDATE url_demo SET url=\u0026#34;https://www.google.com\u0026#34; WHERE id=1; SELECT * FROM url_demo; +----+------------------------+-----------+ | id | url | url_crc | +----+------------------------+-----------+ | 1 | https://www.google.com | 857627499 | +----+------------------------+-----------+ # 查询某个具体的URL时，必须使用下面的查询方法： SELECT * FROM url_demo WHERE url_crc=CRC32(\u0026#34;https://www.google.com\u0026#34;) AND url=\u0026#34;https://www.google.com\u0026#34;; 2. B-Tree 索引 当人们谈论索引时，如果没有特别指明类型，那多半说的是 B-Tree 索引。它使用 B 树(部分引擎使用 B+树)作为底层的数据结构，这通常意味着被索引的值都是按顺序存储的(首先是个 二叉排序树)，并且每一个叶子节点到根节点的举例相同(变形的 多叉排序树)。树的深度和表的大小直接相关。\n假如我们有如下数据表：\nCREATE TABLE people ( last_name varchar(64) NOT NULL, first_name varchar(64) NOT NULL, dob date NOT NULL, gender enum(\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;) NOT NULL, key(last_name, first_name, dob) ); 下图显示了该索引时如何组织数据的：\n以下情况，索引(key(last_name, first_name, bob))是有效的：\n全值匹配：指查询的列和索引中的列完全匹配(字段以及对应的字段顺序)，例如 SELECT * FROM people WHERE last_name= ‘Allen’ AND first_name = 'Cuba' AND bob = '1960-01-01'； 最左前缀匹配：索引的顺序非常重要： 可以匹配所有last_name = ‘Allen’的人，因为 last_name 是索引列中最左边的； 可以只匹配某一列的值得开头部分，如 last_name 全部以 K 开头，即 last_name like 'K%’，注意，这里也是针对最左边的列； 可以匹配 last_name 在 Allen 和 Barrymore 之间的人，即 last_name \u0026gt; ‘Allen’ AND last_name \u0026lt; 'Barrymore’，这里也是针对最左边列； 精准访问某一列并范围匹配另一列：例如第一列last_name全匹配，第二列first_nbame 范围匹配；或者last_name和first_name全匹配，第三列bob范围匹配。 只访问索引的查询：即 覆盖索引。即select的字段就属于索引列，而不用通过“回表”再拿一次。关于覆盖索引，后面会详细介绍。 以下情况，索引会失效（即不会使用之前创建的索引 key(last_name, first_name, bob)）：\n单独列非最左列，索引失效，即 如果不是按照索引的最左列开始查找，无法使用索引。例如：无法查找 WHERE first_name = ‘Bill’；例如 WHERE bob = '1960-01-01’；例如 WHERE first_name like 'K%'。因为查询的列都不是该索引的最左列。同理，WHERE last_name like '%L’也会失效。 跳过某一列，索引失效。即 WHERE last_name='Allen' AND bob='1960-01-01’也不会使用该索引，因为跳过了列first_name。 某列范围查询，右边所有列无法使用索引优化查询。如 WHERE last_name='Allen' AND first_name like ‘J%’ AND bob='1960-01-01’，那么 bob 列无法使用索引优化查询，因为中间的first_name LIKE是一个范围条件。 如果使用B-Tree，创建多列索引时，列的顺序非常重要！\n二、高性能的索引策略 正确地创建和使用索引是实现高性能查询的基础。下面介绍如何正确地运用索引。\n1. 查询时，索引列单独放在比较符号的一侧 如果查询中的列不是独立的，则 MySQL 不会使用索引。 独立的列 是指索引列不能是表达式的一部分，也不能是函数的参数。\n下面这个查询就无法使用score列的索引：\nSELECT * FROM student WHRER score + 1 = 90; 我们都知道上述查询中表达式的值是 89，但是MySQL 无法解析这个方程式。我们应该养成简化 MySQLWHERE条件的习惯，始终将索引列单独放在比较符号的一侧。\n2. 前缀索引和索引选择性 索引选择性是指 不重复的索引数(I) 和 数据表的记录总数(S) 的比值，即 $I/S$，根据其计算方式可知，$I/S \u0026lt;= 1$，并且索引选择性越高，查询性能越高，因为索引选择性高的索引可以让 MySQL 在查询的时候 过滤掉更多行。单一列的索引的选择性是 1，是最好的。\n既然单一列的索引选择性是最好的，我们为什么还要讨论这个问题？想一下要对 某一些很长的列建立索引，这时索引会变的非常大，有可能出现索引文件远大于数据文件的情况。这个时候对整个字段建立索引就显得不太明智，此时索引选择性可以作为一个辅助工具，帮助我们 选择足够长的前缀以保持较高的选择性，同时又不能太长。\n如何选择合适的前缀长度？方法是 计算完整列的选择性，然后逐个计算前缀的选择性，选择最接近完整列的那一个。\n假如完整列的选择性为 0.0312，而不同前缀长度对应的选择性结果为：\n当长度大于 7 时，再增加前缀长度，性能提升的幅度就已经很小了。于是建立索引：\nALTER TABLE demo ADD KEY(city(7)); 优点：使索引又快又小的这种方法；\n缺点：无法使用前缀索引进行 GROUP BY 和 ORDER BY，也无法进行覆盖扫描(覆盖索引)。\n3. 多列索引 我们经常会听到有人说“把 WHERE 条件里面的列都建上索引”这种模糊的建议，但事实上，如果不从实际出发，大多数情况下，在多个列上简历单独的索引并不能提高 MySQL 的查询性能。\nMySQL 5.0 之后引入了一种叫 索引合并(Index Merge) 的策略，一定程度上可以提高多个单列索引查询时的性能。\n关于 索引合并 ，看这篇文章：索引合并\n在以下情况下，建议使用多列索引而不是在每个单独列上建立索引：\n当出现对多个索引做相交操作时(通常是多个 AND 操作)，这通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引； 当出现对多个索引做联合操作时(通常是多个 OR 操作)，通常需要耗费大量的 CPU 和内存用以对结果的缓存、归并和排序上，特别是某些索引的选择性不高时，需要合并扫描大量的数据。 4. 选择合适的列顺序 当使用 B-Tree 索引时，由于其“最左匹配”的性质，索引列的顺序往往意味着索引首先按照最左列进行排序，然后是第二列。对于如何选择多列索引的顺序，有一个经验法则： 将选择性最高的列放在索引最前列。\n5. 聚簇索引 MySQL 的 InnoDB 索引数据结构是 B+树，主键索引叶子节点的值存储的就是 MySQL 的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提。\n首先，用一句话解释什么是聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引。所以主键就是聚簇索引。\n对应地，什么是非聚簇索引？也称二级索引，索引的存储和数据的存储是分离的，在 InnoDB 引擎中，二级索引中存储的是主键值，先通过查找二级索引得到对应的主键值，再通过主键值回表查询需要的字段。\n二级索引使用主键值当做行的指针，会让二级索引占用更多的空间，换来的好处是，InnoDB 在移动行时无需更新索引中的这个指针——这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。\n在 InnoDB 中，主键一定是聚簇索引，InnoDB 一定有主键(如果没有手动设定，InnoDB 会默认创建一个)，并且一张表只允许有一个聚簇索引。\n建议：InnoDB 中应该尽可能按照主键的顺序去插入数据，一般使用一个递增的 bigint 类型 作为主键。最差的情况是使用值完全随机的列如 UUID 作为主键！\n6. 覆盖索引 前面提到过，InnoDB 中，非聚簇索引所存储的值为主键值，要想获得其他列的值，还要进行一个被称为 “回表” 的操作——也就是说，使用非聚簇索引查询更多列，要进行两次查询。但是想一想，如果我们差的刚好就是主键 id，如 SELECT id FROM student WHERE name='Tom';，此时我们需要的列就在二级索引中，不需要再执行“回表”操作，这个操作，可以极大地提高性能。\n如果一个索引包含(或者说 覆盖) 所有查询的字段的值，我们就称为**“覆盖索引”**。\n为什么覆盖索引能提高性能？因为减少了“回表”的操作，减少了很多次随机 IO。\n7. 学会使用 EXPLAIN 在需要执行的 SQL 语句前面加上EXPLAIN，可以查询和分析这条 SQL 语句的执行记录，对我们优化查询效率有很大的帮助。\n先看一个EXPLAIN的示例：\nmysq\u0026gt; explain select * from city\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: city partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 366 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 其他的几个列暂时不考虑，只对 type 和 EXTRA 做记录：\ntype 关联类型，或访问类型——MySQL 如何查找表中的行。以下按照从最差到最优的方式介绍：\nALL： 全表扫描。 index：按照索引次序扫描。跟全表扫描一样，只不过扫描时按照索引顺序进行而不是按照每一行。它的优点是：避免了排序操作。缺点是：要承担按索引次序读取整个表的开销(如果是非聚簇索引，那么索引次序是有序的，但存储的主键不一定是有序的，回表的时候进行的就是随机 IO，此时开销会更大，还不如 ALL)。如果在EXTRA列中看到“Using index”，说明 MySQL 正在使用覆盖索引。 range：范围扫描，即带有WHERE或BETWEEN或\u0026lt;等比较符号的查询语句。比全表扫描好一些，因为不需要遍历全部索引，只需要从满足条件的行开始计算。开销与index相同。 ref：非主键 非唯一索引 等值查找。 eq_ref：主键索引 或 非空唯一索引 进行等值查找。 cost：常量连接，表最多只有一行匹配，通常用于 主键 或者 唯一索引 进行等值比较。 system：系统表，少量数据，往往不需要进行磁盘 IO (可以当成 cost 连接的特例) extra extra 表示 MySQL 如何解析这条查询，参数更多地显示一些关于索引的信息。它的最常用的选值如下：\nusing index：表示本次查询将使用 覆盖索引，避免了 回表 的操作，即 where 筛选条件是索引的前导列 并且 select 选择的列被索引覆盖，没有 回表 操作。 using where：限制了哪一行，也就是说，读取结束之后使用了 Table Filter 进行了过滤。不管查询条件有没有覆盖索引，只要筛选条件没有使用索引，就会有 using where。 using where; using index：查询的列被索引覆盖，但是 筛选条件不是前导列 或者 筛选条件是前导列但是使用了范围查询。 NULL：查询的列未被索引覆盖，但是筛选条件使用了索引的前导列。这种情况意味着用到了索引，但是 select 的字段没有被索引覆盖，因此还要进行 回表 操作，“不是纯粹地使用索引，也没有完全用到索引”，所以为 NULL(没有信息)。 using index condition：查询的列没有被索引全部覆盖，筛选条件使用了索引的前导列的范围查询 或者 查询条件使用到了索引但还有一些别的条件。 上面的这些情形可用如下的表格总结：\n","permalink":"http://localhost:1313/posts/mysql%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95/","summary":"\u003ch2 id=\"一常见的索引类型\"\u003e一、常见的索引类型\u003c/h2\u003e\n\u003ch3 id=\"1-哈希索引\"\u003e1. 哈希索引\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e哈希索引(Hash Index)\u003c/strong\u003e 基于哈希表实现，\u003cstrong\u003e只适合精确匹配，不适合范围查找\u003c/strong\u003e。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算\u003ccode\u003e哈希code\u003c/code\u003e，通过 \u003cstrong\u003eK-V\u003c/strong\u003e 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\u003c/p\u003e","title":"MySQL关于索引"},{"content":"1. 堆排序 堆 是一种数据结构，它具有如下特征：\n是一棵完全二叉树 父节点的值 \u0026gt; 子节点的值 1.1 完全二叉树 若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是 完全二叉树。\n完全二叉树有一个很重要的特点，它的元素可以全部放在一个数组中，这个数组中的元素排列非常紧密，不会出现零值的情况。比如下面这棵树，对应的数组为： [25, 14, 13, 4, 2, 10]。\n如果我们从上到下、从左到右的顺序去遍历这棵树，会发现，元素顺序与数组中完全对应。于是会有下面的公式：\n设数组中父节点的 index 值为i，则左孩子的 index 值为 2*i+1，右孩子的 index 值为 2*i+2。这样数组和数的关系就对应上了。这是堆排序的基础。\n1.2 heapify 我们称 将一棵树变成堆的过程 称为 heapify。具体来说是将 parent、left 和 right这三个结点，通过交换，使得 parent 为最大(left和right哪个大没关系)，因为数的定义是递归的，所以上面这个交换过程也是递归的。此时需要决定的是从下到上，还是从上到下。答案是如果是大根堆，从下到上进行 heapify 过程，因为从上到下的，处理完父节点，还不确定这个父节点是不是就是整个堆中的最大，而从下到上可以看成是一个不断往上 “喂” 最大值的过程。可以写出代码：\n// heapify 从数组的第i个元素为父节点，使其符合大根堆的特性。前提，左右子树均已经是大根堆了 func heapify(arr []int, n int, i int) { if i \u0026gt;= n { return } // 第i个结点的左右孩子分别为 left := 2*i + 1 right := 2*i + 2 // 求得父节点、左孩子、右孩子之间的最大值 maxIndex := i if left \u0026lt; n \u0026amp;\u0026amp; arr[left] \u0026gt; arr[maxIndex] { maxIndex = left } if right \u0026lt; n \u0026amp;\u0026amp; arr[right] \u0026gt; arr[maxIndex] { maxIndex = right } // 如果发生了交换，需要递归去处理对应的子树 if maxIndex != i { // 交换 使得parent为最大的那个 arr[i], arr[maxIndex] = arr[maxIndex], arr[i] //fmt.Println(arr[maxIndex], arr[left], arr[right]) // 此时，修改了原来的结构，为了保证交换后的子树也继续是大根堆，这里递归调用调整子树 heapify(arr, n, maxIndex) } } 1.3 build heap 当我们从下到上构建一个大根堆的时候，没必要从最后一个元素开始，需要从最后一个有孩子的父节点开始，所以第一步是先找到 最后一个有孩子的父节点。方法很简单，找到最后一个孩子，再根据他们之间的关系很容易就能求得其父节点的索引值。之后遍历所有的有孩子的节点，即剩下的 13 , 14, 25，这三个元素刚好按照数组索引的顺序递减，因此可以写出代码：\n// buildHeap 从底向上构建大根堆 func buildHeap(arr []int) { n := len(arr) parent := (n - 1 - 1) / 2 // n-1为数组最后一个元素的index，其父节点为 ((n-1) - 1) / 2 for i := parent; i \u0026gt;= 0; i-- { // 从这个父节点开始，一直到第一个元素，从下到上构建不断heapify heapify(arr, n, i) } } 1.4 heap sort 构建出大根堆之后，堆顶(也就是数组index=0)的元素就是最大值。此时，我们将数组第一个元素和最后一个元素交换位置，之后缩小数组长度再次从头到尾进行 heapify ，之后再交换，最后的结果就是 数组从尾巴到头的元素一次递减。\nfunc heapSort(arr []int) { buildHeap(arr) // 构建大根堆 // 最后一个元素 与 第一个元素(最大)交换，之后再次heapify，再交换，结果就是从尾到头数值依次减小 for i := len(arr) - 1; i \u0026gt;= 0; i-- { arr[0], arr[i] = arr[i], arr[0] heapify(arr, i, 0) } } 2. 插入排序 它的工作原理是构建有序序列，对于未排序的数据，在已经排好序的序列中从后向前扫描，放入合适的位置。\n优点是：对近乎有序的一组数排序，其时间复杂度可以接近线性。 这个特性非常重要！谨记！！\n步骤：\n第一步，将第一个元素看成有序序列，第二个元素到最后一个元素看成未排序的序列； 从头到尾扫描未排序的序列，将这个元素插入到前面的有序序列的合适位置。为了 稳定性 的目的，如果某个元素和有序序列中的某个元素相同，应该将这个元素放在有序序列元素的后面。 // insertionSort 插入排序 func insertionSort(arr []int) { sortedIndex := 0 // 有序序列的最后一个元素 // 遍历所有的未排序元素 for i := sortedIndex + 1; i \u0026lt; len(arr); i++ { // 从当前元素开始向前遍历有序序列 for j := i; j \u0026gt; 0; j-- { // 当前值大于等于前面的，终止循环 if arr[j-1] \u0026lt;= arr[j] { break } // 如果当前值比前一个小，交换，之后循环再不断交换 arr[j-1], arr[j] = arr[j], arr[j-1] } } } 3. 希尔排序 是插入排序的改进版本，更高效一些，但是它是不稳定的。具体步骤如下：\n以 gap 为间隔分组 分好的组内内部排好序 降低 gap，重复上述步骤，直到 gap 变成 1，此时变成对整个数组进行排序 有一个问题，组内排序，采用什么方法？答案是 插入排序法，原因就是，在 gap 不断减小的过程中，数组主键接近有序，此时借助插入排序的优点：对近乎有序的一组数排序，其时间复杂度可以接近线性。是一个不错的选择。\nfunc shellSort(arr []int) { gap := 1 // 计算gap，简单点，可以让gap变成数组长度的一半 for gap \u0026lt; len(arr)/3 { gap = gap*3 + 1 } for gap \u0026gt; 0 { for i := gap; i \u0026lt; len(arr); i++ { tmp := arr[i] j := i - gap // 每次之和当前组内前面的元素比较交换 for j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp { arr[j+gap] = arr[j] j -= gap } arr[j+gap] = tmp } gap /= 3 // 更新gap } } 4. 快速排序 采用的是“分而治之”的思想。步骤如下：\n第一步，挑出基准元素(一般取第一个元素) 对数组进行排序，使得所有小于基准的排在前面，大于基准的排在基准后面。最后返回分区的位置。这个操作我们称之为 partition。 递归地 把小于基准值元素的子数列和大于基准值元素的子数列排序 func quickSort(arr []int) []int { return _QuickSort(arr, 0, len(arr)-1) } func _QuickSort(arr []int, left, right int) []int { if left \u0026lt; right { partitionIndex := partition(arr, left, right) _QuickSort(arr, left, partitionIndex-1) _QuickSort(arr, partitionIndex+1, right) } return arr } func partition(arr []int, startIndex, endIndex int) int { var ( pivot = arr[startIndex] // 基准 left = startIndex right = endIndex ) for left != right { // right指向倒数第一个小于基准的数 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026lt; arr[right] { right-- } // left指向顺数第一个大于基准的 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026gt;= arr[left] { left++ } // 交换left和right处的值 if left \u0026lt; right { arr[left], arr[right] = arr[right], arr[left] } } // 此时left=right，将left与pivot处的值交换即可 arr[startIndex], arr[left] = arr[left], arr[startIndex] return left } ","permalink":"http://localhost:1313/posts/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","summary":"\u003ch2 id=\"1-堆排序\"\u003e1. 堆排序\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e堆\u003c/strong\u003e 是一种数据结构，它具有如下特征：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e是一棵完全二叉树\u003c/li\u003e\n\u003cli\u003e父节点的值 \u0026gt; 子节点的值\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"11-完全二叉树\"\u003e1.1 完全二叉树\u003c/h3\u003e\n\u003cp\u003e若设二叉树的深度为\u003ccode\u003eh\u003c/code\u003e，除第 \u003ccode\u003eh\u003c/code\u003e 层外，其它各层 \u003ccode\u003e(1～h-1)\u003c/code\u003e 的结点数都达到最大个数，第 \u003ccode\u003eh\u003c/code\u003e 层所有的结点都连续集中在最左边，这就是 \u003cstrong\u003e完全二叉树\u003c/strong\u003e。\u003c/p\u003e","title":"排序算法"},{"content":"位运算 位运算讲究技巧，需要多积累经验。\n一、背景知识 Go 语言支持的 位运算符 如下：\n运算符 描述 规则 \u0026amp; 按位 与 二者同为 1 时结果才为 1，否则为 0 | 按位 或 二者同为 0 时结果才为 0，否则是 1 ^ 按位 异或 相同为 0，相异为 1 \u0026laquo; 左移 n 位，相当于乘以 2 的 n 次方 后面补 0 \u0026raquo; 右移一位，相当于除以 2 的 n 次方 截掉最后一位 1. 与 将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的对应位同为 1 时，该位才为 1，否则为 0。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a \u0026amp; b) // 0001 0100 上述例子中，我们从最后一位开始，逐位运算。可以看到只有 倒数第3位 和 倒数第5位 都是 1，结果中也只有倒数第 3 位和倒数第 5 位是 1。\n规律：\n任何数 \u0026amp; 0 = 0； 任何数 \u0026amp; 任何数 = 任何数； 2.或 将参与运算的两个数 各对应的二进制位 相或。只有当二者对应位全部是 0 时，该位结果才是 0，其他情况结果全为 1。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0011 1111 规律：\n任何数 | 0 = 任何数 任何数 | 任何数 = 任何数 3. 异或 逐位异或，对应位相同，结果为 0，否则为 1——可以理解为 “抵消 1” 效果。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0010 1011 规律：\n任何数 ^ 任何数 = 0 任何数 ^ 0 = 任何数 任何数 ^ 1 = ~任何数(按位取反) 二、经典题目 1. 二进制中 1 的个数 LeetCode 题目： 191. 位 1 的个数 1.1 题目描述 请实现一个函数，输入一个整数，输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n举例：\n输入：00000000000000000000000000001011 输出：3 解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 \u0026#39;1\u0026#39;。 1.2 思路 思路 1 最后一位通过和 1 进行 与运算，可以判断最后一位是否为 1；然后将要计算的数字向右移动 1 位，再计算是否最后一位是否为 1。逐渐循环，知道直到要计算的数变成 0。\nfunc hammingWeight(num uint32) int { result := 0 // 保存1出现的次数 for num \u0026gt; 0 { if num\u0026amp;1 == 1 { result++ // 最后一位是 1 } num \u0026gt;\u0026gt;= 1 // 将原数右移一位 } return result } 思路 2 某一位通过和 1 进行 与运算，可以判断该位是是否为 1。题目指定了 32 位无符号整数，那么循环 32 次，从最后一位开始逐位判断，如何向前移动？左移一位即可。\nfunc hammingWeight(num uint32) int { result := 0 base := uint32(1) for i := 0; i \u0026lt; 32; i++ { if base\u0026amp;num != 0 { result++ } base \u0026lt;\u0026lt;= 1 } return result } 思路 3 出发点：n \u0026amp; (n-1)，会消除 n 最后一个 1。因此，n \u0026amp; (n-1) 总是能把 n中最低位的 1 变成 0 ，并保持其他位不变。具体什么原因，暂时不做深究。\nfunc hammingWeight(num uint32) int { result := 0 for num \u0026gt; 0 { result++ num \u0026amp;= num - 1 } return result } 2. 判断一个数是否为 2 的幂 LeetCode 题目：231. 2 的幂 2.1 题目描述 给定一个整数，编写一个函数来判断它是否是 2 的幂次方。\n示例：\n输入: 1 输出: true 解释: 20 = 1 2.2 解题思路 如果将 2 的所有次幂的二进制写出来，你会发现这些数的规律：最高位都是 1，其余位全是 0。也就是说，如果一个数为 2 的次幂，那么它只有一个 1，而且是在最高位，同时也是最后一个 1。再回想一下上一题中的思路三，n \u0026amp; (n-1) 会消除最后一个 1，于是乎：\nfunc isPowerOfTwo(n int) bool { return n \u0026gt; 0 \u0026amp;\u0026amp; n\u0026amp;(n-1) == 0 } 3. 使用位运算求和 LeetCode 题目：剑指 Offer 65. 不用加减乘除做加法 3.1 题目描述 写一个函数，求两个整数之和，要求在函数体内不得使用 “+”、“-”、“*”、“/” 四则运算符号。\n举例：\n输入: a = 1, b = 1 输出: 2 提示：\na, b 均可能是负数或 0 结果不会溢出 32 位整数 3.2 解题思路 我们用 n 表示无进位和，c 表示进位，那么 sum = a + b = n + c，而位运算可以分别计算出 n 和 c。以两个 1 位的二进制数求和为例：\na b 无进位和 n 进位 c 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 10 从上表中可以看出，n = a ^ b，c = (a\u0026amp;b) \u0026lt;\u0026lt; 1。借用 leetcode 上大神的一张图：\n但是在 sum = n + c 中还是使用了加法，而这种情况我们依旧可以使用上面的规律。这里可以使用一个循环来解决，需要存储n 和 c，循环直到c = 0 时停止，而此时n 即为结果。\nfunc add(a,b int) int { /* * 循环解法 for b != 0 { b, a = (a\u0026amp;b) \u0026lt;\u0026lt; 1, a ^ b } return a */ /* * 递归解法，比上面的循环解法更清晰 if b == 0 { return a } return add(a ^ b, (a \u0026amp; b) \u0026lt;\u0026lt; 1) */ } 4. 数组中出现的次数 LeetCode 题目：136. 只出现一次的数字 4.1 题目描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,1] 输出: 1 4.2 解题思路 回想前面背景知识中的 异或 的特性：任何数 ^ 任何数 = 0，并且 任何数 ^ 0 = 任何数。所以思路很明显，全部进行 异或 操作，出现两次的都会被“抵消”，最后剩下那个“没人要的”，就是我们要找的。\nfunc singleNumber(nums []int) int { if len(nums) == 0 { return 0 } // 整体异或运算 for i:=1;i\u0026lt;len(nums);i++ { nums[0] ^= nums[i] // 使用已有数组的第0个位置，节省空间 } return nums[0] } 4.3 进阶——只出现一次的数字 II LeetCode 题目：137. 只出现一次的数字 II 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,3,2] 输出: 3 使用一个 map 的解法这里没必要说了，因为使用了额外空间。\n思路 1 使用数学规律法——原数组去重、再乘以 3 得到的值，刚好就是要找的元素的 2 倍。Go 中没有 set 的这种数据结构，这里提供 Python 解法：\ndef singleNumber(nums){ return int((sum(set(nums))*3 - sum(nums))/2) } 思路 2 回想之前的 异或，发现有两个 1，该位结果是 0；二进制加法中，两个 1 相加，产生了进位，抛弃进位，其结果也是 0——这个过程，可以看成是对应位上 1 的个数对 2 取模的结果。如果是三个数呢？是不是三个数的对应位都是 1 的时候，该位结果才是 0，否则就是 1——对应位上的 1 的个数对 3 取模即可。\nfunc singleNumber(nums []int) int { result := 0 for i := 0; i \u0026lt; 64; i++ { // int至少32位，一般都是64位 // 初始化每一位1的个数为0 number := 0 for _, k := range nums { // 通过右移i位的方式，计算每一位1的个数 number += (k \u0026gt;\u0026gt; i) \u0026amp; 1 } // 对3取模后 最终将抵消后剩余的1放到对应的位数上 res |= (number) % 3 \u0026lt;\u0026lt; i } return res } 再如果 除 1 个元素外，每个元素出现了 4 次呢？原理一样，对 4 取模即可。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%BD%8D%E8%BF%90%E7%AE%97/","summary":"\u003ch1 id=\"位运算\"\u003e位运算\u003c/h1\u003e\n\u003cp\u003e位运算讲究技巧，需要多积累经验。\u003c/p\u003e\n\u003ch2 id=\"一背景知识\"\u003e一、背景知识\u003c/h2\u003e\n\u003cp\u003eGo 语言支持的 \u003cstrong\u003e位运算符\u003c/strong\u003e 如下：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e运算符\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e描述\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e规则\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026amp;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e与\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 1 时结果才为 1，否则为 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e|\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 0 时结果才为 0，否则是 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e^\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e异或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e相同为 0，相异为 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026laquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e左移 n 位，相当于乘以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e后面补 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026raquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e右移一位，相当于除以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e截掉最后一位\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"1-与\"\u003e1. 与\u003c/h3\u003e\n\u003cp\u003e将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的\u003cstrong\u003e对应位同为 1 时，该位才为 1，否则为 0\u003c/strong\u003e。\u003c/p\u003e","title":"LeetCode-位运算"},{"content":"leetcode 上 三数之和 问题：\n15. 三数之和 259. 较小的三数之和 16. 最接近的三数之和 1. 题目描述 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素a，b，c ，使得 a + b + c = 0？请你找出所有满足条件且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例：\n给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 2. 解题思路 直接跳过暴力解法，说说此题的思路。\n首先，对这个数字排一下序；\n之后，采取固定一个数，同时用双指针来查找另外两个数的方式求解：\n比如，先固定第一个元素，下一个元素设置为 left 指针，最后一个元素设置为 right 指针； 计算这三个数之和是否为 0，如果是，这就是一组满足条件的三元组；如果不是，看结果与 0 的关系，如果小于 0，则 left 向右移动，再比较，如果大于 0，则 right 向左移动一位，再比较。 当然，如果当 固定元素+left \u0026gt; 0 或者 固定元素+right \u0026lt; 0 时，就没必要再去比较了。 以下是代码实现：\nfunc threeSum(nums []int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { // 最外层循环为 固定指针 pin = i left = i + 1 // left 为固定指针的下一个元素 right = l - 1 // right 为最后一个元素 // 如果最小的大于0，不用再循环了 if nums[pin] \u0026gt; 0 { break } // 跳过 pin 相同的 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 找到一个三元组 if nums[pin]+nums[left]+nums[right] == 0 { result = append(result, []int{nums[pin], nums[left], nums[right]}) // 跳过left相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } // 跳过 right 相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1] { right-- } // 找到之后，同时改变 left++ right-- } else if nums[pin]+nums[left]+nums[right] \u0026lt; 0 { // 左指针向右移动 left++ } else { right-- } } } return result } 3. 进阶 1——较小的三数之和 给定一个长度为 n 的整数数组和一个目标值 target，寻找能够使条件 nums[i] + nums[j] + nums[k] \u0026lt; target 成立的三元组 i, j, k 个数（0 \u0026lt;= i \u0026lt; j \u0026lt; k \u0026lt; n）。\n示例：\n输入: nums = [-2,0,1,3], target = 2 输出: 2 解释: 因为一共有两个三元组满足累加和小于 2: [-2,0,1] [-2,0,3] 直接上代码：\nfunc threeSumSmaller(nums []int, target int) int { result := 0 // 满足条件的三元组数目 sort.Ints(nums) // 先排序 var pin, left, right int // 固定、左、右 指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { pin = i // 固定指针 left = i + 1 // 左指针指向固定指针的下一个 right = l - 1 // 右指针指向最后一个元素 for left \u0026lt; right { if nums[pin]+nums[left]+nums[right] \u0026gt;= target { // 说明这个 right 不能出现在三元组中, right 左移一位 right-- } else { // 从 left 到 right 之间的那几对都符合条件， left 右移一位 result += right - left left++ } } } return result } 4. 进阶 2——最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1 输出：2 解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 代码如下：\nfunc threeSumClosest(nums []int, target int) int { result := math.MaxInt32 // 结果 sort.Ints(nums) // 先排序 var pin, left, right int // 固定指针 左指针 右指针 l := len(nums) // 数组长度 // 求绝对值 abs := func(a int) int { if a \u0026lt; 0 { return -1 * a } return a } // 更新 result updateFunc := func(sum int) { if abs(sum-target) \u0026lt; abs(result-target) { result = sum } } for i := 0; i \u0026lt; l-2; i++ { pin = i left = i + 1 right = l - 1 // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 如果 right 左移一位，结果离得更远了，说明需要left向右移 //result = min(result, nums[pin]+nums[left]+nums[right]) sum := nums[right] + nums[left] + nums[pin] if sum == target { return target } updateFunc(sum) if sum \u0026gt; target { // 此时需要向左移动 right，并且移动到下一个不相等的 tmp := right - 1 for left \u0026lt; tmp \u0026amp;\u0026amp; nums[tmp] == nums[right] { tmp-- } right = tmp } else { // 向右移动left tmp := left + 1 for tmp \u0026lt; right \u0026amp;\u0026amp; nums[tmp] == nums[left] { tmp++ } left = tmp } } } return result } 5. 总结 解决此类问题，一般都是 升序后，外层循环 + 内层双指针 思路。其中最关键的是 左右指针移动的条件，一般都是和 target 比大小，大于 target 就向左移动右指针，小于 target 就向右移动左指针。\n由此延伸到 四数之和 问题，解决思路与之类似，设置两个固定指针，即外层两个循环，剩下的处理逻辑与 三数之和 一样。\n看一下 四数之和：\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n注意：\n答案中不可以包含重复的四元组。\n示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin1, pin2, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-3; i++ { pin1 = i // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] { continue } for j := i + 1; j \u0026lt; l-2; j++ { pin2 = j left = j + 1 right = l - 1 // 不要重复 if j \u0026gt; i+1 \u0026amp;\u0026amp; nums[j] == nums[j-1] { continue } for left \u0026lt; right { // 相等 if nums[pin1]+nums[pin2]+nums[left]+nums[right] == target { result = append(result, []int{nums[pin1], nums[pin2], nums[left], nums[right]}) for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } for left \u0026lt; right \u0026amp;\u0026amp; nums[right-1] == nums[right] { right-- } left++ right-- } else if nums[pin1]+nums[pin2]+nums[left]+nums[right] \u0026gt; target { right-- } else { left++ } } } } return result } ","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003e三数之和\u003c/code\u003e 问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum/\"\u003e15. 三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-smaller/\"\u003e259. 较小的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-closest/\"\u003e16. 最接近的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-题目描述\"\u003e1. 题目描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给你一个包含 \u003ccode\u003en\u003c/code\u003e 个整数的数组 \u003ccode\u003enums\u003c/code\u003e，判断 \u003ccode\u003enums\u003c/code\u003e 中是否存在三个元素\u003ccode\u003ea，b，c\u003c/code\u003e ，使得 \u003ccode\u003ea + b + c = 0\u003c/code\u003e？请你找出所有满足条件\u003cstrong\u003e且不重复\u003c/strong\u003e的三元组。\u003c/p\u003e","title":"LeetCode-三数之和问题"},{"content":"leetcode 上 twoSum 相关的问题：\n1. 两数之和 167. 两数之和 II - 输入有序数组 170. 两数之和 III .数据结构设计 1. 问题描述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 2. 解决思路 一般情况下，使用的是暴力穷举法，但是这种情况下时间复杂度为 $O(n^2)$，爆炸，不考虑。\n这里采用 空间换时间 的思路：\n设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的 索引i和 map[target-j] 即为所需要的。\n下面通过代码实现：\nfunc twoSum(nums []int, target int) []int { result := make([]int,0) m := make(map[int],int) for i,j := range nums { if v, ok := m[target-j]; ok { result = append(result, v) result = append(result, i) } m[j] = i } return result } 3. 进阶 设计并实现一个 TwoSum 的类，使该类需要支持 add 和 find 的操作。\nadd 操作 - 对内部数据结构增加一个数。\nfind 操作 - 寻找内部数据结构中是否存在一对整数，使得两数之和与给定的数相等。\n示例 1:\nadd(1); add(3); add(5); find(4) -\u0026gt; true find(7) -\u0026gt; false 示例 2:\nadd(3); add(1); add(2); find(3) -\u0026gt; true find(6) -\u0026gt; false 实现如下：\ntype TwoSum struct { M map[int]int } /** Initialize your data structure here. */ func Constructor() TwoSum { return TwoSum{M: make(map[int]int)} } /** Add the number to an internal data structure.. */ func (this *TwoSum) Add(number int) { this.M[number]++ // 这里的map中，key保存number，value保存出现的次数 } /** Find if there exists any pair of numbers which sum is equal to the value. */ func (this *TwoSum) Find(value int) bool { for key := range this.M { other := value - key // 第一种情况，针对出现了两次的元素、value为其2倍的，比如 [3,3]，value为6 if other == key \u0026amp;\u0026amp; this.M[other] \u0026gt; 1 { return true } // 第二种情况，针对出现过一次的元素，比如 [2,6], value 为8 if other != key \u0026amp;\u0026amp; this.M[other] \u0026gt; 0 { return true } } return false } 4. 总结 对于题目 1 和题目 167： 设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的索引i和 map[target-j] 即为所需。\n对于题目 170： 设计数据结构时，map 的 key 为元素，value 为该元素出现的此时。查找时，考虑两种情况：一种是 [3,3]--\u0026gt;6 的情况，一种是 [2,5] --\u0026gt; 7 的情况。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003etwoSum\u003c/code\u003e 相关的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum/\"\u003e1. 两数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/\"\u003e167. 两数之和 II - 输入有序数组\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-iii-data-structure-design/\"\u003e170. 两数之和 III .数据结构设计\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-问题描述\"\u003e1. 问题描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\u003c/p\u003e","title":"LeetCode-两数之和问题"},{"content":"一、设计原理 哈希表(也就是我们说的map)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是O(1)，是典型的 以空间换时间 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：哈希函数 和 冲突解决方法。\n1. 哈希函数 可以将任意长度的数据 映射 到有限长度的域上。通俗解释：你可以把它抽象成一个黑盒(一个函数 f)，它的输入是任意数据 m，输出是另一段固定范围的数据 n，即f(m) = n，n 可以作为 m 的特征(指纹)。\n对任意两个输入m1和m2，如果他们的输出均不同，则称这个函数为 完美哈希函数。如果存在m1和m2，有 f(m1) = f(m2)，则称这个函数为 不均匀哈希函数，这个现象称为 哈希碰撞。\n完美哈希函数很难找到，比较实际的做法是 让哈希函数的结果尽可能地分布均匀，然后通过工程上的手段解决哈希碰撞的问题。但是哈希的结果一定要尽可能均匀，结果不均匀的哈希函数会造成更多的冲突并导致更差的读写性能。\n2. 解决哈希冲突的方法 在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多最终也会造成冲突。\n然而我们的哈希函数往往都是不完美的，输出的范围是有限的，所以一定会发生哈希碰撞，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。\n2.1 开放寻址法 这种方法的核心思想在于 线性探测，通常情况下，这种哈希表的底层数据结构就是数组。先计算index，判断数组的这个index处是否有值，如果没有，直接存入；否则从这个index向后遍历，直到找到一个为空的index。可以大致用下面的代码表示：\nfunc hash1(source string) int { arr := make([]string,10,10) index := hash(source) % len(arr) tmp := index for { if arr[index%len(arr)] == \u0026#34;\u0026#34; { return index }else { index++ } if index == tmp { return -1 // 没找到 } } } 查找的时候，还是先计算 index ，如果数组在该位置的数刚好是要找的，直接返回，否则需要向后逐步遍历比较。在某些情况下，当装载的元素太多时，哈希表的性能会急剧下降，最差的结果就是每次增加和查找，都需要遍历整个数组，此时整个哈希表完全失效。\n2.2 拉链法 与开放地址法相比，拉链法是哈希表中最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。\n拉链法使用链表作为底层数据结构，我们把这个链表称为桶。这种方法对哈希冲突的解决方法是：直接在相同哈希值的结点后面增加一个链表结点。查询的时候，先找到对应链表第一个结点，之后遍历链表寻找符合要求的那个。\n在一个性能比较好的哈希表中，每一个桶中都应该有 01 个元素，有时会有 23 个，很少会超过这个数量，计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：\n装载因子 := 元素数量/桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。\n二、用到的数据结构 我的 Go 版本：\ngo version go1.14.6 darwin/amd64 Go 语言中对哈希表的实现方案是：使用拉链法解决哈希冲突。同时使用了多个数据结构组合来标识哈希表。\n在源码中，表示map 的结构体是 hmap：\n// A header for a Go map. type hmap struct { count int // 当前哈希表中元素个数，调用len(m)时直接返回此值 flags uint8 // B uint8 // 当前哈希表持有的 buckets 数量的对数，即 buckets数量 = 2^B noverflow uint16 // overflow 的 buckets 的近似数(buckets\u0026lt;16时是准确的) hash0 uint32 // 哈希种子，在创建哈希表时确定的随机数，并在调用哈希函数的时候作为参数传入 buckets unsafe.Pointer // 指向 buckets 数组，大小为 2^B，如果元素个数为0则为nil oldbuckets unsafe.Pointer // 渐进式扩容时用于保存之前的 buckets，扩容的时候，buckets 长度会是 oldbuckets 的两倍 nevacuate uintptr // 指示扩容进度，表示即将迁移的旧桶编号 extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. 溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 目前已经使用的溢出桶的地址 oldoverflow *[]*bmap // 在扩容阶段存储旧桶用到的溢出桶的地址 nextOverflow *bmap // 指向下一个空闲溢出桶 } buckets 是一个指针，最终指向的是一个结构体：\n// A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 } bmap 结构体其实不止包含 tophash 字段，由于哈希表中可能存储不同类型的键值对并且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导，这些字段在运行时也都是通过计算内存地址的方式直接访问的，所以它的定义中就没有包含这些字段，实际上的 bmap 是这样的：\ntype bmap struct { topbits [8]uint8 // tophash数组 keys [8]keytype // key数组 values [8]valuetype // value数组 pad uintptr overflow uintptr // 当当前桶存满时，发现还有可用的溢出桶，就会用此指针链接一个溢出桶，溢出桶也是 bmap 结构 } 如上图所示，hmap的桶就是 bmap，每一个 bmap 最多能存储 8 个键值对，这些键值对之所以会落在同一个桶，是因为他们经过哈希计算之后，得到的哈希结果是 “一类的”。当单个桶中存储的数据过多而无法装满时，就会使用 extra.overflow 中的桶存储溢出的数据。上面两种桶在内存中是连续的，我们暂且称之为 常规桶 和 溢出桶。\n我们来看看 bmap 的内部组成：\n最开始是 8 个 tophash，每个 tophash 都是对应哈希值的高 8 位。需要注意的是，key 和 value 是各自放在一起的，这样的好处是为了padding 时节省空间。每一个桶被设计成最多只能存放 8 个键值对，如果有第 9 个键值对落入当前的桶，那就需要再构建一个桶(溢出桶)，然后用 overflow 指针连接起来。\n三、使用 1. 初始化 无论是通过字面量还是运行时，最终底层都会调用 makemap 方法：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // 计算哈希占用的内存是否溢出或者产出能分配的最大值 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } if h == nil { h = new(hmap) } // 获取随机的哈希种子 h.hash0 = fastrand() // 根据传入的hint计算需要的最少的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 创建用于保存桶的数组 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 需要注意的是 makeBucketArray 函数，这个函数会根据传入的 B 计算出的需要创建的桶的数量 在内存中分配一片连续的空间用于存储数据。当桶的数量小于 $2^4$ 时，由于数据较少，使用溢出桶的可能性比较低，这时会省略创建的过程以减少额外开销；当桶的数量多于 $2^4$ 时，就会额外创建 $2^{B-4}$ 个溢出桶。正常情况下，溢出桶和常规桶在内存中的存储空间是连续的，只不过被 hmap 的不同字段引用。\n另外注意makemap 的返回，是一个 *hmap ，指针类型，这个时候传给函数在函数中改变的就是原来的 map ，即 改变map类型的形参，是可以影响实参的。这一点和之前的 slice 不同，slice 返回的是一个 slice 结构体，虽底层共用数组，但是扩容后就与原来的数据脱钩了。\n举个例子，下面的代码：\nmap := make(map[string]string, 10) Go 源码中的负载因子是 6.5 ，在源码 /usr/local/go/src/runtime/map.go:70 可以找到：\n// Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 这里的map 的键值对个数是 10，根据 负载因子 = 键值对个数/桶个数，得到 需要的桶的个数为 2。此时不会创建更多的溢出桶。\n2. 写 源码中执行 写入 操作的是 mapassign 函数，该函数较长，我们分步来看(每一步我会在关键位置写上注释，也更容易理解过程)。\n首先，函数会根据传入的键计算哈希，确定所在的桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // a.调用key类型对应的哈希算法得到哈希 hash := t.hasher(key, uintptr(h.hash0)) // b.设置 写 标志位 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // c.根据 hash 计算位于哪个 bucket bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // d.如果 map 正在扩容，此操作确保此 bucket 已经从 hmap.oldbuckets 被搬运到 hmap.buckets growWork(t, h, bucket) } // e.取得 bucket 所在的内存地址 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) // f.计算此bucket中的tophash，方法是：取高8位 top := tophash(hash) // ... } 在 64 位机器上，步骤 a 计算得到的 hash 值共有 64 个 bit 位。之前提到过，hmap.B 表示桶的数量为 $2^{h.B}$。这里用得到的哈希值的最后 B 个 bit 位表示落在了哪个桶中，用哈希值的 高 8 位表示此 key 在 bucket 中的位置。\n还是以上面的map = make(map[string]int, 10)为例，计算可知 B=2，则应该用后 2 位用来选择桶，高 8 位用来表示 tophash。 某个 key 经过哈希之后得到的 hash=01100100 001011100001101110110010011011001000101111000111110010 01，后两位 01 代表 1 号桶。\n然后，会有两层循环，最外层循环 bucket 以及其链接的溢出桶(如果有的话)，内存逐个遍历所有的tophash： var inserti *uint8 // 目标元素在桶中的索引 var insertk unsafe.Pointer // 桶中键的相对地址 var elem unsafe.Pointer // 桶中值的相对地址 bucketloop: // 最外层是一个死循环，其实是当前 bucket 后面链接的溢出桶(overflow) for { // bucketCnt=8，因为一个bucket最多只能存储8个键值对 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 找到一个tophash不同的 if b.tophash[i] != top { // isEmpty判断当前tophash是否为正常tophash值而不是系统迁移标志 if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // 已经找到一个可以放置的位置了，为什么不直接break掉？是因为有可能K已经存在，需要找到对应位置然后更新掉 } // 如果余下位置都是空的，则不再需要往下找了 if b.tophash[i] == emptyRest { break bucketloop } continue } // tophash 相同后，还需要再比较实际的key是否相同 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // key已经在map中了，更新之 if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } // 外层循环接着遍历这个bucket后面链接的overflow ovf := b.overflow(t) if ovf == nil { break } b = ovf } 在上述代码中有出现isEmpty 以及 emptyRest 等标志位，这其实是 tophash 的状态值，在源码 /usr/local/go/src/runtime/map.go:92 中可以找到：\n// // Possible tophash values. We reserve a few possibilities for special marks. emptyRest = 0 // 这个 cell 是空的, 并且在当前bucket的更高的index 或者 overflow中，其他的都是空的 emptyOne = 1 // 这个 cell 是空的 evacuatedX = 2 // K-V 已经搬迁完毕，但是 key 在新的 bucket 的前半部分(扩容时会提到) evacuatedY = 3 // 同上，key 在新的 bucket 的后半部分 evacuatedEmpty = 4 // cell 是空的，并且已经被迁移到新的 bucket 上 minTopHash = 5 // 正常的 tophash 的最小值 由此也可知，正常的 tophash 是 大于 minTopHash 的。\n如果此时 (键值对数已经超过负载因子 或者 已经有太多的溢出桶) \u0026amp;\u0026amp; 当前没有处在扩容阶段，那么 开始扩容： // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } 具体的扩容过程后面再细说，这里暂不讨论。\n如果没有找到合适的 cell 来存放这个键值对(桶满了)，则 使用预先申请的保存在 hmap.extra.nextoverflow 指向的溢出桶 或者 创建新桶 来保存数据，之后将键值对插入到相应的位置： if inserti == nil { // all current buckets are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } // 将键值对移动到对应的空间 typedmemmove(t.key, insertk, key) *inserti = top h.count++ 而使用预分配的溢出桶还是申请新的桶，在 newoverflow 函数中：\nfunc (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap if h.extra != nil \u0026amp;\u0026amp; h.extra.nextOverflow != nil { // 如果有预分配的 bucket ovf = h.extra.nextOverflow if ovf.overflow(t) == nil { // 并且预分配的溢出桶还没有使用完，则使用这个溢出桶，并更新 h.extra.nextOverflow 指针 h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize))) } else { // 预分配的溢出桶已经用完了，则置空 h.extra.nextOverflow指针 ovf.setoverflow(t, nil) h.extra.nextOverflow = nil } } else { // 没有可用的溢出桶，则申请一个新桶 ovf = (*bmap)(newobject(t.bucket)) } // 更新h.noverflow(overflow的树木)，如果h.B \u0026lt; 16，则自增1，否则“看可能性”自增(没啥用，感兴趣可以自己研究一下) h.incrnoverflow() if t.bucket.ptrdata == 0 { h.createOverflow() *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) return ovf } 3. 读 我们再来说说 读 的过程。map 的读取有两种方式：带 comma 和 不带 comma 的。这两种方式，其实底层调用的分别是：\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer // v1 := m[key] func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) // v2, isExist := m[key] 这两个函数大同小异，我们只看 mapaccess1。我们还是采用分步的方式来从源码中探究细节：\n根据 key 计算得到 hash 值，同时确定在哪个 bucket 中寻找： // 这个函数永远不会返回 nil ，如果map是空的，则返回对应类型的 零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026amp;zeroVal[0]) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map read and map write\u0026#34;) } // 得到 hash 值 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // 本例中m=31 // 得到 bucket b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { // 正处在扩容阶段 // 如果不是等量扩容(后面会讲到) if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. // 非等量扩容，那就是渐进式扩容，在原来基础上增加了2倍，为了得到原来的，这里除以2 m \u0026gt;\u0026gt;= 1 // m=15 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 是否处于扩容阶段 if !evacuated(oldb) { b = oldb } } top := tophash(hash) 和前面 写 的过程类似，也是两个大循环，外层遍历 bucket 以及链接在后面的 溢出桶，内层遍历每个 bucket 中的 tophash，直至找到需要的 键值对： bucketloop: // 外层循环溢出桶 for ; b != nil; b = b.overflow(t) { // bucketCnt=8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { // 和当前index的tophash不相等，并且后面的cell都是空的，说明后面就没不要再去遍历了，直接退出循环，返回对应元素的零值 if b.tophash[i] == emptyRest { break bucketloop } continue } // 找到对应的 key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // tophash相同，还要判断完整的key是否相同 if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } // 根据偏移找到对应的value，直接返回 return e } } } // 没找到，返回对应类型的零值 return unsafe.Pointer(\u0026amp;zeroVal[0]) 另外，编译器还会根据 key 的类型，将具体的操作用更具体的函数替换，比如 string 对应的是 mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer，函数的参数直接就是具体的类型，这么做是因为提前知道了元素类型，而且由于 bmap 中 key 和 value 各自放在一起，内存布局非常清晰，这也是前面说的 “减少 padding 带来的浪费”的原因。\n4. 扩容 在前面介绍 写 过程时，我们跳过了有关扩容的内容，现在回过头来看一下：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } // ... } // 判断h是否正在扩容。 扩容结束之后，h.oldbuckets 会被置空 func (h *hmap) growing() bool { return h.oldbuckets != nil } // 判断map中的键值对数目与已有的buckets 是否超过负载因子 即 count/2^B 与 6.5的大小关系 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 是否有太多的bucket func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. if B \u0026gt; 15 { B = 15 } // 翻译一下这条语句： // 如果 B \u0026lt; 15， 即 bucket总数 \u0026lt; 2^15 时，overflow的bucket数目不超过 2^B // 如果 B \u0026gt;= 15，即 bucket总数 \u0026gt; 2^15 时，overflow的bucket数目不超过 2^15 // 即 noverflow \u0026gt;= 2^(min(B,15)) return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 从现实角度出发，会有以下两种情形：\n在没有溢出、且所有的桶都装满了的情况下，装载因子是 8，超过了 6.5，表明很多的 bucket 中都快装满了，读写效率都会降低，此时进行扩容是必要的； 当装载因子很小、但是 bucket 很多的时候，map 的读写效率也会很低。什么时候会出现 “键值对总数很小、但 bucket 很多”的情况呢？不停地插入、删除元素。当插入很多元素时，导致创建了更多的 bucket ，之后再删除，导致某个 bucket 中的键值对数量非常少。“这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。” 对于上述两种情况，Go 有着不同的策略：\n对于第一种情况，城中人多房少，直接将 B 加一，建更多的房子即可； 对第二种情况，新开辟一块同样大小的空间，然后将旧空间中的键值对全部搬运过去，然后重新组织。 扩容 最基础的一个操作是 将原有的键值对搬到新开辟的空间，如果键值对数量太多，将严重影响性能。因此对于情况一，Go 采取 渐进式扩容，并不会一次全部搬完，每次最多只搬迁 2 个 bucket；第二种情况，称之为 等量扩容 ，可以理解成“内存整理”。接下来我们通过源码来分析实际的过程：\n执行扩容的函数是 hashGrow ， hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数和 evacuate() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。\n我们来看看 hashGrow 函数：\nfunc hashGrow(t *maptype, h *hmap) { // If we\u0026#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026#34;grow\u0026#34; laterally. // 首先通过 是否超过负载因子 判断进行渐进式扩容还是等量扩容 bigger := uint8(1) // 默认等量扩容 if !overLoadFactor(h.count+1, h.B) { // 如果没有超过负载因子，则进行等量扩容 bigger = 0 h.flags |= sameSizeGrow } // 申请新的 bucket 空间，并将原来的 h.buckets 字段 转移到 h.oldbuckets oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) // 将以前原有的buckets的标志位也转移到新申请的buckets去 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 执行grow操作 (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 // h.nevacuate指示扩容进度，表示当前正在搬迁旧的第几个bucket h.noverflow = 0 // 将溢出桶个数置为零 // 将extra中的overflow扔到oldoverflow中去 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026#34;oldoverflow is not nil\u0026#34;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 第 17 行涉及到的 flag 如下：\n// flags iterator = 1 // 可能有迭代器使用 buckets oldIterator = 2 // 可能有迭代器使用 oldbuckets hashWriting = 4 // 有协程正在向 map 中写入 key sameSizeGrow = 8 // 等量扩容（对应第二种情况） 我们再来看看实际执行扩容的 growWork 和 evacuate：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 还没搬迁完成的话，再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) } } evacuate 函数非常长，我们还是逐步去深入：\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位到老的bucket b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() // 存放增长之前的bucket数，结果为 2^B if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. /* // evacDst表示搬迁的目的区域. type evacDst struct { b *bmap // 搬去的bucket i int // bucket中键值对的index k unsafe.Pointer // pointer to current key storage e unsafe.Pointer // pointer to current elem storage } */ // 这里设置两个目标桶，如果是等量扩容，则只会初始化其中一个； // xy 指向新空间的高低区间的起点 var xy [2]evacDst x := \u0026amp;xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 如果是翻倍扩容，则同时初始化，之后会将旧桶中的键值对“分流”到两个新的目标桶中 if !h.sameSizeGrow() { // Only calculate y pointers if we\u0026#39;re growing bigger. // Otherwise GC can see bad pointers. y := \u0026amp;xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell for i := 0; i \u0026lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 当前cell的tophash if isEmpty(top) { // 当前cell为空，即没有key，则标志其为 “搬迁过”，然后继续下一个 cell b.tophash[i] = evacuatedEmpty continue } // 正常情况下，tophash只能是 evacuatedEmpty 或者 正常的tophash(大于等于minTopHash) if top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // 计算如何分流(将这个键值对放到x中还是y中) // 计算方法与前面相同 hash := t.hasher(k2, uintptr(h.hash0)) // !t.key.equal(k2, k2)这种情况，只能是float的NaN了 // 没有协程正在使用map \u0026amp;\u0026amp; 不是float的NaN if h.flags\u0026amp;iterator != 0 \u0026amp;\u0026amp; !t.reflexivekey() \u0026amp;\u0026amp; !t.key.equal(k2, k2) { // 在这种情况下，我们使用 tophash 的低位来作为分流的标准 useY = top \u0026amp; 1 top = tophash(hash) } else { if hash\u0026amp;newbit != 0 { useY = 1 // 新的位置位于高区间 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\u0026#34;bad evacuatedN\u0026#34;) } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026amp;xy[useY] // 放到高位置还是低位置 // 是否要放到 overflow 中 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That\u0026#39;s ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.ptrdata != 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } // 最后会调用 advanceEvacuationMark 增加哈希的 nevacuate 计数器，在所有的旧桶都被分流后清空哈希的 oldbuckets 和 oldoverflow 字段 if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 简单总结一下分流规则：\n对于等量扩容，从旧的 bucket 到新的 bucket，数量不变，因此可以按照 bucket 一一对应，原来是 0 号，搬过去之后还是 0 号； 对于渐进式扩容，要重新计算 key 的 哈希，才能决定落在哪个 bucket 。原来只有 2^B 个bucket ，确定某个 key 位于哪个 bucket 需要使用最后B 位；现在 B 增加了 1，那就应该使用最后的 B+1 位，即向前看一位。比如原来的 B=3，key1和key2的哈希后四位分别是 0x0101 和 0x1101，因为二者的后三位相同，所以会落在同一个 bucket 中，现在进行渐进式扩容，需要多看一位，此时key1和key2的哈希后四位不相同，因为倒数第 4 位有 0 和 1 两种取值，这也就是我们源码中说的 X 和 Y，key1和key2也就会落入不同的 bucket 中——如果是 0，分配到X，如果是 1 ，分配到 Y。 还有一种情况是上面函数中第 64 行 !t.key.equal(k2, k2)，即相同的 key ，对它进行哈希计算，两次结果竟然不相同，这种情况来自于 math.NaN()，NaN 的意思是 Not a Number，在 Go 中是 float64 类型(打印出来直接显示 “NaN”)，当使用它作为某个 map 的 key 时，前后计算出来的哈希是不同的，这样的后果是，我们永远无法通过 GET 操作获取到这个键值对，即使用 map[math.NaN] 是取不到想要的结果的，只有在遍历整个 map 的时候才会出现。这种情况下，在决定分流到 X 还是 Y 中时，就只能 使用tophash的最低位来决定 这个策略了——如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。\n关于 NaN：In computing, NaN, standing for Not a Number, is a member of a numeric data type that can be interpreted as a value that is undefined or unrepresentable, especially in floating-point arithmetic.\n在计算机科学中，NaN 代表 Not a Number，是一个 能够被打印出来的 未定义或者不可预知的 数字类型。\n我们简单总结一下哈希表的扩容设计和原理，哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，整个扩容过程并不是原子的，而是通过 growWork增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流；除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 sameSizeGrow(等量扩容) 这一机制，在出现较多溢出桶时会对哈希进行『内存整理』减少对空间的占用。————Go 语言设计与实现 3.3 哈希表\n5. 删除 Go 语言中删除一个 map 中的 key，使用的是特定的关键字 delete(map, key)。在底层，实际调用的 /usr/local/go/src/runtime/map.go 中的 mapdelete。这个函数的执行过程和 写 过程类似，如果在删除期间当前操作的桶遇到了扩容，就会对该桶进行分流，分流之后找到同种的目标元素完成键值对的删除工作。\n6. 遍历 理论上map 的遍历比较简单——“遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。” 但实际情况是，当我们在遍历一个处在扩容阶段的 map 时，不仅要考虑到已经搬过去的位于 h.buckets 的，还要考虑还没有搬的位于 h.oldbuckets 中的。\n接下来我们还是通过源码的方式逐步探寻 map 遍历 的奥秘。\n与之相关的函数分别是 mapiterinit 和 mapiternext，前者会初始化一个迭代器，之后循环调用后者进行迭代。迭代器结构如下：\ntype hiter struct { key unsafe.Pointer // key的指针，必须放在第一位，nil表示迭代结束 elem unsafe.Pointer // value指针，必须放在第二位 t *maptype // map中key的类型 h *hmap // 指向map的指针 buckets unsafe.Pointer // 初始化时指向的 bucket bptr *bmap // 当前遍历到的 map overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // 起始迭代的 bucket 编号 offset uint8 // 遍历时的偏移量(可以理解成遍历开始的 cell 号) wrapped bool // 是否从头遍历 B uint8 // h.B i uint8 // 当前的 cell 编号 bucket uintptr // 当前的 bucket checkBucket uintptr // 因为扩容，需要检查的 bucket } mapiterinit 主要是对 hiter 的初始化，需要关注的是这几行：\nfunc mapiterinit(t *maptype, h *hmap, it *hiter) { // ... // decide where to start r := uintptr(fastrand()) // bucketCntBits=3 if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } // bucketMask 即 1\u0026lt;\u0026lt;h.B -1 it.startBucket = r \u0026amp; bucketMask(h.B) // bucketCnt=8 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // ... } r 是一个随机数，这里假设我们的 m = make(map[string]int)， h.B=2，即有 2^2=4 个桶，可以计算得到 bucketMask(h.B)=3，二进制表示为 0000 0011，将 r 与这个数相与，就能得到 0~3 的 bucket 序号；同样，第 12 行，7 的二进制表示为 0000 0111，将 r 右移两位之后，与 7 相与，可以得到 0~7 的一个 cell 序号。这就是 map 每次遍历的 key 都是无序的原因。\n之后，使用这个随机的 bucket ，在里面的随机的这个 cell 处开始遍历，取出其中的键值对，直到回到这个 bucket 。\n接下来我们看 mapiternext 的细节：\nfunc mapiternext(it *hiter) { h := it.h if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext)) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t bucket := it.bucket b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // 回到了最开始遍历的那个 bucket，说明遍历结束了，可以退出迭代了 it.key = nil it.elem = nil return } if h.growing() \u0026amp;\u0026amp; it.B == h.B { // 如果我们当前遍历的 bucket 对应的原来的老的 bucket 的状态位显示为 “未搬迁”，则不再遍历当前的 bucket 而去遍历老的 bucket oldbucket := bucket \u0026amp; it.h.oldbucketmask() b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) if !evacuated(b) { checkBucket = bucket } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // 当前 cell 是空的，继续下一个 cell if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() { // 正好遇上扩容但是扩容还没完成，如果我们当前遍历的 bucket 对应的老 bucket还没有进行迁移，那么需要去遍历未搬迁的老的 bucket，但是！并不是遍历对应的全部的老的 bucket，而是只遍历 分流后会落在当前 bucket 的那部分键值对 if t.reflexivekey() || t.key.equal(k, k) { // 对于老 bucket 中不会分流到这个 bucket 的键值对，直接跳过 hash := t.hasher(k, uintptr(h.hash0)) if hash\u0026amp;bucketMask(it.B) != checkBucket { continue } } else { // 处理 math.NaN 情况，还是一样，看最低位来决定是不是落在当前这个 bucket if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue } } } if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // 对于 math.NaN 情况，我们只能通过遍历找到，对它的增删改查都是不可能的(这也是比较幸运的一件事，最起码能访问到，否则那真就成了“幽灵”了——占用空间又无可奈何，而且还能同一个 key 无限制地添加) it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else { // 开始迭代的时候，已经完成了扩容。此时 math.NaN 已经被放置到了别的 bucket 中，这种情况下只需要处置已经被 更新、删除或者删除后重新插入的情况。需要注意的是那些在 equal() 函数中判断为真的但是实际上他们的 key 不相同的情况，比如 +0.0 vs -0.0 rk, re := mapaccessK(t, h, k) if rk == nil { continue // key 已经被删除 } it.key = rk it.elem = re } it.bucket = bucket if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b } it.i = i + 1 it.checkBucket = checkBucket return } b = b.overflow(t) i = 0 goto next } 在 码农桃花源 深度解密 Go 语言之 map 中 map 遍历 一节，作者举了一个非常通俗易懂的例子，非常推荐，建议去看一下加深理解。\n四、总结 这是我第一次非常深入地看源码，也领会到了一切疑难杂症都会在源码面前原形毕露。map 操作的核心，就在于如何在各种情况下定位到具体的 key，搞清楚了这一点，其他问题看源码会更清晰。\nGo 语言中，哈希表的实现采用的哈希查找表，使用拉链法解决哈希冲突。有空间换时间的思想体现(不同的 key 落到不同的 bucket，即定位bucket的过程)，也有 时间换空间 思想的体现(在一个 bucket 中，采用遍历的方式寻找 key 而不是再使用哈希)，同时渐进式扩容和等量扩容的思想也值得我们学习。\n","permalink":"http://localhost:1313/posts/golang-map%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一设计原理\"\u003e一、设计原理\u003c/h2\u003e\n\u003cp\u003e哈希表(也就是我们说的\u003ccode\u003emap\u003c/code\u003e)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是\u003ccode\u003eO(1)\u003c/code\u003e，是典型的 \u003cstrong\u003e以空间换时间\u003c/strong\u003e 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：\u003cstrong\u003e哈希函数\u003c/strong\u003e 和 \u003cstrong\u003e冲突解决方法\u003c/strong\u003e。\u003c/p\u003e","title":"Golang-map详解"},{"content":"一、概述 1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器 主要解决系统线程太重的问题：\n创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大； 系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。 goroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\ngoroutine 是用户态线程，其创建和切换等，都是在用户态完成而无需进入操作系统内核，其开销相比系统线程要小很多； goroutine 启动时默认栈大小只有 2k，可以根据实际情况进行自动伸缩。 2. Go scheduler Go 程序的执行由两部分组成：Go Program 和 runtime，即 用户代码 和 运行时。这里的 runtime 和 Java、Python 中的不一样，Java 的是虚拟机，而Go 的 runtime 和用户代码一起编译到一个可执行文件中。用户代码和 runtime 除了代码组织上有界限之外，运行的时候并没有明显的界限，用户代码中，一些常用的关键字(如 go, new 等)被编译成 runtime 包下的一些函数调用。用户程序进行的系统调用都会被 runtime 拦截，以此来帮助 runtime 进行调度方面以及垃圾回收其他方面的工作。\n一张关系图如下：\n为什么需要 scheduler 呢？runtime 维护所有的 goroutine，就是通过 scheduler 来进行调度。goroutine 和系统线程是独立的，但是 goroutine 需要依赖系统线程才能执行。\n可以用一句话概括 Go scheduler 的目标：\nFor scheduling goroutines onto kernel threads.\nGo scheduler 的核心思想是：\nreuser 系统线程，限制同时运行(不包括阻塞的)的线程数为 N，其中 N 为 CPU 的核心数； 线程使用私有的本地运行队列，并且为了更高地使用 CPU，某个线程可以从其他线程偷 goroutine 来帮助运行，也可以在 goroutine 阻塞的时候将其传递给其他线程。 3. M:N 模型 goroutine 建立在操作系统线程之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。M:N 是指 M 的 goroutine 运行在 N 的操作系统线程上，内核负责对这 N 的操作系统线程进行调度，而 Go runtime 则负责将这 M 个 goroutine 调度运用在这 N 个操作系统线程上。\n简单理解，对 goroutine 的调度，是指程序代码按照一定的算法，在适当的时候挑选出合适的 goroutine 然后放到真正的线程上去执行的过程。其实并没有一个调度器实体，它只是一段代码的抽象化表示，具体来说是 需要发生调度时由操作系统线程执行runtime.schedule方法进行的。\nGo runtime 负责 goroutine 的生老病死，从创建、切换、销毁都一手包办。runtime 在启动的时候，会创建 M 个操作系统线程(CPU 内核执行调度的基本单位)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行。在同一时刻，一个系统线程上只能执行一个 goroutine，当 goroutine 发生阻塞时，runtime 会将当前 goroutine 调走，让其他的 goroutine 继续执行。这样做的目的是尽量提升性能，尽量让所有的系统线程上面都有代码在执行。\n4. GPM 模型 我们观察调度过程的进化，从进程到线程再到协程，其实是一个不断共享、不断减少切换成本的过程。\n要理解调度，需要理解两个概念：运行和阻塞。这里提供两个角度：我们觉得自己就是线程或者协程，运行就是在低头不断做事，阻塞就是我们目前做的事需要等待别人，然后就一直等着，等其他人做完了，我们接着做，这里我们是站在线程或者协程的角度去看的；另一个角度是，我们站在 CPU 的角度看，我正在敲代码写需求(一个线程或者协程)，发现依赖别人的函数还没有提交，那就把敲代码这事放在一边，最小化 IDE 然后点开钉钉沟通下一个需求，等依赖的函数提交了，又打开 IDE 继续敲代码——在 Linux 中，线程对应的是一个叫做task_struct的结构体，从本质上来说，线程并不是一个实体，线程只是代表一个执行流和其状态。真正驱动流程的是 CPU，CPU 根据 PC 寄存器从程序中取指令和操作数，从 RAM 中取数据,，进行计算、 处理、 跳转、 驱动执行流往前。 CPU 并不关注处理的是线程还是协程,，只需要设置 PC 寄存器， 设置栈指针等(这些称为上下文),，那么 CPU 就可以运行这个线程或者协程了。\n所以，线程的运行，其实是被运行；线程的阻塞，其实是换出调度队列，不再去执行这个执行流。协程同理，协程也是一个类似于task_struct数据结构，其作用也是一个执行流或者状态，记录运行什么函数，运行到什么程度，也就是上下文。\nGo 在用户态实现调度，所以 Go 也需要有代表协程这种执行体的数据结构，也要有保存和恢复上下文的处理过程以及调度队列。\n在这些数据结果中，最主要的是一下几个(以下结构体均位于runtime包的runtime.go文件中)：\ng: 它保存了 goroutine 的所有信息，该结构体的每一个实例对象都代表了一个goroutine。调度器代码会通过 g 对象来对 goroutine 进行调度——当 goroutine 被调离系统线程时，调度器负责把 CPU 相关寄存器值等上下文信息保存在 g 对象的成员变量中；当 goroutine 被重新拉起运行时，调度器又负责把 g 对象成员变量中所保存的上下文信息恢复到相关寄存器，也就是恢复了执行上下文。 schedt：一方面保存调度器本身的状态信息，另一方面它拥有一个用来保存 goroutine 的运行队列。因为每个 Go 程序只有一个调度器，所以在每个 Go 程序中 schedt 结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的 goroutine 运行队列，我们称这个运行队列为全局运行队列(GRQ)。 p：表示执行所需要的资源，其最大数量同时也是 Go 代码的最大并行度。每一个运行着 go 代码的工作线程都会与一个 p 结构体的实例对象关联在一起。全局运行队列是每一个工作线程都可以读写的，因此为了并发安全，访问时需要加锁，但加锁势必耗费性能进而称为瓶颈。于是调度器为每一个工作线程引入了一个 私有的 goroutine 运行队列，我们称之为“局部队列(LRQ)”，工作线程优先使用局部队列的 goroutine，只有必要时才会去访问全局队列(后面还会了解到，当一个 p 的局部队列使用完时，还会去别的 p 偷几个 g 过来运行)，这大大减少了锁冲突，提高了工作线程的并发性。 m：代表实际工作线程，每一个工作线程都有唯一的m与之对应。m 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 p 结构体的实例对象之间的绑定关系。于是，通过 m 既可以找到与之对应的工作线程正在运行的 goroutine，又可以找到工作线程的局部运行队列等资源。 他们之间的关系，可以使用下图表示：\n另有一张图可能更清晰形象：\nGo scheduler 的职责就是将所有处于 可运行状态 的 goroutines 均匀分布到在 P 上运行的 M。\n当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。这被称为 Work-stealing，Go 从 1.1 开始实现。\nGo scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。\n实际上，Go scheduler 每一轮调度要做的工作就是找到处于 runnable 的 goroutines，并执行它。寻找的顺序如下：\nruntime.schedule() { // 检查全局队列，防止全局队列中的G被饿死 // if not found, 检查局部队列 // if not found, // 尝试从其他的P偷一些G过来 // if not found, 从全局队列中去一些 // if not found, poll network } 上述任何一步找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来一半的 G。\n这样做的好处是，有更多的 P 可以一起工作，加速执行完所有的 G。\n5. goroutine 的状态 如下图：\n6. Go scheduler 的调度时机 在以下四种情况下，scheduler 可能会发生调度——“可能”意味着，scheduler 只是有机会调度，但并不一定会发生。\n情形 说明 使用关键字 go 创建一个新的 goroutine，scheduler 会考虑调度 GC 肯定会发生调度，因为 GC 必须要在 M 上运行。 发生系统调用 当一个 goroutine 发生系统调用时，会阻塞 M，此时它会被调走，同时调用新的 goroutine 在 M 上运行 内存同步访问 atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 7. 同步/异步系统调用概览 当一个正在执行的 G(goroutine)需要进行系统调用时，根据调用类型，它所依附的 M 有两种情况：同步(系统调用等) 和 异步(网络请求等)。\n同步情况下，M1 会被阻塞，进而从 P 上调度下来，此时 G1 依然依附在 M1 上执行，之后会有一个新的 M2 被调用到 P 上，接着执行 P 的本地运行队列 LRQ 中的 G。一旦系统调用完成，G1 会再次加入 P 的 LRQ 等待被调度，而之前的 M1 则会被隐藏，等到需要的时候再次被使用。\n异步情况下，M1 不会被阻塞，G1 的异步请求会被另一个组件Network Poller接手，而 G1 本身也会被绑定到Network Poller上，等到系统调用结束，G1 会再次回到 P 上。由于 M 没有被阻塞，它可以继续执行当前被绑定的 P 的 LRQ 里面的 G。\n可以看到，在异步情况下，通过调度，Go scheduler 成功地将 IO 任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，极大地提高了效率。\n二、具体实现 有时间再细究。\n未完，待续…\n","permalink":"http://localhost:1313/posts/golang-gpm%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86/","summary":"\u003ch2 id=\"一概述\"\u003e一、概述\u003c/h2\u003e\n\u003ch3 id=\"1-为什么在内核的线程调度器之外go-还需要实现一个自己的调度器\"\u003e1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器\u003c/h3\u003e\n\u003cp\u003e主要解决\u003cstrong\u003e系统线程太重\u003c/strong\u003e的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大；\u003c/li\u003e\n\u003cli\u003e系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003egoroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\u003c/p\u003e","title":"Golang-GPM调度原理"},{"content":"1. Go语言指针的限制 go语言中也有指针，但相对C语言的指针来说，有了很多限制，但这也算是go的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\ngo中指针不能进行数学运算; func main() { num := 1 pNum := \u0026amp;num pNum++ // invalid operation: p++ (non-numeric type *int) } 不同类型的指针不能相互转换 func main() { var a int a = 10 var f *float32 f = \u0026amp;a // cannot use \u0026amp;a (type *int) as type *float32 in assignment } 不同类型的指针之间不能使用==或!=进行比较，也不能相互赋值 func main() { var a int var b float32 a = 1 b = 3.14 pa := \u0026amp;a pb := \u0026amp;b fmt.Println(pa == nil) fmt.Println(pa == pb) // invalid operation: pa == pb (mismatched types *int and *float32) pa = pb // cannot use pb (type *float32) as type *int in assignment } 只有在两个指针类型相同或者可以相互转换的情况下，才可以对两者进行比较。另外，指针可以通过 == 和 != 直接和 nil 作比较。\n2. unsafe包介绍 unsafe 包，“不安全”，为何不安全？是因为它可以使得用户绕过 go 的类型规范检查，能够对指针以及其指向的区域进行读写操作，即“允许程序无视 type 体系对任意类型内存进行读写”。因此使用时要格外小心。\nunsafe包中只有很简单的几个函数和定义:\npackage unsafe // 任意go表达式的类型。只是为了文档而声明的类型，实际上它并不是unsafe包的一部分 type ArbitraryType int // 任意类型代表的指针 type Pointer *ArbitraryType // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr // 返回x所在结构体的起始内存地址到x所对应属性两者距离，单位为byte，参数x的格式应该是structValue.field func Offsetof(x ArbitraryType) uintptr // 内存对齐时使用，这里暂时不研究 func Alignof(x ArbitraryType) uintptr 与此同时，unsafe包提供了两个很重要的功能：\n任何类型的指针 和 unsafe.Pointer 可以相互转换。 uintptr 类型和 unsafe.Pointer 可以相互转换。 即 任何数据类型的指针 \u0026lt;----\u0026gt; unsafe.Pointer \u0026lt;----\u0026gt; uintptr\n上述的功能有何用途？答： Pointer允许程序无视 type 体系对任意类型内存进行读写。\n如何理解这句话？因为unsafe.Pointer不能直接进行数学运算，但是我们可以将其转换成uintptr，对uintptr进行对应的数学运算(比如内存复制与内存偏移计算)，计算之后再转换成unsafe.Pointer类型。\n有了这个基础，我们可以干好多“见不得光”的事，比如 底层类型相同的数组之间的转换、使用 sync/atomic 包中的一些函数、访问并修改 Struct 的私有字段等场景。\n3. unsafe包的使用场景 场景一：访问并修改 struct 的私有属性 先从一个 demo 开始：\npackage main // unsafe修改struct私有属性 type user struct { name string age int company string } func main() { u := new(user) // A fmt.Println(*u) // { 0} uName := (*string)(unsafe.Pointer(u)) // B *uName = \u0026#34;Jemmy\u0026#34; fmt.Println(*u) // {Jemmy 0} uAge := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.age))) // C *uAge = 23 fmt.Println(*u) // {Jemmy 23} uCompany := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.company))) // D *uCompany = \u0026#34;吹牛逼技术有限公司\u0026#34; fmt.Println(*u) // {Jemmy 23 吹牛逼技术有限公司} } 在 A 处，我们新建一个user对象，使用new直接返回此类对象的指针。在这里要注意，在go中，对一个struct进行内存分配，实际上是分配的一块连续的空间，而new返回的指针，其实是struct中第一个元素的地址。\n通过上面的介绍我们知道，unsafe.Offsetof(x ArbitraryType) 返回 x 所在结构体的起始内存地址到 x 所对应属性两者距离，单位为 byte，参数 x 的格式应该是 structValue.field，那么unsafe.Offsetof(u.name)指的就是 u的起始地址，到属性name之间有多少个byte。\n在 C 处，因为unsafe.Pointer不能直接参与数学运算，所以我们先转换成uintptr类型，然后与unsafe.Offsetof(u.age)相加，就是u的属性age的地址，为uintptr类型，之后再转换为unsafe.Pointer，即可通过强制类型转换，直接去修改该属性的值。\n再来看 B 处，因为u的地址就是其第一个属性name的地址，可以直接获取到。其实我们可以改成和 C 处相似的结构：uName := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.name)))，效果一样。\n**注意!!!**上面 C 处的语句的加号两边的对象不能直接拆开去写，也就是说，不能写成:\ntmp := uintptr(unsafe.Pointer(u)) uAge := (*int)(unsafe.Pointer(tmp + unsafe.Offsetof(u.age))) 原因是，uintptr这个临时变量，本身就是一个很大的整数，而程序经过一些很大的计算之后，涉及到栈的扩容，扩容之后，原来的对象的内存位置发生了偏移，而 uintptr 所指的整数对应的地址也就发生了变化。这个时候再去使用，由于这个整数指的地址已经不是原来的地址了，会出现意想不到的 bug。\n场景二： 利用unsafe获取 slice 的长度 通过查看对应的源代码，我们知道slice header的结构体定义为：\ntype slice struct { array unsafe.Pointer // 元素指针 1字节 len int // 长度 1字节 cap int // 指针 1字节 } 当我们调用make函数创建一个新的slice后，底层调用的是makeslice，返回的是slice结构体:\nfunc makeslice(et *_type, len, cap int) slice 因此，我们可以通过unsafe.Pointer和uintptr进行转换，得到 slice 的字段值：\nfunc main() { s := make([]int, 10, 20) // slice结构体中，array类型为pointer，占1个字节8位，uintptr(unsafe.Pointer(\u0026amp;s))表示s的地址也是第一个属性array的地址，那么加上属性array的长度，就是下一个属性len的长度 var sLen = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(8))) fmt.Println(*sLen, len(s)) // 10 10 // 16的原因同上 var sCap = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(16))) fmt.Println(*sCap, cap(s)) // 20 20 } 场景三：实现string和[]byte 的零拷贝转换 一般的做法，都需要遍历字符串或 bytes 切片，再挨个赋值。\n在反射包src/reflect/value.go中，有下面的结构体定义：\ntype StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } 因此，只需共享底层的Data和Len即可：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } 4. unsafe.Sizeof(struct) 的本质 先看源码注释：\n// Sizeof takes an expression x of any type and returns the size in bytes // of a hypothetical variable v as if v was declared via var v = x. // The size does not include any memory possibly referenced by x. // For instance, if x is a slice, Sizeof returns the size of the slice // descriptor, not the size of the memory referenced by the slice. // The return value of Sizeof is a Go constant. // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr 这其中比较有意思的是 unsafe.Sizeof(a struct)的结果问题，即一个struct的 size 值为多少的问题。\n我们来观察一个有趣的事实：一个struct的 size 依赖于它内部的属性的排列顺序，即两个属性相同但排列顺序不同的struct的 size 值可能不同。\n比如，下面这个结构体 A 的 size 是 32：\ntype struct A{ a bool b string c bool } 而另一个和它有相同属性的结构体 B 的 size 是 24:\ntype struct B{ a bool c bool b string } 这都是 内存对齐在捣鬼。我们看一下 A 和 B 的内存位置：\n如上图所示，左边为struct A，右边为struct B。而Aligment可以使 1,2,4 或者 8。对 A 来说，a bool占一个 byte，而下一个属性是b string，占 16 个 byte(后面会说明为什么占 2 个字节)，因此无法进行内存对齐；而对 B 来说，a bool和c bool可以放在同一个 byte 中。\n在Golang中，各类型所占的 byte 如下\nbool,int8,uint8 \u0026ndash;\u0026gt; 1 byte int16,uint16 \u0026ndash;\u0026gt; 2 byte int32,uint32,float32 \u0026ndash;\u0026gt; 4 byte int,int64,uint64,float64,pointer \u0026ndash;\u0026gt; 8 byte string \u0026ndash;\u0026gt; 16 byte (两个字节) 任何 slice \u0026ndash;\u0026gt; 24 byte(3 个字节) 长度为 n 的 array \u0026ndash;\u0026gt; n*对应的 type 的长度 为什么string占到 2 个字节？因为 string 底层也是一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占 8 个字节；\n为什么任意类型的slice占到 3 个字节？同理，slice底层也是一个结构体，有三个域：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 1个字节 len int // 长度 8个byte 1个字节 cap int // 容量 8个byte 1个字节 } 说到这里，你也应该明白了，unsafe.Sizeof总是在编译期就进行求值，而不是在运行时，而且是根据类型来求值，而和具体的值无关。(这意味着，unsafe.Sizeof的返回值可以赋值给const即常量)\n可以通过下面的 demo 输出，判断你的掌握程度：\npackage main type user struct { name string // 2字节 age int // 1字节 company string // 2字节 } func main(){ fmt.Println(unsafe.Sizeof(user{})) // 输出40，5个字节，看 struct user 注释 fmt.Println(unsafe.Sizeof(10)) // 输出8，因为int占1字节 fmt.Println(unsafe.Sizeof([]bool{true, false})) // 输出24，任何slice都输出24 fmt.Println(unsafe.Sizeof([][]string{})) // 输出24，任何slice都输出24，即使是多维数组 } 5. 参考文献 码农桃花源—标准库\u0026ndash;unsafe sizeof-struct-in-go ","permalink":"http://localhost:1313/posts/golang-unsafe%E5%8C%85%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"1-go语言指针的限制\"\u003e1. \u003ccode\u003eGo\u003c/code\u003e语言指针的限制\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ego\u003c/code\u003e语言中也有指针，但相对\u003ccode\u003eC语言\u003c/code\u003e的指针来说，有了很多限制，但这也算是\u003ccode\u003ego\u003c/code\u003e的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\u003c/p\u003e","title":"Golang-unsafe包详解"},{"content":"在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\nGo 语言中数组、字符串和切片三者是密切相关的数据结构。这三种数据类型，在底层原始数据有着相同的内存结构，在上层，因为语法的限制而有着不同的行为表现。\n一、 数组(Array) 1. 概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存其中的元素，我们可以利用数组中元素的索引快速访问元素对应的存储地址。\n数组作为一种基本的数据类型，我们通常都会从两个维度描述数组：类型 和 大小(能够存储的最大元素个数)：\n// 源码位于 /usr/local/go/src/cmd/compile/internal/types/type.go // Array contains Type fields specific to array types. type Array struct { Elem *Type // element type 元素类型 Bound int64 // number of elements; \u0026lt;0 if unknown yet 最大元素个数，小于0表示未知 } // NewArray returns a new fixed-length array Type. func NewArray(elem *Type, bound int64) *Type { if bound \u0026lt; 0 { Fatalf(\u0026#34;NewArray: invalid bound %v\u0026#34;, bound) } t := New(TARRAY) t.Extra = \u0026amp;Array{Elem: elem, Bound: bound} t.SetNotInHeap(elem.NotInHeap()) return t } 从上述代码可以看出，类型Array包含两个属性，一个是数组类型Elem，另一个是数组大小Bound。另外需要注意的是：Go 语言中数组在初始化之后大小无法改变。\n2. 初始化 有两种初始化方式：\narray1 = [5]int{1, 2, 3, 4, 5} array2 = [...]int{1, 2, 3, 4, 5} 上述两种声明方式在运行期间得到的结果是完全相同的，后一种声明方式在编译期间就会被“转换”成为前一种，这也就是编译器对数组大小的推导。\n对第一种方式，那么变量的类型在编译进行到类型检查阶段就会被提取出来，随后会使用 NewArray函数创建包含数组大小的 Array 类型。\n对第二种方式，在第一步会创建一个Array{Elem: elem, Bound: -1}，即其大小会是-1，不过这里的-1只是一个占位符，编译器会在后面的 /usr/local/go/src/cmd/compile/internal/gc/typecheck.go 中对数组大小进行推导，并更新其 Bound 值：\n// The result of typecheckcomplit MUST be assigned back to n, e.g. // n.Left = typecheckcomplit(n.Left) func typecheckcomplit(n *Node) (res *Node) { ... // Need to handle [...]T arrays specially. if n.Right.Op == OTARRAY \u0026amp;\u0026amp; n.Right.Left != nil \u0026amp;\u0026amp; n.Right.Left.Op == ODDD { n.Right.Right = typecheck(n.Right.Right, ctxType) if n.Right.Right.Type == nil { n.Type = nil return n } elemType := n.Right.Right.Type // typecheckarraylit type-checks a sequence of slice/array literal elements. length := typecheckarraylit(elemType, -1, n.List.Slice(), \u0026#34;array literal\u0026#34;) n.Op = OARRAYLIT n.Type = types.NewArray(elemType, length) n.Right = nil return n } ... } 虽然在编译期这两种方式的实现方式不同，但在运行时这两中方式是完全等价的。事实上，[...]T 这种初始化方式也只是 Go 语言为我们提供的一种语法糖，当我们不想计算数组中的元素个数时可以偷个懒。\n另：变量初始化的位置：\n如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化；如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换之后代码才会继续进入 中间代码生成 和 机器码生成 两个阶段，最后生成可以执行的二进制文件。\n3. 赋值与访问 Go 语言中数组是值语义。一个数组变量即表示整个数组，它并不是隐式的指向第一个元素的指针（比如 C 语言的数组），而是一个完整的值。当一个数组变量被赋值或者被传递的时候，实际上会复制整个数组。如果数组较大的话，数组的赋值也会有较大的开销。为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。\nvar a = [...]int{1, 4, 3} // a 是一个数组 var b = \u0026amp;a // b 是指向数组的指针 fmt.Println(a[0], a[1]) // 打印数组的前2个元素 fmt.Println(b[0], b[1]) // 通过数组指针访问数组元素的方式和数组类似 for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v) } 我们可以用for循环来迭代数组。下面常见的几种方式都可以用来遍历数组：\nfmt.Println(\u0026#34;方式一：\u0026#34;) for i := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } fmt.Println(\u0026#34;方式二：\u0026#34;) for i, v := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, v) } fmt.Println(\u0026#34;方式三：\u0026#34;) for i := 0; i \u0026lt; len(a); i++ { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } // 输出 方式一： a[0]: 1 a[1]: 4 a[2]: 3 方式二： a[0]: 1 a[1]: 4 a[2]: 3 方式三： a[0]: 1 a[1]: 4 a[2]: 3 用for range方式迭代的性能可能会更好一些，因为这种迭代可以保证不会出现数组越界的情形，每轮迭代对数组元素的访问时可以省去对下标越界的判断。\n需要注意的是 长度为 0 的数组。长度为 0 的数组在内存中并不占用空间，有时候可以用于强调某种特有类型的操作时避免分配额外的内存空间，比如用于管道的同步操作：\nc1 := make(chan [0]int) go func() { fmt.Println(\u0026#34;c1\u0026#34;) c1 \u0026lt;- [0]int{} }() \u0026lt;-c1 在此场景下我们并不关心管道中的具体数据以及类型，我们需要的只是管道的接收和发送操作用于消息的同步，此时，空数组作为管道类型可以减少管道元素赋值时的开销。当然一般更倾向于用无类型的匿名结构体代替：\nc2 := make(chan struct{}) go func() { fmt.Println(\u0026#34;c2\u0026#34;) c2 \u0026lt;- struct{}{} // struct{}部分是类型, {}表示对应的结构体值 }() \u0026lt;-c2 注：本节参考自Go 语言高级编程 1.4\n二、切片(Slice) 切片和数组非常类似，可以用下标的方式访问，也会在访问越界时发生panic。但它比数组更加灵活，可以自动扩容。\n1. 内部实现 源代码位于： /usr/local/go/src/runtime/slice.go\ntype slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 长度(已经存放了多少个元素) cap int // 容量(底层数组的元素个数)，其中 cap\u0026gt;=len } 需要注意的是，底层的数组是可以被多个 slice 同时指向的，因此，对一个 slice 元素进行操作可能会影响其他指向对应数组的 slice。\n2. slice 的创建 方式 代码示例 说明 直接声明 var arr1 []int 其实是一个nil slice，array=nil,len=0,cap=0。此时没有开辟内存作为底层数组。 new arr2 := *new([]int) 也是一个nil slice，没有开辟内存作为底层数组。也没有设置元素容量的地方，此时只能通过append来添加元素，不能使用下标。 字面量 arr3 := []int{1,2,3} make arr4 := make([]int,2,5) 切片类型、长度、容量，其中容量可以不传，默认等于长度。 从切片或数组“截取” arr5 := arr4[1:2] 3. 关于 make 创建 slice Go 编译器会在编译期，根据以下两个条件来判断在哪个位置创建 slice：\n切片的大小和容量是否足够小 切片是否发生了逃逸 当要创建的切片非常小并且不会发生逃逸时，这部分操作会在编译期完成，并且创建在栈上或者静态存储区。如 n := make([]int,3,4) 会被直接转化成如下所示的代码：\nvar arr = [4]int n := arr[:3] 当发生逃逸或者比较大时，会在运行时调用 runtime.makeslice 函数在堆上初始化。而runtime.makeslice函数非常简单：\n// et是元素类型 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断len cap参数是否合法 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 在堆上申请一片连续的内存 return mallocgc(mem, et, true) } 这个函数的主要作用就是 计算当前切片所占用的内存空间并在堆上申请一段连续的内存，所需的内存空间采用以下的方式计算：\n内存空间 = 元素类型大小 * 切片容量cap 而元素类型的大小参照如下：\n类型 大小 bool, int8, uint8 1 bit int16, uint16 2 bit int32, uint32, float32 4 bit int, int64, uint64, float64, pointer 8 bit (1 个字节) string 16 bit (2 个字节) 长度为 n 的 array n * (对应的 type 的长度) TIPS：1 字节(Byte） = 8 位(bit)\nmallocgc 是专门用于内存申请的函数，后面会详细讲解。\n4. 切片截取 截取 是创建切片的一种方式，可以从数组或者切片直接截取，同时需要制定截取的起始位置。\n需要关注的是下面这种截取方式： arr1 = data[low : high : max]。这里的三个数字都是指原数组或切片的索引值，而非数量。\n这里的 low是最低索引值，是闭区间，也就是说第一个元素是位于data位于low索引处的元素；high是开区间，表示最后一个元素只能索引到 high - 1处；max也是开区间，表示容量为 max - 1。其中：len = high - low，cap = max - low，max \u0026gt;= high \u0026gt;= low。用下面的图来帮助说明：\n基于已有的数组或者切片创建新的切片，新 slice 和老 slice 会公用底层的数组，新老 slice 对底层数组的更改都会影响彼此。需要注意的是，如果某一方执行了append操作引起了 扩容 ，移动到了新位置，两者就不会影响了。所以关键问题在于二者是否会共用底层数组。\n我们通过一个例子来说明，该例子来自于雨痕 Go 学习笔记 P43，做了一些改造：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 55) s2 = append(s2, 77) s1[2] = 66 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } // 输出 [7 6 66] [5 4 3 2 100 200] [9 8 7 6 66 4 3 2 100 0] 让我们一步步来分析：\n首先，创建 slice、s1 和 s2：\nslice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] // len为3，cap默认到底层数组的结尾 s2 := s1[2:6:7] // len为4，cap为5 // 以上三个底层数组相同 之后，向 s2 尾部追加一个元素：\ns2 = append(s2, 55) s2的容量刚好还剩一个，直接追加，不会扩容。因为这三者此时还都共用同一个底层数组，所以这一改动，slice和s1都会受到影响：\n再次向 s2 追加一个元素：\ns2 = append(s2, 77) 此时，s2 的容量不够用，需要扩容。简单来说，扩容是新申请一块更大(具体多大，后面会说到，假设为原来的 2 倍)的内存块，将原来的数据 copy 过去，s2 的array指针指向新申请的那块内存。再次 append 之后：\n最后，修改 s1 索引为 2 处的元素：\ns1[2] = 66 此时 s2 已经使用了新开辟的内存空间，不再指向slice和s1指向的那个数组，因此 s2 不会受影响：\n后面打印 s1 的时候，只会打印出 s1 长度以内的元素。所以，只会打印出 3 个元素，虽然它的底层数组不止 3 个元素。\n5. append 扩容规则 之前说过，扩容是新申请一块更大的内存块，将原来的数据 copy 过去，原来切片的array指针指向新申请的那块内存。这里我们探讨这个“更大”到底是多大：\n第一步，预估扩容后的容量 newCap：\ndata = []int{1,2} data = appand(data,3,4,5) 扩容前的容量 oldCap = 2，新增 3 个元素，理论上应该扩容到 cap=5，之后会进行预估，求得 newCap 规则如下：\n如果 $oldCap * 2 \u0026lt; cap$，那么 newCap = cap；\n否则\n如果 扩容前元素个数oldLen \u0026lt; 1024​ ，那么直接翻倍，即 newCap = oldCap * 2； 否则(即 扩容前元素个数oldLen \u0026gt;= 1024 )，就先扩容 四分之一，也就是 1.25 倍，即 newCap = oldCap * 1.25。 即：\n这段规则的源码位于 /usr/local/go/src/runtime/slice.go：\nfunc growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { if old.len \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } ... } 上述例子中，oldCap=2，至少需要扩容到cap=5，根据预估规则，因为 oldCap*2=4 \u0026lt; 5，因此 newCap=cap=5，即预估结果为newCap=5。\n第二步，确定实际分配的内存，匹配到合适的内存规格\n理论上所需要内存 = 预估容量 * 元素类型大小，难道直接就会分配这么多的内存吗？并不是。\n首先元素类型大小已在 “一.3”中说明过，此处 int 类型的大小是 8bit(1 个字节)。接着看growslice函数：\nfunc growslice(et *_type, old slice, cap int) slice { ... var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) .... } 在这里，sys.PtrSize = 8，et类型是 int，所以 et.size == sys.PtrSize为 true，则 newcap * sys.PtrSize = 5 * 8 = 40。我们看看 roundupsize这个函数，位于 /usr/local/go/src/runtime/msize.go：\n// Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { // ... } } ... } 其中，_MaxSmallSize = 32768，smallSizeMax = 1024，smallSizeDiv = 8，而传进来的 size = 40。而：\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31} 所以上面roundupsize会返回：\nclass_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] = 48 在growslice中，capmem = 48，则最后计算得到的 newcap = int(capmem / sys.PtrSize) = int(48 / 8) = 6，即最终扩容后的容量为 6。而不是之前预估的 5。\n总结一下，首先使用预估规则预估一下需要的容量(本例中为 5)，然后用这个容量乘以 slice 元素的大小(单位是 bit，本例中 int 为 8)，之后根据在 class_to_size 中选择合适大小的值，比如 40，那应该选择比 40 大的更小的那个 48，这就是申请到的真正的容量内存，最后用真正的容量大小除以元素大小，即可得到真正的扩容后的 slice 的cap。\n6. slice 作为函数参数 函数调用处的参数称为 实参，函数定义处的参数称为 形参。形参是实参的拷贝，会生成一个新的切片，但二者指向底层数组的指针相同。\n当函数中没有出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,66,3,4,5,6] } func t1(s []int) { s[1] = 66 } 当函数中出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,2,3,4,5,6] } func t2(s []int) { s = append(s, 66) } 扩容后，指向的底层数组不同，互不影响。\n三、字符串(String) 字符串是 Go 语言中最常用的基础数据类型之一，虽然字符串往往被看做一个整体，但是实际上字符串是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组。\n在设计上，Go 语言中的string是一个只读的字节数组。当然，只读只意味着字符串会分配到只读的内存空间并且这块内存不会被修改，在运行时我们其实还是可以将这段内存拷贝到堆或者栈上，将变量的类型转换成 []byte 之后就可以进行，修改后通过类型转换就可以变回 string，Go 语言只是不支持直接修改 string 类型变量的内存空间。\nstring的底层结构如下：\n// /usr/local/go/src/runtime/string.go type stringStruct struct { str unsafe.Pointer len int } 可以看到和上面的切片结构非常相似，只是少了表示容量的cap。这是因为，字符串作为只读类型，我们并不会对齐进行扩容操作进而改变其自身的内存空间，所有在字符串上执行的写入操作都是通过拷贝实现的。\n关于字符串，讨论最多的是 string和[]byte互相转换的性能问题，在底层是通过 stringtoslicebyte 和 slicebytetostring两个函数实现的，其中出现了内存分配的情况，这里不做细究。\n在说unsafe 那篇文章里，提到了 实现string和[]byte 的零拷贝转换：这里再复习一下：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } ","permalink":"http://localhost:1313/posts/golang-%E6%95%B0%E7%BB%84-%E5%88%87%E7%89%87%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003cp\u003e在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\u003c/p\u003e","title":"Golang-数组,切片和字符串"},{"content":"一、 前言 我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\n最上面为高地址，最下面为低地址，分配时由高地址向低地址增长。函数的地址由低地址向高地址方向存放。\n从高地址到低地址依次为 栈空间、堆空间、全局静态变量区(数据区)、代码区。\n二、函数栈帧 函数执行时需要由足够的内存空间，用于存放 局部变量、返回值、参数等，这段空间对应内存中的栈。栈最上面是高地址，向下增长。\n分配给函数的栈空间，称为 函数栈帧(function stack frame)，栈底称为 栈基(bp)，栈顶称为 栈指针(sp)。函数调用结束后又会释放这个栈帧。bp 和 sp 始终指向正在执行的函数的栈帧。如果出现 A 调用 B，B 调用 C，C 调用 D，那么会出现由上到下分别为A的栈帧-\u0026gt;B的栈帧-\u0026gt;C的栈帧-\u0026gt;D的栈帧的情况:\n计算机执行函数时，会有专门的寄存器存放栈基 bp、栈指针 sp 和下一条要执行的指令 ip。\n所有的函数的栈帧布局都遵循统一的约定，所以被调用者是通过栈指针加上偏移量来定位到每个参数和返回值的。\nGo 在分配栈帧时是 一次性分配(主要是为了防止栈访问越界) ：(首先函数栈帧的空间在编译时期是可以确定的)确定栈基 bp，然后直接将栈指针 sp 移到所需最大栈空间的位置。之后通过栈指针 sp+偏移值这种相对寻址方式来使用函数栈帧。(例如需要将 3 和 4 依次入栈，则对应的指令分别是 sp+16 处存放 3，sp+8 处存放 4)\n由于函数栈帧的大小，可以在编译时期确定，对于栈消耗较大的函数，Go 编译器会在函数头部加上检测代码，如果发现需要进行栈增长，就会另外分配一块足够大的栈空间，并把原来栈上的数据拷过来，同时释放掉原来的栈空间。\n三、函数调用过程 有两个指令：call 和 ret。函数 call 指令实现跳转，而每个函数开始时都会分配栈帧，结束前又会释放自己的栈帧，ret 指令又会把栈恢复到之前的样子。\ncall的过程：\n将下一条指令的地址入栈，这就是返回地址，被调用函数执行结束后会回到这里； 跳转到被调用函数的入口处执行，这后面就是被调用函数的栈帧了。 ret过程：\n弹出返回地址； 跳转到这个返回地址 Go 与 C 语言不同的是，C 是通过寄存器和栈传递参数和返回值的，而 Go 是通过栈。下面通过举例说明 Go 中一个栈帧的结构以及函数调用过程中栈帧的变化：\n设有函数 A 和 B，在 A 内部调用了 B：\nfunc A() { x,y := 2,3 z := B(x,y) fmt.Println(x,y,z) } func B(m, n int) k int { return m + n } 首先需要了解的是，**被调用者的参数和返回值，都在调用者的函数栈帧中。**它们在栈中的顺序由上到下依次是：\nA 的局部变量 被调用函数 B 的返回值 传递给被调用函数 B 的参数(注意，参数顺序与实际书写书序相反) B 调用结束后的返回地址(A 中调用 B 之后要执行的命令，即 fmt.Println(x, y, z)) 调用者 A 的 bp 结构如下：\n而具体执行上述代码第 3 行也就是函数调用的详细过程如下：\n执行 call 函数：\na. 将调用者的下一条指令(第 4 行代码)入栈，这就是返回地址，被调用函数执行结束后会回到这里；\nb. 跳转到被调用者处(修改 ip 寄存器的值) 在被调用函数开始处有三步：\na. 将 sp 向下移动到足够的空间处(如 sp-24 处)；\nb. 调用者栈基(当前 bp 的值)入栈(调用者栈)(如存放到 sp+16 处)； 此时 bp 的值是被调用者 B 的栈基 结果是：bp 和 sp 始终指向正在执行的函数的栈帧； 接下来执行被调用函数剩下的部分；\na. 被调用者结束调用时，在 ret 函数前面还有两步：\n​ 1). 恢复调用者的栈基 bp 地址——第 2 步中的第 2 步，将栈该处的值赋给寄存器 bp\n​ 2). 释放自己的栈帧空间——第 2 步中的第 1 步，分配时向下移动了 24，则释放时向上移动多少 结果是：此时 bp 和 sp 已经恢复到调用者的栈帧了 执行 ret 步骤：\na. 弹出 call 指令的返回地址(对应过程 1 中的第 1 步)\nb. 跳转到弹出的这个地址(修改 ip 寄存器) 结果是：“被调用者”调用完毕，执行的是调用者的下一个指令，即调用完成(执行完被调用者)后，继续执行调用者函数。 如果在 B 中出现了defer操作，那么应该先执行defer，还是先执行return呢，还是先执行ret过程呢？\n答案是：Go 中的 return 并不是真正的返回，真正的返回操作是ret操作，return的作用仅仅是给返回值赋值，之后再执行defer操作，最后才是ret过程(释放自己的栈帧)。\n四、传参与返回值 理论部分已经全部说完了，下面通过一些实战来加深理解：\n为何有时通过函数交换变量位置却不成功？ func swap(a, b int) { a,b = b,a } func main() { a,b := 1,2 swap(a, b) fmt.Println(a,b) // 输出 1 2 // 交换失败 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2, a=1(入栈顺序与调用顺序相反)(没有返回值，对应3.传递给被调用函数 B 的参数) 执行 “a,b = b,a”，交换的是第 7 行入栈的两个变量而不是第 6 行入栈的调用者的局部变量 执行 ret 过程，返回之后，栈中 A 的局部变量并没有被改变，所以还是 a=1, b=2 再看下面的函数：\nfunc swap(a, b *int) { *a, *b = *b, *a } func main() { a,b := 1,2 swap(\u0026amp;a, \u0026amp;b) fmt.Println(a,b) // 输出 2 1 // 交换成功 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2 的地址, a=1 的地址(对应3.传递给被调用函数 B 的参数) 执行 “*a,*b = *b,*a”，传递的是 A 中变量的地址，实际上进行的是 A 中的变量的 b 和 A 中的变量的 a 交换 执行 ret 过程，返回之后，栈中 A 的局部变量被改变 有返回值，匿名返回值 func incr1(a int) int { var b int defer func() { a++ b++ }() a++ b = a return b } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 1 } 过程如下：前面说过，return 的作用相当于给返回值赋值，之后再执行 defer 函数，之后才是 ret 过程\n第 15 行，栈中从上到下为 a=0, b=0 第 16 行，incr1 的返回值，默认 0 值 第 2 行，incr1 的局部变量 b=0 第 9 行，incr1 的参数 a=0，自增后变成 2 第 10 行，incr1 的局部变量 b=1 第 11 行，incr1 的返回值被改变为 1 之后执行 defer 函数，incr1 的局部变量 a=3，incr1 的局部变量 b=1(注意，这里改变的是 incr1 的局部变量，而不是返回值) 返回，返回值依旧是 1 有返回值，非匿名返回值(命名返回值) func incr2(a int) (b int) { defer func() { a++ b++ }() a++ return a } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 2 } 过程与上述类似，只不过返回值变成了 incr1 中的 b，在第 8 步时首先被赋值 1，之后再 defer 中又自增，变成 2，因此返回值变成了 2。\n","permalink":"http://localhost:1313/posts/golang-%E5%85%B3%E4%BA%8E%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/","summary":"\u003ch2 id=\"一-前言\"\u003e一、 前言\u003c/h2\u003e\n\u003cp\u003e我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\u003c/p\u003e","title":"Golang-关于函数调用"},{"content":"选择优化的数据类型 MySQL 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\n更小的通常更好\n一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 0 ~ 200 ，那么字段类型设置为 unsigned tinyint 更好。\n简单就好\n简单数据类型的操作通常需要更少的 CPU 周期。例如整形比字符串的操作代价更低，因为字符串还要考虑 字符集 和 排序规则 ，使得字符串的比较比整形更加复杂。这里有两个例子：存储日期时，应该使用 MySQL 的内建类型( date 、 time 、 datetime 、 timestamp 等)而不是使用字符串；存储 IP 地址时，应该使用整型而非字符串， MySQL 中有专门的处理函数：\nmysql\u0026gt; select INET_ATON(\u0026#34;172.16.11.102\u0026#34;); +----------------------------+ | INET_ATON(\u0026#34;172.16.11.102\u0026#34;) | +----------------------------+ | 2886732646 | +----------------------------+ mysql\u0026gt; select INET_NTOA(2886732646); +-----------------------+ | INET_NTOA(2886732646) | +-----------------------+ | 172.16.11.102 | +-----------------------+ 行属性尽量避免 NULL\n一般情况下，某一行的默认属性是 NULL 。书中(《高性能 MySQL》)建议，最好指定列为 NOT NULL ，除非真的需要存储 NULL 值。这只是一个建议——如果计划在列上建索引，应该尽量避免设计成 可为 NULL 的列。\n1. 数字 1.1 整型(Whole Number) 可使用类型如下：\n类型 位数 范围 TINYINT 8 位（1 字节） -128~127 SMALLINT 16 位（2 字节） -32768~32767 MEDIUMINT 24 位（3 字节） -8388608~8388607（830 万多） INT 32 位（4 字节） -2147483648~2147483647（21 亿多） BIGINT 64 位（8 字节） -9223372036854775808~922, 3372, 0368, 5477, 5807（900 亿亿，反正很大啦） 整型有可选的 unsigned ，表示 非负 ，这大致可使正数的上限提高一倍。\n有符号和无符号整数使用相同的存储空间，有相同的性能，可根据实际情况选择以适合自己业务。\nMySQL 可以为整数类型指定宽度，例如 INT(11)， 但绝大多数情况下没有意义：对于存储和计算来说，**INT(11)**和 **INT(20)**是相同的，宽度不会限制值的合法范围，只是规定了 MySQL 的一些交互工具用来显示字符的个数。\n1.2 实数类型(Real Number) 实数是指 带有小部分的数字。我们能接触到的有 FLOAT 、 DOUBLE 和 DECIMAL 。这三个可以进一步划分： FLOAT 、 DOUBLE 称为浮点型， DECIMAL 就是 DECIMAL 类型。\n我们知道，标准的浮点运算由于硬件原因（篇幅所限具体原因请自行寻找），进行的是近似运算，如 Python 3.8 中 $0.1 + 0.2 = 0.30000000000000004$， Golang go1.13.4 darwin/amd64 中 fmt.Println(fmt.Sprintf(\u0026quot;%0.20f\u0026quot;, 0.1+0.2)) 输出$0.29999999999999998890 $ ，而 FLOAT 和 DOUBLE 所属的 浮点型 进行的就是这种运算。\n而 DECIMAL 用于存储精确的小数。因为 CPU 不支持对 DECIMAL 的直接计算，因此 在 MySQL 5.0及以后的版本 中， MySQL 服务器自身实现了 DECIMAL 的高精度计算。因此我们可以说，后期版本中，MySQL 既支持精确类型，也支持不精确类型。 相对而言， CUP 直接支持原生浮点运算，所以浮点运算明显更快。\nMySQL 使用二进制的形式存储 DECIMAL 类型。使用方式为 DECIMAL(总位数，小数点后位数) ，其中总位数最大为 65，小数点后位数最大为 30；并且位数与字节大小的对应关系为 9位/4字节 ，即每 9 位占 4 个字节，同时小数点占用一个字节。比如 DECIMAL(20, 9)共占用 5 个字节——小数点左边占用 3 个字节，小数点一个字节，小数点右边共占一个字节。\n浮点类型在存储同样范围的值时，通常比 **DECIMAL**使用更少的空间。 FLOAT 使用 4 个字节存储， DOUBLE 占用 8 个字节。需要注意的是，我们能选择的只是类型，即表示的范围大小，和整形一样，在 MySQL 底层进行计算的时候，所有的实数进行计算时都会转换成 DOUBLE 类型。\n2. 字符串 2.1 VARCHAR(变长字符串) VARCHAR 用于存储可变长字符串，是最常见的字符串数据类型。它比定长类型(CHAR)更加节省空间，因为它仅使用必要的空间。\n变长字符串 VARCHAR 需要使用额外的 1 个或 2 个字节记录字符串的长度：如果列的最大长度\u0026lt;=255 字节，则使用 1 个字节表示，否则使用 2 个字节。\nVARCHAR 节省空间，这对性能提升也有帮助，但由于行长是变的，如果通过 UPDATE 操作使得行长变得比原来更长，那就需要做一些额外的工作。不同引擎有不同的处理结果。\n当 VARCHAR 过长时，InnerDB 会将其保存为 BLOB，同时使用专门的外部区域来保存大文件，行中只保存对应的地址。\n2.2 CHAR(定长字符串) 当使用 CHAR(n) 时，会一次性分配足够的空间，注意这里的 n 指的是字符数而不是字节数。当存储 CHAR 时，会自动去掉末尾的空格，而 VARCHAR 不会。\nCHAR 非常适合存储很短的字符串，或者长度都很接近的字符串，例如密码的 MD5 值，因为这是一个定长的值。对于非常短的列， CHAR 比 VARCHAR 在存储空间上更有效率。\n关于“末尾空格截断”，通过下面的例子说明：\n\u0026gt; mysql\u0026gt; CREATE TABLE t1 (cl CHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t1(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t1; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3\u0026#39; | \u0026gt; +--------------------+ \u0026gt; ``` \u0026gt; \u0026gt; 我们再看下VARCHAR： \u0026gt; \u0026gt; ``` mysq \u0026gt; mysql\u0026gt; CREATE TABLE t2 (cl VARCHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t2(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t2; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3 \u0026#39; | \u0026gt; +--------------------+ 区别主要在 string3 后面的空格是否被截断。\n2.3 BLOB 和 TEXT BLOB 和 TEXT 都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。\n它们属于不同的数据类型：字符类型有 TINYTEXT, SMQLLTEXT, TEXT, MEDIUMTEXT, LONGTEXT，对应的二进制类型有 TINYBLOB, SMQLLBLOB, BLOB, MEDIUMBLOB, LONGBLOB。其中 BLOB 是 SMALLBLOB 的同义词，TEXT 是 SMALLTEXT 的同义词。\n当 BLOB 和 TEXT 的值太大时，InnerDB 会使用专门的“外部存储区域”进行存储实际内容，而行内使用 1~4 个字节存储一个外部内容的指针。\nBLOB 和 TEXT 家族之间仅有的不同是：BLOB 存储的是二进制的数据，没有排序规则和字符集，而 TEXT 有字符集和排序规则。\nMySQL 对 BLOB 和 TEXT 进行排序时与其他类型是不同的：它只针对没个列的最前 max_sort_length 字节而不是对整个字符串进行排序。如果需要排序的字符更少，可以尝试减小 max_sort_length ，或者使用 ORDER BY SUSTRING(column,length) 。\nMySQL 不能将 BLOB 或者 TEXT 列全部长度的字符串作为索引！\n3. 枚举、集合和位 3.1 枚举(ENUM) 枚举可以将一些不重复的字符串放到一个预定义的集合中，使用时也只能插入这个预定义集合中的某一个。\nMySQL 在存储枚举值时非常紧凑，在内部保存时，会将每个值在列表中的位置保存为整数(从 1 开始编号)，并在表的.frm 文件中保存“数字-字符串”映射关系的“查找表”；数据保存在两个字节中，因此枚举中可以有 $2^{16} - 1 = 65535$个。\nmysql\u0026gt; CREATE TABLE t2(e ENUM(\u0026#39;fish\u0026#39;,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;)); mysql\u0026gt; INSERT INTO t2(e) VALUES(\u0026#39;fish\u0026#39;),(\u0026#39;dog\u0026#39;),(\u0026#39;apple\u0026#39;),(1); # 注意，这里也可以世界使用枚举值对应的位置，如1对应\u0026#39;apple\u0026#39; # 查询枚举值，默认字符串表示 mysql\u0026gt; SELECT * FROM t2; +-------+ | e | +-------+ | fish | | dog | | apple | | fish | +-------+ # 使用数字形式表示枚举值 mysql\u0026gt; SELECT e+0 FROM t2; +------+ | e+0 | +------+ | 1 | | 3 | | 2 | | 1 | +------+ 尽量不要使用数字作为 ENUM 枚举常量，这种双重性很容易导致混乱，例如 ENUM('1','2','3') 。\n**注意：枚举字段是按照内部存储的整数而不是字符串顺序进行排序的。**一种绕过这种限制的方式是 刚开始就按照字典顺序来定义枚举值，另一中方式是使用 FIELD(列名，'arg1','arg2',…) 函数：\nmysql\u0026gt; SELECT e FROM t2 ORDER BY FIELD(e,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;,\u0026#39;fish\u0026#39;); +-------+ | e | +-------+ | apple | | dog | | fish | | fish | +-------+ 3.2 集合(SET) 如果说 ENUM 是单选的话，那 SET 就是多选。适合存储预定义集合中的多个值。同 ENUM 一样，其底层依旧通过整形存储。\n设定 set 的格式：\n字段名称 SET(\u0026#34;选项1\u0026#34;,\u0026#34;选项2\u0026#34;,...,\u0026#39;选项n\u0026#39;) 如 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); 同样的， SET 的每个选项值也对应一个数字，依次是 1，2，4，8，16...， 最多有 64 个选项。\n使用的时候，可以使用 set 选项的字符串本身（多个选项用逗号分隔），也可以使用多个选项的数字之和（比如：1+2+4=7）。\n通过实例来说明：\n# 建表 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); # 插入一个选项，字符串格式 INSERT INTO t3(hobby) VALUES(\u0026#39;swim\u0026#39;); # 插入多个选项，字符串格式，通过英文逗号分隔 INSERT INTO t3(hobby) VALUES(\u0026#39;swim,movie\u0026#39;); # 插入一个选项，数字格式 INSERT INTO t3(hobby) VALUES(1); # 等同于\u0026#39;swim\u0026#39; INSERT INTO t3(hobby) VALUES(4); # 等同于\u0026#39;movie\u0026#39; # 插入多个选项，数字格式 INSERT INTO t3(hobby) VALUES(7); # 等同于\u0026#39;swim,music,movie\u0026#39;，因为\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;分别为“1,2,4,8”，7=1+2+4. # 显示全部 mysql\u0026gt; SELECT * FROM t3; +------------------+ | hobby | +------------------+ | swim | | swim,movie | | swim | | movie | | swim,music,movie | +------------------+ # 查找包含movie的行 mysql\u0026gt; SELECT * FROM t3 WHERE FIND_IN_SET(\u0026#39;movie\u0026#39;,hobby) \u0026gt; 0; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 寻找包含排号为4的成员的行 mysql\u0026gt; SELECT * FROM t3 WHERE hobby \u0026amp; 4; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 直接使用字符串匹配 mysql\u0026gt; SELECT * FROM t3 WHERE hobby = \u0026#39;swim,movie\u0026#39;; +------------+ | hobby | +------------+ | swim,movie | +------------+ 3.3 位(BIT) NySQL 把 BIT 当成字符串类型而不是数字类型来存储。但是它的存储结果根据上下文会出现不同：\nmysql\u0026gt; CREATE TABLE t4(a BIT(8)); mysql\u0026gt; INSERT INTO t4(a) VALUES(b\u0026#39;00111001\u0026#39;); mysql\u0026gt; SELECT a, a+0 ,BIN(a) FROM t4; # bin()表示整数类型对应的二进制 +------+------+--------+ | a | a+0 | BIN(a) | +------+------+--------+ | 9 | 57 | 111001 | +------+------+--------+ 默认显示数字代表的 ASCII 码字符。\n","permalink":"http://localhost:1313/posts/mysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96/","summary":"\u003ch2 id=\"选择优化的数据类型\"\u003e选择优化的数据类型\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMySQL\u003c/code\u003e 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e更小的通常更好\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 \u003ccode\u003e0 ~ 200\u003c/code\u003e ，那么字段类型设置为 \u003ccode\u003eunsigned tinyint\u003c/code\u003e 更好。\u003c/p\u003e","title":"MySQL数据类型与优化"},{"content":"Docker 一、前言 Docker 是一个开源的应用容器引擎，可以让开发者将他们的应用以及依赖打包到一个可移植的容器中，这个容器可以发布并运行在任何流行的 Linux 环境下。\n理解：Docker 是什么？Docker 是一个容器，这个容器是可以随便移动的，就像一个箱子；箱子里是什么东西呢？箱子里是开发者写好的应用以及这个应用运行时的环境，即箱子里面是一个可以独立运行的沙盒应用；这个箱子有什么特点呢？可以随便搬动，并且能在任何 Linux 系统上直接运行（现在主流的服务器应用大多数都部署在 Linux 系统中）。\nDocker 的构想是实现Build, Ship, Run Anywhere，即通过对应用的 封装(Packaging) 、 分发(Distribution) 、 部署(Deployment) 、 运行(Runtime) 的生命周期进行管理，达到应用组件级别的“一次封装，到处运行”。这里的应用组件，既可以是一个 web 应用、一个编译环境，也可以是拥有运行环境的 web 服务，也可以是一套数据库平台服务，甚至是一个操作系统或者集群。\n二、Docker 架构 Docker 使用客户端-服务端架构。服务端负责构建、运行应用和分发容器（这个过程我是这样理解的：从上图可以看到有几个不同的角色：Client、daemon、registry、image 和 container，其中 registry 代表的是仓库，用来存储 image，同时我们也可以把 registry 中的 image（镜像）pull 到本地，进行修改之后 commit 回去，形成新的 image 存放在 registry，同时我们可以基于某个 image，在其中创建新的容器，这个容器中就是我们的应用和环境），客户端负责提供用户界面；Docker 客户端和守护进程之间使用 RESTful API，通过 unix 套接字或者网络接口进行通信，当我们使用 docker run 这样的命令时，客户端会将这些命令发送给他们的守护进程，然后守护进程执行这些命令；守护进程监听 Docker 客户端的请求并且管理服务端已有的 Docker 对象，如镜像、容器、网络。\n1. Registry（注册表） Docker Registry 用来存储 Docker 镜像。Docker Hub 是任何人都可以使用的公共注册中心，Docker 配置为默认在 Docker Hub 上查找镜像。当然你也可以运行自己的私人 Registry。\n当我们使用 docker pull 或者 docker run 的时候，将会从配置的 Registry 中提取所需要的镜像；使用 docker push 时，当前的镜像也将被推送到配置的 Registry 中。\n2. Image（镜像） 镜像是只读的，是用于创建一个容器的指令模板。通常情况下，一个镜像是基于另一个镜像，再加上自己的一些自定义配置形成的。举个例子，我们可以基于 Ubuntu 系统，在其基础上安装 nginx 以及其他 webserver 服务，以及这个服务运行时的各种配置信息，这样就行成了一个新的镜像。\n常见的虚拟机镜像，通常是由提供者打包成镜像文件，安装者从网上下载或是其他方式获得，恢复到虚拟机中的文件系统里；而 Docker 的镜像必须通过 Docker 打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。这样虽然失去了灵活性，但固定的格式意味着可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，使得在不同的机器中传递和共享 Docker 变得非常方便，这也是 Docker 能够提升工作效率的一处体现。\n通俗地讲，可以将 Docker 镜像理解为包含应用程序以及运行环境的基础文件系统，在容器启动的过程中，它以只读的方式被用于创建容器的运行环境。\nDocker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。\n对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，足以保证全球唯一性，这种编码（64 长度的字符串）的形式在 Docker 很多地方都有体现。由于镜像每层都有唯一的编码，就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，允许在镜像之间共享镜像层。举一个例子，由 Docker 官方提供的两个镜像 ElasticSearch 镜像和 Jenkins 镜像都是在 OpenJDK 镜像之上修改而得，实际使用的时候，这两个镜像是可以共用 OpenJDK 镜像内部的镜像层的。这带来的一项好处就是让镜像可以共用存储空间，达到 1+1\u0026lt;2 的效果，为在同一台机器里存放众多镜像提供了可能。\n2.1 镜像的命名 镜像的命名由三部分组成：username、repository 和 tag，他们的组织规则入下：\nusername 指上传镜像的用户；repository 表示镜像内容，形成对镜像的表意描述。有的镜像没有 username，这表明此镜像是由 Docker 官方进行维护的。\nrepository 表示镜像内容，形成对镜像的表意描述，通常采用的是软件名，这样的原因是，通常情况下，我们只在一个容器中运行一个应用，这样的命名可以更加方便的帮助我们识别镜像中的内容。\ntag 表示镜像版本，是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化，使用 tag 可以很好的区分和标识这些变化。tag 一般以版本号来命名。\n2.3 Container（容器） **容器是镜像的可运行实例。**默认情况下，一个容器和另外的容器机器主机相隔离，但是这都是可配置的。\n三、 概念理解 先说结论：一个”容器“，实际上是由 Linux Namespace 、 Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。\n1. LXC(Linux Container) Docker 其实是容器化技术的具体实现之一，采用 Golang 语言开发。很多人认为 Docker 是一种更轻量级的虚拟机，但事实上不是这样的，Docker 和虚拟机有本质的区别。容器在本质上讲，就是运行在操作系统上的一个进程，只不过加入了对资源的隔离和限制。Docker 正是基于容器的这个设计思想，采用 Linux Container 技术实现的核心管理引擎。\n为什么要进行这种设计呢？在默认情况下，一个操作系统里所有运行的进程共享 CPU 和内存资源，如果设计不当，在最极端的情况下，如果某进程出现死循环可能会耗尽所有的系统资源，其他的进程也会受到影响，这在企业级产品的场景下是不可接受的。\n不过，对资源进行隔离并不是新的发明，Linux 系统本身就支持操作系统级层面的虚拟化技术，叫做 Linux Container，即 LXC 的全称，它的作用是在操作系统的层次上为进程提供虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的 cpu 和 memory 节点，分配特定比例的 cpu 时间、IO 时间，限制可以使用的内存大小（包括内存和是 swap 空间），提供 device 访问控制，提供独立的 namespace（网络、pid、ipc、mnt、uts）。\nLXC，一种“操作系统层虚拟化”技术，为“linux 内核”容器功能的一个“用户空间接口”。LXC(LinuxContainer)是来自于 Sourceforge 网站上的开源项目，LXC 给 Linux 用户提供了用户空间的工具集，用户可以通过 LXC 创建和管理容器，在容器中创建运行操作系统就可以有效的隔离多个操作系统，实现操作系统级的虚拟化。最初的 Docker 容器技术基于 LXC 进行构建，后来 Docker 在自己的内核中刨除了 LXC。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。\n从前面的介绍中我们可以了解到，LXC 能够创建容器用于 Linux 系统的虚拟化，而 LXC 作为用户层管理工具主要提供了管理容器的接口，对实现容器的机制进行了封装隐藏，下面将对 LXC 容器的实现机制进行分析。LXC 有三大特色： cgroup 、 namespace 和 unionFS 。\nnamespace 这是另一个维度的资源隔离技术，与我们平常 C++程序开发中的 namespace 可以相类比。\n如果 cgroup 设计出来是为了隔离上面所描述的物理资源，那么 namespace 则用来隔离 PID、IPC、NETWORK 等系统资源。每一个 namespace 中的资源对其他 namespace 都是透明的，互不干扰。在每一个 namespace 内部，每一个用户都拥有属于自己的 init 进程，pid = 1，对于该用户来说，仿佛他独占了一台物理的 Linux 虚拟机。但是事实上，这个 namespace 中的 pid，只是其父容器的一个子进程而已。\n通过下图来加深理解：\n父容器有两个子容器，父容器的命名空间里有两个进程，id 分别为 3 和 4, 映射到两个子命名空间后，分别成为其 init 进程，这样命名空间 A 和 B 的用户都认为自己独占整台服务器。对于每一个命名空间，从用户看起来，应该像一台单独的 Linux 计算机一样，有自己的 init 进程(PID 为 1)，其他进程的 PID 依次递增，A 和 B 空间都有 PID 为 1 的 init 进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。从图中我们可以看到，进程 3 在父命名空间里面 PID 为 3，但是在子命名空间内，他就是 1. 也就是说用户从子命名空间 A 内看进程 3 就像 init 进程一样，以为这个进程是自己的初始化进程，但是从整个 host 来看，他其实只是 3 号进程虚拟化出来的一个空间而已。\n【参考】 DOCKER 基础技术：LINUX NAMESPACE（上）\nDOCKER 基础技术：LINUX NAMESPACE（下）\ncgroup（control group） 前面，我们介绍了 Linux Namespace，但是Namespace 解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。也就是说，虽然你通过 Namespace 把我 Jail 到一个特定的环境中去了，但是我在其中的进程使用用 CPU、内存、磁盘等这些计算资源其实还是可以随心所欲的。所以，我们希望对进程进行资源利用上的限制或控制。这就是 Linux CGroup 出来了的原因。\ncgroup 用来限定一个进程的资源使用，由 Linux 内核支持，可以限制和隔离 Linux 进程组（process groups）所使用的资源，比如 CPU、内存、磁盘和网络 IO，是 LXC 技术的物理基础。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。\nPrioritization: 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。\nAccounting: 一些审计或一些统计，主要目的是为了计费。\nControl: 挂起进程，恢复执行进程。\n使 ​​​ 用 ​​​ cgroup，系 ​​​ 统 ​​​ 管 ​​​ 理 ​​​ 员 ​​​ 可 ​​​ 更 ​​​ 具 ​​​ 体 ​​​ 地 ​​​ 控 ​​​ 制 ​​​ 对 ​​​ 系 ​​​ 统 ​​​ 资 ​​​ 源 ​​​ 的 ​​​ 分 ​​​ 配 ​​​、优先顺序、拒绝、监控和管理。可以更好地根据任务和用户分配硬件资源，提高总体效率。\n在实践中，系统管理员一般会利用 CGroup 做下面这些事（有点像为某个虚拟机分配资源似的）：\n隔离一个进程集合（比如：nginx 的所有进程），并限制他们所消费的资源，比如绑定 CPU 的核。\n为这组进程 分配其足够使用的内存\n为这组进程分配相应的网络带宽和磁盘存储限制\n限制访问某些设备（通过设置设备的白名单）\n【参考】DOCKER 基础技术：LINUX CGROUP\nunionFS unionFS 的含义是，可以把文件系统上多个目录内容联合挂载到同一个目录下，而目录的物理位置是分开的。\n我们来看一个例子(例子来自耗子叔的文章，但是原文中的不完善，我在这里补充一下)：\n首先我们建立两个目录(fruits 和 vegetables)，并在这两个目录中新建一些文件：\n# 创建目录 \u0026gt;\u0026gt;\u0026gt; mkdir fruits \u0026gt;\u0026gt;\u0026gt; mkdir vegetables \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;apple in fruits\u0026#34; \u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in fruits\u0026#34; \u0026gt; ./fruits/tomato \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;carrots in vegetables\u0026#34; \u0026gt; ./vegetables/carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in vegetables\u0026#34; \u0026gt; ./vegetables/tomato # 查看当前目录结构 \u0026gt;\u0026gt;\u0026gt; tree . . ├── fruits │ ├── apple │ └── tomato └── vegetables ├── carrots └── tomato 然后使用 aufs 进行 mount，注意 fruits 和 vegetables 的顺序：\n# 创建mount目录 \u0026gt;\u0026gt;\u0026gt; mkdir mnt # 把水果目录和蔬菜目录union mount到 ./mnt目录中 \u0026gt;\u0026gt;\u0026gt; sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt # 看一下当前的结构 \u0026gt;\u0026gt;\u0026gt; tree ./mnt ./mnt ├── apple ├── carrots └── tomato # 看一下mnt中的内容 \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables \u0026gt;\u0026gt;\u0026gt; cat ./mnt/tomato tomato in fruits 我们发现，fruits 和 vegetables 中的文件被 merge 到了一起，并且同名的文件只出现一次，默认以第一个文件夹为准。\n下面我们看一下 merge 后的文件和源文件之间的映射关系。第一步，修改源文件，merge 后的文件是否会受影响？\n# 修改fruits的apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 1 after fruits.apple\u0026#34; \u0026gt;\u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple # 查看mnt中的apple \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits append 1 after fruits.apple # 修改vevegtbles中的carrots echo \u0026#34;append 2 after vegetables.carrots\u0026#34; \u0026gt;\u0026gt; ./vevegtbles/carrots \u0026gt;\u0026gt;\u0026gt; cat ./vevegtbles/carrots carrots in vegetables append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots 由此可以得到：修改源文件，merge 后的文件也会同步改变。\n我们继续往下走：修改 mnt 中的文件，源文件会受到什么影响？\n\u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 3 after mnt.apple\u0026#34; \u0026gt;\u0026gt; ./mnt/apple # 查看源文件 \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple append 3 after mnt.apple # 重点来了，修改mnt.carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 4 in mnt.carrots\u0026#34; \u0026gt;\u0026gt; ./mnt/carrots tree . . ├── fruits │ ├── apple │ ├── carrots | └── tomato └── vegetables ├── carrots └── tomato \u0026gt;\u0026gt;\u0026gt; cat ./fruits/carrots append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots append 4 in mnt.carrots 我们 merge 后的第一个目录没有的文件，竟然将该文件复制进了第一个文件，然后进行了修改！\ndocker 通过一个叫做 copy-on-write (CoW) 的策略来保证 base 镜像的安全性，以及更高的性能和空间利用率。\nCopy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.\n当容器需要读取文件的时候: 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的 docker 容器共享运行时相同的文件)。 当容器需要添加文件的时候: 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候: 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候: 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 那么，这种 UnionFS 有什么用？\n历史上，有一个叫 Knoppix 的 Linux 发行版，其主要用于 Linux 演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把 CD/DVD 上的 image 运行在一个可写的存储设备上（比如一个 U 盘上），其实，也就是把 CD/DVD 这个文件系统和 USB 这个可写的系统给联合 mount 起来，这样你对 CD/DVD 上的 image 做的任何改动都会在被应用在 U 盘上，于是乎，你可以对 CD/DVD 上的内容进行任意的修改，因为改动都在 U 盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的 template，和另一个你的 working directory 给 union 在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个 ad hoc snapshot。\nDocker 把 UnionFS 的想像力发挥到了容器的镜像。你是否还记得我在介绍 Linux Namespace 上篇中用 mount namespace 和 chroot 山寨了一镜像。现在当你看过了这个 UnionFS 的技术后，你是不是就明白了，你完全可以用 UnionFS 这样的技术做出分层的镜像来。\n这就是 Docker 容器镜像分层实现的技术基础。所以我们说，Docker 中新的镜像并不是从头开始制作的，而是从一些 base 镜像的基础上创建并加上自定义修改而形成的，这些自定义的设置不会影响原来的 base 镜像。和 git 中的 commit 很像。这种设计的优点就是资源共享。试想一下，一台宿主机上运行 100 个基于 debian base 镜像的容器，难道每个容器中都保存一份重复的 debian 的拷贝吗？这显然不合理。借助 Linux 的 unionFS，宿主机只需要在磁盘上保存一份 base 镜像，内存中也加载一份，就能被所有基于这个 base 镜像的容器所共享。(举一个后面会遇到的例子：当我们使用 docker pull ubuntu:latest 这个命令的时候，可以看到如下的输出信息，从这个过程我们可以看出，镜像文件一般由若干层组成，使用 docker pull 下载中会获取并输出镜像的各层信息，当不同的镜像包括相同的层时，本地仅存了层的其中一份，减小了存储空间。)\n\u0026gt;\u0026gt;\u0026gt; docker pull ubuntu:latest latest: Pulling from library/ubuntu 35c102085707: Pull complete 251f5509d51d: Pull complete 8e829fe70a46: Pull complete 6001e1789921: Pull complete Digest: sha256:66cd4dd8aaefc3f19afd407391cda0bc5a0ade546e9819a392d8a4bd5056314e Status: Downloaded newer image for ubuntu:latest \u0026gt;\u0026gt;\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 5 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB 可以看到最新的 ubuntu 镜像只有 64M，而 centos 也只有 202M，是不是觉得太小了？这是因为 docker 在运行的时候直接使用了 docker 宿主机器的 kernel。\nLinux 操作系统由内核空间和用户空间组成。\n内核空间是 kernel，用户空间是 rootfs, 不同 Linux 发行版的区别主要是 rootfs. 比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。\n所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。\n需要注意的是，base 镜像只是用户空间和发行版一致。kernel 使用的是 docker 宿主机器的 kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。\nAUFS 有所有 Union FS 的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被 mount 好的目录。AUFS 的 whiteout 的实现是通过在上层的可写的目录下建立对应的 whiteout 隐藏文件来实现的。也就是说，如果我们想要删除某个地分支的文件，只需要在高分支的可写目录下，建立一个 whiteout的名字是’.wh.\u0026lt;filename\u0026gt;’ ，那么对应的下层的 \u0026lt;filename\u0026gt; 就会被删除，即使不被删除，也会不可见。\n当用 docker run 启动某个容器的时候，实际上容器的顶部添加了一个新的可写层，这个可写层也叫容器层。容器启动后，它里面的所有对容器的修改包括文件的增删改都只会发生在最顶部的容器层，而对下面的只读镜像层没有影响。\n【参考】DOCKER 基础技术：AUFS\n四、 Docker 镜像 刚开始学习时，很多人会分不清 镜像(image) 和 容器(container) 的区别。这里引用 Stackverflow：What is the difference between a Docker image and a container?的解释：\nAn instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.\nthe image is the recipe, the container is the cake ; -) you can make as many cakes as you like with a given recipe.\n镜像可以理解为一种 构建时(build-in)结构 ，而容器可以理解为一种 运行时(run-time)结构 。我们通常使用 docker service create 和 docker container run 从某个镜像启动一个或者多个容器。一旦容器从镜像启动之后，二者就变成了互相依赖的关系，并且在镜像启动的容器全部停止之前，镜像是无法被删除的。\n1. 镜像命名 docker pull DNS名称/用户名/镜像名:tag名 上述命令可以简写成 docker pull 镜像名 ，表示从 Docker 官方仓库中，默认拉取 tag 为 latest 的镜像。\n2. 常用命令 docker image pull xxx: 下载镜像 docker image ls: 列出当前主机上的所有镜像(-a 列出所有 -p只列出id) docker image inspect xxx: 查看当前image的详情 docker image rm xxx: 删除某个镜像(docker image rm $(docker image ls -a) -f 删除本机上所有的镜像) docker container rm $(docker container ls -a | awk \u0026#39;$1 !=\u0026#34;CONTAINER\u0026#34; {print $1}\u0026#39;) -f：删除所有的container 四、 Dockerfile 在实际开发中，几乎都是采用 Dockerfile 来制作镜像，而很少会采用将容器整个提交的方式。Dockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件。在 Dockerfile 中，包含了构建一个镜像过程中需要执行的命令以及其他操作。常见的 Docker 命令如下：\nFROM 之前提到过，我们不会从 0 开始构建一个镜像，而是会选择一个已经存在的镜像作为 base。FROM 用于指定一个 base 镜像，之后的所有操作都是基于这个 base 镜像来执行的，Docker 会先获取这个给出的 base 镜像，然后在这个 base 镜像上进行后面的构建操作。FROM 支持三种格式：\nFROM \u0026lt;image\u0026gt; [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] [AS \u0026lt;name\u0026gt;] 一般使用第二种，当 tag 不写时，默认为 latest。除了选择现有的镜像之外，Docker 还存在一个特殊的镜像，叫 scratch，它表示一个空白的镜像。如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。\nRUN RUN 用来在构建 docker 镜像的过程中执行命令行命令。但是并不建议一条 shell 命令一个 RUN。为什么呢？之前说过，Dockerfile 中的每一条指令都会建立一层，RUN 也不例外。每一个 RUN 行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这条命令，执行结束后，commit 这一层的修改，构成新的镜像。如果有很多 RUN，会出现很多运行时不需要的东西，结果就是产生了非常臃肿、非常多层的镜像, 不仅增加了构建部署的时间，也很容易出错。正确的做法是将这些命令通过\u0026amp;\u0026amp;符号串起来，如果需要换行就是用“\\”来连接两行，简化为一层，并且及时删除下载的 tgz 文件等。因此，在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\nENV 用于设置环境变量。例如：\nENV VERSION=1.0 DEBUG=on \\ NAME=\u0026#34;Happy Feet\u0026#34; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。\nWORKDIR Dockerfile 中的 WORKDIR 指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。相当于设置根目录。当使用相对目录的情况下，采用上一个 WORKDIR 指定的目录作为基准，相当与 cd 命令，但不同的是指定了 WORKDIR 后，容器启动时执行的命令会在该目录下执行。\nCMD 与 ENTRYPOINT 之前了解到，Docker 不是虚拟机，容器就是进程。既然是进程，那么启动容器的时候，需要指定所运行的程序以及参数。CMD 就是用于默认的容器主进程的启动命令的。当然 Dockerfile 中也可以没有 CMD，在运行时指定也可以。\n另外需要注意的是，容器中运行一个服务没有前后台的概念。为什么呢？对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。举个例子，我们使用了\nCMD service nginx start 然后发现容器执行后就立即退出了，甚至在容器内去使用 systemctl 命令发现根本执行不了。原因是使用“service nginx start”，则是希望 upstart 以后以后台守护进程的形式启动 nginx 服务，但是“CMD service nginx start”会被理解成 CMD [ \u0026ldquo;sh\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;service nginx start\u0026rdquo;]，因此主进程实际上是 sh，那么当 service nginx start 命令结束以后，sh 也就消失了，sh 作为主进程退出了，自然就会使容器退出。正确做法是直接执行 nginx 可执行文件，并且要以前台的形式运行，如\nCMD nginx -g \u0026#39;daemon off;\u0026#39; ENTRYPOINT 的目的和 CMD 一样，都是指定容器启动程序以及参数。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为\n\u0026lt;ENTRYPOINT\u0026gt; \u0026#34;\u0026lt;CMD\u0026gt;\u0026#34; COPY 与 ADD COPY 指令将从构建上下文目录中 \u0026lt;源路径\u0026gt; 的文件/目录复制到新的一层的镜像内的 \u0026lt;目标路径\u0026gt; 位置。\u0026lt;源路径\u0026gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath. Match 规则，比如：\nCOPY package.json /usr/src/app/ \u0026lt;目标路径\u0026gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。\n在使用该指令的时候还可以加上 \u0026ndash;chown=: 选项来改变文件的所属用户及所属组。\nCOPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。使用 ADD 时，如果原路径是一个 url 或者压缩包，Docker 引擎会将这个 url 下载或者将压缩包解压之后再复制。看情况使用即可。\nEXPOSE 声明运行时容器提供服务的端口，这只是一个声明（即打算、推荐用这个端口），在运行是并不会因为这个声明而开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处：\n帮助镜像使用者理解这个镜像服务推荐使用的端口，以方便配置映射；\n在运行时使用端口映射，也就是 docker run -P 时( -P 表示随机映射)，会自动映射 EXPOSE 的端口。\n需要区分 docker run -P 和 docker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; ：\ndocker run -P 会随机映射宿主端口到 Dockerfile 中的 EXPOSE ，如： \u0026gt;\u0026gt;\u0026gt; cat Dockerfile FROM nginx:latest EXPOST 80 90 \u0026gt;\u0026gt;\u0026gt; docker build -t nginx-test . \u0026gt;\u0026gt;\u0026gt; docker run -d -P nginx-test \u0026gt;\u0026gt;\u0026gt; docker container ls # 输出 9e3f0b2d6569 nginx-test \u0026#34;/docker-entrypoint.…\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:32769-\u0026gt;80/tcp, 0.0.0.0:32768-\u0026gt;90/tcp compassionate_pascal 这其中会将本机的 32769 和 32768 暴露出来，同时映射到容器中的 80 和 90 。\ndocker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; 指定宿主机和容器的端口： \u0026gt;\u0026gt;\u0026gt; docker run -d -p 8080:80 nginx-test 此时访问宿主机的 curl 宿主机IP:8080 会映射到容器内的 80 端口。\nVOLUMN docker 提供一种机制，可以将宿主机上的某个目录与容器的某个目录(称为挂载点，或者卷)关联起来，容器挂载点下的内容就是宿主机对应目录下的内容，可以有以下效果：\n容器基于镜像创建，容器的文件系统包括镜像的只读层+可写层，容器进程所产生的的数据均保存在可写层上，一旦容器删除，上面的数据就没有了，除非手动备份下来。而 卷挂载 机制可以让我们把容器中的某个目录和宿主机关联，让容器中的数据持久保存在宿主机上，即使容器删除，产生的数据仍在。 当我们开发一个应用时，开发环境在本机，运行环境启动在一个 docker 容器中，当我们修改一处之后想看到效果，需要重启容器，这显然比较麻烦。此时可以设置容器与本机的某个目录同步，当我们修改主机上的内容是，不需要同步容器，对容器来说是自动生效的，比如一个 web 应用，修改 index.html 后，刷新之后马上就能看到效果。 多个容器运行一组关联服务，共享一些数据。 通过一个 nginx 实例加深理解：\n1. 指明宿主机的目录\n# 拉取nginx镜像 docker pull nginx:latest # 创建宿主机目录 mkdir -p /Users/hujiaming/Downloads/nginx_test/index # 自定义欢迎页内容 cat \u0026#34;\u0026lt;h1\u0026gt; Hello World \u0026lt;/h1\u0026gt;\u0026#34; \u0026gt;\u0026gt;\u0026gt; /Users/hujiaming/Downloads/nginx_test/index/index.html # 将宿主机端口8080映射到容器端口80，将宿主机目录 /Users/hujiaming/Downloads/nginx_test/index 映射到容器目录 /usr/share/nginx/html(这个目录中存放nginx默认的欢迎页index.html) docker run -d -p 8080:80 -v /Users/hujiaming/Downloads/nginx_test/index:/usr/share/nginx/html --name nginx nginx 此时访问 宿主机 IP:8080，会出现 Hello World 而不是 nginx 的默认欢迎页，当我们修改 nginx_test/index/index.html 内容时，刷新浏览器发现也会同步刷新。\n2. 未指定关联的主机目录\ndocker run -d -p 8080:80 -v /data --name nginx nginx 上述命令只设置了容器的挂载点，并没有指定关联的主机目录。这时候 docker 会自动绑定主机上的一个目录。可以通过 docker inspect \u0026lt;name\u0026gt; 查看:\n\u0026gt;\u0026gt;\u0026gt; docker run -d -it -v /data nginx # 查看得到Container ID为： a369cc1f6efa \u0026gt;\u0026gt;\u0026gt; docker inspect a369cc1f6efa # 输出 ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/data\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ], ... 上面 Mounts 下的每条信息记录了容器上一个挂载点的信息，\u0026ldquo;Destination\u0026rdquo; 值是容器的挂载点，\u0026ldquo;Source\u0026quot;值是对应的主机目录。可以看出这种方式对应的主机目录是自动创建的，其目的不是让在主机上修改，而是让多个容器共享。\n此外还可以使用 --volumn-from 参数指定和某个已经存在的容器共享挂载点。\n五、 实战 1. 在 Ubuntu19 中安装 docker # 旧版本中docker叫做 docker , docker.io , docker-engine，如果这些旧版本已经安装，先卸载掉他们 sudo apt-get remove docker docker-engine docker.io containerd runc # 添加依赖 sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 添加GPG curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 在 /etc/apt/sources.list中添加依赖 sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # 更新 sudo apt-get update # 安装docker服务 sudo apt-get install docker-ce 2. 启动和关闭容器 # 查看当前已有的image \u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 10 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB nginx latest 53f3fd8007f7 3 months ago 109MB centos 7 9f38484d220f 5 months ago 202MB jenkins latest cd14cecfdb3a 13 months ago 696MB # 启动(-it 告诉docker，开启容器的交互模式并将读者当前的shell连接到容器的终端；/bin/bash 是说用户在容器内部想运行bash这个进程) \u0026gt;\u0026gt;\u0026gt; docker run -it ubuntu:latest /bin/bash # 不关闭容器而退出容器 \u0026gt;\u0026gt;\u0026gt; 组合键 ctrl + PQ # 在宿主机器上查看运行的机器 \u0026gt;\u0026gt;\u0026gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a847b8ed22b4 ubuntu:latest \u0026#34;/bin/bash\u0026#34; 41 seconds ago Up 40 seconds dreamy_bardeen 6ccf082c4be6 centos:7 \u0026#34;/bin/bash\u0026#34; 4 hours ago Up 4 hours heuristic_tu # 连接到运行中的容器(记得将下面的dreamy_bardeen换成你自己的容器名称，在docker container ls结果最后一列) \u0026gt;\u0026gt;\u0026gt; docker container exec -it dreamy_bardeen bash # 停止容器 \u0026gt;\u0026gt;\u0026gt; docker container stop dreamy_bardeen # 杀死容器 \u0026gt;\u0026gt;\u0026gt; docker container rm dreamy_bardeen 3. 多阶段构建 编写如下 go 文件：\n# main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { engine := gin.Default() engine.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { name := c.Query(\u0026#34;name\u0026#34;) fmt.Println(\u0026#34;hello \u0026#34; + name) c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hello \u0026#34; + name}) }) engine.Run(\u0026#34;:8899\u0026#34;) } 使用 go mod :\ngo mod init demo_go go mod tidy 对于 Dockerfile 的编写，有三种方案：\n方案一：直接使用 golang 全镜像\nFROM golang:1.14-alpine EXPOSE 8899 WORKDIR /go/src/demo_go COPY . /go/src/demo_go RUN GOPROXY=https://goproxy.cn,direct go build -v -o main *.go ENTRYPOINT [ \u0026#34;./main\u0026#34; ] 方案二：使用两个 Dockerfile，第一个编译出可执行二进制，第二个直接将二进制复制进去执行\n# cat Dockerfile.build FROM golang:1.14-alpine WORKDIR /apps/demo_go COPY . . RUN go build -v -o app *.go # cat Dockerfile.copy FROM golang:1.14-alpine WORKDIR /root/ COPY app /root/app RUN chmod a+x /root/app EXPOSE 8899 ENTRYPOINT [\u0026#34;/root/app\u0026#34;] # 这二者通过一个build.sh文件组合在一起 # cat build.sh #!/bin/bash echo \u0026#34;start build demo_go:stage1\u0026#34; docker build -t demo_go:build . -f Dockerfile.build docker create --name extract demo_go:build docker cp extract:/apps/demo_go/app ./app docker rm -f extract echo \u0026#34;start build demo_go:stage2\u0026#34; docker build --no-cache -t demo_go:install . -f Dockerfile.copy rm -rf ./app 方案三：多阶段构建\n# 第一阶段，编译出可执行文件 FROM golang:1.14-alpine as builder WORKDIR /apps COPY . . RUN CGO_ENABLED=0 GOOS=linux GOPROXY=https://goproxy.cn,direct go build -v -a -o app *.go # 第二阶段，将第一阶段编译好的二进制复制进最后一个阶段的容器即可 FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /apps/app . EXPOSE 8899 CMD [\u0026#34;./app\u0026#34;] 分别使用不同的执行构建 image：\n# 第一种 docker build -t demo_go:source -f Dockerfile . # 第二种 bash build.sh # 第三种 docker build -t demo_go:multi -f Dockerfile.multi . 这三种方案有什么区别？我们看一下各自 image 的大小：\n\u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID SIZE demo_go copy ab80d3d110b6 401MB demo_go source 274bf686025c 474MB demo_go app 7e8207b60f07 394MB demo_go multi 62b316cc49bd 21.1MB 看出差距了？\n","permalink":"http://localhost:1313/posts/%E5%85%B3%E4%BA%8Edocker/","summary":"这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要","title":"关于docker"},{"content":" 关于我 你好！我是 hujm2023，欢迎来到我的个人技术博客。\n关于本站 这里是我分享技术经验、学习心得和编程实践的地方。主要内容包括：\n技术栈 编程语言: Golang、Python、Java 数据库: MySQL、Redis 工具: Git、Docker、Kubernetes 系统: Linux 博客内容 算法与数据结构: LeetCode 题解、经典算法实现 后端开发: Go 语言深入解析、并发编程、性能优化 数据库技术: MySQL 底层原理、Redis 源码分析 系统架构: 分布式系统设计、微服务架构 开发工具: 效率工具使用技巧、最佳实践分享 技术理念 追求代码质量和工程实践 重视基础理论与实际应用的结合 持续学习，保持技术敏感度 乐于分享，共同进步 联系方式 如果你对文章内容有疑问，或者想要技术交流，欢迎通过以下方式联系我：\n邮箱: hujm.net@gmail.com GitHub: github.com/hujm2023 声明 本博客所有文章均为个人原创（除特别注明外），转载请注明出处。文章中的观点仅代表个人看法，如有错误欢迎指正。\n感谢你的访问，希望这些内容对你有所帮助！\n","permalink":"http://localhost:1313/about/","summary":"关于本站和作者","title":"关于"},{"content":"前言 堆，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作 根节点（root node），根节点本身没有 父节点（parent node）。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\n优先级队列 是计算机科学中的一类抽象数据类型。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。优先队列往往用堆来实现。\nGolang实现一：根据原理简单实现 package minheap import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; ) /* * @CreateTime: 2021/7/6 21:57 * @Author: hujiaming * @Description: Golang实现最小堆 */ var ErrMinHeapEmpty = errors.New(\u0026#34;minHeap is empty\u0026#34;) const HeapHeadTag int64 = math.MinInt64 type MinHeap struct { elements []int64 } // NewMinHeap 创建一个最小堆实例 func NewMinHeap() *MinHeap { return \u0026amp;MinHeap{elements: []int64{HeapHeadTag}} } /* Add 将一个元素添加到最小堆中，并且添加后要使其满足最小堆的特性 首先将该元素插入到数组最后，然后对这最后一个元素进行 “上浮” 操作： 该元素与父元素进行大小比较，如果小于父元素，则和父元素交换位置，如此循环，直到 到达堆顶 或 子元素小于父元素。 */ func (mh *MinHeap) Add(v int64) { // 1. 先将元素插在数组最后面 mh.elements = append(mh.elements, v) // 2. 将最后一个元素上浮，使其符合最小堆的性质。其实是为 v 找位置 i := len(mh.elements) - 1 for ; mh.elements[i/2] \u0026gt; v; i /= 2 { mh.elements[i] = mh.elements[i/2] } mh.elements[i] = v } /* PopMin 弹出堆中最小的元素 对最小堆而言，移除元素，只能移除堆顶(最小值)的元素。 首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作： 将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。 */ func (mh *MinHeap) PopMin() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } res := mh.elements[1] last := mh.elements[len(mh.elements)-1] // idx 表示最后一个元素应该在的位置 var idx int for idx = 1; idx*2 \u0026lt; len(mh.elements); { // 找出子节点中较小的元素的 index minChildIdx := idx * 2 if minChildIdx \u0026lt; len(mh.elements)-1 \u0026amp;\u0026amp; mh.elements[minChildIdx+1] \u0026lt; mh.elements[minChildIdx] { minChildIdx++ } // 当前结点 大于 较小子节点，和这个较小子节点交换位置，继续循环 if last \u0026gt; mh.elements[minChildIdx] { mh.elements[idx] = mh.elements[minChildIdx] idx = minChildIdx continue } break } mh.elements[idx] = last mh.elements = mh.elements[:len(mh.elements)-1] return res, nil } // PeekHead 只返回堆顶元素(最小值)，不进行下沉操作 func (mh *MinHeap) PeekHead() (int64, error) { if mh.IsEmpty() { return 0, ErrMinHeapEmpty } return mh.elements[1], nil } // IsEmpty 最小堆是否是空的 func (mh *MinHeap) IsEmpty() bool { if len(mh.elements) == 0 || (len(mh.elements) == 1 \u0026amp;\u0026amp; mh.elements[0] == HeapHeadTag) { return true } return false } // Length 返回最小堆中的元素个数 func (mh *MinHeap) Length() int { return len(mh.elements) - 1 } // Print 打印代表最小堆的数组 func (mh *MinHeap) Print() { fmt.Println(mh.elements[1:]) } Test 如下：\nfunc TestMinHeap(t *testing.T) { mh := NewMinHeap() mh.Add(4) mh.Add(2) mh.Add(7) mh.Add(9) mh.Add(1) mh.Add(5) mh.Add(10) mh.Add(3) mh.Add(2) mh.Print() for !mh.IsEmpty() { fmt.Println(mh.PopMin()) } assert.Equal(t, mh.Length(), 0) } // 输出 /* [1 2 5 2 4 7 10 9 3] 1 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 2 \u0026lt;nil\u0026gt; 3 \u0026lt;nil\u0026gt; 4 \u0026lt;nil\u0026gt; 5 \u0026lt;nil\u0026gt; 7 \u0026lt;nil\u0026gt; 9 \u0026lt;nil\u0026gt; 10 \u0026lt;nil\u0026gt; */ Golang 实现二：实现标准库 heap.Interface 接口 先看下标准库中的 Interface，位置在 container/heap/heap.go：\n// The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // An implementation of Interface can be sorted by the routines in this package. // The methods refer to elements of the underlying collection by integer index. type Interface interface { // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the \u0026lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } 我们以此为基础，实现一个 优先级队列:\npackage priorityqueen type Item struct { value int64 // 实际值 priority int64 // 优先级 index int // 当前 item 在数组中的 index } // PriorityQueen 表示优先级队列 type PriorityQueen []*Item func (mh2 PriorityQueen) Len() int { return len(mh2) } func (mh2 PriorityQueen) Less(i, j int) bool { return mh2[i].priority \u0026lt; mh2[j].priority } func (mh2 PriorityQueen) Swap(i, j int) { mh2[i], mh2[j] = mh2[j], mh2[i] mh2[i].index = i mh2[j].index = j } // Push 将 x 添加到数组最后 func (mh2 *PriorityQueen) Push(x interface{}) { l := len(*mh2) c := cap(*mh2) if l+1 \u0026gt; c { cmh2 := make([]*Item, l, c/2) copy(*mh2, cmh2) *mh2 = cmh2 } *mh2 = (*mh2)[:l+1] item := (x).(*Item) item.index = l (*mh2)[l] = item } // Pop 返回数组最后一个元素 func (mh2 *PriorityQueen) Pop() interface{} { l := len(*mh2) c := cap(*mh2) if l \u0026lt; c/2 \u0026amp;\u0026amp; c \u0026gt; 25 { cmh2 := make([]*Item, l, c/2) copy(cmh2, *mh2) *mh2 = cmh2 } item := (*mh2)[l-1] item.index = -1 // for safety *mh2 = (*mh2)[:l-1] return item } // PopHead 弹出堆顶元素 func (mh2 *PriorityQueen) PopHead() *Item { if mh2.Len() == 0 { return nil } item := (*mh2)[0] heap.Remove(mh2, 0) return item } // PopWithPriority 弹出优先级小于 maxP 的堆顶元素，如果没有，返回 nil 和 当前堆顶和maxP的距离 func (mh2 *PriorityQueen) PopWithPriority(maxP int64) (*Item, int64) { if mh2.Len() == 0 { return nil, 0 } item := (*mh2)[0] if item.priority \u0026gt; maxP { return nil, item.priority - maxP } heap.Remove(mh2, 0) return item, 0 } // PeekHead 显示堆顶元素 func (mh2 *PriorityQueen) PeekHead() *Item { if mh2.Len() == 0 { return nil } heap.Init(mh2) item := (*mh2)[0] return item } 测试一下：\nfunc TestPriorityQueen(t *testing.T) { items := make([]*Item, 0) rand.Seed(time.Now().UnixNano()) for i := 0; i \u0026lt; 10; i++ { v := rand.Int63n(100) items = append(items, \u0026amp;Item{ value: v, priority: v, index: i, }) } q := PriorityQueen(items) heap.Init(\u0026amp;q) fmt.Println(q.PeekHead()) maxP := int64(50) for _, i := range q { if i.priority \u0026lt; maxP { fmt.Println(fmt.Sprintf(\u0026#34;p: %d, v: %d\u0026#34;, i.priority, i.value)) } } fmt.Println(\u0026#34;====\u0026#34;) for i := 0; i \u0026lt; 10; i++ { item, _ := q.PopWithPriority(maxP) if item != nil { fmt.Println(item) } } fmt.Println(\u0026#34;====\u0026#34;) for { item := q.PopHead() if item == nil { break } fmt.Println(item) } } // 输出 /* \u0026amp;{5 5 0} p: 5, v: 5 p: 11, v: 11 p: 6, v: 6 p: 33, v: 33 ==== \u0026amp;{5 5 -1} \u0026amp;{6 6 -1} \u0026amp;{11 11 -1} \u0026amp;{33 33 -1} \u0026amp;{50 50 -1} ==== \u0026amp;{52 52 -1} \u0026amp;{73 73 -1} \u0026amp;{85 85 -1} \u0026amp;{97 97 -1} \u0026amp;{99 99 -1} */ Golang 标准库 heap.Interface 源码解析 整个包的实现非常简洁，加上注释以及空行，整个文件才只有120 行：\n// Copyright 2009 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package heap provides heap operations for any type that implements // heap.Interface. A heap is a tree with the property that each node is the // minimum-valued node in its subtree. // // The minimum element in the tree is the root, at index 0. // // A heap is a common way to implement a priority queue. To build a priority // queue, implement the Heap interface with the (negative) priority as the // ordering for the Less method, so Push adds items while Pop removes the // highest-priority item from the queue. The Examples include such an // implementation; the file example_pq_test.go has the complete source. // package heap import \u0026#34;sort\u0026#34; // The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // // !h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // Init establishes the heap invariants required by the other routines in this package. // Init is idempotent with respect to the heap invariants // and may be called whenever the heap invariants may have been invalidated. // The complexity is O(n) where n = h.Len(). func Init(h Interface) { // heapify n := h.Len() // (n/2 - 1) 处的结点是最后一棵子树(没有孩子结点)的根节点 for i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) } } // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 h.Swap(0, n) down(h, 0, n) return h.Pop() } // Remove removes and returns the element at index i from the heap. // The complexity is O(log n) where n = h.Len(). func Remove(h Interface, i int) interface{} { n := h.Len() - 1 if n != i { h.Swap(i, n) if !down(h, i, n) { up(h, i) } } return h.Pop() } // Fix re-establishes the heap ordering after the element at index i has changed its value. // Changing the value of the element at index i and then calling Fix is equivalent to, // but less expensive than, calling Remove(h, i) followed by a Push of the new value. // The complexity is O(log n) where n = h.Len(). func Fix(h Interface, i int) { if !down(h, i, h.Len()) { up(h, i) } } func up(h Interface, j int) { for { i := (j - 1) / 2 // parent if i == j || !h.Less(j, i) { break } h.Swap(i, j) j = i } } func down(h Interface, i0, n int) bool { i := i0 for { j1 := 2*i + 1 if j1 \u0026gt;= n || j1 \u0026lt; 0 { // j1 \u0026lt; 0 after int overflow break } j := j1 // left child if j2 := j1 + 1; j2 \u0026lt; n \u0026amp;\u0026amp; h.Less(j2, j1) { j = j2 // = 2*i + 2 // right child } if !h.Less(j, i) { break } h.Swap(i, j) i = j } return i \u0026gt; i0 } 我们关注其中几个核心实现：\ndown(h Interface, idx, heapLen int) 下沉操作：\n首先，移除堆顶元素，然后将最后一个元素放在堆顶，之后对这第一个元素进行 “下沉” 操作：\n将此元素与两个子节点元素比较，如果当前结点大于两个子节点，则与较小的子节点交换位置，如此循环，直到 到达叶子结点 或 小于较小子节点。\n为什么元素 i 比它的两个子节点都小，就可以跳出循环，不再继续下去呢？这是由于，在 Init 函数中，第一个开始 down 的元素是第 n/2 - 1 个，可以保证总是从最后一棵子树开始 down，因此可以保证 Init-\u0026gt;down 时，如果元素 i 比它的两个子节点都小，那么该元素对应的子树，就是最小堆。\nup(h Interface, curIdx int) 上浮操作：\n主要用在 Push 中，当我们向最小堆插入一个元素时，现将其插入到数组最后，之后进行上浮操作，此时的 curIdx 就是数组最后一个元素的 index，即 h.Len() - 1。当前元素与其父元素进行比较，如果当前元素小于父元素，则与父元素交换位置，如此往复，直到堆顶或者当前元素大于父元素。\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E5%B0%8F%E5%A0%86%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E7%9A%84golang%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"前言\"\u003e前言\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://zh.wikipedia.org/wiki/%E5%A0%86%E7%A9%8D\"\u003e堆\u003c/a\u003e，是计算机科学中的一种特别的完全二叉树。若父节点的值恒小于等于子节点的值，此堆称为\u003cstrong\u003e最小堆（min heap）\u003c/strong\u003e；反之，若母节点的值恒大于等于子节点的值，此堆称为\u003cstrong\u003e最大堆（max heap）\u003c/strong\u003e。在堆中最顶端的那一个节点，称作 \u003cstrong\u003e根节点（root node）\u003c/strong\u003e，根节点本身没有 \u003cstrong\u003e父节点（parent node）\u003c/strong\u003e。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\u003c/p\u003e","title":"最小堆以及优先级队列的Golang实现"},{"content":"select 的缺陷 目前对于高并发的解决方案是 一个线程处理所有连接，在这一点上 select 和 epoll 是一样的。但 当大量的并发连接存在、但短时间内只有少数活跃的连接时，select 的表现就显得捉襟见肘了。\n首先，select 用在有活跃连接时，所以，在高并发的场景下 select 会被非常频繁地调用。当监听的连接以数万计的时候，每次返回的只是其中几百个活跃的连接，这本身就是一种性能的损失。所以内核中直接限定死了 select 可监听的文件句柄数：\n// include/uapi/linux/posix_types.h #define __FD_SETSIZE 1024 其次，内核中实现 select 的方式是 轮询，即每次检测都会遍历所有的 fd_set 中的句柄，时间复杂度为 O(n)，与 fd_set 的长度呈线性关系，select 要检测的句柄数越多就会越费时。\npoll 和 select 的实现机制没有太大差异，相比 select，poll 只是取消了最大监控文件描述符的限制，并没有从根本上解决 select 的缺陷。\n下面这张图中所表达的信息中，当并发连接较小时，select 和 epoll 差距非常小，当并发数逐渐变大时，select 性能就显得非常乏力：\n需要注意的是，这个前提是 保持大量连接，但是只有少数活跃连接，如果活跃连接也特别多，那 epoll 也会有性能问题。\nepoll 相关的数据结构与方法 与 epoll 相关的系统调用有以下三个：\n这三个方法可以在 Linux 系统的机器上通过 man 2 xxx 的方式查看具体用法\n/* 返回 epoll 实例的文件句柄，size 没有实际用途，传入一个大于 0 的数即可。 */ int epoll_create(int size); /* 让 epoll(epfd)实例 对 目标文件(fd) 执行 `ADD | DEL | MOD` 操作，并指定”关心“的事件类型 */ int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); /* 阻塞等待所”关心“的事件发生 */ int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 与 select 相比，epoll 分清了 频繁调用 和 不频繁调用 的操作。例如，epoll_ctl 是不太频繁调用的，而 epoll_wait 是非常频繁调用的。\n这是 epoll 最常见的 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; int main(void) { int epfd,nfds; struct epoll_event ev; // ev用于注册事件，表示自己关心的事哪些事件 struct epoll_event events[5]; // events 用于接收从内核返回的就绪事件 epfd = epoll_create(1); // 创建一个 epoll 实例 ev.data.fd = STDIN_FILENO; // 我们关心的是命令行输入 ev.events = EPOLLIN|EPOLLET; //监听读状态同时设置ET模式(这个后面会讲，可以简单理解成：文件内容发生变化时才会触发对应的事件) epoll_ctl(epfd, EPOLL_CTL_ADD, STDIN_FILENO, \u0026amp;ev); // 注册epoll事件 for(;;) { nfds = epoll_wait(epfd, events, 5, -1); // 进入死循环，最后的 -1 表示无限期阻塞，直到有事件发生 // epoll_wait 返回，表示有对应的事件发生，事件的信息存储在 events 数组中。nfds 表示数组的长度。接下来逐个处理事件 for(int i = 0; i \u0026lt; nfds; i++) { if(events[i].data.fd==STDIN_FILENO) printf(\u0026#34;welcome to epoll\u0026#39;s word!\\n\u0026#34;); } } } 接下来我们看看 epoll 相关的数据结构。\neventpoll /* * This structure is stored inside the \u0026#34;private_data\u0026#34; member of the file * structure and represents the main data structure for the eventpoll * interface. */ struct eventpoll { // 保护 rbr(红黑树) 和 rdllist(等待队列) struct mutex mtx; // 等待队列，用来保存对一个 epoll 实例调用 epoll_wait() 的所有进程。 // 当调用 epoll_wait 的进程发现没有就绪的事件需要处理时，就将当前进程添加到此队列中，然后进程睡眠；后续事件发生，就唤醒这个队列中的所有进程(也就是出现了惊群效应) wait_queue_head_t wq; // 当被监视的文件是一个 epoll 类型时，需要用这个等待队列来处理递归唤醒。 // epoll 也是一种文件类型，因此一个 epoll 类型的 fd 也是可以被其他 epoll 实例监视的。 // 而 epoll 类型的 fd 只会有“读就绪”的事件。当 epoll 所监视的非 epoll 类型文件有“读就绪”事件时，当前 epoll 也会进入“读就绪”状态。 // 因此如果一个 epoll 实例监视了另一个 epoll 就会出现递归。如 e2 监视了e1，e1 上有读就绪事件发生，e1 就会加入 e2 的 poll_wait 队列中。 wait_queue_head_t poll_wait; // 就绪列表(双链表)，产生了用户注册的 fd读写事件的 epi 链表。 struct list_head rdllist; // 保护 rdllist 和 ovflist 。 rwlock_t lock; /* RB tree root used to store monitored fd structs */ // 红黑树根结点，管理所有\u0026#34;关心\u0026#34;的 fd struct rb_root_cached rbr; // 单链表，当 rdllist 被锁定遍历向用户空间发送数据时，rdllist 不允许被修改，新触发的就绪 epitem 被 ovflist 串联起来， // 等待 rdllist 被处理完了，重新将 ovflist 数据写入 rdllist struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ // 创建 eventpoll 的用户结构信息。 struct user_struct *user; // eventpoll 对应的文件结构，Linux 中一切皆文件，epoll 也是一个文件。 struct file *file; /* used to optimize loop detection check */ u64 gen; struct hlist_head refs; }; 如上面 demo 中所示，\nepitem // 红黑树用于管理所有的要监视的文件描述符 fd。当我们向系统中添加一个 fd 时，就会对应地创建一个 epitem 结构体。 // epitem 可以添加到红黑树，也可以串联成就绪列表或其它列表。 struct epitem { union { /* RB tree node links this structure to the eventpoll RB tree */ // 所在的红黑树 struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; }; /* List header used to link this structure to the eventpoll ready list */ // 所在的 eventpoll 的就绪列表 struct list_head rdllink; /* Works together \u0026#34;struct eventpoll\u0026#34;-\u0026gt;ovflist in keeping the single linked chain of items. */ // 关联的 eventpoll 中的 ovflist struct epitem *next; /* The file descriptor information this item refers to */ // 为最开始的 fd 创建 epitem 时的文件描述符信息 struct epoll_filefd ffd; /* List containing poll wait queues */ // poll 等待队列 struct eppoll_entry *pwqlist; /* The \u0026#34;container\u0026#34; of this item */ // 所在的 eventpoll struct eventpoll *ep; /* List header used to link this item to the \u0026#34;struct file\u0026#34; items list */ struct hlist_node fllink; /* wakeup_source used when EPOLLWAKEUP is set */ struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ struct epoll_event event; }; epoll 工作流程 epoll 是有状态的, 内核中维护了一个数据结构用来管理所要监视的 fd，这个数据结构是 eventpoll；\n在 eventpoll 中有一颗红黑树, 用来快速的查找和修改要监视的 fd，每个节点被封装成 epitem 结构；\n在 eventpoll 中有一个列表, 用来收集已经发生事件的 epitem , 这个 list 叫 ready list(rdllist)。\n通过 epoll_ctl 函数添加进来的事件都会被放在红黑树的某个节点内，所以，重复添加是没有用的。当把事件添加进来的时候会完成关键的一步——该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数，该回调函数在内核中被称为：ep_poll_callback。这个回调函数其实就所把这个事件添加到rdllist这个双向链表中——一旦有事件发生，epoll就会将该事件添加到双向链表中。那么当我们调用 epoll_wait 时，epoll_wait 只需要检查 rdlist 双向链表中是否有存在注册的事件，有则返回，效率非常可观。\nepoll_create 细节 // 创建一个 eventpoll 对象，并且关联文件资源 static int do_epoll_create(int flags) { int error, fd; struct eventpoll *ep = NULL; struct file *file; // ... // 创建并初始化核心结构 eventpoll，赋值给 ep error = ep_alloc(\u0026amp;ep); if (error \u0026lt; 0) return error; // 创建一个文件(文件句柄 fd 和 file结构) fd = get_unused_fd_flags(O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (fd \u0026lt; 0) { error = fd; goto out_free_ep; } // 注意，在这里将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象 file = anon_inode_getfile(\u0026#34;[eventpoll]\u0026#34;, \u0026amp;eventpoll_fops, ep, O_RDWR | (flags \u0026amp; O_CLOEXEC)); if (IS_ERR(file)) { error = PTR_ERR(file); goto out_free_fd; } // 绑定 fd 和 file，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程。 ep-\u0026gt;file = file; fd_install(fd, file); return fd; // ... } 这个函数很简单，主要做以下几件事：\n创建并初始化核心结构 eventpoll，赋值给变量 ep； 创建一个 文件句柄fd 和 文件 file结构体，并绑定 fd 和 file、绑定 file 和 eventpoll(将 eventpoll 作为 file 的 private_data 保存起来，后面拿到 epoll 的文件描述符后，通过 file.private_data 就能拿到绑定的 eventpoll 对象)，这个 fd 就是 epoll 实例的句柄，需要返回给用户进程，这也间接说明 epoll 也是一种文件。 关于绑定 fd 和 file，参考：彻底理解 Linux 中的 文件描述符(fd)\nepoll_ctl 细节 // epoll_ctl 的详细实现 int do_epoll_ctl( int epfd/*epoll 文件描述符*/, int op /*操作类型*/, int fd /*要监控的目标文件描述符*/, struct epoll_event *epds/*要监视的事件类型*/, bool nonblock, ) { int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct eventpoll *tep = NULL; // epoll 对应的文件 f = fdget(epfd); // fd 对应的文件 tf = fdget(fd); /* The target file descriptor must support poll */ // epoll 并不能监控所有的文件描述符，只能监视支持 poll 方法的文件描述符 // 其实是检查对应的 file 中的 file_operations 中是否有 poll 方法，即当前文件类型是否实现了 poll 方法(普通文件没有实现，socket 或者 epoll 类型等都实现了，所以可以被 epoll 监控) if (!file_can_poll(tf.file)) goto error_tgt_fput; /* Check if EPOLLWAKEUP is allowed */ // 检查是否允许 EPOLLWAKEUP if (ep_op_has_event(op)) ep_take_care_of_epollwakeup(epds); // epoll 监视的不是自己 error = -EINVAL; if (f.file == tf.file || !is_file_epoll(f.file)) goto error_tgt_fput; // 在 do_epoll_create 实现里 anon_inode_getfile 已经将 private_data 与 eventpoll 关联。 ep = f.file-\u0026gt;private_data; // 当我们添加进来的 file 是一个 epoll 类型的文件时，有可能造成循环引用的死循环。在这里提前检查避免这种情况 error = epoll_mutex_lock(\u0026amp;ep-\u0026gt;mtx, 0, nonblock); if (error) goto error_tgt_fput; if (op == EPOLL_CTL_ADD) { if (READ_ONCE(f.file-\u0026gt;f_ep) || ep-\u0026gt;gen == loop_check_gen || is_file_epoll(tf.file)) { // ... } } // 查找 要添加的 fd 是否已经在红黑树上了，如果是，返回对应的 epitem 结构，否则返回 NULL epi = ep_find(ep, tf.file, fd); error = -EINVAL; switch (op) { case EPOLL_CTL_ADD: // 增加fd if (!epi) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; // fd 不在红黑树上，就将此 fd 添加到红黑树上管理。默认关注的事件是 EPOLLERR | EPOLLHUP error = ep_insert(ep, epds, tf.file, fd, full_check); } else error = -EEXIST; break; case EPOLL_CTL_DEL: // 删除fd if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: // 修改fd事件类型 if (epi) { if (!(epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE)) { epds-\u0026gt;events |= EPOLLERR | EPOLLHUP; error = ep_modify(ep, epi, epds); } } else error = -ENOENT; break; } mutex_unlock(\u0026amp;ep-\u0026gt;mtx); // ... } 在 do_epoll_ctl() 的参数中，操作类型有三种：\nEPOLL_CTL_ADD： 往事件表中注册fd上的事件； EPOLL_CTL_DEL：删除fd上的注册事件； EPOLL_CTL_MOD：修改fd上的注册事件。 而 struct epoll_event 结构表示事件类型，常见的有：\n// eventpoll.h #define EPOLLIN (__force __poll_t)0x00000001 // 有可读数据到来 #define EPOLLPRI (__force __poll_t)0x00000002 // 有紧急数据可读：1. TCP socket 上有外带数据；2. 分布式环境下状态发生改变；3. cgroup.events类型的文件被修改 #define EPOLLOUT (__force __poll_t)0x00000004 // 有数据要写 #define EPOLLERR (__force __poll_t)0x00000008 // 文件描述符上发生错误(不管有没有设置这个 flag，epoll_wait 总是会检测并返回这样的错误) #define EPOLLHUP (__force __poll_t)0x00000010 // 该文件描述符被挂断。常见 socket 被关闭（read == 0） #define EPOLLRDHUP (__force __poll_t)0x00002000 // 对端已关闭链接，或者用 shutdown 关闭了写链 /* Set the Edge Triggered behaviour for the target file descriptor */ #define EPOLLET ((__force __poll_t)(1U \u0026lt;\u0026lt; 31)) // ET 工作模式 /* Set the One Shot behaviour for the target file descriptor */ /* 一般情况下，ET 模式只会触发一次，但有可能出现多个线程同时处理 epoll，此标志规定操作系统最多触发其上注册的一个可读或者可写或者异常事件，且只触发一次，如此无论线程再多，只能有一个线程或进程处理同一个描述符 */ #define EPOLLONESHOT ((__force __poll_t)(1U \u0026lt;\u0026lt; 30)) /* Set exclusive wakeup mode for the target file descriptor */ /* 唯一唤醒事件，主要为了解决 epoll_wait 惊群问题。多线程下多个 epoll_wait 同时等待，只唤醒一个 epoll_wait 执行。 该事件只支持 epoll_ctl 添加操作 EPOLL_CTL_ADD */ #define EPOLLEXCLUSIVE ((__force __poll_t)(1U \u0026lt;\u0026lt; 28)) 关于什么是 “ET(边缘触发)” 和 “LT(水平触发)”，后面会详细说。\nep_insert static int ep_insert(struct eventpoll *ep, const struct epoll_event *event, struct file *tfile, int fd, int full_check) { // ep_insert(ep, epds, tf.file, fd, full_check); // tf 表示 fd 对应的 file 结构 int error, pwake = 0; __poll_t revents; long user_watches; // epoll 文件对象中所监视的 fd 数量 struct epitem *epi; struct ep_pqueue epq; struct eventpoll *tep = NULL; // 当 fd 类型是 epoll 时，tep 用来保存 fd 对应的 eventpoll 结构 // 要监视的文件也是 epoll 类型，用 tep 保存对应的 eventepoll 结构 if (is_file_epoll(tfile)) tep = tfile-\u0026gt;private_data; lockdep_assert_irqs_enabled(); // 判断 epoll 监视的文件个数是否超出系统限制 user_watches = atomic_long_read(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); if (unlikely(user_watches \u0026gt;= max_user_watches)) return -ENOSPC; if (!(epi = kmem_cache_zalloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ // 创建一个双链表，头和尾都是它自己 INIT_LIST_HEAD(\u0026amp;epi-\u0026gt;rdllink); epi-\u0026gt;ep = ep; ep_set_ffd(\u0026amp;epi-\u0026gt;ffd, tfile, fd); // epitem 与 fd 绑定 epi-\u0026gt;event = *event; epi-\u0026gt;next = EP_UNACTIVE_PTR; // 目标文件是 epoll 类型 if (tep) mutex_lock_nested(\u0026amp;tep-\u0026gt;mtx, 1); /* Add the current item to the list of active epoll hook for this file */ if (unlikely(attach_epitem(tfile, epi) \u0026lt; 0)) { kmem_cache_free(epi_cache, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); return -ENOMEM; } if (full_check \u0026amp;\u0026amp; !tep) list_file(tfile); // 当前进程的用户的 epoll_watches 加一 atomic_long_inc(\u0026amp;ep-\u0026gt;user-\u0026gt;epoll_watches); // 将初始化后的 epitem 添加到红黑树中 ep_rbtree_insert(ep, epi); if (tep) mutex_unlock(\u0026amp;tep-\u0026gt;mtx); // 不允许递归监视太多的 epoll if (unlikely(full_check \u0026amp;\u0026amp; reverse_path_check())) { ep_remove(ep, epi); return -EINVAL; } if (epi-\u0026gt;event.events \u0026amp; EPOLLWAKEUP) { error = ep_create_wakeup_source(epi); if (error) { ep_remove(ep, epi); return error; } } /* Initialize the poll table using the queue callback */ epq.epi = epi; // 注册回调函数，作用：add our wait queue to the target file wakeup lists. 在tcp_sock-\u0026gt;sk_sleep中插入一个等待者 // 不同的系统实现 poll 的方式不同，如socket的话, 那么这个接口就是 tcp_poll() init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc); // 可能此时已经有事件存在了, revents返回这个事件 revents = ep_item_poll(epi, \u0026amp;epq.pt, 1); // ... // 如果此时就有关注的事件发生，我们将其放到就绪队列中 if (revents \u0026amp;\u0026amp; !ep_is_linked(epi)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); // 唤醒等待的线程，告诉他们有活干了 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) wake_up(\u0026amp;ep-\u0026gt;wq); if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; } // ... } ep_insert 先申请一个 epitem 对象 epi，并初始化 epitem 的两个 list 的头指针：rdllink(指向 eventpoll 的 rdllist)、pwqlist(指向包含此 epitem 的所有 poll wait queue)，通过 fs 将 epitem、fd 和 file 绑定，通过 epitem.ep 将此 epitem 和 传入的 eventpoll 对象绑定，通过传入的 event 对 epitem.events 赋值，紧接着，将这个 epitem 加入到 eventpoll 的 红黑树中。整个过程结束后，epitem 本身就完成了和 eventpoll 以及 被监视文件fd 的关联。但还要做一件事：将 epitem 加入目标文件的 poll 等待队列并注册对应的回调函数。\n在 ep_insert() 中有一行是 init_poll_funcptr(\u0026amp;epq.pt, ep_ptable_queue_proc);，这其实是注册了一个回调函数——将文件的 poll() 方法与此方法绑定，当文件就绪，就会调用此方法。\n关于 等待队列 的实现，参考：理解 Linux 等待队列\n我们知道，当一个进程加入等待队列之后，需要将设置对应的唤醒函数，当资源就绪的时候调用这个设置好的唤醒函数：\n// 链表中的一个结点 struct wait_queue_entry { unsigned int flags; // 标志，如 WQ_FLAG_EXCLUSIVE，表示等待的进程应该独占资源（解决惊群现象） void *private; // 等待进程相关信息，如 task_struct wait_queue_func_t func; // 唤醒函数 struct list_head entry; // 前后结点 }; 我们再来看下 init_waitqueue_func_entry 这个方法：\nstatic inline void init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func) { wq_entry-\u0026gt;flags = 0; wq_entry-\u0026gt;private = NULL; wq_entry-\u0026gt;func = func; } 正是将等待队列中的结点的唤醒函数设置为 ep_ptable_queue_proc ！\n我们来详细看看 ep_ptable_queue_proc 的实现：\n/* // 当该文件描述符对应的文件有事件到达后，回调用这个函数 // 首先根据pt拿到对应的epi。然后通过pwq将三者关联。 // @file: 要监听的文件 // @whead: 该fd对应的设备等待队列，每个设备的驱动都会带 // @pt: 调用文件的poll传入的东西。 */ static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct ep_pqueue *epq = container_of(pt, struct ep_pqueue, pt); struct epitem *epi = epq-\u0026gt;epi; struct eppoll_entry *pwq; // epitem 的私有项，为每一个 fd 保存内核的 poll。 // 这个结构体主要完成 epitem 和 epitem事件发生时 callback 函数的关联，将唤醒回调函数设置为 ep_poll_callback，然后加入设备等待队列 // ... // 将pwq的等待队列和回调函数ep_poll_callback关联 // ep_poll_callback 才是真正意义上的 poll() 醒来时的回调函数，当设备就绪，就会唤醒设备的等待队列中的进程，此时 ep_poll_callback 会被调用 init_waitqueue_func_entry(\u0026amp;pwq-\u0026gt;wait, ep_poll_callback); pwq-\u0026gt;whead = whead; pwq-\u0026gt;base = epi; // 将 进程对应的等待双链表结点 放入等待队列whead // 将eppoll_entry挂在到fd的设备等待队列上。也就是注册epoll的回调函数 ep_poll_callback if (epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, \u0026amp;pwq-\u0026gt;wait); else add_wait_queue(whead, \u0026amp;pwq-\u0026gt;wait); pwq-\u0026gt;next = epi-\u0026gt;pwqlist; epi-\u0026gt;pwqlist = pwq; } 我们来看看 ep_poll_callback 干了什么：\n/* * This is the callback that is passed to the wait queue wakeup * mechanism. It is called by the stored file descriptors when they * have events to report. * * This callback takes a read lock in order not to contend with concurrent * events from another file descriptor, thus all modifications to -\u0026gt;rdllist * or -\u0026gt;ovflist are lockless. Read lock is paired with the write lock from * ep_scan_ready_list(), which stops all list modifications and guarantees * that lists state is seen correctly. */ static int ep_poll_callback(wait_queue_entry_t *wait, unsigned mode, int sync, void *key) { int pwake = 0; struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-\u0026gt;ep; __poll_t pollflags = key_to_poll(key); unsigned long flags; int ewake = 0; // ... /* * If we are transferring events to userspace, we can hold no locks * (because we\u0026#39;re accessing user memory, and because of linux f_op-\u0026gt;poll() * semantics). All the events that happen during that period of time are * chained in ep-\u0026gt;ovflist and requeued later on. */ // 因为要访问用户空间，所以此时对 rdllist 的访问不应该加锁。如果恰巧这个时候有对应的 // 事件发生，应该将其放到 ovflist 中之后再调度。 if (READ_ONCE(ep-\u0026gt;ovflist) != EP_UNACTIVE_PTR) { if (chain_epi_lockless(epi)) ep_pm_stay_awake_rcu(epi); } else if (!ep_is_linked(epi)) { // 将当前的 epitem 添加到 eventpool 的就绪队列中 /* In the usual case, add event to ready list. */ if (list_add_tail_lockless(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist)) ep_pm_stay_awake_rcu(epi); } /* * Wake up ( if active ) both the eventpoll wait list and the -\u0026gt;poll() * wait list. */ // 同时唤醒 eventpool 和 poll 的等待的进程 if (waitqueue_active(\u0026amp;ep-\u0026gt;wq)) { if ((epi-\u0026gt;event.events \u0026amp; EPOLLEXCLUSIVE) \u0026amp;\u0026amp; !(pollflags \u0026amp; POLLFREE)) { switch (pollflags \u0026amp; EPOLLINOUT_BITS) { case EPOLLIN: if (epi-\u0026gt;event.events \u0026amp; EPOLLIN) ewake = 1; break; case EPOLLOUT: if (epi-\u0026gt;event.events \u0026amp; EPOLLOUT) ewake = 1; break; case 0: ewake = 1; break; } } wake_up(\u0026amp;ep-\u0026gt;wq); } if (waitqueue_active(\u0026amp;ep-\u0026gt;poll_wait)) pwake++; // ... return ewake; } ep_wait 细节 入口在\nSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { struct timespec64 to; return do_epoll_wait(epfd, events, maxevents, ep_timeout_to_timespec(\u0026amp;to, timeout)); } 实际调用的是 do_epoll_wait：\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). * * @epfd: 对应的 eventpoll 文件描述符 * @events: 用于接收已经就绪的事件 * @maxevents：所监听的最大事件个数 * @to：超时事件(-1表示无限制等待) */ // epoll_wait 的具体实现 static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, struct timespec64 *to) { int error; struct fd f; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents \u0026lt;= 0 || maxevents \u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ // 确保用户传进来的地址空间是可写的 if (!access_ok(events, maxevents * sizeof(struct epoll_event))) return -EFAULT; /* Get the \u0026#34;struct file *\u0026#34; for the eventpoll file */ // 获取 epoll 实例 f = fdget(epfd); if (!f.file) return -EBADF; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; // 确保传进来的 epfd 是 epoll 类型 if (!is_file_epoll(f.file)) goto error_fput; /* * At this point it is safe to assume that the \u0026#34;private_data\u0026#34; contains * our own data structure. */ ep = f.file-\u0026gt;private_data; /* Time to fish for events ... */ // 执行具体的 poll，如果有事件产生，返回的 error 就是对应的事件个数，对应的事件也会同时从 eventpoll 对应的 rdllist(就绪队列) 中写入到传进来的 events 数组中 error = ep_poll(ep, events, maxevents, to); error_fput: fdput(f); return error; } 我们看下 ep_poll 的实现细节：\n/** * ep_poll - 检索已经就绪的事件，并将其从内核空间传送到用户空间传进来的events 列表中 * * @ep: eventpoll 实例指针 * @events: 存放就绪事件的用户空间的数组的指针 * @maxevents: events 数组的长度 * @timeout: 获取就绪事件操作的最大超时时间。如果是 0，表示不阻塞；如果是负数，表示一直阻塞 * * Return: 成功收到的事件的个数，或者失败时对应的错误码。 */ static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 设置超时 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { // 有具体的超时时长 slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. */ // 用户设置不阻塞。 timed_out = 1; } // 检查 ep.rdllist 或 ep.ovflist 中是否有就绪的事件，如果有返回就绪事件的个数。否则返回 0 eavail = ep_events_available(ep); while (1) { if (eavail) { // rdllist 中已经有事件了，将其传送到用户空间。 // 如果没有对应的事件并且也没到超时时间，就再等等，直到超时 res = ep_send_events(ep, events, maxevents); if (res) return res; } // 走到这一步，说明没有就绪事件 // 用户设置不阻塞，直接返回 if (timed_out) return 0; // always false eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查当前进程是否有信号处理，返回不为0表示有信号需要处理。 if (signal_pending(current)) return -EINTR; init_wait(\u0026amp;wait); write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有就绪事件，如果没有，让当前进程睡眠(然后进程就阻塞在这里了...) eavail = ep_events_available(ep); if (!eavail) __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 重新计算超时时间 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 进程被唤醒了，说明有事件发生！ __set_current_state(TASK_RUNNING); /* * We were woken up, thus go and try to harvest some events. * If timed out and still on the wait queue, recheck eavail * carefully under lock, below. */ eavail = 1; if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); /* * If the thread timed out and is not on the wait queue, * it means that the thread was woken up after its * timeout expired before it could reacquire the lock. * Thus, when wait.entry is empty, it needs to harvest * events. */ if (timed_out) // list_empty 检查 list 是否为空 eavail = list_empty(\u0026amp;wait.entry); // 将 wait 从 ep 的等待队列中删除 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 我们再来看 ep_send_events的实现：\nstatic int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) { struct epitem *epi, *tmp; LIST_HEAD(txlist); poll_table pt; int res = 0; if (fatal_signal_pending(current)) return -EINTR; init_poll_funcptr(\u0026amp;pt, NULL); mutex_lock(\u0026amp;ep-\u0026gt;mtx); // 将 rdllist 中的元素全部添加到 txlist 中，并清空 ep.rdllist ep_start_scan(ep, \u0026amp;txlist); // 迭代器，逐个处理从 ep-\u0026gt;rdllist 中取出后放在 txlist 中的 epitem // epi 表示正在处理的对象(cursor) list_for_each_entry_safe(epi, tmp, \u0026amp;txlist, rdllink) { struct wakeup_source *ws; __poll_t revents; if (res \u0026gt;= maxevents) break; ws = ep_wakeup_source(epi); if (ws) { if (ws-\u0026gt;active) __pm_stay_awake(ep-\u0026gt;ws); __pm_relax(ws); } // 重置 epitem 中的 rdllink list_del_init(\u0026amp;epi-\u0026gt;rdllink); // 检查就绪事件的 flag 是否是调用方需要的 revents = ep_item_poll(epi, \u0026amp;pt, 1); if (!revents) continue; // 内核向用户态复制数据 if (__put_user(revents, \u0026amp;events-\u0026gt;events) || __put_user(epi-\u0026gt;event.data, \u0026amp;events-\u0026gt;data)) { list_add(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;txlist); ep_pm_stay_awake(epi); if (!res) res = -EFAULT; break; } res++; events++; // 处理水平触发和边缘触发的场景 if (epi-\u0026gt;event.events \u0026amp; EPOLLONESHOT) epi-\u0026gt;event.events \u0026amp;= EP_PRIVATE_BITS; else if (!(epi-\u0026gt;event.events \u0026amp; EPOLLET)) { list_add_tail(\u0026amp;epi-\u0026gt;rdllink, \u0026amp;ep-\u0026gt;rdllist); ep_pm_stay_awake(epi); } } ep_done_scan(ep, \u0026amp;txlist); mutex_unlock(\u0026amp;ep-\u0026gt;mtx); return res; } 而其中的 ep_item_poll，不同的驱动程序，都会有自己的 poll 方法，如果是 TCP套接字，这个poll方法就是 tcp_poll。在 TCP 中，会周期性的调用这个方法调用频率取决于协议栈中断频率的设置。一旦有事件到达后，对应的 tcp_poll 方法被调用，tcp_poll 方法会回调用 sock_poll_wait()，该方法会调用这里注册的 ep_ptable_queue_proc 方法。epoll 其实就是通过此机制实现将自己的回调函数加入到文件的 waitqueue 中的。这也是 ep_ptable_queue_proc 的目的。\nstatic __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt, int depth) { struct file *file = epi-\u0026gt;ffd.file; __poll_t res; pt-\u0026gt;_key = epi-\u0026gt;event.events; if (!is_file_epoll(file)) // 非 epoll 类型的 fd，检查 socket 的就绪事件，fd 关联回调函数 ep_poll_callback。最终执行的 poll 是 tcp_poll res = vfs_poll(file, pt); else res = __ep_eventpoll_poll(file, pt, depth); return res \u0026amp; epi-\u0026gt;event.events; } 再谈 epoll 和 select 从更高的角度看，epoll 和 select 都是 I/O 多路复用，当我们在调用这类函数时，我们传入的是 关心的socket，接收到的返回是 就绪的 socket。那为何会有性能差距呢？我们尝试找出他们的不同点：\n对比 select epoll 连接数限制 1024 理论上无限制 内在处理机制 现行轮训 callback TODO TODO TODO 再回头看看 select 的 demo:\nint main(){ int fds[] = ...; // 关心的 socket 数组 fd_set source_fds; // 将我们关心的 socket 保存到 fd_set 中 fd_set temp_fds; // 临时变量，作为 select 的返回值 // 初始化 source_fds FD_ZERO(\u0026amp;source_fds); for (int i=0; i\u0026lt;fds.length; i++) { FD_SET(fds[i], \u0026amp;source_fds); } while(1) { // select 将一个 fd_set 作为入参，将就绪的 socket 又填充如这个入参中作为出参返回 // 因此，为了快速重置，设置一个临时变量，避免每次都要进行 source_fds 的重置 temp_fds = source_fds; // select 会阻塞，直到关心的 socket 上有事件发生 int n = select(..., \u0026amp;temp_fds, ...); // 在用户态遍历 socket，检查是否有我们关心的事件发生 for (int i=0; i \u0026lt; fds.length; i++) { if (FD_ISSET(fds[i], \u0026amp;temp_fds)) { // ... 进行对应的逻辑处理 FD_CLR(fds[i], \u0026amp;temp_fds); } } } return 0; } select 主要有两点限制：\n所能关注的 socket 太少，只能有 1024 个，对于一些大型 web 应用来说有点捉襟见肘； 尽管 FD_SET 是 O(1) 的操作，但返回后还要在用户态遍历一次整个 fd_set，这是一个线性操作 再回过头来看 epoll:\nint main() { int fds[] = ...; // 关心的 socket 数组 int epfd = epoll_create(...); // 创建 epoll 实例 // 将关心的 socket 添加到 epoll 中(红黑树等) for (int i=0; i \u0026lt; fds.length; i++){ epoll_ctl(epfd,EPOLL_CTL_ADD, fds[i], ...); } // 定义一个结构，用来接收就绪的事件 struct epoll_event events[MAX_EVENTS]; while(1){ // 如果无事件发生，那么进程将阻塞在这里 // 如果有事件发生，则返回就绪的事件个数，同时事件被存储在 events 中 int n = epoll_wait(epfd, \u0026amp;events,...); for (int i=0; i \u0026lt; n; i++) { // 通过下标取到返回的就绪事件，进行对应的逻辑处理 new_event = events[i]; } } return 0; } 每次epoll_wait 返回的都是活跃的 socket，根本不用全部遍历一遍 epoll 底层使用到了 红黑树 来存储所关心的 socket，查找效率有保证；注册的对应的事件通知是通过回调的方式执行的，这种解耦、相互协作的方式更有利于操作系统的调度。 ","permalink":"http://localhost:1313/posts/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/","summary":"\u003ch2 id=\"select-的缺陷\"\u003eselect 的缺陷\u003c/h2\u003e\n\u003cp\u003e目前对于高并发的解决方案是 \u003cstrong\u003e一个线程处理所有连接\u003c/strong\u003e，在这一点上 \u003ccode\u003eselect\u003c/code\u003e 和 \u003ccode\u003eepoll\u003c/code\u003e 是一样的。但 \u003cstrong\u003e当大量的并发连接存在、但短时间内只有少数活跃的连接时，\u003ccode\u003eselect\u003c/code\u003e 的表现就显得捉襟见肘了。\u003c/strong\u003e\u003c/p\u003e","title":"I/O多路复用之 epoll"},{"content":"看 select 源码，fd_set 这个结构体实际上是一个 long 型的数组，但是数组的长度依赖于系统中 typedef long int __fd_mask 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\n本文旨在抛开 select 相关的功能，彻底搞明白 fd_set 的存储原理、FD_SET() 等函数到底实现了什么效果。\n本次调试机器：\n$ uname -a Linux localhost 4.15.0-52-generic #56-Ubuntu SMP Tue Jun 4 22:49:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux fd_set 的源码中有非常多的预编译指令：\n// /usr/include/x86_64-linux-gnu/sys/select.h /* The fd_set member is required to be an array of longs. */ typedef long int __fd_mask; /* Some versions of \u0026lt;linux/posix_types.h\u0026gt; define this macros. */ #undef __NFDBITS /* It\u0026#39;s easier to assume 8-bit bytes than to get CHAR_BIT. */ #define __NFDBITS (8 * (int) sizeof (__fd_mask)) #define __FD_MASK(d) ((__fd_mask) (1UL \u0026lt;\u0026lt; ((d) % __NFDBITS))) /* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 我简单整理一下，去掉和本系统无关的，结果如下：\ntypedef long int __fd_mask; // 8 #define __NFDBITS (8 * (int) sizeof (__fd_mask) // 64 #define __FD_SETSIZE 1024 typedef struct { __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; // 长度为 1024/64=16，类型为 long } fd_set; 接着，我们看一个 demo：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; void print_set1(fd_set *fdset); void print_set2(fd_set *fdset); int main() { fd_set fdset; FD_ZERO(\u0026amp;fdset); printf(\u0026#34;sizeof long int: %ld\\n\u0026#34;, sizeof(long int)); // 8 printf(\u0026#34;sizeof int: %ld\\n\u0026#34;, sizeof(int)); // 4 printf(\u0026#34;sizeof short: %ld\\n\u0026#34;, sizeof(short)); // 2 FD_SET(1, \u0026amp;fdset); FD_SET(2, \u0026amp;fdset); FD_SET(3, \u0026amp;fdset); FD_SET(7, \u0026amp;fdset); print_set1(\u0026amp;fdset); // 10001110 -\u0026gt; 第 1 2 3 7 位分别设置成了 1 FD_SET(15, \u0026amp;fdset); FD_SET(16, \u0026amp;fdset); FD_SET(31, \u0026amp;fdset); // 10000000000000011000000010001110 -\u0026gt; 长度为 32 FD_SET(32, \u0026amp;fdset); FD_SET(33, \u0026amp;fdset); FD_SET(62, \u0026amp;fdset); // 100000000000000000000000000001110000000000000011000000010001110 0-\u0026gt;长度为 63 print_set2(\u0026amp;fdset); FD_SET(63, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 0 -\u0026gt; 长度为 64 print_set2(\u0026amp;fdset); FD_SET(64, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 -\u0026gt; 长度还是 64，但产生了进位 print_set2(\u0026amp;fdset); FD_SET(128, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 1-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(129, \u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000010001110 1 3-\u0026gt; 长度还是 63，但是在 64 和 128 的时候产生了进位 FD_SET(1023, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1024, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 FD_SET(1025, \u0026amp;fdset); // 13835058070314647694 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 print_set2(\u0026amp;fdset); int isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 1，代表第 7 位被设置 FD_CLR(7, \u0026amp;fdset); print_set2(\u0026amp;fdset); // 1100000000000000000000000000001110000000000000011000000000001110 1 3 0 0 0 0 0 0 0 0 0 0 0 0 9223372036854775808 -\u0026gt; 第 7 位的 1 变成了 0 isset = FD_ISSET(7, \u0026amp;fdset); printf(\u0026#34;isset = %d\\n\u0026#34;, isset);// 输出 0，代表第 7 位没有被设置 return 0; } void print_set2(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%llu \u0026#34;, (unsigned long long)fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } void print_set1(fd_set *fdset) { int i; for (i = 0; i \u0026lt; 16; i++) { printf(\u0026#34;%ld \u0026#34;,fdset-\u0026gt;__fds_bits[i]); } printf(\u0026#34;\\n\u0026#34;); } print_set() 函数是我自己添加的，用于打印出 fd_set 中的 __fds_bits 数组中的内容。需要注意两点：\n数组长度是 16，是如何确定的？答：在处理过预编译指令之后，__FD_SETSIZE 的值是 1024，__NFDBITS 的值是 64，计算得到数组长度为 16；\n类型的长度如何确定？答：在最开始使用了 typedef long int __fd_mask，long int 其实就是 long，即 long signed integer type。熟悉 C语言的同学都知道，当我们描述 short、int 和 long 的长度时，只有对 short 的长度是肯定的，而对后两者都使用了 可能 的说法：可能长度为 8。这是因为 C语言 没有对其做出严格的规定，只做了宽泛的限制：short 占 2字节；int 建议为机器字长，64 位机器下占4字节；2 ≤ short ≤ int ≤ long，如上述代码中打印结果所示，在我测试的这台机器上，long 占 8字节 即 64位。\n接下来我们看 main() 中的代码：\n在调用 FD_SET() 设置 1 2 3 7 后，我们调用print_set1()打印结果，输出：142 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，数组第一位竟然是 142？！哪来的？但我们将 142 转成二进制就一下子了然了：10001110， 总共占 8 位，从右往左从 0 开始数，只有第 1 2 3 7 位被设置成了 1， 这个二进制对应的数就是 142，因为 142 完全在一个 long 的范围(64位)内，所以正常表示了。那如果我们对一个超过 long 范围的数调用 FD_SET()，会是什么效果？\n代码继续走到 FD_SET(62, \u0026amp;fdset)，我们调用 print_set1()，输出 4611686033459871886 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，4611686033459871886 转成二进制为 100000000000000000000000000001110000000000000011000000010001110，字符串长度为 63，可以看到，依旧在 long 的范围之内；执行到 FD_SET(63,\u0026amp;fdset) 呢，调用 print_set1()，输出 -4611686003394903922 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0，出现了负数。我们想一下原因。只执行FD_SET(62,\u0026amp;fdset) 会将第 63 位处设置为 1，对应的二进制为 100000000000000000000000000000000000000000000000000000000000000(长度为 63)；根据 FD_SET() 的功能，我们可以猜测，FD_SET(63,\u0026amp;fdset) 会将第 64 位设置为 1，其对应的二进制应该是 1000000000000000000000000000000000000000000000000000000000000000(长度为 64)。\n在这里我们补充一个知识：参考这里 Wiki-无符号数，在计算机底层，有符号数可以表示特定范围内的整数(包括负数)，无符号数只能表示非负数(0 以及正数)，有符号数能够表示负数的原因是，最高位被用来当做符号位，1 表示负数，0 表示正数，代价就是所表示的数的范围少了一半，举个例子，8 位可以表示无符号数 [0,255](最小00000000；最大11111111，对应的十进制就是 255)，对应的有符号数范围就是 [-127,127]。\n再回头看 1000000000000000000000000000000000000000000000000000000000000000，__fd_mask 的类型是 long，是一个有符号数，最高位的 1 表示负数，后面的才是真正的值，于是这个二进制转成有符号十进制的结果就是 0，而且还是个 -0。为了验证我们的想法，我们将 print_set1() 换成 print_set2()，这两个函数唯一的不同是，将数组中的每一位的类型强转成了无符号数，这下结果就成了 9223372036854775808，符合我们的预期。 所以后面的调试，我们都使用 print_set2() 这个函数。\n刚才的 FD_SET(63,\u0026amp;fdset) 已经到达一个 long 的最大可 表示范围了，如果再多一位，会发生什么？我们看下 FD_SET(64, \u0026amp;fdset)，输出 13835058070314647694 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0，13835058070314647694 转换成二进制后为 1100000000000000000000000000001110000000000000011000000010001110(长度为 64)，和 设置 63 时的一样，但数组的第二位变成了 1。按照前面的推测，单独执行 FD_SET(64, \u0026amp;fdset)，应该将第 65 位设置成 1，长度为 65，但是 65 显然超过了 long 的可表示的长度(64位)，于是，产生了“进位”，这个进位的基本单位就是 64位，即 __NFDBITS 的值。于是，可以用如下 python 代码表示(python 对大数处理非常好，一般不会出现溢出)：\n#!/usr/local/env python3 # coding:utf-8 # get_fd_set_bin 返回 fd_set 表示的真实二进制(从右往左方向) # every_fd_bits 表示数组中每个元素代表多少位 # set_array 表示 fd_set 的 long 数组 def get_fd_set_bin(every_fd_bits, set_array): int_value = 0 for idx in range(len(set_array)): int_value = int_value | (set_array[idx] \u0026lt;\u0026lt; every_fd_bits * idx) return bin(int_value)[2:] # 输出 \u0026#34;0bxxxxxx\u0026#34;，为了方便展示，去掉前缀 # print_bin 将二进制按照 step 为一组打印 def print_bin(output, step=64): le = len(output) m = le % step padding = step - m if m != 0 else 0 output = output.zfill(le + padding) print(\u0026#39; \u0026#39;.join(\u0026#39;\u0026#39;.join(output[idx * step:(idx + 1) * step]) for idx in range((le + padding) // step))) 在我们当前的例子中，every_fd_bits = 64, set_array 的长度为 16。测试一下我们的代码：\n# 输入(相当于设置了 1 2 3 7) get_fd_set_bin(64, [142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000010001110 # 输入(相当于设置了 1 2 3 7 64) get_fd_set_bin(64, [142,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]) # 输出 0000000000000000000000000000000000000000000000000000000000000001 0000000000000000000000000000000000000000000000000000000010001110 我用 Golang 做了简单实现：\npackage main import ( \u0026#34;math/big\u0026#34; \u0026#34;strings\u0026#34; ) type FdSet interface { FD_CLR(fd int) error FD_ISSET(fd int) (bool, error) FD_SET(fd int) error FD_ZERO() error FdSetString() string } type fdType uint64 const ( maxFdSetSize = 1024 fdMask = 8 // sizeof long int in c fdBits = 8 * fdMask ) type FdSetGolang struct { data [maxFdSetSize / fdBits]fdType } func NewGdSetGolang() *FdSetGolang { return \u0026amp;FdSetGolang{data: [maxFdSetSize / fdBits]fdType{}} } func (fs *FdSetGolang) FD_CLR(fd int) error { fs.clear(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ISSET(fd int) (bool, error) { return fs.isSet(fs.getMask(fd)), nil } func (fs *FdSetGolang) FD_SET(fd int) error { fs.set(fs.getMask(fd)) return nil } func (fs *FdSetGolang) FD_ZERO() error { for i := range fs.data { fs.data[i] = 0 } return nil } func (fs *FdSetGolang) FdSetString() string { tmp := make([]string, 0, len(fs.data)) for i := len(fs.data) - 1; i \u0026gt;= 0; i-- { if v := fs.uintBin(uint64(fs.data[i])); v != \u0026#34;\u0026#34; { tmp = append(tmp, v) } } // 最左边的那个，可以将前面的 0 全部去掉 if len(tmp) \u0026gt; 0 { t := tmp[0] if t != \u0026#34;\u0026#34; { for i := 0; i \u0026lt; len(t); i++ { if t[i] != \u0026#39;0\u0026#39; { tmp[0] = t[i:] break } } } } return \u0026#34;--\u0026gt;\u0026#34; + strings.Join(tmp, \u0026#34; \u0026#34;) + \u0026#34;\u0026lt;--\u0026#34; } func (fs *FdSetGolang) getMask(fd int) (idx int, n int) { return fd / fdBits, fd % fdBits } // set 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 1 func (fs *FdSetGolang) set(idx int, n int) { old := fs.data[idx] fs.data[idx] = 1\u0026lt;\u0026lt;n | old } // clear 将数组下标为 idx 的数的从右往左数的第(n+1)位设置为 0 func (fs *FdSetGolang) clear(idx int, n int) { if fs.isSet(idx, n) { fs.data[idx] ^= 1 \u0026lt;\u0026lt; n } } func (fs *FdSetGolang) isSet(idx, n int) bool { old := fs.data[idx] this := 1 \u0026lt;\u0026lt; n if int(old)\u0026amp;this == this { return true } return false } // uintBin 输出 n 的二进制表示 func (fs *FdSetGolang) uintBin(n uint64) string { if n == 0 { return \u0026#34;\u0026#34; } s := big.NewInt(0).SetUint64(n).Text(2) return strings.Repeat(\u0026#34;0\u0026#34;, fdBits-len(s)) + s } ","permalink":"http://localhost:1313/posts/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3linux-select%E4%B8%AD%E7%9A%84fd_set/","summary":"\u003cp\u003e看 \u003ccode\u003eselect\u003c/code\u003e 源码，\u003ccode\u003efd_set\u003c/code\u003e 这个结构体实际上是一个 \u003ccode\u003elong\u003c/code\u003e 型的数组，但是数组的长度依赖于系统中 \u003ccode\u003etypedef long int __fd_mask\u003c/code\u003e 的长度。当我去调试的时候，经常打印出一些很奇怪的值，有时候还会溢出。\u003c/p\u003e","title":"彻底理解Linux Select中的FD_SET"},{"content":"关于事务 事务的特性 原子性(Atomic, A)：要么全部执行，要么全部不执行； 一致性(Consistent, C)：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态； 隔离性(Isolation, I)：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务； 持久性(Durability, D)：事务提交后，其结果永久保存在数据库中。 事务ACID特性的实现思想\n原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 并发操作带来的问题 脏读(Dirty Reads)：一个事务在处理的过程中读取到了另一个未提交事务中的事务； 不可重复读(Non-Reapeatable Reads)：一个事务在读取某些数据后的某个时间再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了； 幻读(Phantom Reads)：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据。 不可重复读 和 幻读 区别是什么？\n不可重复读 的重点是 修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）\n幻读 的重点是 新增/删除：在同一事务中，同样的条件，第一次和第二次读出来的 记录数不一样。（因为中间有其他事务提交了插入/删除）\n事务的隔离级别 读未提交(Read UnCommitted)：所有的事务都可以看到其他事务未提交的修改(很少用到业务中)。(脏读：Y，不可重复读：Y，幻读：Y，) 读已提交(Read Committed)：只能看到其他已经提交的事务。(脏读：N，不可重复读：Y，幻读：Y) 可重复读(Reapeatable Read)：确保同一个事务在并发读取时数据一致(MySQL 默认的事务级别)。(脏读：N，不可重复读：N，幻读：Y) 可串行化(Serializable)：串行化读取数据(最高隔离级别，锁竞争激烈)。(脏读：N，不可重复读：N，幻读：N) 不同的数据库支持的隔离级别不同。在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据库中，只支持 Serializable (串行化)级别和 Read committed (读已提交)这两种级别，其中默认的为 Read committed 级别。\nMySQL 中有哪几种锁？ 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 什么是 MVCC？ 多版本并发控制(MultiVersion Concurrency Control) 是一种并发控制的方法，一般用在数据库管理系统中，实现对数据库的并发访问。\n为什么需要 MVCC？ 主要实现对数据的隔离，解决读写之间的阻塞问题，提高读写并发度。\n最原生的锁，锁住一个资源之后禁止其他任何线程访问。但是很多应用的场景都是 读多写少，很多数据的读取次数远远大于修改的次数，而这种读数据的操作之间进行排斥就显得很没必要； 所以出现了 读写锁，读锁与读锁不互斥，而写锁与写锁、写锁与读锁之间互斥，这样已经很大地提升了系统的并发能力。 后来人们发现并发读还是不够，又提出了一种让读写之间也不冲突的方法：快照读。就是读取数据的时候通过一种类似于 “快照” 的方式将第一眼看到的数据保存下来，这样读锁和写锁就不冲突了，不同的事务会看到自己特定版本的数据。当然，“快照”是一种概念模型，不同的数据库实现方式可能不太一样。 所以我们可以看到这样的“提高并发”的演进思路：\n普通锁，串行执行 \u0026ndash;\u0026gt; 读写锁，实现读读并发 \u0026ndash;\u0026gt; MVCC，实现读写并发。\nMVCC 解决了哪些问题？ 读写之间的阻塞问题：可以实现并发读写； 降低了死锁的概率：MySQL 的 InnoDB 的 MVCC 使用了乐观锁，读数据时并不需要加锁；对于写操作，也只锁定必要的行； 解决一致性读的问题：一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。 MVCC 只在 可重复读(REPEATABLE READ) 和 提交读(READ COMMITTED) 两个隔离级别下工作。其他两个隔离级别都和 MVCC 不兼容，因为 未提交读 总是读取最新的数据行，而不是符合当前事务版本的数据行。而 可串行化则会对所有读取的行都加锁。\nMVCC 如何实现的？ Innodb 中使用 B+树 作为索引的数据结构，并且主键所在的索引称为 聚簇索引(ClusterIndex)，聚簇索引的叶子结点保存了完整的一条数据。一张表只能有一个主键，所以也只能有一个聚簇索引，如果没有定义主键，InnoDB 将使用一个隐藏列作为聚簇索引。除了 聚簇索引，还有 二级索引(SecondaryIndex)，它的叶子结点中保存的是主键。\nInnoDB 的叶子段中保存了数据页，数据页中保存了行记录，而在行记录中有三个个重要的隐藏记录：\nDB_ROW_ID(隐藏行 ID)：隐藏的行 ID，用来生成默认的聚簇索引。如果我们创建表时没有指定聚簇索引，那么 InnoDB 会使用这个隐藏 ID来创建聚簇索引。 DB_TRX_ID(行的事务ID)：操作这行数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。新增一个事务时事务ID会增加，DB_TRX_ID 能够表示事务开始的先后顺序。 DB_ROLL_PT(行的回滚指针)：回滚指针，指向这行记录的 Undo Segment 中的 undo log。 MVCC 在 MySQL 中的实现依赖的是 undo log 和 ReadView。\nundo log：\n除了记录 redo log 之外，当进行数据修改时还会记录 undo log。undo log 用于数据的撤回操作，它记录修改的反向操作，比如插入对应删除，修改对应修改为原来的数据。undo log 分为两种：Insert 和 Update，Delete 可以看做是一种特殊的 Update，即在记录上修改删除标记。而 Insert undo log 在事务提交之后可以删除，因为用不到。所以我们可以理解为：update undo log记录了数据之前的数据信息，通过这些信息可以还原到之前版本的状态。\nReadView：\n也称为 一致性读视图。它并不实际存在，只是一个概念，通过 undo log 和版本计算出来，用以决定当前事务能看到哪些数据。\n对于 READ UNCOMMITTED 隔离级别，所有事务直接读取数据库的最新值即可；SERIALIZABLE 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 ReadView 的版本控制。\n所以我们才说 MVCC 只支持 Read Committed 以及 Repeated Read 隔离级别的实现，而核心逻辑就是依赖 undo log 以及版本控制。针对这个问题 InnoDB 在设计上增加了ReadView 的设计，ReadView 中主要包含当前聚簇索引对应的、当前系统中还有哪些活跃的读写事务，把它们的 事务ID 放到一个列表中，我们把这个列表命名为为 m_ids。对于查询时版本数据能否被看到的判断依据是：\n如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问； 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问； 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 先说结论：Read Committed 和 Repeatable Read 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同：\n在 Read Committed 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态； 在 Repeatable Read 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证 可重复读(Repeatale Read)。 腾讯面试：MySQL事务与MVCC如何实现的隔离级别？ 中有一个例子特别好，以截图方式展示：\nRead Committed 下的 ReadView：\nRepeatable Read 下的 ReadView：\nMySQL 中哪些存储引擎支持事务？ MySQL 服务器层不管理事务，事务是由下层的存储引擎实现的。支持事务的存储引擎有InnoDB 和 NDB Cluster。\n什么是自动提交？ MySQL 默认使用 InnoDB 引擎，并且默认采用 自动提交(AUTOCOMMITTED) 模式。也就是说，如果不是显式地开启一个事务，则每一个查询都被当成一个事务执行提交操作。\nMySQL 支持的存储引擎 我们主要关注三个：InnoDB、MyISAM 和 Memory。\nInnoDB MySQL 的默认事务型引擎，支持事务和外键。在你增删改查时匹配的条件字段带有索引时，InnoDB 使用 行级锁；在你增删改查时匹配的条件字段不带有索引时。InnoDB 使用的将是 表级锁。\nMyISAM 旧版本MySQL 的默认存储引擎。主要特点是快，不支持事务，也不支持外键。\nMemory 使用内存空间来创建表。Memory 类型的表访问非常快，因为它的数据是放在内存中的，并且默认使用 Hash 索引，但是一旦服务关闭，表中的数据就会丢失掉。\n关于索引 按照数据结构分：哈希索引、B+树索引 和 全文索引。\n按物理存储方式分：聚簇索引 和 二级索引。\nInnoDB到底支不支持哈希索引？\nInnoDB 用户无法手动创建哈希索引，这一层上说，InnoDB 确实不支持哈希索引; InnoDB 会 自调优(self-tuning)，如果判定建立 自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB 自己会建立相关哈希索引，这一层上说，InnoDB 又是支持哈希索引的。 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 B+树索引 所有的数据都在叶子节点，非叶子结点只存储叶子结点的索引，且每一个叶子节点都带有指向下一个节点的指针，形成了一个有序的链表，这样就可以实现范围查询。优势：\nB+Tree 它的非叶子节点不存储数据，只存储索引，而数据会存放在叶子节点中。非叶子结点存储的索引越多，叶子结点能表示的数据就越多，同样数量情况下，树的高度越小，查找数据时进行的 IO 次数就越少。 全文索引 只支持英文，实现方式为 倒排索引：先分词，再建立对应的B+树索引。\nInnoDB 中的索引策略 覆盖索引 最左前缀原则 索引下推 索引下推优化是 MySQL 5.6 引入的，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 InnoDB 中创建索引有什么原则 最左前缀匹配原则 频繁作为查询条件的字段才去创建索引 频繁更新的字段不适合创建索引 索引列不能参与计算，不能有函数操作 优先考虑扩展索引，而不是新建索引，避免不必要的索引 在order by或者group by子句中，创建索引需要注意顺序 区分度低的数据列不适合做索引列(如性别） 定义有外键的数据列一定要建立索引。 对于定义为text、image数据类型的列不要建立索引。 删除不再使用或者很少使用的索引 MySQL 分库分表 分库分表方案 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。 分库分表可能遇到的问题 事务问题：需要用分布式事务啦 跨节点Join的问题：解决这一问题可以分两次查询实现 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。 数据迁移，容量规划，扩容等问题 ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID 跨分片的排序分页问题（后台加大pagesize处理？） MySQL InnoDB 索引为什么使用 B+树？ 可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？\n为什么不是一般二叉树？ 如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。\n为什么不是平衡二叉树呢？ 我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。\n那为什么不是B树而是B+树呢？ B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。 B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。 ","permalink":"http://localhost:1313/posts/mysql%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch3 id=\"关于事务\"\u003e关于事务\u003c/h3\u003e\n\u003ch4 id=\"事务的特性\"\u003e事务的特性\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e原子性(Atomic, A)\u003c/code\u003e：要么全部执行，要么全部不执行；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e一致性(Consistent, C)\u003c/code\u003e：事务的执行，使得数据库由一种正确状态转变为另一种正确的状态；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e隔离性(Isolation, I)\u003c/code\u003e：在事务正确提交之前，不应该把该事务对数据的改变提供给其他事务；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e持久性(Durability, D)\u003c/code\u003e：事务提交后，其结果永久保存在数据库中。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e事务ACID特性的实现思想\u003c/p\u003e","title":"MySQL面试汇总"},{"content":"当我们谈论 Redis 时，应该谈论什么？ Redis 基本数据类型有哪些？以及他们各自的使用场景是什么？ 常见的有五种：字符串、哈希、列表、集合、有序集合。5.0 版本中新添加了 Stream 类型。\n字符串 String: 就是常规的 GET/SET 操作。是 Redis 最基本的数据类型，一个键最大能存储 512MB(底层数据结构：SDS)； 哈希 Hash：可以理解成一个键值对的集合，十分适合存储结构化数据。比如 MySQL 中有一条记录：id=1, name=demo, age=18，那么可以使用 hash 将其存到 Redis 中：HSET user:1 name demo age 18(数据结构：ZipList 或 HashTable)； 列表 List：就是简单的字符串列表，按照插入顺序排序。比较常见的场景是当做队列或者栈使用(数据结构：QuickList，是 ZipList 和 双向链表 的组合)。 集合 Set：存放的是一堆不重复值的集合，通常用来做去重，同时还提供了不同 Set 之间求交集、并集、合集等功能，业务上也能使用的到。它底层也是通过哈希表去实现的，可以做到增删改查都是 O(1) 的复杂度(数据结构：HashTable)。 有序集合 Sorted Set：跟 Set 一样，也是一堆不重复值的集合，不同的是每一个元素都会关联一个 float64 类型的分数，而 Redis 正是基于这个分数为集合中的成员进行排序的。比较常见的使用场景是存排行榜数据，去 Top N 会非常方便(数据结构：跳表SkipList)。 流式数据 Stream：这是 V5.0 版本引入的新的数据类型，用来弥补 Pub/Sub 的不足，工作模式类似于 kafka，可以使用 XADD 往一个 stream 中发送消息，而消费者可以是单个，也可以是消费者集群，并且任意一个消费者消费之后，必须手动调用 XACK 才会完全标志这条消息被处理，特别适合做消息队列。 Redis 使用场景 热数据存储：当成缓存中间件来使用，以缓解 DB 的压力。 做消息队列：我们可以使用它的 List 或 Stream 或 Pub/Sub 来实现一个消息队列，完成业务逻辑上的数据解耦； 排行榜：利用 Redis Sorted Set 实现； 限流器：利用单线程、原子递增等特性，可以记录某个用户在某段时间内的访问量，结合业务逻辑做到限流效果； 分布式锁：setnx 命令，设置成功表示拿到锁，不成功表示没拿到锁。 Redis 是单线程还是多线程？为什么这么快？ 4.0 以前，不管是主业务逻辑还是持久化，都是单线程； 4.0 版本，引入了多线程处理 AOF 等不太核心的操作，但主 Reactor 模型依旧使用单线程。主要是体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等; 6.0 版本，主 Reactor 真正引入多线程处理用户逻辑。 既然是单线程，为什么还这么快？\n官方的 QA 里说过，Redis 是基于内存的操作，CPU 并不是 Redis 的瓶颈，最大的瓶颈可能来自于机器内存大小以及网络带宽。快的原因：\n基于内存操作，并且有许多非常优秀的的数据结构为数据存储和处理做支撑； 单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能损失； 基于 I/O 多路复用 实现了自己类似于 Reactor 模型的事件库，大大提高网络处理能力。 Redis 是如何实现分布式锁的？ 主要利用 Redis 的 SETNX 命令实现：SETNX k v，当 k 不存在时，k v 设置成功并返回成功，表示拿到锁；k 已经存在则返回失败，加锁失败。操作结束后，可以使用 del k 删除，表示释放锁；也可以在加锁的同时，给这个锁一个过期时间，避免锁没有被显式释放而造成永久锁住。\n但上述方式也存在一些问题：\nSETNX 和 EXPIRE 并不是原子性操作，如果我 SET 之后因为网络原因没有 EXPIRE，锁因为没有设置超时时间而永远无法释放。很多开源的解决方案是 通过 lua 脚本同时设置过期时间，也可以 使用原生的 SET 命令，加上 nx 选项以及对应的过期时间，都可以解决没有 没有expire造成的锁不释放 问题。 使用了 expire，但有可能出现新的问题：就是加锁的一方的执行时间超过了 expire，此时锁自动过期释放，另一个线程获得锁，此时两个线程并发运行，就会出问题，而且如果当前线程处理完后调用 expire 也会将另一个线程的锁解除；而且这个锁也不是可重入锁。 针对这个问题，Redis 作者提出了在基于分布式环境下提出了更高级的分布式锁的实现：RedLock。(不过也并不是完美的，而且实际使用时也不会给你 5 个独立的 redis master)\n结论：Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。\n缓存雪崩、缓存穿透、缓存击穿等问题 缓存雪崩 现象：大量的热 key 设置了相同的过期时间，在该时刻这些热 key 全部失效，所有的请求铺天盖地都打到了 DB。\n解决方案：不要设置相同的过期时间，可以在一个 baseDuration 上加减一个随机数。\n缓存穿透 现象：一般的逻辑都是在 redis 中找不到，就会去 DB 查，然后将结果缓存到 Redis。但是如果某些 Key 在 DB 中也不存在(如小于 0 的用户 ID)，这类 Key 每次都会进行两次无用的查询。\n解决方案：\n加强非法参数的逻辑校验，提前返回失败； 将不存在的 Key 也缓存下来； 使用布隆过滤器，可以帮助识别：哪些数据一定不存在和可能存在，提前过滤一定不存在的数据。 缓存击穿 现象：某一个热点 key 扛着非常大的并发，某一时刻这个热点 key 失效，所有请求全部打到 DB 上，像是在墙上穿了一个洞。\n解决方案：1. 设置这个热点 key 永不过期；2. 如果非要更新，那么在这个热点 key 为空的时候，设置一个锁(比如 SETNX)，只让一个请求去数据库拉取数据，取完之后释放锁，恢复正常缓存逻辑。\nRedis 持久化方式以及实现细节 Redis 是在内存中处理数据的，但断电后内存数据会消失，因此需要将内存数据通过某种方式存储到磁盘上，以便服务器重启后能够恢复原有数据，这就是 Redis 的持久化。有三种方式：\nAOF日志(Append Only File)：文件追加方式，并且以文本的形式追加到文件中； RDB快照(Redis DataBase)：将某一时刻的内存数据，以二进制的形式全部存到磁盘中； 混合持久方式：v4.0 增加了混合持久化方式，集成了 RDB 和 AOF 的优点。 AOF AOF 采用的是写后日志的方式，现将数据写入内存，再记录到日志文件中。AOF 记录的是实际的操作命令和数据，即我们在终端输入的命令。等到重启恢复时，只需要将 AOF 文件中的命令重复执行一遍(涉及到 AOF 重写)。\n命令同步到 AOF 需要经历三个阶段：\n命令追加：Redis 将执行完的命令、命令的参数等信息“传播” AOF 程序中： 缓存追加：AOF 程序根据接收到的命令数据，将命令编码为自己的网络通信协议，然后将内容追加到服务器的 AOF 缓存中(redisServer 中有一个字段叫 sds aof_buf)； 文件写入和保存：缓存数据到一定条件，在事件处理器之后，会调 flushAppendOnlyFile 函数，这个函数会执行两个操作： WRITE：将 aof_buf 中的数据缓存写入 AOF 文件中； SAVE：调用 fsync 或者 fdataasync函数，将AOF 文件保存到磁盘中； 而 AOF 的文件保存模式有三种：\n不保存：WRITE 会被执行，SAVE 只会在服务关闭等常见会被执行一次，平常会被略过。这个时候，这两个操作都是由主线程来完成的，会阻塞主线程； 每秒保存一次：WRITE 每次都被执行，SAVE 启动子线程每秒执行一次。WRITE 操作由主进程执行，阻塞主进程；SAVE 操作由子线程执行，不直接阻塞主进程，但 SAVE 完成的快慢会影响 WRITE 的阻塞时长。 每执行一个命令保存一次：每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。这两个动作都由主线程执行，会阻塞主线程。 文件重写(bgrewriteaof):\n当开启的AOF时，随着时间推移，AOF文件会越来越大,当然redis也对AOF文件进行了优化，即触发AOF文件重写条件（后续会说明）时候，redis将使用bgrewriteaof对AOF文件进行重写。这样的好处在于减少AOF文件大小，同时有利于数据的恢复。常见的重写策略：\n重复或无效的命令不写入文件； 过期的数据不再写入文件； 多条命令合并写入。 RDB 按照指定时间间隔对你的数据集生成的时间点快照。它是 Redis 数据库中数据的内存快照，它是一个二进制文件（默认名称为：dump.rdb，可修改），存储了文件生成时 Redis 数据库中所有的数据内容。在 Redis Server 重启时可以通过加载 RDB 文件来还原数据库状态。 可用于 Redis 的数据备份、转移与恢复。\nrdbSave 负责将内存中的数据以 RDB 的格式保存到磁盘中，如果 RDB 文件已经存在，那么旧的文件会被新的文件替换。\n而 SAVE 和 BGSAVE 都会调用 rdbSave 函数，但他们的执行方式不同：\nSAVE 直接调用 rdbSave，阻塞 Redis 主进程，直到保存完为止。在主进程阻塞期间，服务器不能处理任何客户端请求； BGSAVE 则会 folk 出一个子进程，子进程调用 rdbSave，并在结束后向主进程发送信号通知。因为 rdbSave 是在子进程运行的，所以并不会阻塞主进程，在此期间服务器仍旧可以继续处理客户端的请求。 其他需要注意的：\n为了避免产生竞争条件， BGSAVE 执行时， SAVE 命令不能执行。 调用 rdbLoad 函数载入 RDB 文件时，不能进行任何和数据库相关的操作，不过订阅与发布方面的命令可以正常执行，因为它们和数据库不相关联。 AOF 文件的保存频率通常要高于 RDB 文件保存的频率， 所以一般来说， AOF 文件中的数据会比 RDB 文件中的数据要新。因此， 如果服务器在启动时， 打开了 AOF 功能， 那么程序优先使用 AOF 文件来还原数据。 只有在 AOF 功能未打开的情况下，Redis 才会使用 RDB 文件来还原数据。 混合持久化 混合持久化就是 同时结合 RDB 持久化以及 AOF 持久化混合写入 AOF文件。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据，缺点是 AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性差，并且 4.0 之前的版本并不识别；\n混合持久化同样也是通过 bgrewriteaof 完成的，不同的是当开启混合持久化时，fork 出的子进程先将共享的内存副本全量的以 RDB 方式写入 AOF文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有 RDB 格式和 AOF 格式的 AOF文件 替换旧的的 AOF文件。\n总结 RDB 优点：\n是一个非常紧凑的问题，特别适合文件备份以及灾难恢复； 节省性能。开启子进程不影响主进程功能。 RDB 缺点：\nRDB 是某一时刻的快照，无法保存全部数据，在请求较大时，丢失的数据会更多。 AOF 优点：\n数据更完整，秒级数据丢失(取决于设置fsync策略)； 文件内容可读性高，方便 debug。 AOF 缺点：\n文件体积更大，且恢复速度慢于 RDB。 Redis 如何实现高可用 Redis 实现高可用主要有三种方式：主从复制、哨兵模式，以及 Redis 集群。\n主从复制 在 主从复制 中，Redis server 分为两类：主库 master 和 从库 slave。主库可以进行读写操作，当写操作导致数据变化时会自动同步到从库。而从库一般是只读的，并接受来自主库的数据，一个主库可拥有多个从库，而一个从库只能有一个主库。\n哨兵模式 哨兵(sentinel) 是官方推荐的的 高可用(HA) 解决方案。Redis 的主从高可用解决方案，这种方案的缺点在于当 master 故障时候，需要手动进行故障恢复，而 sentinel 是一个独立运行的进程，它能监控一个或多个主从集群，并能在 master 故障时候自动进行故障转移，更为理想的是 sentinel 本身是一个分布式系统，其分布式设计思想有点类似于 zookeeper，当某个时候 Master 故障后，sentinel集群 采用一致性算法来选取Leader，故障转移由 Leader 完成。而对于客户端来说，操作 Redis 的主节点，我们只需要询问 sentinel，sentinel 返回当前可用的 master，这样一来客户端不需要关注的切换而引发的客户端配置变更。\nRedis 集群 从最开始的 一主N从，到 读写分离，再到 Sentinel 哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。为什么还需要 Redis 集群？这是因为某些场景下，单实例会存在一下几个问题：\n写并发：读操作可以通过负载均衡由诸多从节点分担，但所有的写操作只能由主节点完成，在海量数据高并发场景下，主节点压力也会飙升； 海量数据的存储压力：单实例本质上是只有一台主节点作为存储，其他从结点都是复制主节点的数据，也就是说，Redis 服务的存储能力取决于主节点所能承载的上线。 为了扩展写能力和存储能力，Redis引入集群模式。\nRedis3.0 加入了 集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的 master 节点上面，从而解决了海量数据的存储问题。\n同时 Redis集群 采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。\nRedis 也内置了高可用机制，支持 N 个 master节点 ，每个 master节点 都可以挂载多个slave节点，当 master节点 挂掉时，集群会提升它的某个slave节点 作为新的master节点。\nRedis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点(其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用)。\n问：集群中那么多 master节点，集群在存储的时候如何确定选择哪个节点呢？\n采用 类一致性哈希算法 实现节点选择。\n首先，集群将自己分成 16384 个 slot(槽位)，然后让每个节点分别负责一部分槽位(范围固定)。当某个 key 到来时，某个集群的 master 会先计算这个 key 应该被分配到哪个槽位(CRC16后的哈希值与 16384 取模的结果就是应该放入的槽位号)，如果这个槽位刚好是自己负责，那么开始处理并返回；如果不属于当前节点负责的范围，那么会返回一个 moved error，并告诉你应该去哪个节点指定这个写入命令。\n问：那集群如何实现扩容？\n通过 reshard(重新分片)来实现。它可以将已经分配给某个节点的任意数量的 slot 迁移给另一个节点，同时将对应 slot 的数据也全部迁移值新的节点。\nRedis 的过期策略以及内存淘汰机制 过期策略 定期随机检测删除：Redis 默认每隔 xxx ms就随机抽取设置了过期时间的 key，检测这些 key 是否过期，如果过期就删除。\n惰性删除：不再是 Redis主动去删除，而是在客户端获取某个 key 时，先检查是否过期，没过期则正常返回，如果过期则删除并且返回 nil。\n内存淘汰机制 惰性删除可以解决一些过期了，但没被定期删除随机抽取到的 key。但有些过期的 key 既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以 Redis 提供了内存淘汰机制来解决这个问题。\nRedis 在使用内存达到某个阈值(通过 maxmemory 配置)的时候，就会触发内存淘汰机制，选取一些 key 来删除。当内存不足以容纳新写入的数据时，内存淘汰有以下几种策略：\nnoeviction：报错。默认策略。 allkeys-lru：在所有的 key 中，删除最近最少使用的 key； allkeys-random：在所有的 key 中，随机移除某个 key； volatile-lru：在所有设置了过期时间的 key中，删除最近最少使用的 key； volatile-random：在所有设置了过期时间的 key中，随机移除某个 key； volatile-ttl：在所有设置了过期时间的 key中，有更早过期时间的 key 优先移除。 Redis 中 大key 和 热key 问题 大Key 问题 现象：\n什么是大 Key：\n单个简单的 key 存储的 value 很大：会导致网络拥塞，内存使用不均(集群模式下)； hash、set、zset 以及 list 结构中存储过多的元素：单个命令耗时太长容易阻塞其他命令，严重会引起集群发生故障切换，循环故障从而整个集群宕机。 如何发现：\nRedis 监控对超多 xxx 的 kv 报警； 定时脚本不断去 scan 拿到结果进而报警然后处理优化； 利用 redis-cli --bigkeys 命令行工具分析； 使用 redis-rdb-tools 工具对 RDB 文件进行分析 如何解决：\n删除：4.0 以后有 lazy delete，不会阻塞主线程。但这只是临时方案； hash： 使用 hscan + hdel set ： 使用 sscan + srem zset ： 使用 zremrangebyrank list ： 使用 scan + ltrim 拆分，然后使用 multiGet 获取; 热Key 问题 现象：\n突然有非常大的请求去访问 Redis 上的某个特定的key，流量过于集中，甚至达到物理网卡的上限，导致这台 Redis 服务器宕机。此时，这台Redis上的其他读写请求都变得不可用；热 key 会落到同一个 Redis 实例上，无法通过扩容解决；所有的请求都打在 DB 上，Redis 都扛不住，DB 大概率会挂掉。\n如何发现：\n业务经验预估 对用户行为数据分析，如点击、加购行为都会有打点数据 如果是集群，可以利用集群 proxy 统计分析 Redis v4.3 的 redis-cli 有一个 --hotkeys 选项，可以在命令行直接获取当前 namespace 中的热点 key(实现上是通过 scan + object freq 完成的)。 利用 redis-cli monitor 抓取数据，利用现有开源工具如 redis-faina 进行分析，统计出热 key。 怎么解决：\n增加 Redis 副本数量，将读请求的压力分配到不同的副本节点上； 业务上缓存(本地缓存)：比如使用一个大小限定的 map，每次去 Redis 查询前先检查内存中是否存在，如果存在就直接返回了。 集群条件下热key 备份：在集群条件下，一个 key 会被放入指定的实例的 slot，增加集群的节点数是没有用的。为了将针对某一个 key 的请求打散到不同的实例上，可以给对应的 key 增加前缀或者后缀，这样就可以实现将热key的流量让整个集群来分担，而不是某个节点。不过整个方案需要进行一定的业务开发，比如 key 前后缀的生成方式。 Redis 通信协议简单介绍 简称 RESP(Redis Serilization Protocol)，是 Redis 自定义的用于服务端和客户端之间的通信协议。特点是：实现简单、可读性强、快速解析。\n间隔符号，在 类Unix 下是 \\r\\n，在 Windows 是 \\n。\n+：简单字符串：\u0026quot;+OK\\r\\n\u0026quot; -：错误信息：\u0026quot;-Error unknow command 'foobar'\\r\\n\u0026quot; :：整数：\u0026quot;:1000\\r\\n\u0026quot; $：批量字符串：\u0026quot;$6\\r\\nfoobar\\r\\n\u0026quot;，前面的数组表示字符串长度 *：数组：\u0026quot;\\*2\\\\r\\\\n$2\\\\r\\\\nfoo\\\\r\\\\n$3\\\\r\\\\nbar\\\\r\\\\n\u0026quot;，数组包含2个元素，分别是字符串foo和bar。 ","permalink":"http://localhost:1313/posts/redis-%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","summary":"\u003ch2 id=\"当我们谈论-redis-时应该谈论什么\"\u003e当我们谈论 Redis 时，应该谈论什么？\u003c/h2\u003e\n\u003ch3 id=\"redis-基本数据类型有哪些以及他们各自的使用场景是什么\"\u003eRedis 基本数据类型有哪些？以及他们各自的使用场景是什么？\u003c/h3\u003e\n\u003cp\u003e常见的有五种：\u003ccode\u003e字符串\u003c/code\u003e、\u003ccode\u003e哈希\u003c/code\u003e、\u003ccode\u003e列表\u003c/code\u003e、\u003ccode\u003e集合\u003c/code\u003e、\u003ccode\u003e有序集合\u003c/code\u003e。\u003ccode\u003e5.0\u003c/code\u003e 版本中新添加了 \u003ccode\u003eStream\u003c/code\u003e 类型。\u003c/p\u003e","title":"Redis 面试汇总"},{"content":"一、原理 0. 简介 channel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 容量capacity。\n在 runtime 中是通过 hchan 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\ntype hchan struct { qcount uint // 环形队列中已经有的元素个数 dataqsiz uint // 环形队列容量，就是用户创建时指定的 capacity buf unsafe.Pointer // 环形队列所在的地址 elemsize uint16 // channal 中元素类型的大小 closed uint32 // channel 是否关闭 elemtype *_type // channel 元素类型 sendx uint // 环形队列中已经发送的 index recvx uint // 环形队列中已经接受的 index recvq waitq // 等待接受 channel 中消息的 goroutine 队列 sendq waitq // 等待向 channel 中发送消息的 goroutine 队列 lock mutex } 1. 用法以及常见问题汇总 已经关闭的 channel，再次关闭会 panic 向已经关闭的 channel 发送数据会造成 panic 如果从 channel 中取出元素的方式是 for-range，则在 channel 关闭时会自动退出循环 func main() { ch := make(chan int, 10) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } // 注意这里的 close，如果没有，将会出现死锁 panic close(ch) }() for j := range ch { fmt.Println(j) } } close 一个 channel 时，如果还有 sender goroutine 挂在 channel 的发送队列中，则会引起 panic。首先 close 会唤醒所有在此 channel 等待队列中的 goroutine，使其状态变为 Grunable，再看下文 3 中的 sendchan 源码就知道，当 goroutine 被唤醒之后，还会去检查 channel 是否已经被关闭，如果被关闭则会 panic。\n从已经 close 的 channel 中取值(说明已经正常关闭，channel 是空的)，会返回 channel 元素的零值。区分零值还是真实值，可以使用 comma, ok 的语法：\nx, ok := \u0026lt;- ch if !ok{ // channel 已经被关闭 // ..... } If the receiving goroutine queue of the channel is not empty, in which case the value buffer of the channel must be empty, all the goroutines in the receiving goroutine queue of the channel will be unshifted one by one, each of them will receive a zero value of the element type of the channel and be resumed to running state.\n没有通过 make 来初始化的 channel 被称为 nil channel，关闭一个 nil channel 会直接 panic 2. 创建 channel // 初始化 channel func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // 如果 hchan 中的元素不包含指针，那么也就不需要 GC var c *hchan switch { case mem == 0: /* channel 中缓冲区大小是 0(ch := make(chan int, 0)) 或者 元素类型的大小是 0(ch := make(chan struct{})) 此时所需的空间只有 hchan 这一个元素的 */ // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: /* channel 中元素的类型不是指针。 此时所需要的空间除了 hchan 的，还有对应元素的：uintptr(size)*elem.size + hchanSize 因为不是指针，GC 也不会对channel中的元素进行 scan */ // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: /* channel 中的元素包含指针。 注意，这里进行了两次空间分配，一次是给 hchan，第二次是给 channel 中的元素 */ // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } 3. 向 channel 发送 // select {case \u0026lt;-xxx} 的入口 func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } // entry point for c \u0026lt;- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } // 向一个 channel 发送数据的具体实现 // c 就是 channel 实体，ep 表示要发送的数据，block 表示是否阻塞(正常业务逻辑中是 true，如果是 select 则是 false) func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { /* 应用层的 channel 是空的，如 var ch chan int ch \u0026lt;- 1 如果非阻塞，则直接返回； 如果阻塞，也就是向一个 nil channel 发送数据，那么将永久阻塞下去 需要注意的是，空的channel 和 已经关闭的channel是不同的。向空 channel 发送将永久阻塞，向 closed channel 发送将 panic。 */ if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 数据竞争相关的检测，后面专门说明 if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread\u0026#39;s view of c.closed and full(). /* 这里的 FastPath 其实是对 非阻塞channel(select) 操作判断的一种优化：已经要求不要在 channel 上发生阻塞， 那么这里迅速做一个判断，“能失败则立刻失败”——如果 非阻塞 \u0026amp;\u0026amp; 未关闭 \u0026amp;\u0026amp; 已经满了，那就不往后面走了。 // 检查 channel 是否已经满了 func full(c *hchan) bool { // 无缓冲的 channel if c.dataqsiz == 0 { // 如果等待队列中有 goroutine 等待，那么就返回 channel 未满，可以进行后续的处理 return c.recvq.first == nil } // 有缓冲的 channel，看环形链表中的元素数量是否已经到达容量 return c.qcount == c.dataqsiz } 如何理解这个 full？ 答：For a zero-capacity (unbuffered) channel, it is always in both full and empty status. */ if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 向一个已经关闭的 channel 发送数据，会造成 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). /* 这里也是一个 FastPath： 通常情况下往一个 channel 中发送数据，会先将数据复制到环形链表中，然后 等待接受的 goroutine 来取，再讲数据从唤醒链表中拷贝到 goroutine 中。 但是考虑一种情况，等待接收的 goroutine 早就在等了(等待队列不为空)， 这个时候发送过来一个数据，就没必要再先放进 buffer、再拷贝给等待 goroutine 了， 直接将数据从发送 goroutine 的栈拷贝到接受者 goroutine 的栈中，节省资源。 */ send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. /* 如果是有缓冲的 channel 并且 buffer 中空间足够，那么就将数据拷贝到 buffer 中。 同时更新 */ qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } // 将数据从发送 goroutine 拷贝到 buffer 中 typedmemmove(c.elemtype, qp, ep) // 发送 index++ c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } // buffer 中 已有元素数量++ c.qcount++ unlock(\u0026amp;c.lock) return true } // 如果是非阻塞的 channel(select)，发送的工作已经走完了，可以返回了，后面的都是阻塞 channel 要做的事 if !block { unlock(\u0026amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. // 在 channel 上阻塞，receiver 会帮我们完成后续的工作 // 将当前的发送 goroutine 打包成一个 sudog 结构 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 将打包好的 sudog 入队到 channel 的 sendq(发送队列)中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 将这个发送 g 的状态改变：Grunning -\u0026gt; Gwaiting，之后进入休眠 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren\u0026#39;t considered as roots of the // stack tracer. KeepAlive(ep) // 后面的是当前 goroutine 被唤醒后的逻辑 // 醒来后检查一下状态，才会返回成功 // someone woke us up. if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } // 醒来后发现 channel 已经被关闭了，直接 panic panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } 4. 从 channel 中接收 func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } // entry points for \u0026lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller\u0026#39;s stack. // 从 hchan 中接收数据，并将数据拷贝到 ep 对应的空间中。ep 可以是 nil，这种情况下数据会被丢弃； // 如果 ep 不为 nil，那么必须指向 堆 或者 调用者g的栈地址 // 这里的返回值 selected 表示是否被 select 到，received 表示是否成功接收到数据 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 从一个阻塞的 nil channel 中接收数据，则会永久阻塞 if c == nil { if !block { return } // 这种情况其实就是 goroutine 泄露 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // FastPath: 如果不阻塞并且没有内容可接收，直接返回 false false if !block \u0026amp;\u0026amp; empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026#34;open and empty\u0026#34;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026amp;c.closed) == 0 { // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. // 走到这里，说明 channel 是非阻塞的，并且已经关闭了，而且 channel 中没有数据留下，此时会返回对应值的零值 if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // 当前 channel 中没有数据可读，直接返回 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { // 将 ep 设置成对应元素的零值 typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). /* 这里也是一个 FastPath：如果我们去接收的时候，发现 buffer 是空的，但是 发送等待队列不为空，那么直接从这个等待的 goroutine 中拷贝数据。 如果 buffer 不为空，那么需要先从 buffer 中拿，然后将等待队列中的元素再放到 buffer 中 */ recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } if c.qcount \u0026gt; 0 { // Receive directly from queue // 如果 buffer 中有数据可取，直接从 buffer 中拿 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 将 buffer 中的数据拷贝到目标地址 if ep != nil { typedmemmove(c.elemtype, ep, qp) } // 清空 buffer 中取出的元素的内容 typedmemclr(c.elemtype, qp) // 接收 index++ c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } // buffer 中 总数-- c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 如果非阻塞，返回 false if !block { unlock(\u0026amp;c.lock) return false, false } // no sender available: block on this channel. // 如果是阻塞的 channel，那么接收的 goroutine 将阻塞在这里 // 将等待的 goroutine 打包成 sudog，并将其放到等待队列中，之后休眠 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // 被唤醒 // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 如果 channel 没有被关闭，那就是真的 receive 到数据了 return true, success } 5. 关闭 channel func closechan(c *hchan) { // close 一个 nil channel 将 panic if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) // close 一个已经 closed 的 channel，将 panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } // 明确关闭 channel c.closed = 1 var glist gList // release all readers /* 将所有的接收等待队列中的 goroutine 全部弹出， 每一个 goroutine 将会收到 channel 中元素类型的零值， 并且恢复到 Grunning 状态 */ for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { // 这一步设置零值 typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) /* 将所有发送队列中的 goroutine 全部弹出，并恢复到 Grunning 状态。 恢复到后将继续进行“往 channel buffer 中发送数据”操作 但这个方法中已经将 closed 设置成 1，恢复运行后会检查，如果已经 closed，则会直接 panic */ for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 二、使用 如何正确关闭 channel 不同的场景介绍几种建议方案，尤其是生产-消费模型相关的。\n1. M receivers, one sender, the sender says \u0026ldquo;no more sends\u0026rdquo; by closing the data channel 一个生产者、多个消费者，由 producer 来关闭 channel，通知数据已经发送完毕。\nfunc main(){ consumerCnt := 10 // 这里可以是缓冲的，也可以是非缓冲的 taskChan := make(chan int, consumerCnt) wg := \u0026amp;sync.WaitGroup{} go func() { for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for data := range taskChan { fmt.Printf(\u0026#34;consumer %d received: %d\\n\u0026#34;, idx, data) } }(i) } }() for i := 0; i \u0026lt; consumerCnt * 2; i++ { taskChan \u0026lt;- i } close(taskChan) wg.Wait() } 2. One receiver, N senders, the only receiver says \u0026ldquo;please stop sending more\u0026rdquo; by closing an additional signal channel 一个 consumer、多个 producer 场景，多添加一个用于 通知 的 channel，由其中一个消费者告诉生产者“已经够了，不要再发了”。\nfunc main(){ rand.Seed(time.Now().UnixNano()) producerCnt := 10 taskChan := make(chan int) wg := \u0026amp;sync.WaitGroup{} // 用于信号通知 stopChan := make(chan struct{}) // 多个 producer 一直在生产消息，直到收到停止的信号 for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { // 这是一个 try-receive 操作，尝试能否快速退出 select { case \u0026lt;-stopChan: return default: } // 即使上面刚进行了判断没有退出，但到这一步的过程中 stopChan 可能就有数据 或者 被close了 select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- rand.Intn(1000): } } }(i) } // 一个消费者 wg.Add(1) go func() { defer wg.Done() for value := range taskChan { // 在这里确定要退出的逻辑 if value%7 == 0 { fmt.Println(value) fmt.Printf(\u0026#34;%d is times of 7, bye \\n\u0026#34;, value) // 在这里使用 close(stopChan) 和 stopChan \u0026lt;- struct{}{} 都能达到同样的效果 close(stopChan) // stopChan \u0026lt;- struct{}{} return } fmt.Println(value) } }() wg.Wait() } 3. M receivers, N senders, any one of them says \u0026ldquo;let\u0026rsquo;s end the game\u0026rdquo; by notifying a moderator to close an additional signal channel 多个 producer、多个 consumer 的场景下，当其中任何一个发生异常时，全部退出。这种场景下，不能让任何一个 producer 或者 consumer 来关闭 taskChan，也不能让任何一个 consumer 来关闭 stopChan 进而通知所有的 goroutine 退出。这个时候，我们可以再添加一个类似于主持人角色的 channel，让它来做 close stopChan 这个操作。\nfunc main(){ rand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int, consumerCnt) stopChan := make(chan struct{}) // 这里必须使用有缓冲的 buffer，主要是为了避免 moderator 还没启动时就已经有一个 toStop 消息到达导致它没收到 toStop := make(chan string, 1) var stoppedBy string // moderator go func() { stoppedBy = \u0026lt;-toStop close(stopChan) }() // producer for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { value := rand.Intn(10000) if value == 0 { // 达到退出的条件 /* 注意这里的用法，直接换成 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) 是否可行？ 答案是不行，会造成死锁。 */ select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx): default: } return } // 剩下的逻辑和前一个 demo 一样 select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case taskChan \u0026lt;- value: } } }(i) } wg := \u0026amp;sync.WaitGroup{} // consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-stopChan: return default: } select { case \u0026lt;-stopChan: return case value := \u0026lt;-taskChan: // 达到 consumer 的退出条件 if value%7 == 0 { select { case toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, value): default: } return } fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;exit by\u0026#34;, stoppedBy) } 注意当 producer 或者 consumer 达到退出的条件时，往 toStop channel 发送数据的方式。因为 toStop 的容量只有 1，直接使用 toStop \u0026lt;- fmt.Sprintf(\u0026quot;consumer-%d\u0026quot;, value) ，当 toStop 满了塞不下了，那么所有的往里面塞的 goroutine 都将被阻塞挂起，而这些 goroutine 还在等 stopChan 通知退出，而 moderator 的实现里，只接收一个，这就造成了死锁。所以正确做法是，通过 select 尝试往 toStop 中发送，成功还好，不成功(说明已经有其他的 goroutine 通知了)直接 return。\n也可以不使用“通过 select 尝试发送”的方式，那就是让 toStop 的容量变成容纳所有可能发送的 goroutine 的数量，这个时候就可以放心直接往 toStop 里灌数据了：\n// ... toStop := make(chan string, producerCnt + consumerCnt) // ... // producer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;producer-%d\u0026#34;, idx) // ... // consumer 中达到退出条件 toStop \u0026lt;- fmt.Sprintf(\u0026#34;consumer-%d\u0026#34;, idx) 4. A variant of the \u0026ldquo;N sender\u0026rdquo; situation: the data channel must be closed to tell receivers that data sending is over 上面三个 demo 中，我们都没有对 tashChan 进行明确的 close，close 操作交给了 GC。但是有些场景下，会要求没数据时一定要关闭 taskChan，然后通知调用consumer明确告知“数据已经发送完了”。但是当有多个 producer 时，直接关闭肯定行不通。再这样的场景下，可以引入一个 middle channel ，producer 的数据不再直接发给 consumer，而是先发给middle channel，这个 middle channel 只有一个 sender，可以做到 close taskChan 了。\nrand.Seed(time.Now().UnixNano()) const producerCnt = 10 const consumerCnt = 100 taskChan := make(chan int) middleChan := make(chan int) closing := make(chan string) done := make(chan struct{}) var stoppedBy string stop := func(by string) { select { case closing \u0026lt;- by: \u0026lt;-done case \u0026lt;-done: } } // 多个 producer，将数据发送给 middle channel for i := 0; i \u0026lt; producerCnt; i++ { go func(idx int) { for { select { case \u0026lt;-done: return default: } value := rand.Intn(10000) if value%7 == 0 { fmt.Println(value, \u0026#34; will stop\u0026#34;) stop(\u0026#34;producer-\u0026#34; + strconv.Itoa(idx)) return } select { case \u0026lt;-done: return case middleChan \u0026lt;- value: } } }(i) } // middle channel go func() { exit := func(v int, needSend bool) { close(done) if needSend { taskChan \u0026lt;- v } close(taskChan) } for { select { case stoppedBy = \u0026lt;-closing: exit(0, false) return case v := \u0026lt;-middleChan: select { case stoppedBy = \u0026lt;-closing: exit(v, true) return case taskChan \u0026lt;- v: } } } }() wg := \u0026amp;sync.WaitGroup{} // 多个 consumer for i := 0; i \u0026lt; consumerCnt; i++ { wg.Add(1) go func(idx int) { defer wg.Done() for { select { case \u0026lt;-done: return default: } for value := range taskChan { fmt.Println(value) } } }(i) } wg.Wait() fmt.Println(\u0026#34;stopped by\u0026#34;, stoppedBy) ","permalink":"http://localhost:1313/posts/golang-channel%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一原理\"\u003e一、原理\u003c/h2\u003e\n\u003ch3 id=\"0-简介\"\u003e0. 简介\u003c/h3\u003e\n\u003cp\u003echannel 分为有缓冲和无缓冲，或者阻塞和非阻塞，主要区别就在于是否有 \u003ccode\u003e容量capacity\u003c/code\u003e。\u003cbr /\u003e\n在 \u003ccode\u003eruntime\u003c/code\u003e 中是通过 \u003ccode\u003ehchan\u003c/code\u003e 这个结构体来表示的，它里面的主要成员可以理解成包含两个大部分：环形队列相关 和 sudog等待队列 相关。\u003cbr /\u003e\n对于有缓冲的 channel，会设置环形队列相关的参数，如已有的元素数量、容量、指向队列的指针等；\u003cbr /\u003e\n等待队列有发送等待队列和接受等待队列，他们分别在发送时 channel 已满、接收时 channel 为空的情况下，会将当前 goroutine 打包成一个 sudog 结构，添加到对应的队列中，直到条件符合时再被唤醒工作。\u003c/p\u003e","title":"Golang Channel详解"},{"content":" Redis 设计与实现\u0026ndash;事件 中有很清晰的说明。\nredis 要处理的事件有两种类型：\n文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发； 时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。 一、时间事件 时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\n每个时间事件主要由三个属性组成：\nwhen ：以毫秒格式的 UNIX 时间戳为单位，记录了应该在什么时间点执行事件处理函数。 timeProc ：事件处理函数。 next 指向下一个时间事件，形成链表。 根据 timeProc 函数的返回值，可以将时间事件划分为两类：\n如果事件处理函数返回 ae.h/AE_NOMORE ，那么这个事件为单次执行事件：该事件会在指定的时间被处理一次，之后该事件就会被删除，不再执行。 如果事件处理函数返回一个非 AE_NOMORE 的整数值，那么这个事件为循环执行事件：该事件会在指定的时间被处理，之后它会按照事件处理函数的返回值，更新事件的 when 属性，让这个事件在之后的某个时间点再次运行，并以这种方式一直更新并运行下去。 这些常规操作主要包括：\n更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 对不合理的数据库进行大小调整。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主节点的话，对附属节点进行定期同步。 如果处于集群模式的话，对集群进行定期同步和连接测试。 二、文件事件 Redis 服务器通过在多个客户端之间进行多路复用， 从而实现高效的命令请求处理： 多个客户端通过套接字连接到 Redis 服务器中， 但只有在套接字可以无阻塞地进行读或者写时， 服务器才会和这些客户端进行交互。\nRedis 将这类因为对套接字进行多路复用而产生的事件称为文件事件（file event）， 文件事件可以分为读事件和写事件两类。\n1. 读\u0026ndash;标志着客户端命令请求的发送状态 当一个新的客户端连接到服务器时， 服务器会给为该客户端绑定读事件， 直到客户端断开连接之后， 这个读事件才会被移除。\n有两种状态：\n等待：客户端只是连接到服务器，并没有发送命令； 就绪：客户端给服务端发送命令请求、并且请求已经到达(相应的套接字可以无阻塞地执行读操作)时，读事件状态更新为“就绪”。 当一个新的客户端连接到服务器\n2. 写\u0026ndash;标志着客户端对命令结果的接受状态 服务器只会在有命令结果要传回给客户端时， 才会为客户端关联写事件， 并且在命令结果传送完毕之后， 客户端和写事件的关联就会被移除。\n也只有两种状态：\n等待：有结果返回，但客户端还未能执行无阻塞写时； 就绪：有结果返回，并且能无阻塞写时。 当客户端向服务器发送命令请求， 并且请求被接受并执行之后， 服务器就需要将保存在缓存内的命令执行结果返回给客户端， 这时服务器就会为客户端关联写事件。\n3.读 和 写的关系 读事件只有在客户端断开和服务器的连接时，才会被移除。这也就是说，当客户端关联写事件的时候，实际上它在同时关联读/写两种事件。因为在同一次文件事件处理器的调用中， 单个客户端只能执行其中一种事件（要么读，要么写，但不能又读又写）， 当出现读事件和写事件同时就绪的情况时，事件处理器优先处理读事件————也就是说， 当服务器有命令结果要返回客户端， 而客户端又有新命令请求进入时， 服务器先处理新命令请求。\n4. 常见的文件事件 为Server端的接口（TCP Socket，Unix Socket，管道）客户端连接的可读事件（在server.c的initServer()函数中） 为各个客户端连接的Socket添加读/写事件（在networking.c中） AOF的管道（Pipe）添加读/写事件（在aof.c中） Cluster集群连接的读/写事件（在cluster.c中） 主从复制连接的读/写事件（在replication.c中） Redis哨兵模式连接的读/写事件（在sentinel.c中） ","permalink":"http://localhost:1313/posts/redis%E4%BA%8C-%E4%BB%80%E4%B9%88%E6%98%AF-redis-%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://redisbook.readthedocs.io/en/latest/internal/ae.html\"\u003eRedis 设计与实现\u0026ndash;事件\u003c/a\u003e 中有很清晰的说明。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eredis 要处理的事件有两种类型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文件事件：网络连接套接字。服务器与多个客户端通过网络套接字连接，当对应套接字上出现“读”或“写”需求时，对应的事件就会触发；\u003c/li\u003e\n\u003cli\u003e时间事件：在指定时间点运行的事件。如持续运行的服务器为了维持一个健康稳定的状态，需要定期对自身的资源和状态进行检查和整理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"一时间事件\"\u003e一、时间事件\u003c/h3\u003e\n\u003cp\u003e时间事件记录着那些要在指定时间点运行的事件， 多个时间事件以无序链表的形式保存在服务器状态中。\u003cbr /\u003e\n每个时间事件主要由三个属性组成：\u003c/p\u003e","title":"Redis(二): 什么是 Redis 中的事件"},{"content":"一、前言 在关注 redis 单线程/多线程 时，有几个重要的时间节点：\nBefore Redis v4.0，真正的单线程； Redis v4.0，引入多线程处理 AOF 等任务，但核心的网络模型中依旧使用单线程； Redis v6.0，正式在网络模型中实现 I/O多线程。 从 Redis v1.0 到 Redis v6.0以前，Redis 的核心网络模型一直都是一个典型的 单Reactor模型，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 单Reactor模型 的所有运作细节，为以后更好地理解新的 Multi-Reactors/Master-Workers 模型做准备。\n注：本文基于 Redis v5.0.0 版本分析。\n二、概览 Reactor 模式本质上指的是使用 I/O多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O) 的模式。传统的 单Reactor 模型中有三种角色：\nReactor：主线程，模型核心，通过事件循环不断处理事件，如果是新的连接事件，则交给 Acceptor，如果是已经连接的 I/O 事件，则交给 Handler； Acceptor：负责 server 和 client 的连接。Reactor 模式一条最重要的原则就是：I/O 操作不能阻塞主线程循环，所以对于阻塞的网络 I/O，一般都是通过 I/O 多路复用实现的，如 Linux 上的epoll，这样可以最大程度地满足“一个线程非阻塞地监听多个 I/O 事件”。当有新的连接到来是，Acceptor 创建一个新的 socket，并将这个 socket添加到 epoll 的监听队列中，指定事件类型(读事件 或 写事件)，指定对应事件发生时的回调函数，这样当此客户端的请求到来时，epoll 会调用设定好的回调函数(可以理解成 Handler)； Handler：真正的业务处理逻辑。已经建立连接的客户端请求到来后，触发 epoll 的读事件，调用 Handler 执行具体的业务逻辑。 Redis v6.0 之前的网络模型就是一个典型的 单Reactor 模型：\n我们先逐一认识一下对应的角色概念：\naeEventLoop：这是 Redis 自己实现的一个高性能事件库，里面封装了适配各个系统的 I/O多路复用(I/O multiplexing)，除了 socket 上面的事件以外，还要处理一些定时任务。服务启动时就一直循环，调用 aeProcessEvent 处理事件； client ：代表一个客户端连接。Redis 是典型的 CS 架构（Client \u0026lt;---\u0026gt; Server），客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。Redis 使用结构体 client 存储客户端的所有相关信息，包括但不限于封装的套接字连接 \u0026ndash; *conn，当前选择的数据库指针 \u0026ndash;*db，读入缓冲区 \u0026ndash; querybuf，写出缓冲区 \u0026ndash; buf，写出数据链表 \u0026ndash; reply等； acceptTcpHandler：角色 Acceptor 的实现，当有新的客户端连接时会调用这个方法，它会调用系统 accept 创建一个 socket 对象，同时创建 client 对象，并将 socket 添加到 EventLoop 的监听列表中，并注册当对应的读事件发生时的回调函数 readQueryFromClient，即绑定 Handler，这样当该客户端发起请求时，就会调用对应的回调函数处理请求； readQueryFromClient：角色 Handler 的实现，主要负责解析并执行客户端的命令请求，并将结果写到对应的 client-\u0026gt;buf 或者 client-\u0026gt;reply 中； beforeSleep：事件循环之前的操作，主要执行一些常规任务，比如将 client 中的数据写会给客户端、进行一些持久化任务等。 有了这写概念，我们可以试着描绘一下 客户端client 与 Redis server 建立连接、发起请求到接收到返回的整个过程：\nRedis 服务器启动，开启主线程事件循环 aeMain，注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来； 客户端和服务端建立网络连接，acceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上作为对应事件发生时的回调函数，并初始化一个 client 绑定这个客户端连接； 客户端发送请求命令，触发读就绪事件，主线程调用 readQueryFromClient 通过 socket 读取客户端发送过来的命令存入 client-\u0026gt;querybuf 读入缓冲区； 接着调用 processInputBuffer，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 根据 Redis 协议解析命令，最后调用 processCommand 执行命令； 根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族的一系列函数将响应数据写入到对应 client 的写出缓冲区：client-\u0026gt;buf 或者 client-\u0026gt;reply ，client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client 添加进一个 LIFO 队列 clients_pending_write； 在事件循环 aeMain 中，主线程执行 beforeSleep --\u0026gt; handleClientsWithPendingWrites，遍历 clients_pending_write 队列，调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 sendReplyToClient 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。 三、事件库 aeEventLoop 实现细节 先来看核心数据结构：\n/* State of an event based program */ typedef struct aeEventLoop { int maxfd; // 当前已经注册在此的最大文件描述符 int setsize; // 可“关心”的文件描述符数量 long long timeEventNextId; // 下一个 timer 的id time_t lastTime; // 上一轮事件循环时的系统事件，用来诊断系统时间偏差 aeFileEvent *events; // 注册的文件事件 aeTimeEvent *timeEventHead; // 注册的时间事件 aeFiredEvent *fired; // 就绪的事件 int stop; // 事件轮询是否停止 void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; // 下一次事件轮训之前的钩子函数 aeBeforeSleepProc *aftersleep; // 事件轮询结束后的钩子函数 } aeEventLoop; /* File event structure */ typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE) */ aeFileProc *rfileProc; // 读事件就绪时的回调函数 aeFileProc *wfileProc; // 写事件就绪时的回调函数 void *clientData; // fd 对应的 client 实例 } aeFileEvent; /* Time event structure */ typedef struct aeTimeEvent { long long id; /* time event identifier. */ long when_sec; /* seconds */ long when_ms; /* milliseconds */ aeTimeProc *timeProc; aeEventFinalizerProc *finalizerProc; void *clientData; struct aeTimeEvent *next; } aeTimeEvent; /* A fired event */ typedef struct aeFiredEvent { int fd; int mask; } aeFiredEvent; 关于 时间事件 和 文件事件，可参考：redis 中的事件(时间事件和文件事件)到底是什么？\naeEventLoop 的 Prototypes 有很多，我们关注几个重要的：\n1. aeEventLoop *aeCreateEventLoop(int setsize) 创建一个 aeEventLoop 实例 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; int i; if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;lastTime = time(NULL); eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; if (aeApiCreate(eventLoop) == -1) goto err; /* Events with mask == AE_NONE are not set. So let\u0026#39;s initialize the * vector with it. */ for (i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } 这个方法的实现很简单，就是一些成员变量的初始化。需要注意的是 aeApiCreate，在 src/ae.c 的最开始，有下面的代码：\n/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */ #ifdef HAVE_EVPORT #include \u0026#34;ae_evport.c\u0026#34; #else #ifdef HAVE_EPOLL #include \u0026#34;ae_epoll.c\u0026#34; #else #ifdef HAVE_KQUEUE #include \u0026#34;ae_kqueue.c\u0026#34; #else #include \u0026#34;ae_select.c\u0026#34; #endif #endif #endif 这段代码的意思是，根据当前的系统类型，选择性能最好的 I/O多路复用 库，比如当前系统是 Linux，那么应该使用 ae_epoll，Mac 下使用 ae_kqueue等，ae_select 是保底方案。而 ae_xxx 是对不同系统下的 I/O多路复用 的封装，将底层的不同系统调用都通过统一的 API接口 和 数据结构 aeApiStates 暴露出去，供上层调用。我们看下 Linux 系统中 aeApiCreate 的实现：\ntypedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } // 创建 epoll 实例 state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 而 Mac 下的实现又是这样的：\ntypedef struct aeApiState { int kqfd; struct kevent *events; } aeApiState; static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct kevent)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;kqfd = kqueue(); if (state-\u0026gt;kqfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } eventLoop-\u0026gt;apidata = state; return 0; } 2. aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) 监听文件事件 int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData) { if (fd \u0026gt;= eventLoop-\u0026gt;setsize) { errno = ERANGE; return AE_ERR; } aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; if (aeApiAddEvent(eventLoop, fd, mask) == -1) return AE_ERR; fe-\u0026gt;mask |= mask; if (mask \u0026amp; AE_READABLE) fe-\u0026gt;rfileProc = proc; if (mask \u0026amp; AE_WRITABLE) fe-\u0026gt;wfileProc = proc; fe-\u0026gt;clientData = clientData; if (fd \u0026gt; eventLoop-\u0026gt;maxfd) eventLoop-\u0026gt;maxfd = fd; return AE_OK; } 同样，aeApiAddEvent 在不同系统下有不同的实现，在 Linux 系统中，会调用 epoll_ctl ，将 fd 添加到 epoll 实例的监听列表中，同时指定对应事件触发时的回调函数为 *proc。\n3. aeProcessEvents(aeEventLoop *eventLoop, int flags) 事件轮训处理的核心逻辑 /* The function returns the number of events processed. */ int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; // 只处理时间事件和文件事件 if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; // 先处理文件事件 if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { // 计算下一次时间事件到来之前应该阻塞等待的时长 // 调用底层的 poll 函数，获取已经就绪的事件 numevents = aeApiPoll(eventLoop, tvp); // 如果设置了 aftersleep 钩子函数，那应该在 poll 之后调用 if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); // 调用对应事件的回调函数 for (j = 0; j \u0026lt; numevents; j++) { aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[eventLoop-\u0026gt;fired[j].fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fd = eventLoop-\u0026gt;fired[j].fd; int rfired = 0; // 读事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { rfired = 1; fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } // 写事件 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!rfired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); } processed++; } } // 最后再处理时间事件 if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; /* return the number of processed file/time events */ } 四、Redis 单线程流程详解 在这个 section，我们将通过源码的角度，看看 section 1 中的 Redis 的 单Reactor 网络模型中的实现细节，我们对照这张图开始：\n1. server 启动，创建 EventLoop 在 src/server.c 中的 main 方法中，当服务器启动时，会调用 initServer方法，在这个方法中，Redis 会创建全局唯一的 aeEventLoop 实例，并注册 Server socket 到对应的多路复用组件上，同时指定回调函数为 acceptTcpHandler，意思是服务器接收到新的连接时，应该调用 acceptTcpHandler 这个回调函数。\nvoid initServer(void) { ... // 创建全局唯一的 EventLoop 实例 server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } ... /* Create an event handler for accepting new connections in TCP and Unix * domain sockets. */ // ipfd 表示服务启动是监听的 socket 对应的 fd，epoll 监听此 fd，有读事件发生(新连接到来)时调用回调函数 acceptTcpHandler for (j = 0; j \u0026lt; server.ipfd_count; j++) { if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler,NULL) == AE_ERR) { serverPanic( \u0026#34;Unrecoverable error creating server.ipfd file event.\u0026#34;); } } } .... 2. 新连接到来时创建连接以及 client 实例 在前面我们将 server 对应的 socket 添加到 epoll 的监听队列，当有新的连接到来时，会触发读事件就绪，此时回调函数 acceptTcpHandler 就会被调用：\nvoid acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 创建 connect fd，代表 Redis Server 和客户端的一个连接(socket) cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), \u0026amp;cport); if (cfd == ANET_ERR) { if (errno != EWOULDBLOCK) serverLog(LL_WARNING, \u0026#34;Accepting client connection: %s\u0026#34;, server.neterr); return; } serverLog(LL_VERBOSE, \u0026#34;Accepted %s:%d\u0026#34;, cip, cport); acceptCommonHandler(cfd, 0, cip); } static void acceptCommonHandler(int fd, int flags, char *ip) { client *c; // 1. 为 connect fd 创建一个 Client 对象 if ((c = createClient(fd)) == NULL) { serverLog(LL_WARNING, \u0026#34;Error registering fd event for the new client: %s (fd=%d)\u0026#34;, strerror(errno), fd); close(fd); /* May be already closed, just ignore errors */ return; } // 2. 检查是否超过了最大连接数 if (listLength(server.clients) \u0026gt; server.maxclients) { char *err = \u0026#34;-ERR max number of clients reached\\r\\n\u0026#34;; /* That\u0026#39;s a best effort error message, don\u0026#39;t check write errors */ if (write(c-\u0026gt;fd, err, strlen(err)) == -1) { /* Nothing to do, Just to avoid the warning... */ } server.stat_rejected_conn++; freeClient(c); return; } // 3. 检查 protect mode 是否开启，如果开启，不允许远程登录 if (server.protected_mode \u0026amp;\u0026amp; server.bindaddr_count == 0 \u0026amp;\u0026amp; server.requirepass == NULL \u0026amp;\u0026amp; !(flags \u0026amp; CLIENT_UNIX_SOCKET) \u0026amp;\u0026amp; ip != NULL) { ... } server.stat_numconnections++; c-\u0026gt;flags |= flags; } client *createClient(int fd) { client *c = zmalloc(sizeof(client)); ... // 1. 标记 fd 为非阻塞 anetNonBlock(NULL, fd); // 2. 设置不开启 Nagle 算法 anetEnableTcpNoDelay(NULL, fd); // 3. 设置 KeepAlive if (server.tcpkeepalive) anetKeepAlive(NULL, fd, server.tcpkeepalive); // 4. 为 fd 创建对应的文件事件监听对应 socket 的读事件，并指定对应事件发生之后的回调函数为 readQueryFromClient if (aeCreateFileEvent(server.el, fd, AE_READABLE, readQueryFromClient, c) == AE_ERR) { close(fd); zfree(c); return NULL; } // 5. 默认使用 0 号 db selectDb(c, 0); uint64_t client_id; // 6. 设置 client 其他默认属性 atomicGetIncr(server.next_client_id, client_id, 1); c-\u0026gt;id = client_id; c-\u0026gt;fd = fd; ... return c; } 在这个方法中，主要做了以下几件事：\n为新连接创建一个 socket，并将这个 socket 添加到 epoll 的监听队列中，注册读事件，并指定对应读事件触发后的回调函数为 readQueryFromClient； 创建一个 client 对象，将 client、socket 等互相绑定，建立联系。 3. 客户端请求到来，执行具体的 handler 在 createClient 中我们知道对应客户端的 socket 上有事件发生时，回调函数是 readQueryFromClient。这个方法主要做一件事：将客户端的请求读取到 client 对象的 querybuf 中。之后再调用 processInputBufferAndReplicate 进一步处理请求。\nvoid readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) { ... // 调用 read 从 socket 中读取客户端请求数据到 client-\u0026gt;querybuf c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); nread = read(fd, c-\u0026gt;querybuf+qblen, readlen); ... // 如果 client-\u0026gt;querybuf 的大小超过 client_max_querybuf_len，直接返回错误，并关闭连接 if (sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClient(c); return; } // 处理客户端请求 processInputBufferAndReplicate(c); } 再来看 processInputBufferAndReplicate 的实现，它其实是 processInputBuffer 的封装，多加了一层判断：如果是普通的 server，则直接调用 processInputBuffer ；如果是主从客户端，还需要将命令同步到自己的从服务器中。\nvoid processInputBufferAndReplicate(client *c) { if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) { processInputBuffer(c); } else { size_t prev_offset = c-\u0026gt;reploff; processInputBuffer(c); size_t applied = c-\u0026gt;reploff - prev_offset; if (applied) { replicationFeedSlavesFromMasterStream(server.slaves, c-\u0026gt;pending_querybuf, applied); sdsrange(c-\u0026gt;pending_querybuf,applied,-1); } } } processInputBuffer 会试着先从缓冲区中解析命令类型，判断类型，之后调用 processCommand 执行：\nvoid processInputBuffer(client *c) { // 设置 server 的当前处理 client 为c，可以理解为获得了 server 这把锁 server.current_client = c; // 不断从 querybuf 中取出数据解析成成对的命令，直到 querybuf 为空 while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { // 进行一些 flags 的判断 ... // 根据命令类型判断是 单条指令 还是 多条指令一起执行 if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); } // 参数个数为 0 时重置客户端，可以接收下一个命令 if (c-\u0026gt;argc == 0) { resetClient(c); } else { // 执行命令 if (processCommand(c) == C_OK) { // 集群信息同步 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MULTI)) { /* Update the applied replication offset of our master. */ c-\u0026gt;reploff = c-\u0026gt;read_reploff - sdslen(c-\u0026gt;querybuf) + c-\u0026gt;qb_pos; } // 如果不是阻塞状态，则重置client，可以接受下一个命令 if (!(c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) || c-\u0026gt;btype != BLOCKED_MODULE) resetClient(c); } // 释放“锁” if (server.current_client == NULL) break; } } // 重置 querybuf if (c-\u0026gt;qb_pos) { sdsrange(c-\u0026gt;querybuf,c-\u0026gt;qb_pos,-1); c-\u0026gt;qb_pos = 0; } server.current_client = NULL; } 我们再来看 processCommand，在真正执行命令之前，会进行非常多的校验，校验通过后才会真正执行对应的命令。\nint processCommand(client *c) { // 1. 如果命令是 quit，则直接退出 if (!strcasecmp(c-\u0026gt;argv[0]-\u0026gt;ptr, \u0026#34;quit\u0026#34;)) { addReply(c, shared.ok); c-\u0026gt;flags |= CLIENT_CLOSE_AFTER_REPLY; return C_ERR; } // 2. 在 command table 寻找对应命令的处理函数， c-\u0026gt;cmd = c-\u0026gt;lastcmd = lookupCommand(c-\u0026gt;argv[0]-\u0026gt;ptr); ... // 3. 用户权限校验 if (server.requirepass \u0026amp;\u0026amp; !c-\u0026gt;authenticated \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand) { flagTransaction(c); addReply(c, shared.noautherr); return C_OK; } // 4. 如果是集群模式，还需要处理集群 node 重定向 if (server.cluster_enabled \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_LUA \u0026amp;\u0026amp; server.lua_caller-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;getkeys_proc == NULL \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;firstkey == 0 \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand)) { ... } // 5. 处理 maxmemory 情形 if (server.maxmemory \u0026amp;\u0026amp; !server.lua_timedout) { ... } // 6. 非 master 或者 磁盘有问题是，不要进行 AOF 等持久化操作 int deny_write_type = writeCommandsDeniedByDiskError(); if (deny_write_type != DISK_ERROR_TYPE_NONE \u0026amp;\u0026amp; server.masterhost == NULL \u0026amp;\u0026amp; (c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE || c-\u0026gt;cmd-\u0026gt;proc == pingCommand)) { flagTransaction(c); if (deny_write_type == DISK_ERROR_TYPE_RDB) addReply(c, shared.bgsaveerr); else addReplySds(c, sdscatprintf(sdsempty(), \u0026#34;-MISCONF Errors writing to the AOF file: %s\\r\\n\u0026#34;, strerror(server.aof_last_write_errno))); return C_OK; } // 7. 当此服务器时master时：如果配置了 repl_min_slaves_to_write，当slave数目小于时，禁止执行写命令 if (server.masterhost == NULL \u0026amp;\u0026amp; server.repl_min_slaves_to_write \u0026amp;\u0026amp; server.repl_min_slaves_max_lag \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE \u0026amp;\u0026amp; server.repl_good_slaves_count \u0026lt; server.repl_min_slaves_to_write) { flagTransaction(c); addReply(c, shared.noreplicaserr); return C_OK; } // 8. 当只读时，除了 master 的命令，不执行任何其他指令 if (server.masterhost \u0026amp;\u0026amp; server.repl_slave_ro \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_WRITE) { addReply(c, shared.roslaveerr); return C_OK; } // 9. 当客户端处于 Pub/Sub 时，只处理部分命令 if (c-\u0026gt;flags \u0026amp; CLIENT_PUBSUB \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != pingCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != subscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != unsubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != psubscribeCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != punsubscribeCommand) { addReplyError(c, \u0026#34;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\u0026#34;); return C_OK; } // 10. 服务器为slave，但是没有连接 master 时，只会执行带有 CMD_STALE 标志的命令，如 info 等 if (server.masterhost \u0026amp;\u0026amp; server.repl_state != REPL_STATE_CONNECTED \u0026amp;\u0026amp; server.repl_serve_stale_data == 0 \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_STALE)) { flagTransaction(c); addReply(c, shared.masterdownerr); return C_OK; } // 11. 正在加载数据库时，只会执行带有 CMD_LOADING 标志的命令，其余都会被拒绝 if (server.loading \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;flags \u0026amp; CMD_LOADING)) { addReply(c, shared.loadingerr); return C_OK; } // 12. 当服务器因为执行lua脚本阻塞时，只会执行部分命令，其余都会拒绝 if (server.lua_timedout \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != authCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != replconfCommand \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == shutdownCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;n\u0026#39;) \u0026amp;\u0026amp; !(c-\u0026gt;cmd-\u0026gt;proc == scriptCommand \u0026amp;\u0026amp; c-\u0026gt;argc == 2 \u0026amp;\u0026amp; tolower(((char *) c-\u0026gt;argv[1]-\u0026gt;ptr)[0]) == \u0026#39;k\u0026#39;)) { flagTransaction(c); addReply(c, shared.slowscripterr); return C_OK; } // 13. 真正执行命令 if (c-\u0026gt;flags \u0026amp; CLIENT_MULTI \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != execCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != discardCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != multiCommand \u0026amp;\u0026amp; c-\u0026gt;cmd-\u0026gt;proc != watchCommand) { // 如果是事务命令，则开启事务，命令进入等待队列 queueMultiCommand(c); addReply(c, shared.queued); } else { // 否则调用 call 直接执行 call(c, CMD_CALL_FULL); c-\u0026gt;woff = server.master_repl_offset; if (listLength(server.ready_keys)) handleClientsBlockedOnKeys(); } return C_OK; } 最后就是 call 函数，这是 Redis 执行命令的核心函数，它会处理通用的执行命令的前置和后续操作：\n如果有监视器 monitor，则需要将命令发送给监视器； 调用 redisCommand 的 proc 方法，执行对应具体的命令逻辑； 如果开启了 CMD_CALL_SLOWLOG，则需要记录慢查询日志； 如果开启了 CMD_CALL_STATS，则需要记录一些统计信息； 如果开启了 CMD_CALL_PROPAGATE，则当 dirty 大于0时，需要调用 propagate 方法来进行命令传播(命令传播就是将命令写入 repl-backlog-buffer 缓冲中，并发送给各个从服务器中。)。 void call(client *c, int flags) { .... start = ustime(); c-\u0026gt;cmd-\u0026gt;proc(c); duration = ustime() - start; .... } 经过上面的过程，命令执行结束，对应的结果已经写在了 client-\u0026gt;buf缓冲区 或者 client-\u0026gt;reply链表中：client-\u0026gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-\u0026gt;reply 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client添加进一个 LIFO 队列 server.clients_pending_write。\n4. 在下一次事件循环之前，将写缓冲区中的数据发送给客户端 这个过程在主事件循环之前的钩子函数 beforeSleep 中，这个函数在 main 中指定，在 aeMain 中执行：\nint main(int argc, char **argv) { ... aeSetBeforeSleepProc(server.el, beforeSleep); aeSetAfterSleepProc(server.el, afterSleep); aeMain(server.el); // 启动单线程网络模型 .... } void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; // 这是一个死循环，一直到 redis-server 停止 while (!eventLoop-\u0026gt;stop) { if (eventLoop-\u0026gt;beforesleep != NULL) eventLoop-\u0026gt;beforesleep(eventLoop); aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP); // 处理三个事件：time file call_after_sleep } } 再具体的实现中，我们只关注如何将写缓冲区的数据写回给客户端：\nvoid beforeSleep(struct aeEventLoop *eventLoop) { ... /* Handle writes with pending output buffers. */ handleClientsWithPendingWrites(); .... } int handleClientsWithPendingWrites(void) { listIter li; listNode *ln; int processed = listLength(server.clients_pending_write); // clients_pending_write 是一个 client 队列，listRewind 获取一个用于迭代的游标 listRewind(server.clients_pending_write,\u0026amp;li); // 当队列不为空时，持续进行下面的逻辑处理 while((ln = listNext(\u0026amp;li))) { client *c = listNodeValue(ln); c-\u0026gt;flags \u0026amp;= ~CLIENT_PENDING_WRITE; // 将遍历过 client 从队列中删除 listDelNode(server.clients_pending_write,ln); /* If a client is protected, don\u0026#39;t do anything, * that may trigger write error or recreate handler. */ if (c-\u0026gt;flags \u0026amp; CLIENT_PROTECTED) continue; // 将 client 的数据写回 client 对应的s ocket if (writeToClient(c-\u0026gt;fd,c,0) == C_ERR) continue; // 这次一次性没发完，那就给对应 socket 创建额外的写事件 if (clientHasPendingReplies(c)) { int ae_flags = AE_WRITABLE; /* For the fsync=always policy, we want that a given FD is never * served for reading and writing in the same event loop iteration, * so that in the middle of receiving the query, and serving it * to the client, we\u0026#39;ll call beforeSleep() that will do the * actual fsync of AOF to disk. AE_BARRIER ensures that. */ if (server.aof_state == AOF_ON \u0026amp;\u0026amp; server.aof_fsync == AOF_FSYNC_ALWAYS) { ae_flags |= AE_BARRIER; } if (aeCreateFileEvent(server.el, c-\u0026gt;fd, ae_flags, sendReplyToClient, c) == AE_ERR) { freeClientAsync(c); } } } return processed; } 对 client-\u0026gt;buf 和 client-\u0026gt;reply 的处理在 writeToClient 方法中：\n/* Write data in output buffers to client. Return C_OK if the client * is still valid after the call, C_ERR if it was freed. */ int writeToClient(int fd, client *c, int handler_installed) { ssize_t nwritten = 0, totwritten = 0; size_t objlen; clientReplyBlock *o; while(clientHasPendingReplies(c)) { // 优先处理 buf，先发送一批。在执行之前会判断如果 client-\u0026gt;buf 中有数据，则发送 client-\u0026gt;buf 中的 if (c-\u0026gt;bufpos \u0026gt; 0) { nwritten = write(fd,c-\u0026gt;buf+c-\u0026gt;sentlen,c-\u0026gt;bufpos-c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If the buffer was sent, set bufpos to zero to continue with * the remainder of the reply. */ if ((int)c-\u0026gt;sentlen == c-\u0026gt;bufpos) { c-\u0026gt;bufpos = 0; c-\u0026gt;sentlen = 0; } } else { // client-\u0026gt;buf 中没数据了，则处理 client-\u0026gt;reply 链表中剩下的 o = listNodeValue(listFirst(c-\u0026gt;reply)); objlen = o-\u0026gt;used; if (objlen == 0) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); continue; } nwritten = write(fd, o-\u0026gt;buf + c-\u0026gt;sentlen, objlen - c-\u0026gt;sentlen); if (nwritten \u0026lt;= 0) break; c-\u0026gt;sentlen += nwritten; totwritten += nwritten; /* If we fully sent the object on head go to the next one */ if (c-\u0026gt;sentlen == objlen) { c-\u0026gt;reply_bytes -= o-\u0026gt;size; listDelNode(c-\u0026gt;reply,listFirst(c-\u0026gt;reply)); c-\u0026gt;sentlen = 0; /* If there are no longer objects in the list, we expect * the count of reply bytes to be exactly zero. */ if (listLength(c-\u0026gt;reply) == 0) serverAssert(c-\u0026gt;reply_bytes == 0); } } if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } server.stat_net_output_bytes += totwritten; if (nwritten == -1) { if (errno == EAGAIN) { nwritten = 0; } else { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, strerror(errno)); freeClient(c); return C_ERR; } } if (totwritten \u0026gt; 0) { /* For clients representing masters we don\u0026#39;t count sending data * as an interaction, since we always send REPLCONF ACK commands * that take some time to just fill the socket output buffer. * We just rely on data / pings received for timeout detection. */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } // 数据全部发送完毕了，那么前一步因为没发完而创建的文件监听事件可以从 EventLoop 中删除了 if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; if (handler_installed) aeDeleteFileEvent(server.el,c-\u0026gt;fd,AE_WRITABLE); /* Close connection after entire reply has been sent. */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClient(c); return C_ERR; } } return C_OK; } ","permalink":"http://localhost:1313/posts/redis%E4%B8%80-redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e在关注 \u003cstrong\u003eredis 单线程/多线程\u003c/strong\u003e 时，有几个重要的时间节点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBefore \u003ccode\u003eRedis v4.0\u003c/code\u003e，真正的单线程；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v4.0\u003c/code\u003e，引入多线程处理 \u003ccode\u003eAOF\u003c/code\u003e 等任务，但\u003cstrong\u003e核心的网络模型中依旧使用单线程\u003c/strong\u003e；\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eRedis v6.0\u003c/code\u003e，正式在网络模型中实现 \u003ccode\u003eI/O多线程\u003c/code\u003e。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e从 \u003ccode\u003eRedis v1.0\u003c/code\u003e 到 \u003ccode\u003eRedis v6.0以前\u003c/code\u003e，Redis 的核心网络模型一直都是一个典型的 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e，所有的事件都在这个线程内处理完成。本 issue 旨在解释清楚这个 \u003cstrong\u003e单Reactor模型\u003c/strong\u003e 的所有运作细节，为以后更好地理解新的 \u003cstrong\u003eMulti-Reactors/Master-Workers\u003c/strong\u003e 模型做准备。\u003c/p\u003e","title":"Redis系列(一): Redis 单线程事件循环"},{"content":"题目描述 使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\n1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z 思路 使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\n代码参考 func printEach() { letter, number := make(chan bool), make(chan bool) wait := sync.WaitGroup{} go func() { i := 1 for { select { case \u0026lt;-number: fmt.Print(i) i++ letter \u0026lt;- true } } }() wait.Add(1) go func(wait *sync.WaitGroup) { str := \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34; i := 0 for { select { case \u0026lt;-letter: if i \u0026gt;= len(str) { wait.Done() return } fmt.Print(str[i : i+1]) i++ if i \u0026gt;= len(str) { wait.Done() return } number \u0026lt;- true } } }(\u0026amp;wait) // 让数字先开始打印 number \u0026lt;- true // 等待循环结束，表示整个打印可以结束了 wait.Wait() // 最后关闭 channel，防止内存泄露 close(letter) close(number) } 代码解释：\nletter 用于通知打印字母，number 用于通知打印数字。\nsync.Waitgroup{} 用于阻塞主线程等待整个打印过程结束。\n倒数第 4 行中的 number \u0026lt;- true 表示让数字先开始打印。\n结束后记得关闭 channel，防止内存泄露\n扩展 有三个函数，分别可以打印 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo;，要求每个函数都起一个 goroutine，并按照 \u0026ldquo;cat\u0026rdquo; \u0026ldquo;dog\u0026rdquo; \u0026ldquo;fish\u0026rdquo; 的顺序打印在屏幕上，5 次。\nfunc printCatDogFish(){ cat, dog, fish := make(chan struct{}), make(chan struct{}), make(chan struct{}) wg := \u0026amp;sync.WaitGroup{} target := 100 go func() { // cat for { select { case \u0026lt;-cat: fmt.Println(\u0026#34;cat\u0026#34;) dog \u0026lt;- struct{}{} } } }() go func() { // dog for { select { case \u0026lt;-dog: fmt.Println(\u0026#34;dog\u0026#34;) fish \u0026lt;- struct{}{} } } }() wg.Add(1) go func(w *sync.WaitGroup) { // fish defer w.Done() i := 0 for { select { case \u0026lt;-fish: fmt.Println(\u0026#34;fish\u0026#34;) i++ if i \u0026gt;= target { return } cat \u0026lt;- struct{}{} } } }(wg) cat \u0026lt;- struct{}{} wg.Wait() close(cat) close(dog) close(fish) } ","permalink":"http://localhost:1313/posts/%E9%9D%A2%E8%AF%95%E9%A2%98%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003ch3 id=\"题目描述\"\u003e题目描述\u003c/h3\u003e\n\u003cp\u003e使用两个 goroutine 交替打印序列，一个 goroutine 打印数字， 另外一个 goroutine 打印字母， 最终效果如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e1A2B3C4D5E6F7G8H9I10J11K12L13M14N15O16P17Q18R19S20T21U22V23W24X25Y26Z\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"思路\"\u003e思路\u003c/h3\u003e\n\u003cp\u003e使用 channel 来控制打印的进度。使用两个 channel，来分别控制数字和字母的打印进度，数字打印完通过 channel 通知数字打印，数字打印完通过 channel 通知字母打印。如此周而复始，直到终止条件。\u003c/p\u003e","title":"面试题:交替打印数字和字符串"},{"content":" 本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\n一、介绍 当我们谈论加解密方式时，通常有两种情形：对称加密 和 非对称加密。\n对于 对称加密，加密和解密使用同一份秘钥，加密者必须将加密方式告知使用者，否则使用者无法解密，这就面临着 “秘钥配送问题”。\n而在 非对称加密 中，有公钥和私钥加密使用公钥，解密使用私钥；公钥是公开的，任何人都可以获得，私钥则是保密的。只有持有私钥的人才能解开被对应公钥加密的数据。因此非对称加密算法，也称公钥加密算法。\n如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。\n1977 年，三位数学家 Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做 RSA算法。从那时直到现在，RSA 算法一直是最广为使用的\u0026quot;非对称加密算法\u0026quot;。毫不夸张地说，只要有计算机网络的地方，就有 RSA 算法。\n这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA 密钥是 768 个二进制位。也就是说，长度超过 768 位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024 位的 RSA 密钥 基本安全，2048 位的密钥极其安全。\n二、使用 Golang 的标准库中已经对 RSA 相关的加密算法进行了实现，这里展示基本用法 以及 使用自定义密码 的场景。\n对 RSA 的使用大致分为三个步骤：\nRSAGenKey 生成公钥和私钥； RSAEncrypt 加密数据，传入 待加密数据 和 公钥，返回 加密后的数据； RSADecrypt 解密数据，传入 被加密的数据 和 私钥，返回 解密后的数据。 1. RSA 加密的基本用法 // RSAGenKey 生成公私钥 func RSAGenKey(bits int) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥（bits=1024基本安全，2048 极其安全） privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 4、通过pem将设置的数据进行编码，并写入磁盘文件 // fPrivate, err := os.Create(\u0026#34;privateKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPrivate.Close() // err = pem.Encode(fPrivate, block1) // if err != nil { // return err // } // 4. 有两种方式，一种是将秘钥写入文件，一种是当成返回值返回，由使用者自行决定 prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } // fPublic, err := os.Create(\u0026#34;publicKey.pem\u0026#34;) // if err != nil { // return err // } // defer fPublic.Close() // pem.Encode(fPublic, \u0026amp;block2) // 同样，可以将公钥写入文件，也可以直接返回 pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // RSAEncrypt 对数据进行加密操作 func RSAEncrypt(src []byte, pubKey []byte) (res []byte, err error) { block, _ := pem.Decode(pubKey) // 使用X509将解码之后的数据 解析出来 keyInit, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return } publicKey := keyInit.(*rsa.PublicKey) // 使用公钥加密数据 res, err = rsa.EncryptPKCS1v15(rand.Reader, publicKey, src) return } // 对数据进行解密操作 func RSADecrypt(src []byte, prvKey []byte) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo:\nfunc main() { sourceData := \u0026#34;我的头发长，天下我为王\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKey(2048) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecrypt(encryptData, prvKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 我的头发长，天下我为王 after encrypt: [153 1 185 195 ...(很长的字节数组)] after decrypt: 我的头发长，天下我为王 equal? true 2. 使用自定义密码的 RSA 算法 有时候我们想在随机生成的基础上加上自定义的密码，可以使用下面的方式：\n// RSAGenKeyWithPwd generate rsa pair key with specified password func RSAGenKeyWithPwd(bits int, pwd string) (pubKey, prvKey []byte, err error) { /* 生成私钥 */ // 1、使用RSA中的GenerateKey方法生成私钥 privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return nil, nil, err } // 2、通过X509标准将得到的RAS私钥序列化为：ASN.1 的DER编码字符串 privateStream := x509.MarshalPKCS1PrivateKey(privateKey) // 3、将私钥字符串设置到pem格式块中 block1 := \u0026amp;pem.Block{ Type: \u0026#34;private key\u0026#34;, Bytes: privateStream, } // 通过自定义密码加密 if pwd != \u0026#34;\u0026#34; { block1, err = x509.EncryptPEMBlock(rand.Reader, block1.Type, block1.Bytes, []byte(pwd), x509.PEMCipherAES256) if err != nil { return nil, nil, err } } prvKey = pem.EncodeToMemory(block1) /* 生成公钥 */ publicKey := privateKey.PublicKey publicStream, err := x509.MarshalPKIXPublicKey(\u0026amp;publicKey) block2 := \u0026amp;pem.Block{ Type: \u0026#34;public key\u0026#34;, Bytes: publicStream, } pubKey = pem.EncodeToMemory(block2) return pubKey, prvKey, nil } // 加密方式与 RSAEncrypt 没有区别，可以共用 // RSADecryptWithPwd decrypt src with private key and password func RSADecryptWithPwd(src []byte, prvKey []byte, pwd string) (res []byte, err error) { // 解码 block, _ := pem.Decode(prvKey) blockBytes := block.Bytes if pwd != \u0026#34;\u0026#34; { blockBytes, err = x509.DecryptPEMBlock(block, []byte(pwd)) if err != nil { return nil, err } } privateKey, err := x509.ParsePKCS1PrivateKey(blockBytes) // 还原数据 res, err = rsa.DecryptPKCS1v15(rand.Reader, privateKey, src) return } 看一个 demo：\nfunc main() { sourceData := \u0026#34;好的代码本身就是最好的说明文档\u0026#34; pwd := \u0026#34;123456\u0026#34; // 创建公私钥 pubKey, prvKey, err := RSAGenKeyWithPwd(2048, pwd) if err != nil { panic(err) } fmt.Println(\u0026#34;gen pubKey and prvKey ok!\u0026#34;) fmt.Printf(\u0026#34;before encrypt: %s\\n\u0026#34;, sourceData) // 使用公钥加密 encryptData, err := RSAEncrypt([]byte(sourceData), pubKey) if err != nil { panic(err) } fmt.Printf(\u0026#34;after encrypt: %v\\n\u0026#34;, encryptData) // 使用私钥解密 decryptData, err := RSADecryptWithPwd(encryptData, prvKey, pwd) if err != nil { panic(err) } fmt.Printf(\u0026#34;after decrypt: %s\\n\u0026#34;, string(decryptData)) fmt.Printf(\u0026#34;equal? %v \\n\u0026#34;, string(decryptData) == sourceData) } // 输出 gen pubKey and prvKey ok! before encrypt: 好的代码本身就是最好的说明文档 after encrypt: [136 134 26 233 ...(很长的字节数组)] after decrypt: 好的代码本身就是最好的说明文档 equal? true 参考文章： golang 使用 RSA 生成公私钥，加密，解密，并使用 SHA256 进行签名，验证 GO 语言 RSA 加密解密 go - 如何在 golang 中使用密码创建 rsa 私钥 RSA 算法原理（一） ","permalink":"http://localhost:1313/posts/golang%E4%B8%AD%E4%BD%BF%E7%94%A8rsa%E8%BF%9B%E8%A1%8C%E5%8A%A0%E8%A7%A3%E5%AF%86/","summary":"\u003c!-- @format --\u003e\n\u003cp\u003e本文对 RSA 加密算法 的细节不做深究，仅描述大致用法。具体算法原理请阅读参考文献中的 2 和 4。\u003c/p\u003e\n\u003ch2 id=\"一介绍\"\u003e一、介绍\u003c/h2\u003e\n\u003cp\u003e当我们谈论加解密方式时，通常有两种情形：\u003cstrong\u003e对称加密\u003c/strong\u003e 和 \u003cstrong\u003e非对称加密\u003c/strong\u003e。\u003c/p\u003e","title":"Golang中使用RSA进行加解密"},{"content":"介绍 boltdb 是一个使用 Go 编写的键值对数据库，它的目标是 简单、快速和稳定的轻型数据库，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\n使用 1. 安装 go get github.com/boltdb/bolt/... 2. 打开(Open)一个数据库文件连接 func main() { dbPath := \u0026#34;./data.db\u0026#34; // 指定你的数据库文件要存储的地方 db, err := bolt.Open(dbPath, os.ModePerm, nil) if err != nil { panic(err) } ... } bolt 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 Open 操作添加超时：\ndb, err := bolt.Open(dbPath, os.ModePerm, \u0026amp;bolt.Options{Timeout: time.Second * 5}) 运行如上代码，如果 5 秒内未能成功打开文件，会返回一个 timeout 错误。\n3. 事务(Transaction) 在某一时刻， bolt 只允许有一个读写事务 或者 允许多个只读事务。其事务的隔离级别对应 MySQL 中的 可重复读，即每一个事务在 commit 之前，多次读库多看到的信息视图是一致的。\n3.1 读写事务(Read-write Transactions) 启动一个 读写事务，可以通过下面的方式：\nerr := db.Update(func(tx *bolt.Tx) error { ... return nil }) if err != nil { log.Fatal(err) } 或者：\n// open a Read-write transaction with the first argument `true` tx,err := db.Begin(true) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } Update 中的函数就是一个 可重复读 的事务，在这个函数里面可以进行任何的数据库操作。最后需要通过 return nil 来提交修改；如果提交一个 error，那么整个修改会进行 Rollback，回到最初的状态，不会产生任何改变。注意，在 Update 中手动进行 Rollback，会造成 panic。\n3.2 只读事务(Read-only Transactions) 通过下面的方式打开一个只读事务：\nerr := db.View(func(tx *bolt.Tx) error { ... return nil }) 或者：\n// open a Read-only transaction with the first argument `false` tx,err := db.Begin(false) if err != nil { log.Fatal(err) } defer tx.Rollback() // do something ... // commit the transaction if err := tx.Commit();err != nil { log.Fatal(err) } 需要注意的是，在 View 只读事务中，无法做一些“写入”操作，能做的可以是：读一个 bucket，读对应 bucket 中的值，或者复制整个 db。注意，在 View 中手动进行 Rollback，会造成 panic。\n3.3 批量读写事务(Batch read-write transactions) 通过以下方式使用 Batch：\nerr := db.Batch(func(tx *bolt.Tx) error { b := tx.Bucket(bucketName) for i := 0; i \u0026lt; 100; i++ { if err := b.Put([]byte(fmt.Sprintf(\u0026#34;name-%d\u0026#34;, i+1)), []byte(fmt.Sprintf(\u0026#34;%d\u0026#34;, rand.Int31n(math.MaxInt32)))); err != nil { return err } } return nil }) Batch 和 Update 相似，以下情形除外：\nBatch 中的操作可以被合并成一个 transaction； 传给 Batch 的函数可能被执行多次，不管返回的 error 是否为 nil 这也就意味着，Batch 里面的操作必须是幂等的，这似乎会带来一些额外的工作，因此之建议在 多个 goroutine 同时调用的时候使用。\n创建一个 DB 对象是线程安全的，但一个事务里面的操作并不是线程安全的。另外，读写事务 和 只读事务 不应该相互依赖，或者不应该同时在同一个 goroutine 中被长时间打开，因为 读写事务 需要周期性地 re-map 数据，但是当 只读事务 打开时，这个操作会造成死锁。\n4. bolt 的读与写 首先，不管是读还是写，都需要先指定一个 bucket，这个概念类似于关系型数据库中的 table。对于 bucket 的操作，有以下几种：\nCreateBucket 创建一个 bucket ，但当 bucket 已经存在时，会返回错误 bucket already exists；如果成功，会返回一个 Bucket对象： bucketName := \u0026#34;my-bucket\u0026#34; _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，当 bucket 已经存在时，会返回错误 b, err := tx.CreateBucket([]byte(bucketName)) if err != nil { return err } // ... do some thing return nil }) CreateBucketIfNotExists 创建一个 bucket，创建成功 或 bucket已经存在时，返回 Bucket 对象： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // ... return nil }) Bucket 选择一个已经存在的 bucket，bucket 不存在时不会报错，但返回的 Bucket 对象为 nil，后续所有对 b 的操作都会造成空指针错误： _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式选择一个已经存在的 bucket b, err := tx.Bucket([]byte(bucketName)) if err != nil { return err } fmt.Println(b == nil) // 如果 bucket 不存在，则 b 为 nil，后面所有对 b 的操作都会造成空指针错误 return nil }) DeleteBucket 删除一个已经存在的 bucket，如果 bucket 不存在会返回 bucket not found 错误。 _ = db.Update(func(tx *bolt.Tx) error { // 通过此方式删除一个已经存在的 bucket，如果 bucket 不存在会返回 `bucket not found` 错误 err := tx.DeleteBucket([]byte(bucketName)) if err != nil { return err } return nil }) 4.1 写 或 修改 只有一种方式：使用 Put(k,v []byte) 方法。\n_ = db.Update(func (tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } // set name = Jemmy err = b.Put([]byte(\u0026#34;name\u0026#34;),[]byte(\u0026#34;Jemmy\u0026#34;)) if err != nil { return err } }) Value 不一定是一个字符串，你可以存储整个序列化后的对象：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket111\u0026#34; err = db.Update(func(tx *bolt.Tx) error { // 通过此方式创建一个 bucket，不过 bucket 已经存在时不会返回错误 b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } u := \u0026amp;User{ ID: 1, Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) err = b.Put([]byte(key), data) if err != nil { return err } fmt.Printf(\u0026#34;%s\\n\u0026#34;, b.Get([]byte(key))) return nil }) if err != nil { log.Fatal(err) } } 输出：\n{\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 比较有用的一个技巧：可以使用 NextSequence() 得到一个递增的 unique identifier，你可以把它理解成 MySQL 中的递增主键：\nfunc main() { db, err := bolt.Open(\u0026#34;./data.db\u0026#34;, os.ModePerm, nil) if err != nil { panic(err) } type User struct { ID uint64 Name string Age int } bucketName := \u0026#34;my-bucket222\u0026#34; err = db.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(bucketName)) if err != nil { return err } for i:=0;i\u0026lt;5;i++ { u := \u0026amp;User{ Name: \u0026#34;Jemmy\u0026#34;, Age: 18, } // 获取一个主键值。只有当 Tx被关闭 或者 b不可写 时，才会返回错误。在 Update() 函数中不可能发生 id, err := b.NextSequence() if err != nil { return err } u.ID = id // 将 user 序列化成 []byte data, err := json.Marshal(u) if err != nil { return err } key := fmt.Sprintf(\u0026#34;%d\u0026#34;, u.ID) // 使用 Put 保存 err = b.Put([]byte(key), data) if err != nil { return err } } return nil }) if err != nil { log.Fatal(err) } _ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) } 输出：\nkey=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 4.2 读取 正如上面代码所示，你可以使用 func (b *Bucket) Get(key []byte) []byte 。下面介绍一些更高阶的用法：\n遍历整个 bucket: bolt 通过 byte-sorted 的顺序在 bucket 中存储键值对，这个设计使得对 key 的迭代遍历非常方便也非常快：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 使用 游标 cursor 可以非常方便地移动，类似的函数还有：\nFirst() Move to the first key. Last() Move to the last key. Seek() Move to a specific key. Next() Move to the next key. Prev() Move to the previous key. 所以你可以使用下面的方式进行倒序遍历：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) c := b.Cursor() for k, v := c.Last(); k != nil; k, v = c.Prev() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 当然，如果你明确知道你要遍历整个 bucket，并且是正序输出，也可以通过 ForEach：\n_ = db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(bucketName)) err := b.ForEach(func(k, v []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) return nil }) if err != nil { return err } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=4, value={\u0026#34;ID\u0026#34;:4,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=5, value={\u0026#34;ID\u0026#34;:5,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 前缀匹配搜索，可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() prefix := []byte(\u0026#34;1\u0026#34;) for k, v := c.Seek(prefix); k != nil \u0026amp;\u0026amp; bytes.HasPrefix(k, prefix); k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} 范围搜索，也可以使用 Seek() 函数： _ = db.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(bucketName)).Cursor() min := []byte(\u0026#34;1\u0026#34;) max := []byte(\u0026#34;3\u0026#34;) for k, v := c.Seek(min); k != nil \u0026amp;\u0026amp; bytes.Compare(k, max) \u0026lt;= 0; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) // 输出 key=1, value={\u0026#34;ID\u0026#34;:1,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=2, value={\u0026#34;ID\u0026#34;:2,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} key=3, value={\u0026#34;ID\u0026#34;:3,\u0026#34;Name\u0026#34;:\u0026#34;Jemmy\u0026#34;,\u0026#34;Age\u0026#34;:18} ","permalink":"http://localhost:1313/posts/boltdb%E4%BD%BF%E7%94%A8%E4%B8%80%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","summary":"\u003ch2 id=\"介绍\"\u003e介绍\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/boltdb/bolt\"\u003eboltdb\u003c/a\u003e 是一个使用 Go 编写的键值对数据库，它的目标是 \u003cstrong\u003e简单、快速和稳定的轻型数据库\u003c/strong\u003e，适用于那些不需要使用像 MySQL 一样的完整的数据库系统的项目。\u003c/p\u003e\n\u003ch2 id=\"使用\"\u003e使用\u003c/h2\u003e\n\u003ch3 id=\"1-安装\"\u003e1. 安装\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ego get github.com/boltdb/bolt/...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-打开open一个数据库文件连接\"\u003e2. 打开(Open)一个数据库文件连接\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;./data.db\u0026#34;\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 指定你的数据库文件要存储的地方\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003edb\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebolt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eOpen\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003edbPath\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eos\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eModePerm\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\tpanic(\u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003ebolt\u003c/code\u003e 打开一个文件之后，会一直获得此文件的锁，在这期间，其他的进程无法再次打开此文件，直到最开始的进程释放锁。打开一个已经打开的 bolt文件 会导致当前进程无限制地等待下去，直到另一个已经打开的进程结束这个文件的使\u0026gt; 用。为了避免这种无限制的等待，可以给 \u003ccode\u003eOpen\u003c/code\u003e 操作添加超时：\u003c/p\u003e","title":"Boltdb使用(一)基本用法"},{"content":" 实验机器：MacBook Pro (Retina, 15-inch, Mid 2015)\nGolang 版本：go version go1.14.6 darwin/amd64\n一、前言 网卡 也称 网络适配器，是电脑与局域网进行相互连接的设备，在 OSI 七层模型中，工作在 物理层 和 数据链路层，其作用可以简单描述为：\n将本机的数据封装成帧，通过网线发送到网络上去； 接收网络上其他设别传过来的帧，将其重新组合成数据，向上层传输到本机的应用程序中。 这里的网卡指的是真实的网卡，是一个真实的物理设备。今天我们要了解的是一个叫 虚拟网卡 的东西。\n在当前的云计算时代，虚拟机和容器的盛行离不开网络管理设备，即 虚拟网络设备，或者说是 虚拟网卡。虚拟网卡有以下好处：\n对用户来说，虚拟网卡和真实网卡几乎没有区别。我们对虚拟网卡的操作不会影响到真实的网卡，不会影响到本机网络； 虚拟网卡的数据可以直接从用户态读取和写入，这样方便我们在用户态进行一些额外的操作(比如截包、修改后再发送出去) Linux 系统中有众多的虚拟网络设备，如 TUN/TAP 设备、VETH 设备、Bridge 设备、Bond 设备、VLAN 设备、MACVTAP 设备 等。这里我们只关注 TUN/TAP 设备。\ntap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。\n二、理解 tun/tap 数据传输过程 TUN 设备是一种虚拟网络设备，通过此设备，程序可以方便地模拟网络行为。TUN 模拟的是一个三层设备(OSI 模型的第三层：网络层，即IP 层),也就是说，通过它可以处理来自网络层的数据，更通俗一点的说，通过它，通过它我们可以处理 IP 数据包。\n先看一下正常情况下的物理设备是如何工作的：\n这里的 ethx 表示的就是一台主机的真实的网卡接口，一般一台主机只会有一块网卡，像一些特殊的设备，比如路由器，有多少个口就有多少块网卡。\n我们先看一下 ifconfig 命令的输出：\n$ ifconfig ... en0: flags=8863\u0026lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST\u0026gt; mtu 1500 options=400\u0026lt;CHANNEL_IO\u0026gt; ether ac:bc:32:96:86:01 inet6 fe80::456:7cb8:3dc5:2722%en0 prefixlen 64 secured scopeid 0x4 inet 10.0.0.176 netmask 0xffffff00 broadcast 10.0.0.255 nd6 options=201\u0026lt;PERFORMNUD,DAD\u0026gt; media: autoselect status: active ... 可以看到 etho 这个网卡接口分配到的 IP 地址是 10.0.0.176，这是一块物理网卡，它的两端分别是 内核协议栈 和 外面的网络，从物理层收到的数据，会被转发给内核进而通过某种接口被应用层的用户程序读到；应用程序要想和网络中的另一个进程进行数据通信，会先将数据发送给内核，然后被网卡发送出去。\n接下来我们看一看 tun/tap 设备的工作方式：\n上图中应用层有两个应用程序，而 网络协议栈 和 网络设备(eth0 和 tun0) 都位于内核层，对于 socket，可以这么理解：socket 就像是一组 接口(interface)，它将更复杂的 TCP/IP 协议簇隐藏在 socket 接口后面，只对用户暴露更简单的接口，就像操作系统隐藏了底层的硬件操作细节而只对用户程序暴露接口一样，它是 应用层 与 TCP/IP协议簇 通信的中间软件抽象层。\ntun0 就是一个 tun/tap 虚拟设备，从上图中就可以看出它和物理设备 eth0 的区别：虽然它们的一端都是连着网络协议栈，但是 eth0 另一端连接的是物理网络，而 tun0 另一端连接的是一个 应用层程序，这样协议栈发送给 tun0 的数据包就可以被这个应用程序读取到，此时这个应用程序可以对数据包进行一些自定义的修改(比如封装成 UDP)，然后又通过网络协议栈发送出去——这就是目前大多数 代理 的工作原理。\n假如 eth0 的 IP 地址是 10.0.0.176，而 tun0 配的 IP 为 192.168.1.2。上图是一个典型的使用 tun/tap 进行 VPN 工作的原理，发送给 192.168.1.0/24 的数据通过 应用程序 B 这个 隧道 处理(隐藏一些信息)之后，利用真实的物理设备 10.0.0.176 转发给目的地址(假如为 49.233.198.76)，从而实现 VPN。我们看下每一个流程：\nApplication A 是一个普通的应用程序，通过 Socket A 发送了一个数据包，这个数据包的目的地址是 192.168.1.2； Socket A 将这个数据包丢给网络协议栈； 协议栈根据数据包的目的地址，匹配本地路由规则，得知这个数据包应该由 tun0 出去，于是将数据包丢给了 tun0； tun0 收到数据包之后，发现另一端被 Application B 打开，于是又将数据包丢给了 Application B； Application B 收到数据包之后，解包，做一些特殊的处理，然后构造一个新的数据包，将原来的数据嵌入新的数据包中，最后通过 Socket B 将数据包转发出去，这个时候新数据包的源地址就变成了 eth0 的地址，而目的地址就变成了真正想发送的主机的地址，比如 49.233.198.76； Socket B 将这个数据包丢给网络协议栈； 协议栈根据本地路由得知，这个数据包应该从 eth0 发送出去，于是将数据包丢给 eth0； eth0 通过物理网络将这个数据包发送出去 简单来说，tun/tap 设备的用处是将协议栈中的部分数据包转发给用户空间的特殊应用程序，给用户空间的程序一个处理数据包的机会，比较常用的场景是 数据压缩、加密等，比如 VPN。\n三、使用 Golang 实现一个简易 VPN 先看客户端的实现：\npackage main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; \u0026#34;github.com/songgao/water\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; ) /* * @CreateTime: 2020/11/16 11:08 * @Author: hujiaming * @Description: 数据传输过程： 用户数据，如ping --\u0026gt; 协议栈conn --\u0026gt; IfaceWrite --\u0026gt; IfaceRead --\u0026gt; 协议栈conn --\u0026gt; 网线 */ var ( serviceAddress = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;10.0.0.245:9621\u0026#34;, \u0026#34;service address\u0026#34;) tunName = flag.String(\u0026#34;dev\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;local tun device name\u0026#34;) ) func main() { flag.Parse() // create tun/tap interface iface, err := water.New(water.Config{ DeviceType: water.TUN, PlatformSpecificParams: water.PlatformSpecificParams{ Name: *tunName, }, }) if err != nil { color.Red(\u0026#34;create tun device failed,error: %v\u0026#34;, err) return } // connect to server conn, err := net.Dial(\u0026#34;tcp\u0026#34;, *serviceAddress) if err != nil { color.Red(\u0026#34;connect to server failed,error: %v\u0026#34;, err) return } // go IfaceRead(iface, conn) go IfaceWrite(iface, conn) sig := make(chan os.Signal, 3) signal.Notify(sig, syscall.SIGINT, syscall.SIGABRT, syscall.SIGHUP) \u0026lt;-sig } /* IfaceRead 从 tun 设备读取数据 */ func IfaceRead(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 在这里你可以对拿到的数据包做一些数据，比如加密。这里只对其进行简单的打印 color.Cyan(\u0026#34;get data from tun: %v\u0026#34;, packet[:n]) // 通过物理连接，将处理后的数据包发送给目的服务器 err = forwardServer(conn, packet[:n]) if err != nil { color.Red(\u0026#34;forward to server failed\u0026#34;) } } } /* IfaceWrite 从物理连接中读取数据，然后通过 tun 将数据发送给 IfaceRead */ func IfaceWrite(iface *water.Interface, conn net.Conn) { packet := make([]byte, 2048) for { // 从物理请求中读取数据 nr, err := conn.Read(packet) if err != nil { color.Red(\u0026#34;WRITE: read from tun failed\u0026#34;) break } // 将处理后的数据通过 tun 发送给 IfaceRead _, err = iface.Write(packet[4:nr]) if err != nil { color.Red(\u0026#34;WRITE: write to tun failed\u0026#34;) } } } // forwardServer 通过物理连接发送一个包 func forwardServer(conn net.Conn, buff []byte) (err error) { output := make([]byte, 0) bsize := make([]byte, 4) binary.BigEndian.PutUint32(bsize, uint32(len(buff))) output = append(output, bsize...) output = append(output, buff...) left := len(output) for left \u0026gt; 0 { nw, er := conn.Write(output) if er != nil { err = er } left -= nw } return err } 再看服务端的实现：\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;net\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; ) /* * @CreateTime: 2020/11/16 11:39 * @Author: hujiaming * @Description: */ var clients = make([]net.Conn, 0) func main() { listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:9621\u0026#34;) if err != nil { color.Red(\u0026#34;listen failed,error: %v\u0026#34;, err) return } color.Cyan(\u0026#34;server start...\u0026#34;) for { // 对客户端的每一个连接，都起一个 go 协程去处理 conn, err := listener.Accept() if err != nil { color.Red(\u0026#34;tcp accept failed,error: %v\u0026#34;, err) break } clients = append(clients, conn) color.Cyan(\u0026#34;accept tun client\u0026#34;) go handleClient(conn) } } func handleClient(conn net.Conn) { defer conn.Close() buff := make([]byte, 65536) for { n, err := conn.Read(buff) if err != nil { if err != io.EOF { color.Red(\u0026#34;read from client failed\u0026#34;) } break } // broadcast data to all clients for _, c := range clients { if c.RemoteAddr().String() != conn.RemoteAddr().String() { c.Write(buff[:n]) } } } } 在这里，我们把 网络协议栈 抽象成了一个黑盒。在接下来的步骤中，我们将逐渐抽丝剥茧，一步步了解网络协议栈的工作原理，以及用 Golang 去实现它。\n四、参考 原创 详解云计算网络底层技术——虚拟网络设备 tap/tun 原理解析 TUN/TAP概述及操作 TUN/TAP设备浅析 https://github.com/ICKelin/article/issues/9 ","permalink":"http://localhost:1313/posts/%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87tuntap/","summary":"\u003cblockquote\u003e\n\u003cp\u003e实验机器：\u003ccode\u003eMacBook Pro (Retina, 15-inch, Mid 2015)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eGolang 版本：\u003ccode\u003ego version go1.14.6 darwin/amd64\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e网卡\u003c/strong\u003e 也称 \u003cstrong\u003e网络适配器\u003c/strong\u003e，是电脑与局域网进行相互连接的设备，在 \u003ccode\u003eOSI\u003c/code\u003e 七层模型中，工作在 \u003cstrong\u003e物理层\u003c/strong\u003e 和 \u003cstrong\u003e数据链路层\u003c/strong\u003e，其作用可以简单描述为：\u003c/p\u003e","title":"虚拟网络设备tuntap"},{"content":"一、前言 公司后端服务已经全部微服务化，想要调试某个服务可以使用 grpcui，但要对某个接口进行压测，grpcui 还做不到。诸多努力之后找到本次主角：https://github.com/bojand/ghz，官网：ghz.sh。\n推荐理由：简洁！可以一次性解决掉 proto 文件相互之间引用的烦心事！\n二、使用 这里只介绍在 Mac 环境下的用法，其他环境请参阅官网。\n另：我们仍旧使用 GOPATH 方式来管理包，我的： export GOPATH=/Users/hujiaming/go ，本次测试目录为：/Users/hujiaming/go/src/hujm.net。\n1. 安装 直接使用 brew 来安装：\nbrew install ghz 如果不成功，可以直接去 https://github.com/bojand/ghz/releases 下载二进制，下载后放在 PATH 中即可。\n注：还需要有 protoc 工具。\n2. 生成 protoset 文件 如果你的 proto 文件中还引用了其他文件，强烈建议使用 protoset 方式。\n假如我在如下的 proto 中定义一个 GRPC服务：\n/** * @filename: api.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/offer.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/association.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; service ApiService { rpc CreateSKUAssociations(CreateSKUAssociationsReq) returns (CreateSKUAssociationsReply) {}; } message CreateSKUAssociationsReq { repeated Association associations = 1 [ (validator.field) = {repeated_count_min : 1} ]; } message CreateSKUAssociationsReply {} 而 Association 是定义在 \u0026quot;xxx/cm/fulfillment/offermanager/offerpb/association.proto” 文件中的：\n/** * @filename: association.proto */ syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;github.com/mwitkow/go-proto-validators/validator.proto\u0026#34;; import \u0026#34;xxx/mms2/utils/i18n/moneypb/money.proto\u0026#34;; import \u0026#34;xxx/cm/fulfillment/offermanager/offerpb/supplier.proto\u0026#34;; import \u0026#34;xxx/cm/core/price/pricepb/price.proto\u0026#34;; package offerpb; message Association { int64 offer_id = 1 [ (validator.field) = {int_gt : 1000000000} ]; string sku_code = 2 [ (validator.field) = {string_not_empty : true} ]; string author = 3 [ (validator.field) = {string_not_empty : true} ]; } 如果采用非 protoset 方式，可能要先生成 association.pb.go，再生成 api.pb.go 文件。这里我们采用 protoset 方式，一步到位：\nprotoc \\ --include_imports \\ -I. -I/usr/local/include \\ -I/usr/local/go \\ -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \\ -I$GOPATH/src \\ --proto_path=. \\ --descriptor_set_out=api.bundle.protoset \\ api.proto 需要注意的点如下：\n如果你的 proto 文件中有引用，上述命令中一定要有 include_imports 参数； 在后面运行时如果出现 no descriptor found for \u0026quot;xxxxxx\u0026quot;，可能是某个文件没有通过 -I 引用进来，记得加上重新执行。 不出意外，会在当前目录下生成 api.bundle.protoset 文件。\n3. 执行压测任务 可以看一下 ghz 的用法：\n$ ghz --help usage: ghz [\u0026lt;flags\u0026gt;] [\u0026lt;host\u0026gt;] Flags: -h, --help Show context-sensitive help (also try --help-long and --help-man). --config= Path to the JSON or TOML config file that specifies all the test run settings. --proto= The Protocol Buffer .proto file. --protoset= The compiled protoset file. Alternative to proto. -proto takes precedence. --call= A fully-qualified method name in \u0026#39;package.Service/method\u0026#39; or \u0026#39;package.Service.Method\u0026#39; format. -i, --import-paths= Comma separated list of proto import paths. The current working directory and the directory of the protocol buffer file are automatically added to the import list. --cacert= File containing trusted root certificates for verifying the server. --cert= File containing client certificate (public key), to present to the server. Must also provide -key option. --key= File containing client private key, to present to the server. Must also provide -cert option. --cname= Server name override when validating TLS certificate - useful for self signed certs. --skipTLS Skip TLS client verification of the server\u0026#39;s certificate chain and host name. --skipFirst=0 Skip the first X requests when doing the results tally. --insecure Use plaintext and insecure connection. --authority= Value to be used as the :authority pseudo-header. Only works if -insecure is used. -c, --concurrency=50 Number of requests to run concurrently. Total number of requests cannot be smaller than the concurrency level. Default is 50. -n, --total=200 Number of requests to run. Default is 200. -q, --qps=0 Rate limit, in queries per second (QPS). Default is no rate limit. -t, --timeout=20s Timeout for each request. Default is 20s, use 0 for infinite. -z, --duration=0 Duration of application to send requests. When duration is reached, application stops and exits. If duration is specified, n is ignored. Examples: -z 10s -z 3m. -x, --max-duration=0 Maximum duration of application to send requests with n setting respected. If duration is reached before n requests are completed, application stops and exits. Examples: -x 10s -x 3m. --duration-stop=\u0026#34;close\u0026#34; Specifies how duration stop is reported. Options are close, wait or ignore. -d, --data= The call data as stringified JSON. If the value is \u0026#39;@\u0026#39; then the request contents are read from stdin. -D, --data-file= File path for call data JSON file. Examples: /home/user/file.json or ./file.json. -b, --binary The call data comes as serialized binary message or multiple count-prefixed messages read from stdin. -B, --binary-file= File path for the call data as serialized binary message or multiple count-prefixed messages. -m, --metadata= Request metadata as stringified JSON. -M, --metadata-file= File path for call metadata JSON file. Examples: /home/user/metadata.json or ./metadata.json. --stream-interval=0 Interval for stream requests between message sends. --reflect-metadata= Reflect metadata as stringified JSON used only for reflection request. -o, --output= Output path. If none provided stdout is used. -O, --format= Output format. One of: summary, csv, json, pretty, html, influx-summary, influx-details. Default is summary. --connections=1 Number of connections to use. Concurrency is distributed evenly among all the connections. Default is 1. --connect-timeout=10s Connection timeout for the initial connection dial. Default is 10s. --keepalive=0 Keepalive time duration. Only used if present and above 0. --name= User specified name for the test. --tags= JSON representation of user-defined string tags. --cpus=8 Number of cpu cores to use. --debug= The path to debug log file. -e, --enable-compression Enable Gzip compression on requests. -v, --version Show application version. Args: [\u0026lt;host\u0026gt;] Host and port to test. 需要关注的几个参数：\n--skipTLS --insecure：如果服务不支持 HTTPS 的话，可以使用此参数跳过 TLS 验证；\n--protoset：指定本次运行的 protoset 文件路径，即上面生成的 api.bundle.protoset；\n--call：需要调用的方法名，格式为：包名.服务名.方法名。比如我要调用 offerpb 包下的 ApiService 服务的 CreateSKUAssociations 方法，那么 call 参数应该是： --call offerpb.ApiService.CreateSKUAssociations；\n--data：本次请求的参数，通过 jsonString 的格式传入；\n--data-file：本次请求的参数，只不过通过文件的形式传入，文件中是标准的通过 json 序列化后的数据；\n--metadata：metadata 参数，通过 jsonString 的格式传入；\n-c：并发数，默认 50(这里有坑，具体参照官网解释：-c。虽然会其多个 goroutine，但是所有的 goroutine 会公用一个连接)；\n-n：请求数，默认 200。n 不能小于 c。\n假设 ApiService服务的地址是：localhost:58784。我们执行下面的命令，发起一次压测任务：\n$ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data \u0026#39;{\u0026#34;associations\u0026#34;:[{\u0026#34;sku_code\u0026#34;: \u0026#34;test:6985079117562211244\u0026#34;,\u0026#34;offer_id\u0026#34;: 8629237865019910744,\u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34;}]}\u0026#39; \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 当你的请求参数比较多时，将他们放在一个文件中、然后使用 --data-file 参数是更好的选择：\n$ cat test_data.json { \u0026#34;associations\u0026#34;: [ { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6237052533738512496\u0026#34;, \u0026#34;offer_id\u0026#34;: 5655307241153104444, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:2156276639623439583\u0026#34;, \u0026#34;offer_id\u0026#34;: 6360134836979240095, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:8361104385030719827\u0026#34;, \u0026#34;offer_id\u0026#34;: 3705044490439993926, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:6023087259299523902\u0026#34;, \u0026#34;offer_id\u0026#34;: 3776027093787512475, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; }, { \u0026#34;sku_code\u0026#34;: \u0026#34;test:9196748606623463644\u0026#34;, \u0026#34;offer_id\u0026#34;: 1506864634761125694, \u0026#34;author\u0026#34;: \u0026#34;test_by_ghz\u0026#34; } ] } $ ghz \\ --skipTLS --insecure --protoset /Users/hujiaming/go/src/hujm.net/api.bundle.protoset \\ --call offerpb.ApiService.CreateSKUAssociations \\ --data-file /Users/hujiaming/go/src/hujm.net/test_data.json \\ -m \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;}\u0026#39; \\ -c 100 -n 1000 \\ localhost:58784 看下输出：\nSummary: Count:\t1000 Total:\t743.17 ms Slowest:\t194.74 ms Fastest:\t37.67 ms Average:\t69.32 ms Requests/sec:\t1345.59 Response time histogram: 37.670 [1]\t| 53.377 [384]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 69.084 [349]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 84.791 [138]\t|∎∎∎∎∎∎∎∎∎∎∎∎∎∎ 100.498 [26]\t|∎∎∎ 116.205 [2]\t| 131.912 [0]\t| 147.619 [16]\t|∎∎ 163.326 [33]\t|∎∎∎ 179.033 [17]\t|∎∎ 194.739 [34]\t|∎∎∎∎ Latency distribution: 10 % in 46.59 ms 25 % in 49.94 ms 50 % in 57.28 ms 75 % in 69.51 ms 90 % in 102.33 ms 95 % in 163.38 ms 99 % in 183.99 ms Status code distribution: [OK] 1000 responses Summary 的参数：\nCount：完成的请求总数，包括成功的和失败的； Total：本次请求所用的总时长，从 ghz 启动一直到结束； Slowest：最慢的某次请求的时间； Fastest：最快的某个请求的时间； Average：(所有请求的响应时间) / Count。 Requests/sec：RTS，Count / Total 的值。 三、参考资料 https://github.com/bojand/ghz Simple gRPC benchmarking and load testing tool ","permalink":"http://localhost:1313/posts/%E4%BD%BF%E7%94%A8ghz%E5%8E%8B%E6%B5%8Bgrpc%E6%8E%A5%E5%8F%A3/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e公司后端服务已经全部微服务化，想要调试某个服务可以使用 \u003ca href=\"https://github.com/fullstorydev/grpcui\"\u003e\u003ccode\u003egrpcui\u003c/code\u003e\u003c/a\u003e，但要对某个接口进行压测，\u003ccode\u003egrpcui\u003c/code\u003e 还做不到。诸多努力之后找到本次主角：\u003ca href=\"https://github.com/bojand/ghz\"\u003ehttps://github.com/bojand/ghz\u003c/a\u003e，官网：\u003ca href=\"https://ghz.sh\"\u003eghz.sh\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e推荐理由：简洁！可以一次性解决掉 \u003ccode\u003eproto\u003c/code\u003e 文件相互之间引用的烦心事！\u003c/p\u003e","title":"使用ghz压测GRPC接口"},{"content":"一、简介 默克尔树是一种典型的二叉树结构，由一个根节点、一组中间节点 和 一组叶节点 组成。默克尔树最早由 Merkle Ralf 在 1980 年提出，曾广泛用于 文件系统 和 P2P 系统中，比如 Git、区块链、IPFS 等大名鼎鼎的项目或技术。\n他又被称为 哈希树，即存储哈希值的树。树的叶子结点是 数据块(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\n最下面的叶节点包含存储数据或其哈希值。 非叶子节点（包括中间节点和根节点）都是它的两个孩子节点内容的哈希值。 如果是奇数个叶子结点，那么其父节点保存的哈希值就是它本身或者复制一份自己凑成对再进行哈希的结果(具体实现取决于实际情况) 当然，默克尔树可以推广到多叉树的情形，此时非叶子节点的内容为它所有的孩子节点的内容的哈希值。\n二、原理与用途 最开始，我们有一组已经准备好的数据块(比如文件)，他们根据某个标准有序(比如根据文件名字典排序)，而每一个文件都有唯一的哈希值与之对应。这是最底层的情况，当我们向上走的时候，每两个当前层的节点(左右孩子结点)的哈希值可以重新组合，形成一个新的节点(父节点)，这个新的结点中不存储数据，其哈希值为左右孩子结点组合后再次使用预设的哈希函数求哈希值。如此以往，直到生成树根，这个树根我们称为 Merkel Root。有一个特殊情况需要注意，有可能某一层的节点数是奇数，这样就会剩下最后一个结点，再没有结点与其组队生成父节点，这种情况下有两种解决方案：一种是复制一份自己；另一种是不复制，让其父节点只有它一个子节点，而且是左孩子结点。\n目前，默克尔树的典型应用场景包括如下几种。\n快速比较大量数据 对每组数据排序后构建默克尔树结构。当两个默克尔树根相同时，则意味着所代表的两组数据必然相同。否则，必然不同。\n由于 Hash 计算的过程可以十分快速，预处理可以在短时间内完成。利用默克尔树结构能带来巨大的比较性能优势。\n快速定位修改 假如我们基于文件 D0~D3 构建如上的默克尔树，如果 D2 被修改，那么会影响到结点 N2、N2 和 Root。此时我们可根据发生变化的节点，沿着 Root -\u0026gt; N5 -\u0026gt; N2， 通过 O(logN) 的时间复杂度快速定位到哪个结点发生了变化。\n零知识证明 它指的是证明者能够在不向验证者提供任何有用的信息的情况下(没有泄露信息)，使验证者相信某个论断是正确的。有一个很简单的例子：A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法：\nA 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。\nB 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。\n后面的第二种方法属于零知识证明。它的好处在于，在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。\n在默克尔树中，我们仍旧以上图为例，如何向他人证明我拥有 D0 这个数据，而不用暴露更多系统的信息呢？模仿上面的例子，验证者随机提供数据 D1、D2 和 D3，证明者构造如图的默克尔树，并公布 N1 、N5 和 Root。验证者自行计算 Root 值，看是否一致，从而检验 D0 是否存在，因为如果存在，N0 一定相同，那么 N4(N0-N1) 也一定相同、Root(N4-N5)也一定相同。整个过程中验证着没有得到任何除了 D0 外的敏感信息(其他的 D)。\n三、Golang 实现 首先，我们定义需要的结构：\n// Node 表示默克尔树中的 叶结点、非叶结点 或者 Root type Node struct { Tree *MerkleTree // 所在的 Merkle Tree Parent *Node // 父节点 Left *Node // 左孩子 Right *Node // 右孩子 leaf bool // 是否叶子结点 Hash []byte // 如果是叶子结点，则为叶子结点数据的哈希值；如果是非叶子结点，则为左右孩子哈希值组合后的哈希值 C Content // 叶子结点存储的数据块 } // Content 代表一个数据块 type Content interface { CalculateHash() ([]byte, error) Equals(other Content) (bool, error) } // MerkleTree 默克尔树 type MerkleTree struct { Root *Node // Merkle Root 树根 merkleRoot []byte // 树根的哈希值 Leafs []*Node // 所有的叶子结点 hashStrategy func() hash.Hash // 计算哈希的方法 } 需要注意的是，hashStrategy 是一个函数，其返回 type hash.Hash interface，目前最常见的实现是 sha256.New 等，这里为了说明清楚原理，我们自己实现一个，计算 hash 时，只是简单将其转化为 []byte 即可：\ntype myHash struct { hash []byte data []byte blockSize int } func newMyHash() hash.Hash { h := \u0026amp;myHash{ data: make([]byte, 0), blockSize: 64, } return h } // Write 将 p 中的数据更新进 m func (m *myHash) Write(p []byte) (n int, err error) { nn := 0 if len(m.data) == 0 { m.data = p nn = len(p) } else { m.data = append(m.data, 38) m.data = append(m.data, p...) nn = len(m.data) + 1 + len(p) } return nn, nil } // Sum 后面追加 func (m *myHash) Sum(b []byte) []byte { m.data = append(m.data, b...) return m.data } func (m *myHash) Reset() { m.data = make([]byte, 0) m.blockSize = 64 } func (m *myHash) Size() int { return len(m.data) } func (m *myHash) BlockSize() int { return m.blockSize } func newMyHashFunc() hash.Hash { return newMyHash() } 另外，对于 type Content interface，我们也简单实现一个：\ntype myContent string func newMyContent(s string) myContent { return myContent(s) } func (c myContent) CalculateHash() ([]byte, error) { //hash := md5.New() //hash.Write(c.ToBytes()) //return hash.Sum(nil), nil return []byte(c), nil } func (c myContent) Equals(other merkletree.Content) (bool, error) { return reflect.DeepEqual(c, other), nil } 创建 接下来我们提供一个构造方法：\n//NewTree creates a new Merkle Tree using the content cs. func NewTree(cs []Content) (*MerkleTree, error) { var defaultHashStrategy = sha256.New // 默认使用 sha256.New 进行哈希 t := \u0026amp;MerkleTree{ hashStrategy: defaultHashStrategy, } root, leafs, err := buildWithContent(cs, t) // 逐层构建结点 if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } // NewTreeWithHashStrategy 效果同 NewTree，不过使用自定义的哈希函数 func NewTreeWithHashStrategy(cs []Content, hashStrategy func() hash.Hash) (*MerkleTree, error) { t := \u0026amp;MerkleTree{ hashStrategy: hashStrategy, } root, leafs, err := buildWithContent(cs, t) if err != nil { return nil, err } t.Root = root t.Leafs = leafs t.merkleRoot = root.Hash return t, nil } 接着我们来看 buildWithContent 做了什么：\n// buildWithContent 主要将 Content 转变成 Node，为下一步的逐层构建做好准备 func buildWithContent(cs []Content, t *MerkleTree) (*Node, []*Node, error) { if len(cs) == 0 { return nil, nil, errors.New(\u0026#34;error: cannot construct tree with no content\u0026#34;) } var leaves []*Node // 将当前的所有 Content 转化成 Node，放在数组 leaves 中 for _, c := range cs { hash, err := c.CalculateHash() if err != nil { return nil, nil, err } leaves = append(leaves, \u0026amp;Node{ Hash: hash, C: c, leaf: true, Tree: t, }) } root, err := buildIntermediate(leaves, t) // 逐层构建默克尔树，最后返回树根 if err != nil { return nil, nil, err } return root, leaves, nil } 再看 buildIntermediate 如何逐层构建：\nfunc buildIntermediate(nl []*Node, t *MerkleTree) (*Node, error) { var nodes []*Node // 如果是单数，不复制自己以凑成对，而是使自己的父节点只有一个左孩子结点(自己)，没有右孩子结点 for i := 0; i \u0026lt; len(nl); i += 2 { h := t.hashStrategy() left, right := i, i+1 var chash []byte if right == len(nl) { // 单数个，父节点计算哈希时只计算左孩子的 chash = nl[left].Hash } else { // 双数个，父节点从左右子孩子的哈希计算得到自己的哈希 chash = append(nl[left].Hash, nl[right].Hash...) } if _, err := h.Write(chash); err != nil { return nil, err } // 生成父节点 node := \u0026amp;Node{ Left: nl[left], Hash: h.Sum(nil), Tree: t, } if right \u0026lt; len(nl) { node.Right = nl[right] } nodes = append(nodes, node) if right \u0026lt; len(nl) { node.Right.Parent = node } nl[left].Parent = node // 如果只有两个，说明当前构造的 node 就是根节点，结束递归 if len(nl) == 2 { return node, nil } } // 递归调用 return buildIntermediate(nodes, t) } 打印 为了方便调试，我们先实现反序列化默克尔树——逐层遍历二叉树。逐层遍历二叉树是数据结构课程中的基础操作，需要用到一个队列，我们先实现一个简单的队列：\ntype queue struct { data []*Node } func newQueue() queue { q := queue{data: make([]*Node, 0)} return q } // 入队 func (q *queue) enqueue(c *Node) { q.data = append(q.data, c) } // 出队 func (q *queue) dequeue() *Node { if len(q.data) == 0 { return nil } data := q.data[0] q.data = q.data[1:] return data } // 是否为空 func (q *queue) isEmpty() bool { return len(q.data) == 0 } // 队列中元素个数 func (q *queue) len() int { return len(q.data) } 借助队列实现默克尔树的打印：\n// Print 打印默克尔树 func (m *MerkleTree) Print() { if len(m.Leafs) == 0 { fmt.Println(\u0026#34;empty tree\u0026#34;) return } q := newQueue() q.enqueue(m.Root) for !q.isEmpty() { size := q.len() for i := 0; i \u0026lt; size; i++ { tmp := q.dequeue() if tmp == nil { break } if !tmp.leaf { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } else { fmt.Printf(\u0026#34;hash(%s) \u0026#34;, tmp.Hash) } if tmp.Left != nil { q.enqueue(tmp.Left) } if tmp.Right != nil { q.enqueue(tmp.Right) } } fmt.Print(\u0026#34;\\n\u0026#34;) } } 查找 先看实现：\n// 查找 content 对应的从上到下的路径，index 表示是否为左孩子 func (m *MerkleTree) GetMerklePath(content Content) ([][]byte, []int64, error) { for _, current := range m.Leafs { ok, err := current.C.Equals(content) if err != nil { return nil, nil, err } if ok { currentParent := current.Parent var merklePath [][]byte var index []int64 for currentParent != nil { // 当前节点是父节点的右孩子 if bytes.Equal(currentParent.Right.Hash, current.Hash) { merklePath = append(merklePath, currentParent.Right.Hash) index = append(index, 1) } else { merklePath = append(merklePath, currentParent.Left.Hash) index = append(index, 0) } current = currentParent currentParent = currentParent.Parent } // 添加 root if len(merklePath) \u0026gt; 0 { if bytes.Equal(m.Root.Left.Hash, merklePath[0]) { index = append(index, 0) } else { index = append(index, 1) } merklePath = append(merklePath, m.Root.Hash) } return merklePath, index, nil } } return nil, nil, nil } 验证(证明) 首先验证一棵默克尔树是否是有效的：\nfunc (m *MerkleTree) VerifyTree() (bool, error) { calculatedMerkleRoot, err := m.Root.verifyNode() if err != nil { return false, err } // 重新根据各个结点构建一棵默克尔树，并得到其 root，看是否与已存在的相同 if bytes.Compare(m.merkleRoot, calculatedMerkleRoot) == 0 { return true, nil } return false, nil } func (n *Node) verifyNode() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } var ( rightBytes []byte leftBytes []byte err error ) // 递归处理 if n.Right != nil { rightBytes, err = n.Right.verifyNode() if err != nil { return nil, err } } if n.Left != nil { leftBytes, err = n.Left.verifyNode() if err != nil { return nil, err } } h := n.Tree.hashStrategy() if _, err := h.Write(append(leftBytes, rightBytes...)); err != nil { return nil, err } return h.Sum(nil), nil } 再次验证某个 Content 是否属于这棵树(零知识证明)：\nfunc (m *MerkleTree) VerifyContent(content Content) (bool, error) { for _, l := range m.Leafs { ok, err := l.C.Equals(content) if err != nil { return false, err } // 存在于已知的节点中 if ok { // 逐层计算 hash，并比较 currentParent := l.Parent for currentParent != nil { h := m.hashStrategy() var allBytes []byte leftBytes, err := currentParent.Left.calculateNodeHash() if err != nil { return false, err } allBytes = leftBytes if currentParent.Right != nil { rightBytes, err := currentParent.Right.calculateNodeHash() if err != nil { return false, err } allBytes = append(allBytes, rightBytes...) } if _, err := h.Write(allBytes); err != nil { return false, err } if bytes.Compare(h.Sum(nil), currentParent.Hash) != 0 { return false, nil } currentParent = currentParent.Parent } return true, nil } } return false, nil } // calculateNodeHash 计算当前 node 的哈希(左右孩子哈希值组合后，再求哈希) func (n *Node) calculateNodeHash() ([]byte, error) { if n.leaf { return n.C.CalculateHash() } h := n.Tree.hashStrategy() var allBytes []byte allBytes = n.Left.Hash if n.Right != nil { allBytes = append(allBytes, n.Right.Hash...) } if _, err := h.Write(allBytes); err != nil { return nil, err } return h.Sum(nil), nil } 重建 // RebuildTree 根据保存的文件块(leaves)重新构建默克尔树 func (m *MerkleTree) RebuildTree() error { var cs []Content for _, c := range m.Leafs { cs = append(cs, c.C) } root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 也可以根据提供的 []Content 重新构建：\n// RebuildTreeWith 根据提供的 content 完全重建一棵树 func (m *MerkleTree) RebuildTreeWith(cs []Content) error { root, leafs, err := buildWithContent(cs, m) if err != nil { return err } m.Root = root m.Leafs = leafs m.merkleRoot = root.Hash return nil } 四、参考文档 Merkle 树结构 Merkle Tree（默克尔树）算法解析 go 语言实现的 merkle 树 我修改了部分实现 ","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%BB%98%E5%85%8B%E5%B0%94%E6%A0%91/","summary":"\u003ch2 id=\"一简介\"\u003e一、简介\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Merkle_tree\"\u003e默克尔树\u003c/a\u003e是一种典型的二叉树结构，由\u003cstrong\u003e一个根节点\u003c/strong\u003e、\u003cstrong\u003e一组中间节点\u003c/strong\u003e 和 \u003cstrong\u003e一组叶节点\u003c/strong\u003e 组成。默克尔树最早由 \u003ccode\u003eMerkle Ralf \u003c/code\u003e在 1980 年提出，曾广泛用于 \u003cstrong\u003e文件系统\u003c/strong\u003e 和 \u003cstrong\u003eP2P\u003c/strong\u003e 系统中，比如 \u003ccode\u003eGit\u003c/code\u003e、区块链、\u003ccode\u003eIPFS\u003c/code\u003e 等大名鼎鼎的项目或技术。\u003c/p\u003e\n\u003cp\u003e他又被称为 \u003cstrong\u003e哈希树\u003c/strong\u003e，即存储哈希值的树。树的叶子结点是 \u003cstrong\u003e数据块\u003c/strong\u003e(文件或者对象)的哈希值，而非叶子结点保存的是其子节点连接起来后的哈希值。简单来说，它有以下特点：\u003c/p\u003e","title":"优秀数据结构--默克尔树"},{"content":"一、前言 前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\n有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\n这道题本质上是解决 判断数据是否存在于一个大集合中。我当时的回答大致是：前面设置一个 布隆过滤器，可以判断哪些 key 一定不存在、哪些可能存在；通过布隆过滤器的检测之后，后面再设置 n 个 redis 数据库(桶)，通过一个 hash 函数进行分桶操作，之后在某个桶中判断某个 key 是否存在就是 O(1) 的时间复杂度。\n需要注意的是，在计算机中，判断一个元素是不是在一个集合中，通常是用 hash 来解决，这在数据量不大的时候是可以的，但是当数据量很大的时候存储空间就会爆炸。\n当时面试官并没有表示满意或者不满意，毕竟这和其他众多更加底层的面试题比起来，只是冰山一角。最后的面试结果是通过，但因为薪资没有达到我的期望，因此也就没有后续了。\n正好国庆假期有时间，系统总结一下 布隆过滤器 的原理，介绍现有的 Redis 实现，并希望通过 Golang 简单实现，算是学习与总结。\n二、原理 布隆过滤器(Bloom Filter) 由 布隆 于 1970 年提出，在这里可以看到原论文：Space/time Trade-offs in Hash Coding with Allowable Errors。从论文标题可以看出，布隆过滤器在时空复杂度方面有着非常大的优势，同时使用到了哈希，但是存在误算率。实际上，布隆过滤器由 一个很长的二进制数组 和 一系列哈希函数 组成，它的作用是 可以检索一个元素是否存在于一个集合中，优点是 插入与查询的时空效率都远超一般的算法，缺点是 存在一定的误识别率 和 删除困难。\n下面我们看一下布隆过滤器的工作流程：\n布隆过滤器本质上是由长度为 m 的 位向量 或者 位列表 (仅包含 0 或者 1 的列表)组成，并且列表的所有元素被初始化为 0：\n当然还会有一系列哈希函数：\n当我们插入一个 key 时，先通过几个哈希函数得到各自的哈希值，然后将位列表对应位设置为 1：\n再插入元素时，继续将对应位设置为 1 即可，而不用担心之前的值是否为 1：\n当我们查询 another_key 是否在上面的位列表中时，还是经过同样的哈希函数，得到各个列表索引值，进而得到位列表处的值，之后进行判断：如果全为 1，则表示可能存在，如果出现一个为 0，则表明一定不存在。\n为什么说当 结果全为 1 时可能存在，而不是 一定存在？假设我们要查一个单词 test 是否存在，其计算的哈希索引值分别为 [2, 5, 14]，位列表中对应的值也全是 1，但是三个 1 是由 hu 和 Jemmy 两个单词插入的结果，原来并没有 test，这种情况下就会出现误判。\n你可以在这个在线网站 Bloom Filters 上自己体会一下这个过程。\n我们假设位列表的长度为 m，有 k 个哈希函数，那么其误判率大概为：\n对于给定的 m 和 n，当\n的时候，误差率取得最小值。具体的推导过程可参考这篇文章：布隆过滤器的误判率该如何计算？ - Xdims 的回答 - 知乎。我们只需要记住结论即可：\n不要让实际元素数量远大于初始化数量； 如果实际元素数量超过初始化数量，则应该选择更大的 m 重建布隆过滤器，将之前的元素进行批量 add。 三、在 Redis 中使用 在低版本需要安装插件并且重新启动：\n下载插件并安装 cd ~/Documents \u0026amp;\u0026amp; git clone https://github.com/RedisBloom/RedisBloom \u0026amp;\u0026amp; cd RedisBloom \u0026amp;\u0026amp; make # 会得到一个 redisbloom.so 文件 重启 redis-server： # 在redis-cli中关闭服务器，其他方法比如 命令行下 kill -9 (redis-server的pid)是没用的 shutdown # 之后退出 # 重启 redis-server /usr/local/etc/redis.conf --loadmodule ~/Documents/RedisBloom/redisbloom.so \u0026amp; 重新进入 redis-cli 即可。 常用命令如下：\nbf.add name key ：往名为 name 的布隆过滤器中添加一个 key bf.madd name key1 key2 ... keyn: 往名为 name 的布隆过滤器中批量添加多个 key bf.exists name key：检查 key 是否存在于名为 name 的布隆过滤器中 bf.mexists name key1 key2 ... keyn：查询多个 key 是否存在于布隆过滤器中。 五、使用 Golang 实现 package main import ( \u0026#34;encoding/binary\u0026#34; \u0026#34;github.com/spaolacci/murmur3\u0026#34; \u0026#34;hash\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;unsafe\u0026#34; ) /* * @CreateTime: 2020/10/7 17:28 * @Author: Jemmy(hujm20151021@gmail.com) * @Description: 布隆过滤器 实现 */ // BloomFilter 布隆过滤器的struct type BloomFilter struct { m uint8 // 位数组长度为 2^m n uint64 // 已有元素 k uint32 // 哈希函数的个数 hashFunc []hash.Hash64 // 哈希函数，使用 murmur3 算法，性能好实现简单，但是易于遭受DDoS攻击 data []byte sync.RWMutex // 读写锁 } // NewBloomFilter 初始化一个布隆过滤器 // m 表示位数组长度为 2的m次方 // k 表示哈希函数的个数 func NewBloomFilter(m uint8, k int) *BloomFilter { if k \u0026lt;= 0 { panic(\u0026#34;invalid number k for hashFunc num \u0026#34;) } hashFunc := make([]hash.Hash64, k) // 初始化哈希函数 for i := 0; i \u0026lt; k; i++ { hashFunc[i] = murmur3.New64WithSeed(uint32(i)) } filter := \u0026amp;BloomFilter{ m: m, n: 0, k: uint32(k), hashFunc: hashFunc, data: make([]byte, 1\u0026lt;\u0026lt;m), } // 防止创建数组越界 if len(filter.data) == 0 { panic(\u0026#34;m is too big to make slice\u0026#34;) } return filter } // exists 检查元素是否存在于集合中 // true: 可能存在 // false: 一定不存在 func (b *BloomFilter) exists(data []byte) bool { b.RLock() defer b.RUnlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) f.Reset() if b.data[position] == 0 { return false } } return true } func (b *BloomFilter) add(data []byte) { b.Lock() defer b.Unlock() for _, f := range b.hashFunc { _, _ = f.Write(data) position := uint(f.Sum64() \u0026amp; ((1 \u0026lt;\u0026lt; b.m) - 1)) b.data[position] = 1 f.Reset() } b.n++ } // Reset 清空布隆过滤器中的所有元素 func (b *BloomFilter) Reset() { b.Lock() defer b.Unlock() b.data = make([]byte, 1\u0026lt;\u0026lt;b.m) b.n = 0 } // Number 返回过滤器中的元素个数 func (b *BloomFilter) Number() uint64 { b.RLock() defer b.RUnlock() return b.n } // AddString 向布隆过滤器中添加字符串对象 func (b *BloomFilter) AddString(s string) { b.add(stringToBytes(s)) } // ExistsString 检查s是否存在于集合中 func (b *BloomFilter) ExistsString(s string) bool { return b.exists(stringToBytes(s)) } // AddNumber 添加数字m func (b *BloomFilter) AddNumber(m uint64) { b.add(uint64ToBytes(m)) } // ExistsNumber 检查数字m是否存在于集合中 func (b *BloomFilter) ExistsNumber(m uint64) bool { return b.exists(uint64ToBytes(m)) } // AddBytes 添加 序列化后的对象 func (b *BloomFilter) AddBytes(data []byte) { b.add(data) } // ExistsBytes 检查对象data是否存在 func (b *BloomFilter) ExistsBytes(data []byte) bool { return b.exists(data) } /* ********************************************* 辅助函数 ***************************************************** */ // stringToBytes 将string转换成byte数组，零拷贝 func stringToBytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } // bytesToString byte数组转换成string，零拷贝 func bytesToString(b []byte) string { return *(*string)(unsafe.Pointer(\u0026amp;b)) } // uint64ToBytes 将uint64转为byte数组 func uint64ToBytes(num uint64) []byte { data := make([]byte, 8) binary.LittleEndian.PutUint64(data, num) return data } 写一个测试一下：\nfunc main() { filter := NewBloomFilter(10, 3) filter.AddNumber(1) filter.AddNumber(2) filter.AddNumber(3) filter.AddNumber(4) filter.AddNumber(5) filter.AddNumber(7) filter.AddString(\u0026#34;hu\u0026#34;) filter.AddString(\u0026#34;Jemmy\u0026#34;) fmt.Println(filter.Number()) // 8 fmt.Println(filter.ExistsNumber(3)) fmt.Println(filter.ExistsNumber(5)) fmt.Println(filter.ExistsNumber(6)) fmt.Println(filter.ExistsString(\u0026#34;Jemmy\u0026#34;)) fmt.Println(filter.ExistsString(\u0026#34;jemmy\u0026#34;)) } // 输出 8 true true false true false 【参考资料】\n布隆过滤器论文\n维基百科 布隆过滤器\n在线演示\n","permalink":"http://localhost:1313/posts/%E4%BC%98%E7%A7%80%E7%BB%84%E4%BB%B6-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e前段时间辞职骑完川藏线后回来找工作，面试 贝尔科教后端开发工程师 岗位时，遇到这样一个面试题：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e有一个几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能。\u003c/p\u003e","title":"优秀组件-布隆过滤器"},{"content":"一、前言 大家应该对 二分查找算法 不陌生，二分查找之所以能达到 O(logN) 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 随机访问数据 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\n事实上，对于一个有序的链表，我们可以通过建索引的方式，做到类似二分查找的效果。\n假设我们有一个已经排好序的链表(其实是一个双链表，这里为了方便，看待成单链表)：\n如果要对这个链表进行查找，那将是 O(n) 的时间复杂度，我们做一些额外的工作：先对链表中每两个结点建一个索引构成一级索引，再对一级索引进行同样的操作得到二级索引：\n当我们要查找元素 20 时，从最高层开始查，则查找路线应该是 1(向右)-\u0026gt;8(向右)-\u0026gt;14(向下)-\u0026gt;14(向右)-\u0026gt;20，经过了 5 个结点；如果直接在原始链表中查找，需要经过 11 个结点，速度有很明显的提升。不过你也发现了，这是典型的 空间换时间 ，虽然查找速度提升了，但是需要花费空间去存储每一层的索引，占用了更大的空间。\n这种带多级索引的链表结构，就是我们今天要详细学习的 跳表。许多开源软件中都有使用到 跳表 这种数据结构，比如 Redis 中的 zset ，我也是最近看 redis 源码才发现对 skiplist 了解甚少，才决定专门学习一遍。\n二、跳表的性质 跳表 可以视为一个 水平排列(Level)、垂直排列(Tower) 的位置(position，对具体结点 Entry 访问的抽象) 的二维集合。跳表具有如下性质：\n由多层(Level)组成，最底层为第 1 层，向上一层为第 2 层，以此类推。层数不会超过规定的一个最大值 LMAX；\n每一层都是一个拥有头结点的有序列表，第 1 层的链表包含所有的元素；\n如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。 这也是 “第 k 层是第 k-1 层的索引” 描述的体现。\n为了节省空间，第一层之上都不存储实际数据，只有指针，包含同层下一个元素的指针 和 同列下一个元素的指针。\n当查找元素时，会从最顶层链表的头节点开始遍历。以升序跳表为例，如果当前节点的下一个节点包含的值比目标元素值小，则继续向右查找。如果下一个节点的值比目标值大，就转到当前层的下一层去查找。重复向右和向下的操作，直到找到与目标值相等的元素为止。以下为找到元素 20 的路径：\n三、跳表的 Golang 实现 跳表首先由 William Pugh 在其 1990 年的论文《Skip lists: A probabilistic alternative to balanced trees》中提出。由该论文的题目可以知道两点：\n跳表是概率型数据结构。 跳表是用来替代平衡树的数据结构。准确来说，是用来替代自平衡二叉查找树（self-balancing BST）的结构。 在这里我们用 Golang 具体实现一遍。\n首先定义需要的结构体：\ntype Node struct { Value int // 某个结点的值，为了方便理解，这里暂时使用 int forward []*Node // 存储该节点所有层的下一个节点的信息，纵向观察，数组的长度是固定的，为 maxLevel。 curLevel int // 本节点最高层 } type SkipList struct { head *Node // 当前结点 length int // (最后一层)总结点长度 maxLevel int // 跳表的最大层 } 这里最让人疑惑的是 forward []*Node 这个属性，它用来存储该结点所有层的下一个节点。怎么理解呢？看上图，对于结点 8 来说，第一层该结点的下一个节点是 9，第二层该结点的下一个节点是 10，第三层该结点的下一个节点是 14，当 maxLevel = 3(代表forward数组长度为 3) 时，结点 8 的 forward 的应该是 [9, 10, 14]。\n当我们要定位一个元素时，从最顶层 先行后列、从上到下 进行对比。怎么个先行后列？从最顶层开始，如上图，这就选定了第一个元素 1，如果当前的元素比要定位的元素小并且后面的元素不为空时，将当前的位置水平向右移动(p = p.forward[i])，否则，向下移动。重复这个动作，直到找到合适的位置。\n接下来我们还要有一个初始化 SkipList 的操作：\n// CreateSkipList 初始化一个 SkipList func CreateSkipList(base,maxLevel int) *SkipList { s := new(SkipList) s.head = new(Node) s.maxLevel = maxlevel // 第一列默认全都为 base ，并且不计算在 length 中 s.head.curLevel = maxlevel - 1 // 计算层数的时候，为了和 forward 数组保持一致，从第 0 层开始计数 s.head.forward = make([]*Node, maxlevel) s.head.Value = base s.length = 0 return s } 我们先看插入一个元素：\n1. 插入新元素 第一步，确定这个元素的位置；第二步，确定这个元素应该有的层数。\n参考之前的性质：如果一个元素出现在第 k 层，那么它一定出现在第 1 ~ (k-1) 层；同时会按照一定的概率 p 出现在第 k+1 层。这个概率我们可以通过一个函数来解决：\n// func (s *SkipList) getNodeLevel() int { var level int = 0 // 根据性质 第1层包含所有的元素，所以第一层肯定包含这个新元素，所以默认在第一层 rand.Seed(time.Now().UnixNano()) for { // 第 k 层 有 1/2 的概率成为 k-1 层的索引，并且不会超过最大层 if rand.Intn(2) == 1 || level \u0026gt;= s.maxLevel-1 { break } level++ } return level } 接下来我们看插入的过程：\nfunc (s *SkipList) Insert(value int) (bool, error) { v, err := checkSkipListValid(s) if v == false { return false, err } p := s.head newNode := new(Node) newNode.Value = value newNode.forward = make([]*Node, s.maxLevel) level := s.getNodeLevel() // 当前节点所包含的层数 // forward []*Node 存储该节点所有层的下一个节点的信息 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从最高层开始，向下移动 for { // 找到应该插入的位置 if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; value { p = p.forward[i] // 不为空且插入的值比当前值大，向右移动 } else { // 当前值的当前行的后继为空或者大于插入值，应该向下走，即 i-1 break } } //find the last Node which match user defined IsLess() condition in i level //insert new Node after the node // 在第i层找到应该插入的最佳位置，然后在该位置插入新的节点 // level层以下都有这个节点 if i \u0026lt;= level { // 相当于链表的插入操作，新节点在当前层的下一个节点就是当前节点的后一个节点 newNode.forward[i] = p.forward[i] p.forward[i] = newNode // 当前节点的后一个节点就是新节点 } } newNode.curLevel = level s.length++ // 更新节点长度加一 return true, nil } 我们通过一组图来说明这个情况：\n加入我们设定 maxLevel = 5、插入节点 10 时得到的 level = 1，那么效果如下：\n当我们继续 插入元素 20 时，假如计算得到 level = 2，从上述代码第 15 行开始进去循环，从节点 p = base 开始遍历，在第二个 for 循环，也就是第 17 行里面，base 的 forward = [10, 10, nil, nil, nil] ，第 4 层和第 3 层都直接跳过。\n当 i = 2 也就是第 2 层时，base.forward[2] = nil，所以不会走到第 20 行，但是此时 i \u0026lt;= level，于是有 newNode.forward[2] = p.forward[2] = base.forward[2] = nil，也就是第 2 层的下一个结点，p.forward[2] = base.forward[2] = newNode(结点 20)：\n当 i = 1 也就是第 1 层时，在第 19 行处，base.forward[1] = 10 != nil，并且 10 \u0026lt; 20，因此会走到底 20 行，p = p.forward[i] = base.forward[1] = 10，之后跳出内层循环，来到第 30 行，同样执行赋值操作：\n同样，当 i = 0 即最底下一层时，操作步骤和 i=1 时一样，最终效果为：\n再比如我们 插入元素 15。假如得到的 level = 0，即只出现在最底层。i \u0026gt;= 1 这个过程和插入 20 时没多大区别：\n当 i = 0 时，第 19 行代码中，base.forward[0] = 10 != nil，并且 ·10 \u0026lt; 15，因此 p = p.forward[0] = 10，继续内层循环，此时发现虽然 p.forward[0] = 结点10.forward[0] = 20 != nil，但是 20 \u0026gt; 15，因此跳出内层循环，在下面第 30 行，将 结点 15 插在了结点 10 和结点 20 的中间，效果如下：\n2. 查找元素 查找元素 value 是否在跳表中，如果存在返回对应的 Node，否则返回 nil。\n还是固定的遍历策略，先看代码：\n//try to find the first node which not match the user defined IsLess() condition func (s *SkipList) Search(value int) *Node { p := s.head // 从最高层开始 for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { // 从左往右 for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i] \u0026lt; value { p = p.forward[i] // 当前节点的 next 不空，且当前值小于待查找值，则向右移动 } else { break } } } // 假如我们需要查找 value=14，此时已经定位到第一层的10 p = p.forward[0] // 还是要再判断一下p的 value，比如我们要查找14，那 p=15 就不符合，应该返回 nil if p.Value != value { return nil } return p } 3. 删除元素 假设我们已经有了如下的跳表：\n代码如下：\nfunc (s *SkipList) RemoveNode(obj int) bool { var update []*Node = make([]*Node, s.maxLevel) // 用来存储被删除结点每一层的前缀 p := s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p.forward[i] != nil \u0026amp;\u0026amp; p.forward[i].Value \u0026lt; obj { p = p.forward[i] } else { break } } update[i] = p } p = p.forward[0] // 删除的节点不存在 if p == nil || p.Value \u0026lt; obj || obj \u0026lt; p.Value { return false } for i := p.curLevel; i \u0026gt;= 0; i-- { // 将被删除结点的前缀，指向删除结点的 next update[i].forward[i] = p.forward[i] } s.length-- return true } 现在我们想 删除结点 20。运行到第 16 行时，update = [15, 10, base, base, base]。p = p.forward[0] = 20，即此时 p 指向被删除的节点。在第 23 行，从 结点 20 的最高层开始，逐层替换掉被删除结点的前缀结点的后缀结点。\n4. 逐层打印跳表 直接看代码：\nfunc (s *SkipList) Traverse() { var p *Node = s.head for i := s.maxLevel - 1; i \u0026gt;= 0; i-- { for { if p != nil { fmt.Print(\u0026#34;%d\u0026#34;,p.Value) if p.forward[i] != nil { fmt.Print(\u0026#34;--\u0026gt;\u0026#34;) } p = p.forward[i] } else { break } } fmt.Println() p = s.head } } 四、时空复杂度分析 都是 O(logn)。具体证明方法请阅读 【参考文献】中 2 跟 3 。\n五、总结 跳表 是一个非常优秀的数据结构，在 Redis 中被用来作为 zset 的底层实现，但是 Redis 的实现比上述设计要复杂的多，比如其引入了 span 表示当前节点到下一个 forward 跨过了几个元素，用来快速计算排名等。\n不过有一点，二叉平衡树也能用来做排序查找，为什么 Redis 不采用树形结构呢？其实 Redis 的作者已经在 这里 说出了原因：\nThere are a few reasons:\nThey are not very memory intensive. It\u0026rsquo;s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.\nA sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.\nThey are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.\n大致意思就是：\n跳表更加节省内存，并且计算随机层数的函数，可以由自己随意更改来获得更多或者更少的索引；\nzset 经常用来实现整体遍历操作，这一点上二者相差无几；\n跳表在调试的时候更容易操作一些。\n【参考文献】\n1. Golang 跳表的实现 https://github.com/GrassInWind2019/skipList/blob/master/src/skipList/skipList.go 2. 跳表时空复杂度分析 https://lotabout.me/2018/skip-list/ 3. 一文彻底搞懂跳表的各种时间复杂度、适用场景以及实现原理 ","permalink":"http://localhost:1313/posts/%E8%B7%B3%E8%A1%A8/","summary":"\u003ch2 id=\"一前言\"\u003e一、前言\u003c/h2\u003e\n\u003cp\u003e大家应该对 \u003cstrong\u003e二分查找算法\u003c/strong\u003e 不陌生，二分查找之所以能达到 \u003ccode\u003eO(logN)\u003c/code\u003e 的时间复杂度，一个重要原因在于它所依赖的数据结构是数组，数组支持随机访问，可通过下标很容易地定位到中间的某个元素。但是链表就没有 \u003cstrong\u003e随机访问数据\u003c/strong\u003e 这个特性，要判断是否包含某个元素，只能从头开始遍历对比。但是数组有数组的局限性，比如需要连续的内存空间，插入删除操作会引起数组的扩容和元素移动；链表有链表的优势，链表不需要先申请连续的空间，插入删除操作的效率非常高。\u003c/p\u003e","title":"跳表原理以及Golang实现"},{"content":"首先明确，Redis 是一个使用 C 语言编写的键值对存储系统。Redis 是众所周知的 “快”，一方面，它是一个内存数据库，所有的操作都是在内存中完成的，内存的访问速度本身就很快；另一方面，得益于它底层的数据结构。Redis 的常见类型可在这个网页找到：Redis 命令参考简体中文版，其使用到的底层数据结构有如下六种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和 整数数组。本篇文章，将具体了解这些底层数据结构的实现。\n本文所涉及源码位于：https://github.com/redis/redis，所选版本为 6.0.8。\n绘图工具为 draw.io\n涉及到内存操作的函数：\nvoid *zmalloc(size_t size); // 调用zmalloc函数，申请size大小的空间 void *zcalloc(size_t size); // 调用系统函数calloc申请内存空间 void *zrealloc(void *ptr, size_t size); // 原内存重新调整为size空间的大小 void zfree(void *ptr); // 调用zfree释放内存空间 char *zstrdup(const char *s); // 字符串复制方法 size_t zmalloc_used_memory(void); // 获取当前以及占用的内存空间大小 void zmalloc_enable_thread_safeness(void); // 是否设置线程安全模式 void zmalloc_set_oom_handler(void (*oom_handler)(size_t)); // 可自定义设置内存溢出的处理方法 float zmalloc_get_fragmentation_ratio(size_t rss); // 获取所给内存和已使用内存的大小之比 size_t zmalloc_get_rss(void); // 获取RSS信息(Resident Set Size) size_t zmalloc_get_private_dirty(void); // 获得实际内存大小 size_t zmalloc_get_smap_bytes_by_field(char *field); // 获取/proc/self/smaps字段的字节数 size_t zmalloc_get_memory_size(void); // 获取物理内存大小 void zlibc_free(void *ptr); // 原始系统free释放方法 一、底层数据结构 1. 简单动态字符串 源码文件：sds.h\n1.1 数据结构 SDS（Simple Dynamic Strings, 简单动态字符串）是 Redis 的一种基本数据结构，主要是用于存储字符串和整数。 在 Redis 3.2 版本以前，SDS 的实现如下：\nstruct sdshdr { // 记录 buf 数组中已使用字节的数量，等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; 比如，字符串 Redis6.0 的结构如下：\nSDS 遵循 C 字符串以空字符结尾的惯例， 但保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面， 并且为空字符分配额外的 1 字节空间， 以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的， 所以这个空字符对于 SDS 的使用者来说是完全透明的——这样做的好处是，SDS 可以直接使用 C 库中的有关字符串的函数。\n但是在 Redis 3.2 以后，为了提高效率以及更加节省内存，Redis 将 SDS 划分成一下五种类型：\nsdshdr5 sdshdr8 sdshdr16 sdshdr32 sdshdr64 先看 sdshdr5，增加了一个 flags 字段来标识类型，用一个字节(8 位)来存储：\n// Note: sdshdr5 is never used, we just access the flags byte directly. struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 前 3 位表示类型, 后 5 为表示长度 */ char buf[]; }; 对于 sdshdr5 ，因为其可存储长度最大为 2^5 - 1 = 31，当字符串长度超过 31 时，仅靠 flag 的后 5 为表示长度是不够的，这时需要使用其他的四个结构来保存：\nstruct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; // 已使用长度 1字节 uint8_t alloc; // 总长度 1字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; // 已使用长度 2字节 uint16_t alloc; // 总长度 2字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; // 已使用长度 4字节 uint32_t alloc; // 总长度 4字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; // 已使用长度 8字节 uint64_t alloc; // 总长度 8字节 unsigned char flags; // 前 3 位表示存储类型，后 5 位 预留 char buf[]; }; C/C++ 中 __packed 的作用：\n假设有以下结构体：\nstruct { char a; // 1 字节 int b; // 4 字节 char c[2]; // 2 字节 double d; // 8 字节 }Struct_A; 在计算机内存中，结构体变量的存储通常是按字长对齐的，比如在 8 位机上，就按照 1 字节(8 位)对齐，上述结构体占用 1+4+2+8=15​ 字节的内存；在 16 位机上，按照 2 字节对齐，则该结构体占用 2+4+2+8=16​ 字节。也就是说，在更高位的机器中，如果按照默认的机器字长做内存对齐的标准，那总会有一些空间是浪费的，比如上面 16 位时，为了对齐，使用了 2 字节来存储一个char类型的变量。为什么要对齐？这是因为对内存操作按照整字存取会有更高的效率，是 “以空间换时间” 的思想体现。当然，在空间更优先的情况下，也可以不使用默认的机器字长做内存对齐，这个时候，使用 __packed___关键字，可以强制使编译器将结构体成员按照 1 字节进行内存对齐，可以得到非对齐的紧凑型结构体。\n1.2 API 创建 SDS /* Create a new sds string starting from a null terminated C string. */ sds sdsnew(const char *init) { size_t initlen = (init == NULL) ? 0 : strlen(init); // 拿到要创建的字符串的长度 return sdsnewlen(init, initlen); // 传入字符串、字符串长度，调用 sdsnewlen 动态分配内存 } sds sdsnewlen(const void *init, size_t initlen) { void *sh; sds s; char type = sdsReqType(initlen); // 根据字符串长度得到合适的类型 // 一般情况下，创建一个空字符串的目的都是为了后面的append操作，因此，空字符串的情况下，直接创建SDS_TYPE_8，减少后面的扩容操作 if (type == SDS_TYPE_5 \u0026amp;\u0026amp; initlen == 0) type = SDS_TYPE_8; // 计算类型对应的结构体头部长度(len alloc flags的长度) int hdrlen = sdsHdrSize(type); // 指向flag的指针 unsigned char *fp; // 申请内存，内存大小为 结构体头部长度+字符串长度(buf)+1，这里+1是因为要考虑 \u0026#39;\\0\u0026#39; 字符 sh = s_malloc(hdrlen+initlen+1); if (sh == NULL) return NULL; if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); // 将s指向buf s = (char*)sh+hdrlen; // 将 s-1 指向flag fp = ((unsigned char*)s)-1; // 对sds结构体变量进行赋值 switch(type) { case SDS_TYPE_5: { *fp = type | (initlen \u0026lt;\u0026lt; SDS_TYPE_BITS); break; } case SDS_TYPE_8: { SDS_HDR_VAR(8,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = initlen; *fp = type; break; } ... } if (initlen \u0026amp;\u0026amp; init) memcpy(s, init, initlen); // 在s的最后添加\u0026#39;\\0\u0026#39; s[initlen] = \u0026#39;\\0\u0026#39;; // 返回指向 buf 数组的指针s return s; } 注意，创建 SDS 时返回给上层的是指向 buf 数组的指针 s，而不是结构体的指针，那如何找到结构体中的其他元素呢？上面提到了 __packed__ 关键字，使用 1 字节进行内存对齐，那么知道了 buf 的地址，将其减去对应类型的长度(偏移量)，就能得到结构体中其他类型的地址。\n清空 SDS 清空一个 SDS 有两个途径：\n第一种是直接调用 s_free() 函数：\n/* Free an sds string. No operation is performed if \u0026#39;s\u0026#39; is NULL. */ void sdsfree(sds s) { if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1])); } 另一种方式是 重置 len 为 0 的方式，这种情况下 buf 所占用的空间并没有被清除掉，新的数据会直接覆盖 buf 中的原有数据而无需再申请新的内存空间：\n/* Modify an sds string in-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */ void sdsclear(sds s) { sdssetlen(s, 0); s[0] = \u0026#39;\\0\u0026#39;; } 拼接 SDS 拼接使用的是 sds sdscatsds(sds s, sds t)，但最终调用的还是 sdscatlen：\n// 将 t 拼接到 s 后面。调用此方法之后，sds底层的buf可能经过了扩容迁移了原来的位置，注意更新原来变量中对应的指针 sds sdscatsds(sds s, const sds t) { return sdscatlen(s, t, sdslen(t)); } sds sdscatlen(sds s, const void *t, size_t len) { size_t curlen = sdslen(s); // 计算当前s的长度 s = sdsMakeRoomFor(s,len); // 空间不够的话扩容，确保s的剩余空间足够放得下t if (s == NULL) return NULL; // 扩容失败 memcpy(s+curlen, t, len); // 拼接 sdssetlen(s, curlen+len); // 更新s的属性len s[curlen+len] = \u0026#39;\\0\u0026#39;; // 给s最后加上 \u0026#39;\\0\u0026#39; return s; } 接下来我们详细看一下扩容规则，在函数 sdsMakeRoomFor 中：\n// 将sds s的 buf 的可用空间扩大，使得调用此函数之后的s能够再多存储 addlen 长度的字符串。 // 注意：此方法并未改变 sds 的len属性，仅仅改变的是 sds 的 buf 数组的空间。 sds sdsMakeRoomFor(sds s, size_t addlen) { void *sh, *newsh; size_t avail = sdsavail(s); // 当前的可用空间长度：s.alloc - s.len size_t len, newlen; char type, oldtype = s[-1] \u0026amp; SDS_TYPE_MASK; int hdrlen; // 情况1：剩余长度大于所需要长度，没必要扩容，直接返回 if (avail \u0026gt;= addlen) return s; len = sdslen(s); // 当前字符串长度 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 新字符串长度 // 情况2：扩容 // 情况2.1： 如果 新长度 \u0026lt; 1MB，则按 新长度的2倍 扩容 // 否则，就按 新长度+1MB 扩容 if (newlen \u0026lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; // 计算新长度的类型 type = sdsReqType(newlen); // 还是为了后续使用减少扩容次数的原因，将 sdshdr5 变为 sdshdr8 if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) { // 如果新长度对应的类型没变，则直接调用 s_realloc 扩大动态数组即可 newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; } else { /* Since the header size changes, need to move the string forward, * and can\u0026#39;t use realloc */ // 类型发生了改变，意味着sds结构体头部的三个属性的类型也要跟着变化，此时直接重新申请一块内存 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; // 原s的数据拷贝到新的内存上 memcpy((char*)newsh+hdrlen, s, len+1); // 释放掉原来的s的空间，并将其更新为刚才新申请的 s_free(sh); s = (char*)newsh+hdrlen; // 更新 flag s[-1] = type; // 更新 len sdssetlen(s, len); } // 更新 alloc sdssetalloc(s, newlen); return s; } 代码中注释已经很清楚了，这里再总结一下扩容策略：如果 剩余长度 avail \u0026gt;= 新增长度 addlen ，则无需扩容；否则，如果 avail + addlen \u0026lt; 1MB，按照 2 * (avail + addlen)扩容，否则按照 avail + addlen + 1MB 扩容。\n1.3 总结 创建 SDS 时返回的是指向 buf 数组的指针，而不是 SDS 类型的对象，这样的好处是兼容了已有的 C 语言中的相关函数； 读取内容时，先通过类对应类型计算偏移量，再通过 len 属性来限制读取的长度，杜绝了缓冲区溢出，二进制安全； 根据字符串的长度，定义了五种不同的类型，节省了空间； 进行字符串拼接时，会通过 sdsMakeRoomFor 函数来决定是否有底层 buf 数组的扩容操作。 2. 双端链表 源码文件：adlist.h\n2.1 数据结构 当我们使用 lpush 或者 rpush 的时候，其实底层对应的数据结构就是一个双端链表。\n首先我们来了解结点 listNode：\ntypedef struct listNode { struct listNode *prev; // 头指针 struct listNode *next; // 尾指针 void *value; // 具体的值，因为值的类型不确定，此处使用万能指针 } listNode; 虽然使用多个 listNode就已经足够表示一个双端链表，但是为了更方便，Redis 还有如下结构：\ntypedef struct list { listNode *head; // 头指针 listNode *tail; // 尾指针 void *(*dup)(void *ptr); // 拷贝结点函数 void (*free)(void *ptr); // 释放结点值函数 int (*match)(void *ptr, void *key); // 判断两个结点是否相等的函数 unsigned long len; // 链表长度 } list; 他们的关系可用如下图表示：\n2.2 API 创建 list 对象 创建的是一个 list 对象，首先会尝试申请分配空间，失败返回 NULL ：\n// 创建的只是一个 list 对象，这个对象可以被 AlFreeList() 释放掉，但是仅仅释放的是这个 list 对象，其上面的 listNode 对象还需要另外手动释放 list *listCreate(void) { struct list *list; // 申请分配内存，失败返回 NULL if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 给其他属性赋值 list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; list-\u0026gt;dup = NULL; list-\u0026gt;free = NULL; list-\u0026gt;match = NULL; // 最终返回 list 对象 return list; } 添加元素 listNode 到 list 给一个带头的双向链表添加元素，有三种添加方法：头插入 、 尾插入 和 指定位置，分别对应的操作为 lpush 、rpush 和 linsert。对于 lpush 和 rpush 的实现如下，本质上就是对双端链表的基础操作：\nlist *listAddNodeHead(list *list, void *value) { listNode *node; // 申请分配内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; // 将 listNode 插入到 list 的元素中 if (list-\u0026gt;len == 0) { // 如果之前 list 没有元素，那么 list 的 head 和 tail 均指向当前的 listNode list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { // 链表的头插入 node-\u0026gt;prev = NULL; node-\u0026gt;next = list-\u0026gt;head; list-\u0026gt;head-\u0026gt;prev = node; list-\u0026gt;head = node; } // 更新 len list-\u0026gt;len++; // 返回的是传进来的 list ，失败返回的是 NULL return list; } // 尾插入，过程和头插入类似 list *listAddNodeTail(list *list, void *value) { listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (list-\u0026gt;len == 0) { list-\u0026gt;head = list-\u0026gt;tail = node; node-\u0026gt;prev = node-\u0026gt;next = NULL; } else { node-\u0026gt;prev = list-\u0026gt;tail; node-\u0026gt;next = NULL; list-\u0026gt;tail-\u0026gt;next = node; list-\u0026gt;tail = node; } list-\u0026gt;len++; return list; } 关于 linsert ，其用法如下：\nLINSERT key BEFORE|AFTER pivot value\n将值value插入到列表key当中，位于值pivot之前或之后。\n当pivot不存在于列表key时，不执行任何操作。\n当key不存在时，key被视为空列表，不执行任何操作。\n如果key不是列表类型，返回一个错误。\n在 Redis 底层，对应的方法为 listInsertNode，当然，为了找到 old_node，前面还需要遍历 list，这个操作的时间复杂度是 O(n)，我们这里只关注如何插入元素：\n// 在 list 的 old_node 的前或后(after\u0026lt;0,在前面增加；after\u0026gt;0，在后面增加)新增值为 value 的新listNode list *listInsertNode(list *list, listNode *old_node, void *value, int after) { listNode *node; // 为新增的 listNode 申请内存，失败返回 NULL if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-\u0026gt;value = value; if (after) { // after\u0026gt;0，在后面插入 node-\u0026gt;prev = old_node; node-\u0026gt;next = old_node-\u0026gt;next; if (list-\u0026gt;tail == old_node) { list-\u0026gt;tail = node; } } else { // after\u0026lt;0，在前面插入 node-\u0026gt;next = old_node; node-\u0026gt;prev = old_node-\u0026gt;prev; if (list-\u0026gt;head == old_node) { list-\u0026gt;head = node; } } if (node-\u0026gt;prev != NULL) { node-\u0026gt;prev-\u0026gt;next = node; } if (node-\u0026gt;next != NULL) { node-\u0026gt;next-\u0026gt;prev = node; } // 更新 len list-\u0026gt;len++; // 成功 返回传进来的 list return list; } 删除元素 删除元素的情况有以下几种：清空整个 list ，删除某个 listNode。\n我们先看清空整个 list ，它只是释放掉了这个 list 上连的所有的 listNode ，而 list 对象并没有被销毁：\n/* Remove all the elements from the list without destroying the list itself. */ void listEmpty(list *list) { unsigned long len; listNode *current, *next; current = list-\u0026gt;head; len = list-\u0026gt;len; // 遍历整个链表，逐个释放空间，直到为空 while(len--) { next = current-\u0026gt;next; if (list-\u0026gt;free) list-\u0026gt;free(current-\u0026gt;value); zfree(current); current = next; } list-\u0026gt;head = list-\u0026gt;tail = NULL; list-\u0026gt;len = 0; } 而下面这个 listRelease 方法，会释放所有：\n/* Free the whole list. * * This function can\u0026#39;t fail. */ void listRelease(list *list) { listEmpty(list); // 先清空所有的 listNode zfree(list);\t// 再释放 list } 然后看删除某个具体的 listNode：\nvoid listDelNode(list *list, listNode *node) { // 是否是 list 中的第一个元素 if (node-\u0026gt;prev) node-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; else list-\u0026gt;head = node-\u0026gt;next; // 是否是 list 中的最后一个元素 if (node-\u0026gt;next) node-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; else list-\u0026gt;tail = node-\u0026gt;prev; // 释放当前节点的值 if (list-\u0026gt;free) list-\u0026gt;free(node-\u0026gt;value); // 释放内存 zfree(node); // 更新 len list-\u0026gt;len--; } 2.3 总结 Redis 基于双端链表，可以提供各种功能：列表键、发布订阅功能、监视器等；\n因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表；\n仔细看过源代码后会发现，这是一个典型的双端链表，其底层实现与我在《数据结构》中遇到的如出一辙，这也从侧面说明了熟悉基本的数据结构的重要性。\n3. 字典 字典，由一个个键值对构成，首先想一下，一个字典应该提供什么样的功能？键值对用来存储数据，之后还要能插入数据、修改数据、删除数据、遍历(读取)数据，字典最大的特点就是上面这些所有的操作都可以在 O(1) 的时间复杂度里完成。\n比如在 redis-cli 中，我输入如下命令：\nredis\u0026gt; set name Jemmy 这条命令在 redis 的内存中生成了一个键值对(key-value)，其中 key 是 name，value 是 Jemmy的字符串对象，\nRedis 的字典采用 哈希表 来实现。一个哈希表，你可以简单把它想成一个数组，数组中的每个元素称为一个桶，这也就对应上我们经常所说，一个哈希表由多个桶组成，每个桶中保存了键值对的数据(哈希桶中保存的值其实并不是值本身，而是一个指向实际值的指针)。\n提到哈希，首先要关注的是哈希算法以及解决哈希冲突的方式。哈希算法的具体实现我们暂时不关心，只需要知道 Redis 使用的是 MurmurHash2，“这个算法的优点在于：即使输入的键是有规律的，算法仍能够给出一个很好的随机分布性，计算速度也很快”；对于解决哈希冲突的方法，最常见的是 开放地址法 和 拉链法。二者实现原理在 Golang-map 详解 中已经说过，这里不再细讲，目前只需要知道，Redis 采用拉链法解决哈希冲突。\n在 Redis 中，有以下几个概念：哈希表、哈希表结点和字典，他们的关系大致可以描述为：字典是一个全局的字典，一个字典中包含两个哈希表，一个正在使用，另一个用作扩容用；哈希表中包含多个哈希表结点。接下来我们详细看下每个结构的具体实现：\n源码文件：dict.h\n3.1 数据结构 哈希表结点 哈希表节点使用 dictEntry 结构表示， 每个 dictEntry 结构都保存着一个键值对：\ntypedef struct dictEntry { // key void *key; // value，可以是指针 uint64_t int64_t double中的某一个 union { void *val; uint64_t u64; int64_t s64; double d; } v; // 指向另一个哈希表结点的指针，连接哈希值相同的键值对，用来解决哈希冲突 struct dictEntry *next; } dictEntry; 哈希表 typedef struct dictht { dictEntry **table; // dictEntry数组，dictEntry代表一个键值对 unsigned long size; // 哈希表大小(容量) unsigned long sizemask; // 值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 unsigned long used; // 哈希表已有结点的数量 } dictht; 下图可以表示 哈希表 dictht 和 哈希表结点 dictEntry 之间的关系：\n字典 typedef struct dict { dictType *type; // 类型对应的特定函数 void *privdata; // 私有数据 dictht ht[2]; // 两个哈希表，一个正常使用，另一个用于扩容 long rehashidx; // rehash 索引值，扩容时使用，正常时为-1 unsigned long iterators; // 正在运行的迭代器的数量 } dict; 这里的 type 是一个指向 dictType 结构体的指针，而每一个 dictType 结构体保存了 一组用于操作特定类型键值对的函数，不同的类型有不同的操作函数，privdata 保存了需要传递给特定类型函数的可选参数：\ntypedef struct dictType { // 计算哈希值的函数 uint64_t (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键是否相同的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj); } dictType; ht 属性是一个包含两个项的数组， 数组中的每个项都是一个 dictht 哈希表， 一般情况下， 字典只使用 ht[0] 哈希表， ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。\n除了 ht[1] 之外， 另一个和 rehash 有关的属性就是 rehashidx ： 它记录了 rehash 目前的进度， 如果目前没有在进行 rehash ， 那么它的值为 -1 。\n下图展示了一个普通状态(没有进行 rehash )的字典：\n3.2 哈希冲突的解决方式 当两个以上的键经过哈希函数计算之后，落在了哈希表数组的同一个索引上面，我们就称这些键发生了 哈希冲突(hash collision)。\nRedis 的哈希表使用 链接法来解决键冲突： 每个哈希表节点(dictEntry)都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。写入时，因为没有直接指向链的最后一个元素的指针，因此为了更少的时间复杂度， Redis 采用的是在链表头部插入；读取时，先定位到链头，之后逐个比较值是否与所求相同，直到遍历完整个链。\n比如上图中，在 dictht.table 的 3 号桶中已经存在一个键值对 k1-v1，此时又新加入一个键值对 k2-v2，经过哈希计算后正好也落在 3 号桶中，经过插入后结果如下：\n3.4 rehash 细节 当哈希表的键值对数量太多或者太少时，需要根据实际情况对哈希表的大小进行扩大或者缩小，这个过程通过 rehash(重新散列) 来完成。 而判断是否进行 rehash ，是在向哈希表插入一个键值对的时候，接下来我们通过分析源代码的方式，详细了解 rehash 的细节。\n首先，添加一个新键值对，用到的是 dictAdd 方法：\n/* Add an element to the target hash table */ int dictAdd(dict *d, void *key, void *val) { dictEntry *entry = dictAddRaw(d,key,NULL); // 将键值对封装成dictEntry if (!entry) return DICT_ERR; // 如果创建dictEntry，返回失败 dictSetVal(d, entry, val); // 键不存在，则设置dictEntry结点的值 return DICT_OK; } 我们接着看 dictAddRaw，这一步主要将键值对封装成一个 dictEntry 并返回 ：\n// 将 key 插入哈希表中 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing) { long index; dictEntry *entry; dictht *ht; // 如果哈希表正在rehash，则向前 rehash一步(渐进式rehash的体现) // 是否正在进行 rehash，是通过 dict.rehashidx == -1 来判断的 if (dictIsRehashing(d)) _dictRehashStep(d); // 调用_dictKeyIndex() 检查键是否存在，如果存在则返回NULL if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; // 获取当前正在使用的ht，如果正在 rehash，使用 ht[1]，否则使用 ht[0] ht = dictIsRehashing(d) ? \u0026amp;d-\u0026gt;ht[1] : \u0026amp;d-\u0026gt;ht[0]; // 为新增的节点分配内存 entry = zmalloc(sizeof(*entry)); // 将结点插入链表头部 entry-\u0026gt;next = ht-\u0026gt;table[index]; ht-\u0026gt;table[index] = entry; // 更新结点数量 ht-\u0026gt;used++; // 设置新节点的键，使用的是 type 属性中的 keyDup 函数 dictSetKey(d, entry, key); return entry; } 我们再看 _dictKeyIndex 这个方法，作用是计算某个 key 应该存储在哪个空的 bucket ，即需要返回这个 key 应该存储在 dictEntry 数组的 index，如果已经存在，返回 -1。需要注意的是，当哈希表正在 rehash 时，返回的 index 应该是要搬迁的 ht：\n// 传进来的 existing 是 NULL, hash是通过 type 中的哈希函数计算的 static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing) { unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; // 检查是否需要扩展哈希表，如果需要则进行扩展 if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table \u0026lt;= 1; table++) { idx = hash \u0026amp; d-\u0026gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-\u0026gt;ht[table].table[idx]; while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (existing) *existing = he; return -1; } he = he-\u0026gt;next; } if (!dictIsRehashing(d)) break; } return idx; } 最后，我们关注 检查是否需要 rehash，需要则启动 的 _dictExpandIfNeeded：\nstatic int _dictExpandIfNeeded(dict *d) { // 如果正在 rehash，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果哈希表中是空的，则将其收缩为初始化大小 DICT_HT_INITIAL_SIZE=4 if (d-\u0026gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // 在 (ht[0].used/ht[0].size)\u0026gt;=1前提下，如果 系统允许扩容 或者 ht[0].used/t[0].size\u0026gt;5 时，容量扩展为原来的2倍 if (d-\u0026gt;ht[0].used \u0026gt;= d-\u0026gt;ht[0].size \u0026amp;\u0026amp; (dict_can_resize || d-\u0026gt;ht[0].used / d-\u0026gt;ht[0].size \u0026gt; dict_force_resize_ratio)) { return dictExpand(d, d-\u0026gt;ht[0].used * 2); // 扩容至原来容量的2倍 } return DICT_OK; } 仔细看看 dictExpand 是如何扩展哈希表容量的，这个函数中，判断是否需要扩容，如果需要，则新申请一个 dictht ，赋值给 ht[0]，然后将字典的状态设置为 正在 rehash(rehashidx \u0026gt; -1)，需要注意的是，这个方法中并没有实际进行键值对的搬迁：\n// 扩容 或者 新建一个 dictht int dictExpand(dict *d, unsigned long size) { /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 如果正在 reahsh 或者 传进来的size不合适(size比当前已有的容量小，正常情况下这是不可能的)，直接返回错误 if (dictIsRehashing(d) || d-\u0026gt;ht[0].used \u0026gt; size) return DICT_ERR; dictht n; // 新哈希表 // 计算 扩展或缩放新哈希表容量 的大小，必须是2的倍数 unsigned long realsize = _dictNextPower(size); // 如果计算扩容后的新哈希表的容量，和原来的相同，就没必要扩容，直接返回错误 if (realsize == d-\u0026gt;ht[0].size) return DICT_ERR; // 为新哈希表申请内存，并将所有的指针初始化为NULL n.size = realsize; n.sizemask = realsize - 1; n.table = zcalloc(realsize * sizeof(dictEntry *)); n.used = 0; /* Is this the first initialization? If so it\u0026#39;s not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果原来的哈希表是空的，意味着这是在新建一个哈希表，将新申请的 dictht 赋值给 ht[0]，直接返回创建成功 if (d-\u0026gt;ht[0].table == NULL) { d-\u0026gt;ht[0] = n; return DICT_OK; } // 如果不是新建哈希表，那就是需要实打实的扩容，此时将刚才新申请的 哈希表 赋值给 ht[1]，并将当前字典状态设置为\u0026#34;正在rehash\u0026#34;(rehashidx \u0026gt; -1) d-\u0026gt;ht[1] = n; d-\u0026gt;rehashidx = 0; return DICT_OK; } // 哈希表的容量必须是 2的倍数 static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size \u0026gt;= LONG_MAX) return LONG_MAX + 1LU; while (1) { if (i \u0026gt;= size) return i; i *= 2; } } 什么时候进行 桶 的搬迁呢？这里涉及到一个名词：渐进式扩容。我们知道，扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面，如果哈希表中的键值对数量少，那么一次性转移过去不是问题；但是键值对的数量很大，几百万几千万甚至上亿，那么一次性搬完的计算量+单线程很有可能使 redis 服务停止一段时间。因此，为了避免 rehash 对服务造成影响，服务不是一次性 rehash 完成的，而是 分多次、渐进式地将 ht[0] 中的键值对搬迁到 ht[1] 中。\n源码中真正执行搬迁的函数是 _dictRehashStep：\n// _dictRehashStep 让 rehash 的动作向前走一步(搬迁一个桶)，前提是当前字典没有被遍历，即iterators==0，iterators表示当前正在遍历此字典的迭代器数目 static void _dictRehashStep(dict *d) { if (d-\u0026gt;iterators == 0) dictRehash(d, 1); } 再看 dictRehash ：\n// dictRehash 向前 rehash n步。如果还没有搬迁完，返回 1，搬迁完成返回0 int dictRehash(dict *d, int n) { // 当dictRehash时，rehashidx指向当前正在被搬迁的bucket，如果这个bucket中一个可搬迁的dictEntry都没有，说明就没有可搬迁的数据。 // 这个时候会继续向后遍历 ht[0].table 数组，直到找到下一个存有数据的bucket位置，如果一直找不到，则最多向前走 empty_visits 步，本次搬迁任务结束。 int empty_visits = n * 10; // 整个dict的 rehash 完成了，返回0 if (!dictIsRehashing(d)) return 0; // 外层大循环，确保本次最多向前走n步 以及 ht[0].table中还有值 while (n-- \u0026amp;\u0026amp; d-\u0026gt;ht[0].used != 0) { dictEntry *de, *nextde; // 确保 rehashidx 不会超过 ht[0].table 的长度，因为 rehashidx 指向当前正在被搬迁的bucket，其实就是 ht[0].table 数组的下标，这里保证数组下标访问不会越界 assert(d-\u0026gt;ht[0].size \u0026gt; (unsigned long)d-\u0026gt;rehashidx); // 当前的bucket搬迁完了，继续寻找下一个bucket，知道全部为空 或者 向前走的步数超过了限定值 while (d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] == NULL) { d-\u0026gt;rehashidx++; if (--empty_visits == 0) return 1; } // 终于找到了可搬迁的某个bucket中的 dictEntry de = d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx]; // 将这个 bucket 中的所有 dictEntry 包括链表上的，前部搬迁到新的 ht[1] 中 while (de) { uint64_t h; nextde = de-\u0026gt;next; // 获取当前键值对在新的哈希表中的桶的序号，这里进行取模的是 ht[1]的sizemask，所以 h 很大概率会与在 ht[0] 中的不一样 h = dictHashKey(d, de-\u0026gt;key) \u0026amp; d-\u0026gt;ht[1].sizemask; // 更新 新桶与旧桶 中的属性 de-\u0026gt;next = d-\u0026gt;ht[1].table[h]; d-\u0026gt;ht[1].table[h] = de; d-\u0026gt;ht[0].used--; d-\u0026gt;ht[1].used++; de = nextde; } // 搬迁完成，将原来的ht[0]中的bucket置空 d-\u0026gt;ht[0].table[d-\u0026gt;rehashidx] = NULL; // rehashidx 自增，表示又搬完了一个桶 d-\u0026gt;rehashidx++; } // 检查是否搬完了整张表 if (d-\u0026gt;ht[0].used == 0) { // 全部完成搬迁，则释放掉ht[0]的内存，将ht[1]的内容放到ht[0]中，重置ht[1]，并标志rehash完成(rehashidx=-1) zfree(d-\u0026gt;ht[0].table); d-\u0026gt;ht[0] = d-\u0026gt;ht[1]; _dictReset(\u0026amp;d-\u0026gt;ht[1]); d-\u0026gt;rehashidx = -1; return 0; } // 否则后面的动作还要继续搬迁 return 1; } 那什么时候会进行渐进式rehash呢？在源码中搜索 _dictRehashStep：有以下几处出现了：\ndictAddRaw ：向字典增加一个键值对时； dictGenericDelete：查找并移除某个键值对时； dictFind ：根据 key 查找对应的 dictEntry 时； dictGetRandomKey：返回一个随机的 dictEntry 时； dictGetSomeKeys：随机返回指定 count 个 dictEntry 时，会进行 count 次 _dictRehashStep 总结一下：\n为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。\n3.5 API 添加键值对 dictAdd 在上面讲 rehash 时，使用的例子，就是 添加键值对，这里不再赘述。\n删除键值对 dictDelete 其底层调用的是 dictGenericDelete：\n// 找到key对应的键值对，并移除它。此处dictDelete 调用时传入 nofree=0 static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) { uint64_t h, idx; dictEntry *he, *prevHe; int table; // 如果字典中键值对数量为0，返回 未找到 if (d-\u0026gt;ht[0].used == 0 \u0026amp;\u0026amp; d-\u0026gt;ht[1].used == 0) return NULL; // 如果当前处于 rehash 阶段，则往前进行一步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table \u0026lt;= 1; table++) { // 获取桶的索引 idx = h \u0026amp; d-\u0026gt;ht[table].sizemask; // 获取桶中的第一个 dictEntry he = d-\u0026gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表，找到之后将其从链表中删除 while (he) { if (key == he-\u0026gt;key || dictCompareKeys(d, key, he-\u0026gt;key)) { if (prevHe) prevHe-\u0026gt;next = he-\u0026gt;next; else d-\u0026gt;ht[table].table[idx] = he-\u0026gt;next; if (!nofree) { dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } d-\u0026gt;ht[table].used--; return he; } prevHe = he; he = he-\u0026gt;next; } // 如果没有再 rehash，就没必要再去 ht[1] 中寻找了 if (!dictIsRehashing(d)) break; } return NULL; // 没找到，返回 NULL } 查找键值对 dictFind 过程跟 dictGenericDelete 一模一样， dictGenericDelete 还多了一个删除操作。\n4. 跳表 会有专门的一篇文章来讲。看这里：跳表原理以及 Golang 实现\n5. 整数集合 当一个集合中只包含整数，并且元素的个数不是很多的话，redis 会用整数集合作为底层存储，它的一个优点就是可以节省很多内存，虽然字典结构的效率很高，但是它的实现结构相对复杂并且会分配较多的内存空间。当然，当整数集合中的 元素太多(redis.conf 中 set-max-intset-entries=512) 或者 添加别的类型的元素是，整个整数集合会被转化成 字典。\n源码文件：intset.h\n5.1 数据结构 整数集合（intset） 是 Redis 用于保存整数值的集合抽象数据结构， 它可以保存类型为 int16_t 、 int32_t 或者 int64_t 的整数值， 并且保证集合中不会出现重复元素。\ntypedef struct intset { // 编码方式 uint32_t encoding; // 集合中包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; } intset; contents 数组中的元素按照从小到大的顺序排列，并且保证没有重复值；length 表示整数集合中包含的元素数量，即 contents 数组的长度。虽然 contents 数组的类型是 int8_t，但实际上并不保存 int8_t 类型的值，而是会根据实际 encoding 的值做出判断，比如 encoding = INTSET_ENC_INT16，那么数组的底层类型均为 int16_t ，整个数组中的元素类型都是 int16_t：\n/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 \u0026lt; INTSET_ENC_INT32 \u0026lt; INTSET_ENC_INT64. */ #define INTSET_ENC_INT16 (sizeof(int16_t)) // int16 16位 #define INTSET_ENC_INT32 (sizeof(int32_t)) // int32 32位 #define INTSET_ENC_INT64 (sizeof(int64_t)) // int64 64位 // 返回 v 对应的 encoding 值 static uint8_t _intsetValueEncoding(int64_t v) { if (v \u0026lt; INT32_MIN || v \u0026gt; INT32_MAX) return INTSET_ENC_INT64; else if (v \u0026lt; INT16_MIN || v \u0026gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16; } 下面是一个使用 INTSET_ENC_INT16 编码的、长度为 6 的整数集合：\n5.2 API 初始化 intset // 创建一个空的 intset intset *intsetNew(void) { // 为 intset 对象申请空间 intset *is = zmalloc(sizeof(intset)); // 默认使用 INTSET_ENC_INT16 作为存储大小 is-\u0026gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 数组长度为0，因为没有初始化的操作 is-\u0026gt;length = 0; return is; } 这里有一点需要注意，创建 intset 的时候并没有初始化 contents 数组，应为没必要。在常规情况下，访问数组是根据数组第一个元素地址加上类型大小作为偏移值读取，但是 intset 的数据类型依赖于 encoding，读取的时候通过 memcpy 按照 encoding 的值重新计算偏移量暴力读取的，属于 非常规操作数据，因此，刚开始没必要申请数组的空间，等添加一个元素时，动态扩容该元素的大小的内存即可。\n添加元素 我们先看代码：\n// 在 intset 中添加一个整数 intset *intsetAdd(intset *is, int64_t value, uint8_t *success) { uint8_t valenc = _intsetValueEncoding(value); // 根据要插入的 value 的类型 获取对应的 encoding uint32_t pos; if (success) *success = 1; // success = NULL if (valenc \u0026gt; intrev32ifbe(is-\u0026gt;encoding)) { // 插入元素的 encoding 值大于 intset 当前的，升级 return intsetUpgradeAndAdd(is,value); } else { // 插入元素的 encoding 值小于等于当前 intset 的，则找到这个 value 应该插入的位置，赋值给 pos，已经存在的话直接返回 if (intsetSearch(is,value,\u0026amp;pos)) { if (success) *success = 0; return is; } // 动态扩容 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 将 pos 位置后面的元素整体向后挪一位，给 pos 腾位置 if (pos \u0026lt; intrev32ifbe(is-\u0026gt;length)) intsetMoveTail(is,pos,pos+1); } // 将 pos 位置设置为 value _intsetSet(is,pos,value); // 更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } // 动态扩容，即将原来数组的容量 (is.length*encoding) 调整为 ((is.length+1)*encoding) static intset *intsetResize(intset *is, uint32_t len) { uint32_t size = len*intrev32ifbe(is-\u0026gt;encoding); is = zrealloc(is,sizeof(intset)+size); return is; } // 暴力迁移pos位置之后的数据，为pos位置挪出位置 static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) { // from = pos, to = pos+1 // src 表示 pos 相对于数组头部的迁移量 // dst 表示 pos下一个元素相对于数组头部的偏移量 void *src, *dst; // pos位置 距离数组末尾的元素个数，bytes*类型大小 即是pos后面的所有元素的总长度 uint32_t bytes = intrev32ifbe(is-\u0026gt;length)-from; // encoding uint32_t encoding = intrev32ifbe(is-\u0026gt;encoding); if (encoding == INTSET_ENC_INT64) { src = (int64_t*)is-\u0026gt;contents+from; dst = (int64_t*)is-\u0026gt;contents+to; bytes *= sizeof(int64_t); } else if (encoding == INTSET_ENC_INT32) { src = (int32_t*)is-\u0026gt;contents+from; dst = (int32_t*)is-\u0026gt;contents+to; bytes *= sizeof(int32_t); } else { src = (int16_t*)is-\u0026gt;contents+from; dst = (int16_t*)is-\u0026gt;contents+to; bytes *= sizeof(int16_t); } // 从 src 复制 bytes 个字符到 dst memmove(dst,src,bytes); } 整个过程可以简单总结为：先判断当前插入值的 encoding 是否超过了 intset 的，如果超过了，进行升级，升级 操作我们待会儿再看。没超过的话，需要找到当前元素应该插入的位置 pos ，查找 操作我们还是待会儿再看。之后是动态扩容，动态扩容的过程有：先将数组容量增加，之后将 pos 后面的元素整体移一位，最后将 value 值写入 pos 处。特别需要注意的是，将 pos 后面的元素整体后移一位 这一步，没有逐个移动元素，而是计算好 src 和 dst，直接调用 memmove 将 src 处的 bytes 个字符复制到 dst 处，这正是利用了 intset 数组非常规读取数组的特点。下面通过一个例子看一下插入的过程：\n升级 当插入的元素的类型比集合中现有所有元素的类型都要长时，需要先将数组整个升级之后，才能继续插入元素。升级 指的是 将数组类型变成和插入值类型相同的过程。\n升级过程大致可分为三个步骤：\n根据新元素类型，扩展底层数组的大小，并为新元素分配空间； 将底层数组的所有元素都转化成与新元素相同，并将转换后的元素放在合适的位置上，并且在防止的过程中，需要维持底层数组中数组顺序不变； 将新元素添加到新数组中 下面我们直接看代码：\nstatic intset *intsetUpgradeAndAdd(intset *is, int64_t value) { uint8_t curenc = intrev32ifbe(is-\u0026gt;encoding); // 当前 encoding uint8_t newenc = _intsetValueEncoding(value); // 插入元素的 encoding int length = intrev32ifbe(is-\u0026gt;length); // 插入到 数组最左边 还是 数组最右边。为什么会是最值？因为要升级，所以插入值肯定超出了现有 encoding 对应类型的最值，要么是负数越界，要么是正数越界 int prepend = value \u0026lt; 0 ? 1 : 0; // 首先，设置 intset 的 encoding 为插入元素的 encoding(更大的那个) is-\u0026gt;encoding = intrev32ifbe(newenc); // 根据新元素类型 扩展数组大小 is = intsetResize(is,intrev32ifbe(is-\u0026gt;length)+1); // 从数组最后一个元素开始遍历，将其放入合适的位置。prepend 的作用就是确保我们能给待插入值留下最左边的位置 或 最右边的位置 while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); // 在数组头部或者数组尾部插入 value if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-\u0026gt;length),value); // 最后更新 length is-\u0026gt;length = intrev32ifbe(intrev32ifbe(is-\u0026gt;length)+1); return is; } 通过一个例子说明升级的过程：\n注意：整数集合没有降级操作！一旦对数组进行了升级， 编码就会一直保持升级后的状态。\n查找 在 intset 中查找 value 是否存在，如果存在，返回 1，同时将 pos 值设置为数组的索引值；如果不存在，返回 0，同时将 pos 设置成应该存放的位置的索引值：\nstatic uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) { int min = 0, max = intrev32ifbe(is-\u0026gt;length)-1, mid = -1; int64_t cur = -1; // 当 intset 中没有元素时，直接返回 if (intrev32ifbe(is-\u0026gt;length) == 0) { if (pos) *pos = 0; return 0; } else { // 大于当前数组中最大值 或 小于最小值，也是直接返回 if (value \u0026gt; _intsetGet(is,max)) { if (pos) *pos = intrev32ifbe(is-\u0026gt;length); return 0; } else if (value \u0026lt; _intsetGet(is,0)) { if (pos) *pos = 0; return 0; } } // 因为数组有序，所以采用二分法查找位置是一个非常正确的选择 while(max \u0026gt;= min) { mid = ((unsigned int)min + (unsigned int)max) \u0026gt;\u0026gt; 1; cur = _intsetGet(is,mid); if (value \u0026gt; cur) { min = mid+1; } else if (value \u0026lt; cur) { max = mid-1; } else { break; } } if (value == cur) { // value 已经存在 if (pos) *pos = mid; return 1; } else { // value 不存在 if (pos) *pos = min; return 0; } } 5.3 总结 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 整数集合中的元素不能太对，当超过配置值后，会被转化成字典。 6. 压缩列表 压缩列表 是 Redis 自己实现的一个数据存储结构，有点类似数组，通过一片连续的空间存储数据，只不过数组的每个元素大小都相同，压缩列表允许每个元素有自己的大小。其核心思想，就是在一个连续的内存上，模拟出一个链表的结构。\n在源代码中有这么一段描述：\nThe ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist.\n大致意思是：ziplist 是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist 可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以 O(1) 的时间复杂度在表的两端提供 push 和 pop 操作。但由于每次操作都需要重新分配 ziplist 使用的内存，所以实际的复杂度与 ziplist 使用的内存量有关。\n源码文件：ziplist.h\n6.1 数据结构 ziplist 并没有实际的 struct 表示，但在 ziplist.c 中有如下描述：\nThe general layout of the ziplist is as follows:\n\u0026lt;zlbytes\u0026gt; \u0026lt;zltail\u0026gt; \u0026lt;zllen\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;entry\u0026gt; \u0026hellip; \u0026lt;entry\u0026gt; \u0026lt;zlend\u0026gt;\nzlbytes：本身占用 4 字节，整个压缩列表占用的总字节数(包括他自己) zltail：本身占用 4 字节，起始位置到最后一个结点的偏移量，用来快速定位最后一个元素，在反向输出压缩列表时会有用 zllen：本身占用 2 字节，压缩列表包含的元素个数 entry：元素内容。用数组存储，内存上紧挨着 zlend：本身占用 1 字节，压缩列表结束的标志位，一般为常量 0xFF 接下来看 entry 这个结构：\n\u0026lt;prevlen\u0026gt; \u0026lt;encoding\u0026gt; \u0026lt;entry-data\u0026gt;\nprevlen：1 字节或者 5 字节，表示前一个 entry 长度，在反向遍历的时候会有用 encoding：1、2 或 5 字节，表示当前 entry 的编码方式，表示当前 entry 的类型，integer 或 string entry-data：实际所需的字节数，结点真正的值，可以是 integer 或 string。它的类型和长度由 encoding 来决定 接下来我们详细关注这三个参数：\nprevlen 以字节为单位，记录前一个 entry 的长度。prevlen 的长度可以是 1 字节 或者 5 字节：\n当前一个结点的长度小于 254 字节时，prevlen 的长度为 1 字节，前一个 entry 的长度就保存在这一个字节中； 当前一个结点的长度大于等于 254 字节时，prevlen 的长度为 5 字节，其中第一个字节会被设置成 0xFE(十进制的 254)，表示这是一个 5 字节长 的 prevlen，后面的四个字节则保存前一个 entry 的长度。 prevlen 的作用是：在反向遍历压缩数组时，可以通过当前元素的指针，减去 prevlen ，就能得到前一个元素的地址。\nencoding 节点的 encoding 属性记录了节点的 entry-data 属性所保存 数据的类型 以及 长度：\n一字节、两字节或者五字节长， 值的最高位为 00 、 01 或者 10 的是字节数组编码： 这种编码表示节点的 content 属性保存着 字符串(字节数组)， 数组的长度由编码除去最高两位之后的其他位记录： 编码 编码长度 content 中保存的值 00bbbbbb 1 字节 长度小于等于 63 字节的字节数组(6 位分辨位，2^6 = 64，除去全 0 的) 01bbbbbb | xxxxxxxx 2 字节 长度小于等于 16383 字节的字节数组(14 位分辨位，2^14 = 16384，除去全 0 的) 10000000 | xxxx…xxxx(32 位) 5 字节 长度小于等于 4294967295 字节的字节数组(32 位分辨位，2^32 = 4294967296) 一字节长， 值的最高位以 11 开头的是整数编码： 这种编码表示节点的 entry-data 属性保存着整数值， 整数值的类型和长度由编码除去最高两位之后的其他位记录: 编码 编码长度 entry-data 中保存的值 11000000 1 字节 int16_t 类型整数 11010000 1 字节 int32_t 类型整数 11100000 1 字节 int64_t 类型整数 11110000 1 字节 24 位有符号整数 11111110 1 字节 8 位有符号整数 1111xxxx 1 字节 使用这一编码的节点没有相应的 entry-data 属性， 因为编码本身的 xxxx 四个位已经保存了一个介于 0 和 12 之间的值， 所以它无须 entry-data 属性。 entry-data 节点的 entry-data 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。\n6.2 API 创建ziplist 返回一个只包含 \u0026lt;zlbytes\u0026gt;\u0026lt;zltail\u0026gt;\u0026lt;zllen\u0026gt;\u0026lt;zlend\u0026gt; 的 ziplist：\nunsigned char *ziplistNew(void) { unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; // 头部的 4+4+2 和 尾部的1 总共 11 字节 unsigned char *zl = zmalloc(bytes); // 这里的ziplist类型是一个 char 数组，而不是某个具体的结构体 ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); // 设置 zlbytes 为 初始分配的值，即 bytes ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); // 设置 zltail 为 header 结束的地方 ZIPLIST_LENGTH(zl) = 0; // 设置 zllen 为 0 zl[bytes-1] = ZIP_END; // 最后一个字节存储常量 255 ，表示 ziplist 结束 return zl; } 插入ziplistInsert 这个函数的作用是 在 ziplist 的任意数据项前面插入一个新的数据项：\nunsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { return __ziplistInsert(zl,p,s,slen); } // 在 p 处 插入 s，s 的长度为 slen；插入后s占据p的位置，p及其后面的数据整体后移。其中 p 指向 ziplist 中某一个 entry 的起始位置，或者 zlend(当向尾部插入时) unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) { // reqlen 表示 将 s 变成一个 entry 所需要的总字节数，即 prevlen,encoding,entry-data 的总长度 size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; // 随便使用一个一眼就能看出来的值表示当前变量未被逻辑初始化，避免 warning zlentry tail; if (p[0] != ZIP_END) { // 如果不是插入尾部，则根据p获取 p所在的 entry 的前一个 entry 的 prevlen，需要保存 prevlen的字节数保存在 prevlensize(1字节或者5字节，前面有介绍) ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); } else { // p 指向的是 尾部标志 unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) { // 获取 ziplist 最后一个 entry 的长度，保存在 prevlen 中 prevlen = zipRawEntryLength(ptail); } } // 尝试能否转化成整数 if (zipTryEncoding(s,slen,\u0026amp;value,\u0026amp;encoding)) { // 可以转化成 int，则 reqlen 即为存储此 int 所需的字节数，即 entry-data 的长度 reqlen = zipIntSize(encoding); } else { // 无法转换成 int，那就是字节数组，reqlen 就是要存入的字符串的长度，即 entry-data 的长度 reqlen = slen; } // reqlen reqlen += zipStorePrevEntryLength(NULL,prevlen); // 再加上 prevlen 的长度 reqlen += zipStoreEntryEncoding(NULL,encoding,slen); // 再加上 encoding 的长度 // 当不是向尾部插入时，我们必须确保下一个 entry 的 prevlen 等于当前 entry 的长度 int forcelarge = 0; // 【1】nextdiff 存储的是p的prevlen的变化值(新元素长度reqlen - p之前entry的prelen)，具体解释看代码后面【1】处的解释 nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 \u0026amp;\u0026amp; reqlen \u0026lt; 4) { nextdiff = 0; forcelarge = 1; // 这种情况下意味着，本来可以用 1 字节的，却使用了 5 个字节 } /* Store offset because a realloc may change the address of zl. */ // 存储 p 相对于 ziplist 的偏移量，因为 resize 可能改变 ziplist 的起始地址 offset = p-zl; // 到这一步已经能确定 ziplist 需要的总的容量了，调用 resize 调整 ziplist 的大小 zl = ziplistResize(zl,curlen+reqlen+nextdiff); // 重新定位 p p = zl+offset; // 将 p 以及其后面的数据移动为 s 挪地方，别忘了更新 zltail 的值 if (p[0] != ZIP_END) { // 在p前面腾出reqlen字节给新entry使用（将p move到p+reqlen，考虑了prelen缩减或增加） memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); // 更新 s 的后一个 entry（p+reqlen即p的新地址）的prevlen； if (forcelarge) // 【2】强制使用 5 字节存储，避免连锁更新时的大量重新分配空间操作，不进行缩容 zipStorePrevEntryLengthLarge(p+reqlen,reqlen); else // 计算 reqlen 进而判断使用 1 字节 还是 5 字节 zipStorePrevEntryLength(p+reqlen,reqlen); // 更新 zltail ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); // 更新zltail zipEntry(p+reqlen, \u0026amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); } } else { // 如果是在尾部插入，则直接修改 zltail 为 s ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); } // 如果 nexydiff 不等于0，整个 s 后面的 ziplist 的 prevlen 都可能发生变化，这里尝试进行维护 if (nextdiff != 0) { offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; // 改变的只是 p 后面的，前面的没变，因此 s 插入的位置没变 } // 存入 s 这个 entry p += zipStorePrevEntryLength(p,prevlen); p += zipStoreEntryEncoding(p,encoding,slen); if (ZIP_IS_STR(encoding)) { memcpy(p,s,slen); } else { zipSaveInteger(p,value,encoding); } // ziplist 的长度加 1 ZIPLIST_INCR_LENGTH(zl,1); return zl; } // 将 ziplist 的长度变成 len unsigned char *ziplistResize(unsigned char *zl, unsigned int len) { zl = zrealloc(zl,len); ZIPLIST_BYTES(zl) = intrev32ifbe(len); zl[len-1] = ZIP_END; return zl; } 解释【1】：这种情况发生在 插入的位置不是尾部 的情况，我们假设 p 的前一个元素为 p0，此时 p 的 prevlen 存储的是 p0 的长度。但是由于要将 s 插入到 p 之前，那么 p 的 prevlen 的值就应该变成 s 的长度，这样 p 本身的长度也就发生了变化，有可能变大也有可能变小。这个变化了多少的值就是 nextdiff，如果变大了，nextdiff 是正数，否则是负数。如果是负数，只有一种情况，那就是 p0 的长度大于 254，用 5 个字节存；而 s 的长度小于 254，用 1 个字节存就够了。\n解释【2】：关于 forcelarge，这是一个已经被修改后的 bug，大致意思是，这种操作发生在 连锁更新(90 行) 的时候，为了防止大量的重新分配空间的动作，如果一个 entry 的长度只需要 1 个字节就能够保存,但是连锁更新时如果原先已经为 prevlen 分配了 5 个字节,则不会进行缩容操作。关于为何，可以参考这篇文章：Redis 的一个历史 bug 及其后续改进，作者对这个 bug 进行了复现，以及提到了 Redis 对此作出的更新(提出了更优化的结构 listpack)。\n我们接着说 连锁更新。回忆一个 entry 的结构，其中 prevlen 表示前一个 entry 的长度：如果前一个结点长度小于 254，则 prevlen 占用 1 字节，否则占用 5 字节。现在， 考虑这样一种情况： 在一个压缩列表中， 有多个连续的、长度介于 250 字节到 253 字节之间的节点 e1 至 eN 。因为 e1 至 eN 的所有节点的长度都小于 254 字节， 所以记录这些节点的长度只需要 1 字节长的 prevlen 属性， 换句话说， e1 至 eN 的所有节点的 prevlen 属性都是 1 字节长的。此时，如果我们在 e1 前面插入一个长度大于 254 的元素 m，因为 e1 的 prevlen 仅为 1 字节，无法保存大于 254 的数，因此，我们还要对 ziplist 进行空间重分配操作，使得 e1 能够保存 m 的长度，即将 ziplist 的大小再增加 4 字节，让 e1 的 prevlen 大小由 1 字节变为 5 字节，这种操作我们称为 m 对 e1 发生了 扩展。回到刚才的情况，现在麻烦来了，e1 大小发生了变化，肯定超过了原来的 254，此时 e1 需要对 e2 进行扩展，又到后面，e2 需要对 e3 进行扩展……程序需要不断地对压缩列表执行空间重分配操作， 直到 eN 为止。\nRedis 将这种在特殊情况下产生的连续多次空间扩展操作称之为 “连锁更新”（cascade update）。我们看看 连锁更新 的具体实现：\n// p 指向第一个不需要更新的 entry unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) { size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; // 当 p 是 ziplist 的”尾巴“时停止更新 while (p[0] != ZIP_END) { zipEntry(p, \u0026amp;cur); // 【1】将 entry 解码称为一个易于操作的 entry 结构体，细节见代码后解释 rawlen = cur.headersize + cur.len; // 当前节点的长度 rawlensize = zipStorePrevEntryLength(NULL,rawlen); // 存储当前节点所需要的 prevlen 大小 // 没有下一个节点，直接返回 if (p[rawlen] == ZIP_END) break; // 获取 p 的下一个节点 zipEntry(p+rawlen, \u0026amp;next); // 如果下一个节点的 prevlen 等于当前节点的 长度，则没必要更新，直接退出循环 if (next.prevrawlen == rawlen) break; // 下一个节点的 prevlen 小于当前节点的长度(当前节点长度为 5 字节，next 的 prevlen 为1 字节) if (next.prevrawlensize \u0026lt; rawlensize) { // ziplist的地址可能发生改变，先记录 p 相对于zl起始位置的偏移量 offset = p-zl; // 额外需要申请的空间 5 - 1 = 4 extra = rawlensize-next.prevrawlensize; // 改变 ziplist 的容量 zl = ziplistResize(zl,curlen+extra); // 重新计算 p 的位置 p = zl+offset; /* Current pointer and offset for next element. */ np = p+rawlen; // next 的新地址 noffset = np-zl; // next新地址相对于 ziplist 头部的偏移量 // 更新 zltail if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) { ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra); } // 扩展 next 的 prevlen，并将数据拷贝 memmove(np+rawlensize, np+next.prevrawlensize, curlen-noffset-next.prevrawlensize-1); // 在扩展后的 next 的 prevlen 中重新记录 p 的长度 zipStorePrevEntryLength(np,rawlen); /* Advance the cursor */ // 更新 p 为下一个 entry p += rawlen; // 更新 p 的长度(需要加上扩展的 prevlen 的 extra 个字节) curlen += extra; } else { // 这种情况下，next 的 prevlen 足够表示 当前 p 的长度 if (next.prevrawlensize \u0026gt; rawlensize) { // next 的 prevlen \u0026gt; p 的长度(next.prevlen = 5 结点，p的长度小于 5 个结点)，此时应该 缩容，但出于性能以及操作的方便性(减少后续连锁更新的可能性)，我们通常不进行缩容，这个时候，直接将 next 的 prevlen 设置为 5 个结点 zipStorePrevEntryLengthLarge(p+rawlen,rawlen); } else { // 相等 zipStorePrevEntryLength(p+rawlen,rawlen); } // next 的长度并没有发生变化(没有缩容)，终止循环 break; } } return zl; } 解释【1】：“辅助结构体” zlentry，这个结构体与 ziplist 中的一个实际 entry 相对应，其作用是为了更加方便地操作一个 实际的 entry：\ntypedef struct zlentry { unsigned int prevrawlensize; // 存储 prevrawlen 所需要的字节数，同样也有 1字节 和 5字节之分 unsigned int prevrawlen; // 对应 prevlen unsigned int lensize; // 存储 len 所需要的字节数 unsigned int len; // 当前 entry 的长度 unsigned int headersize; // ziplist头部大小: prevrawlensize + lensize unsigned char encoding; // 编码方式 unsigned char *p; // 指向某个实际 entry 的地址 } zlentry; 其他的一些操作，比如删除、查找，过程与插入类似，无非就是各个 entry 地址的计算，删除时还有可能涉及到连锁更新。 这里不再描述，想了解的可以根据上面的思路自己研究源代码。\n6.3 总结 ziplist是 redis 为了节省内存，提升存储效率自定义的一种紧凑的数据结构，每一个 entry 都保存这上一个 entry 的长度，可以很方便地进行反向遍历； 添加和删除节点可能会引发连锁更新，极端情况下会更新整个ziplist，但是概率很小； 在 Redis 中，当元素个数较少时，哈希表(hset 等操作) 和 列表(lpush 等操作) 的底层结构都是 ziplist。 7. 紧凑列表 源码文件：listpack.h\n实现文档：Listpack specification\n紧凑列表是 压缩列表 的升级版，目的是在未来代替 ziplist。\n有时间再完善。\n二、 Redis 对象对应的数据结构 前面大致介绍了 简单动态字符串 sds、双端链表 adlist、字典 dict、跳表 skiplist、整数集合 intset 和 压缩列表 ziplist 等基础数据结构，同时我们知道 Redis 中有 字符串对象(string)、列表对象(list)、哈希对象(hash)、集合对象(set) 和 有序集合对象(zset) 等五种对象，他们都至少用了上面一种基础数据结构来实现。在 Redis 中，客户端的一条命令以及参数会被解释成一个 robj 结构体：\n源码文件： server.h\ntypedef struct redisObject { unsigned type : 4; // 类型 unsigned encoding : 4;\t// 编码 unsigned lru : LRU_BITS; // 对象最后被访问的时间，我们暂时不关注 LRU int refcount;\t// 引用次数 void *ptr;\t// 指向实现对象的数据结构 } robj; /* Object types */ #define OBJ_STRING 0 /* String object. */ #define OBJ_LIST 1 /* List object. */ #define OBJ_SET 2 /* Set object. */ #define OBJ_ZSET 3 /* Sorted set object. */ #define OBJ_HASH 4 /* Hash object. */ /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The \u0026#39;encoding\u0026#39; field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 // 简单动态字符串 sds #define OBJ_ENCODING_INT 1 // long 类型 #define OBJ_ENCODING_HT 2 // 字典 dict #define OBJ_ENCODING_ZIPMAP 3 // zipmap(弃用) #define OBJ_ENCODING_LINKEDLIST 4 // 双端链表 adlist #define OBJ_ENCODING_ZIPLIST 5 // 压缩列表 ziplist #define OBJ_ENCODING_INTSET 6 // 整数集合 intset #define OBJ_ENCODING_SKIPLIST 7 // 跳表 skiplist #define OBJ_ENCODING_EMBSTR 8 // 采用embstr编码的sds #define OBJ_ENCODING_QUICKLIST 9 // qunicklist，用于列表 #define OBJ_ENCODING_STREAM 10 // 紧凑列表 listpack #define LRU_BITS 24 obj 的作用大致为：\n为多种数据类型提供一种统一的表示方式。 允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。 支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。 说到底， robj 所表示的就是 五种 Object types 和 11 中 Object encoding 之间的对应方式，起到一个桥梁作用。这种对应关系可用如下的图来表示：\n","permalink":"http://localhost:1313/posts/redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-1-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1/","summary":"\u003cp\u003e首先明确，\u003ccode\u003eRedis\u003c/code\u003e 是一个\u003cstrong\u003e使用 C 语言编写的键值对存储系统\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 是众所周知的 “\u003cstrong\u003e快\u003c/strong\u003e”，一方面，它是一个内存数据库，所有的操作都是在\u003cstrong\u003e内存\u003c/strong\u003e中完成的，内存的访问速度本身就很快；另一方面，得益于它\u003cstrong\u003e底层的数据结构\u003c/strong\u003e。\u003ccode\u003eRedis\u003c/code\u003e 的常见类型可在这个网页找到：\u003ca href=\"https://redis.readthedocs.io/en/2.4/index.html\"\u003eRedis 命令参考简体中文版\u003c/a\u003e，其使用到的底层数据结构有如下六种：\u003cstrong\u003e简单动态字符串\u003c/strong\u003e、\u003cstrong\u003e双向链表\u003c/strong\u003e、\u003cstrong\u003e压缩列表\u003c/strong\u003e、\u003cstrong\u003e哈希表\u003c/strong\u003e、\u003cstrong\u003e跳表\u003c/strong\u003e和 \u003cstrong\u003e整数数组\u003c/strong\u003e。本篇文章，将具体了解这些底层数据结构的实现。\u003c/p\u003e","title":"Redis源码阅读--1.基础数据结构与对象"},{"content":"一、常见的索引类型 1. 哈希索引 哈希索引(Hash Index) 基于哈希表实现，只适合精确匹配，不适合范围查找。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算哈希code，通过 K-V 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\n使用哈希索引，有一点需要注意：如何解决哈希冲突？就目前而言，大多数使用 “链接法”——冲突之后，在原来的位置添加一个链表结构，多个冲突值通过链表的形式保存；当查询的时候，通过哈希 code 定位到对应的链表，之后遍历链表，直到找到符合条件的。\n借用《高性能 MySQL》中实例：\n哈希索引的特点：\n哈希索引只包含哈希值和行指针，不存储字段值。因此无法使用覆盖索引等相关特性； 哈希索引并不按照索引值顺序存储，因此不适合排序操作； 哈希索引不支持部分索引列匹配查找，因为计算哈希时，始终使用的是索引列的全部内容。例如，在数据列\u0026lt;A, B\u0026gt;上建立哈希索引，如果查询的只有\u0026lt;A\u0026gt;，那么无法使用该索引，因为 hash(\u0026lt;A, B\u0026gt;) 和 hash(\u0026lt;A\u0026gt;) 的结果一点关系都没有； 哈希索引只支持等值比较( =、IN()和 \u0026lt;=\u0026gt;(效果等同于等号，不过可以比较 NULL))，不支持任何的范围查询(比如 BETWEEN、\u0026lt; 等)； 访问哈希索引的速度非常快，除非出现很多的哈希冲突，此时的查询会退化成链表的遍历； 如果哈希冲突很多的话，索引的维护代价将会非常高，此时对索引的增删改，回退化成对链表的增删改，**O(n)**的时间复杂度。 创建自定义的哈希索引：\n通过一个实例来说明：\n提出问题：假如我们要存储大量的URL，同时还有通过 URL 查询该条记录的需求，应该如何建立索引？ 调研：如果直接在 URL 上建立索引，那么索引会很长，并且很大 解决方案：删除原来 URL 上的索引，新增一个被索引的 url_crc 列，存储 URL 列被 CRC32 之后的值，之后的查询可通过这个索引来查。缺点是还要花时间维护这个索引列。 # 建表 CREATE TABLE url_demo ( id int unsigned NOT NULL auto_increment, url varchar(255) NOT NULL, url_crc int unsigned NOT NULL DEFAULT 0, PRIMARY KEY(id) ); # 为了减少维护工作，可以创建一个触发器 DELIMITER // CREATE TRIGGER url_demo_crc_ins BEFORE INSERT ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; CREATE TRIGGER url_demo_crc_upd BEFORE UPDATE ON url_demo FOR EACH ROW BEGIN SET NEW.url_crc=crc32(NEW.url); END; // DELIMITER ; # 之后可验证增删改查 INSERT INTO url_deml(url) VALUES(\u0026#34;https://www.baidu.com\u0026#34;); SELECT * FROM url_demo; +----+-----------------------+------------+ | id | url | url_crc | +----+-----------------------+------------+ | 1 | https://www.baidu.com | 3010065587 | +----+-----------------------+------------+ UPDATE url_demo SET url=\u0026#34;https://www.google.com\u0026#34; WHERE id=1; SELECT * FROM url_demo; +----+------------------------+-----------+ | id | url | url_crc | +----+------------------------+-----------+ | 1 | https://www.google.com | 857627499 | +----+------------------------+-----------+ # 查询某个具体的URL时，必须使用下面的查询方法： SELECT * FROM url_demo WHERE url_crc=CRC32(\u0026#34;https://www.google.com\u0026#34;) AND url=\u0026#34;https://www.google.com\u0026#34;; 2. B-Tree 索引 当人们谈论索引时，如果没有特别指明类型，那多半说的是 B-Tree 索引。它使用 B 树(部分引擎使用 B+树)作为底层的数据结构，这通常意味着被索引的值都是按顺序存储的(首先是个 二叉排序树)，并且每一个叶子节点到根节点的举例相同(变形的 多叉排序树)。树的深度和表的大小直接相关。\n假如我们有如下数据表：\nCREATE TABLE people ( last_name varchar(64) NOT NULL, first_name varchar(64) NOT NULL, dob date NOT NULL, gender enum(\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;) NOT NULL, key(last_name, first_name, dob) ); 下图显示了该索引时如何组织数据的：\n以下情况，索引(key(last_name, first_name, bob))是有效的：\n全值匹配：指查询的列和索引中的列完全匹配(字段以及对应的字段顺序)，例如 SELECT * FROM people WHERE last_name= ‘Allen’ AND first_name = 'Cuba' AND bob = '1960-01-01'； 最左前缀匹配：索引的顺序非常重要： 可以匹配所有last_name = ‘Allen’的人，因为 last_name 是索引列中最左边的； 可以只匹配某一列的值得开头部分，如 last_name 全部以 K 开头，即 last_name like 'K%’，注意，这里也是针对最左边的列； 可以匹配 last_name 在 Allen 和 Barrymore 之间的人，即 last_name \u0026gt; ‘Allen’ AND last_name \u0026lt; 'Barrymore’，这里也是针对最左边列； 精准访问某一列并范围匹配另一列：例如第一列last_name全匹配，第二列first_nbame 范围匹配；或者last_name和first_name全匹配，第三列bob范围匹配。 只访问索引的查询：即 覆盖索引。即select的字段就属于索引列，而不用通过“回表”再拿一次。关于覆盖索引，后面会详细介绍。 以下情况，索引会失效（即不会使用之前创建的索引 key(last_name, first_name, bob)）：\n单独列非最左列，索引失效，即 如果不是按照索引的最左列开始查找，无法使用索引。例如：无法查找 WHERE first_name = ‘Bill’；例如 WHERE bob = '1960-01-01’；例如 WHERE first_name like 'K%'。因为查询的列都不是该索引的最左列。同理，WHERE last_name like '%L’也会失效。 跳过某一列，索引失效。即 WHERE last_name='Allen' AND bob='1960-01-01’也不会使用该索引，因为跳过了列first_name。 某列范围查询，右边所有列无法使用索引优化查询。如 WHERE last_name='Allen' AND first_name like ‘J%’ AND bob='1960-01-01’，那么 bob 列无法使用索引优化查询，因为中间的first_name LIKE是一个范围条件。 如果使用B-Tree，创建多列索引时，列的顺序非常重要！\n二、高性能的索引策略 正确地创建和使用索引是实现高性能查询的基础。下面介绍如何正确地运用索引。\n1. 查询时，索引列单独放在比较符号的一侧 如果查询中的列不是独立的，则 MySQL 不会使用索引。 独立的列 是指索引列不能是表达式的一部分，也不能是函数的参数。\n下面这个查询就无法使用score列的索引：\nSELECT * FROM student WHRER score + 1 = 90; 我们都知道上述查询中表达式的值是 89，但是MySQL 无法解析这个方程式。我们应该养成简化 MySQLWHERE条件的习惯，始终将索引列单独放在比较符号的一侧。\n2. 前缀索引和索引选择性 索引选择性是指 不重复的索引数(I) 和 数据表的记录总数(S) 的比值，即 $I/S$，根据其计算方式可知，$I/S \u0026lt;= 1$，并且索引选择性越高，查询性能越高，因为索引选择性高的索引可以让 MySQL 在查询的时候 过滤掉更多行。单一列的索引的选择性是 1，是最好的。\n既然单一列的索引选择性是最好的，我们为什么还要讨论这个问题？想一下要对 某一些很长的列建立索引，这时索引会变的非常大，有可能出现索引文件远大于数据文件的情况。这个时候对整个字段建立索引就显得不太明智，此时索引选择性可以作为一个辅助工具，帮助我们 选择足够长的前缀以保持较高的选择性，同时又不能太长。\n如何选择合适的前缀长度？方法是 计算完整列的选择性，然后逐个计算前缀的选择性，选择最接近完整列的那一个。\n假如完整列的选择性为 0.0312，而不同前缀长度对应的选择性结果为：\n当长度大于 7 时，再增加前缀长度，性能提升的幅度就已经很小了。于是建立索引：\nALTER TABLE demo ADD KEY(city(7)); 优点：使索引又快又小的这种方法；\n缺点：无法使用前缀索引进行 GROUP BY 和 ORDER BY，也无法进行覆盖扫描(覆盖索引)。\n3. 多列索引 我们经常会听到有人说“把 WHERE 条件里面的列都建上索引”这种模糊的建议，但事实上，如果不从实际出发，大多数情况下，在多个列上简历单独的索引并不能提高 MySQL 的查询性能。\nMySQL 5.0 之后引入了一种叫 索引合并(Index Merge) 的策略，一定程度上可以提高多个单列索引查询时的性能。\n关于 索引合并 ，看这篇文章：索引合并\n在以下情况下，建议使用多列索引而不是在每个单独列上建立索引：\n当出现对多个索引做相交操作时(通常是多个 AND 操作)，这通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引； 当出现对多个索引做联合操作时(通常是多个 OR 操作)，通常需要耗费大量的 CPU 和内存用以对结果的缓存、归并和排序上，特别是某些索引的选择性不高时，需要合并扫描大量的数据。 4. 选择合适的列顺序 当使用 B-Tree 索引时，由于其“最左匹配”的性质，索引列的顺序往往意味着索引首先按照最左列进行排序，然后是第二列。对于如何选择多列索引的顺序，有一个经验法则： 将选择性最高的列放在索引最前列。\n5. 聚簇索引 MySQL 的 InnoDB 索引数据结构是 B+树，主键索引叶子节点的值存储的就是 MySQL 的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提。\n首先，用一句话解释什么是聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引。所以主键就是聚簇索引。\n对应地，什么是非聚簇索引？也称二级索引，索引的存储和数据的存储是分离的，在 InnoDB 引擎中，二级索引中存储的是主键值，先通过查找二级索引得到对应的主键值，再通过主键值回表查询需要的字段。\n二级索引使用主键值当做行的指针，会让二级索引占用更多的空间，换来的好处是，InnoDB 在移动行时无需更新索引中的这个指针——这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。\n在 InnoDB 中，主键一定是聚簇索引，InnoDB 一定有主键(如果没有手动设定，InnoDB 会默认创建一个)，并且一张表只允许有一个聚簇索引。\n建议：InnoDB 中应该尽可能按照主键的顺序去插入数据，一般使用一个递增的 bigint 类型 作为主键。最差的情况是使用值完全随机的列如 UUID 作为主键！\n6. 覆盖索引 前面提到过，InnoDB 中，非聚簇索引所存储的值为主键值，要想获得其他列的值，还要进行一个被称为 “回表” 的操作——也就是说，使用非聚簇索引查询更多列，要进行两次查询。但是想一想，如果我们差的刚好就是主键 id，如 SELECT id FROM student WHERE name='Tom';，此时我们需要的列就在二级索引中，不需要再执行“回表”操作，这个操作，可以极大地提高性能。\n如果一个索引包含(或者说 覆盖) 所有查询的字段的值，我们就称为**“覆盖索引”**。\n为什么覆盖索引能提高性能？因为减少了“回表”的操作，减少了很多次随机 IO。\n7. 学会使用 EXPLAIN 在需要执行的 SQL 语句前面加上EXPLAIN，可以查询和分析这条 SQL 语句的执行记录，对我们优化查询效率有很大的帮助。\n先看一个EXPLAIN的示例：\nmysq\u0026gt; explain select * from city\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: city partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 366 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 其他的几个列暂时不考虑，只对 type 和 EXTRA 做记录：\ntype 关联类型，或访问类型——MySQL 如何查找表中的行。以下按照从最差到最优的方式介绍：\nALL： 全表扫描。 index：按照索引次序扫描。跟全表扫描一样，只不过扫描时按照索引顺序进行而不是按照每一行。它的优点是：避免了排序操作。缺点是：要承担按索引次序读取整个表的开销(如果是非聚簇索引，那么索引次序是有序的，但存储的主键不一定是有序的，回表的时候进行的就是随机 IO，此时开销会更大，还不如 ALL)。如果在EXTRA列中看到“Using index”，说明 MySQL 正在使用覆盖索引。 range：范围扫描，即带有WHERE或BETWEEN或\u0026lt;等比较符号的查询语句。比全表扫描好一些，因为不需要遍历全部索引，只需要从满足条件的行开始计算。开销与index相同。 ref：非主键 非唯一索引 等值查找。 eq_ref：主键索引 或 非空唯一索引 进行等值查找。 cost：常量连接，表最多只有一行匹配，通常用于 主键 或者 唯一索引 进行等值比较。 system：系统表，少量数据，往往不需要进行磁盘 IO (可以当成 cost 连接的特例) extra extra 表示 MySQL 如何解析这条查询，参数更多地显示一些关于索引的信息。它的最常用的选值如下：\nusing index：表示本次查询将使用 覆盖索引，避免了 回表 的操作，即 where 筛选条件是索引的前导列 并且 select 选择的列被索引覆盖，没有 回表 操作。 using where：限制了哪一行，也就是说，读取结束之后使用了 Table Filter 进行了过滤。不管查询条件有没有覆盖索引，只要筛选条件没有使用索引，就会有 using where。 using where; using index：查询的列被索引覆盖，但是 筛选条件不是前导列 或者 筛选条件是前导列但是使用了范围查询。 NULL：查询的列未被索引覆盖，但是筛选条件使用了索引的前导列。这种情况意味着用到了索引，但是 select 的字段没有被索引覆盖，因此还要进行 回表 操作，“不是纯粹地使用索引，也没有完全用到索引”，所以为 NULL(没有信息)。 using index condition：查询的列没有被索引全部覆盖，筛选条件使用了索引的前导列的范围查询 或者 查询条件使用到了索引但还有一些别的条件。 上面的这些情形可用如下的表格总结：\n","permalink":"http://localhost:1313/posts/mysql%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95/","summary":"\u003ch2 id=\"一常见的索引类型\"\u003e一、常见的索引类型\u003c/h2\u003e\n\u003ch3 id=\"1-哈希索引\"\u003e1. 哈希索引\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e哈希索引(Hash Index)\u003c/strong\u003e 基于哈希表实现，\u003cstrong\u003e只适合精确匹配，不适合范围查找\u003c/strong\u003e。对于每一行数据，存储引擎都会使用一个哈希函数，对改行的对应索引列计算\u003ccode\u003e哈希code\u003c/code\u003e，通过 \u003cstrong\u003eK-V\u003c/strong\u003e 的形式保存起来，其中“K”为哈希 code，“V”是指向改行记录的指针。\u003c/p\u003e","title":"MySQL关于索引"},{"content":"1. 堆排序 堆 是一种数据结构，它具有如下特征：\n是一棵完全二叉树 父节点的值 \u0026gt; 子节点的值 1.1 完全二叉树 若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是 完全二叉树。\n完全二叉树有一个很重要的特点，它的元素可以全部放在一个数组中，这个数组中的元素排列非常紧密，不会出现零值的情况。比如下面这棵树，对应的数组为： [25, 14, 13, 4, 2, 10]。\n如果我们从上到下、从左到右的顺序去遍历这棵树，会发现，元素顺序与数组中完全对应。于是会有下面的公式：\n设数组中父节点的 index 值为i，则左孩子的 index 值为 2*i+1，右孩子的 index 值为 2*i+2。这样数组和数的关系就对应上了。这是堆排序的基础。\n1.2 heapify 我们称 将一棵树变成堆的过程 称为 heapify。具体来说是将 parent、left 和 right这三个结点，通过交换，使得 parent 为最大(left和right哪个大没关系)，因为数的定义是递归的，所以上面这个交换过程也是递归的。此时需要决定的是从下到上，还是从上到下。答案是如果是大根堆，从下到上进行 heapify 过程，因为从上到下的，处理完父节点，还不确定这个父节点是不是就是整个堆中的最大，而从下到上可以看成是一个不断往上 “喂” 最大值的过程。可以写出代码：\n// heapify 从数组的第i个元素为父节点，使其符合大根堆的特性。前提，左右子树均已经是大根堆了 func heapify(arr []int, n int, i int) { if i \u0026gt;= n { return } // 第i个结点的左右孩子分别为 left := 2*i + 1 right := 2*i + 2 // 求得父节点、左孩子、右孩子之间的最大值 maxIndex := i if left \u0026lt; n \u0026amp;\u0026amp; arr[left] \u0026gt; arr[maxIndex] { maxIndex = left } if right \u0026lt; n \u0026amp;\u0026amp; arr[right] \u0026gt; arr[maxIndex] { maxIndex = right } // 如果发生了交换，需要递归去处理对应的子树 if maxIndex != i { // 交换 使得parent为最大的那个 arr[i], arr[maxIndex] = arr[maxIndex], arr[i] //fmt.Println(arr[maxIndex], arr[left], arr[right]) // 此时，修改了原来的结构，为了保证交换后的子树也继续是大根堆，这里递归调用调整子树 heapify(arr, n, maxIndex) } } 1.3 build heap 当我们从下到上构建一个大根堆的时候，没必要从最后一个元素开始，需要从最后一个有孩子的父节点开始，所以第一步是先找到 最后一个有孩子的父节点。方法很简单，找到最后一个孩子，再根据他们之间的关系很容易就能求得其父节点的索引值。之后遍历所有的有孩子的节点，即剩下的 13 , 14, 25，这三个元素刚好按照数组索引的顺序递减，因此可以写出代码：\n// buildHeap 从底向上构建大根堆 func buildHeap(arr []int) { n := len(arr) parent := (n - 1 - 1) / 2 // n-1为数组最后一个元素的index，其父节点为 ((n-1) - 1) / 2 for i := parent; i \u0026gt;= 0; i-- { // 从这个父节点开始，一直到第一个元素，从下到上构建不断heapify heapify(arr, n, i) } } 1.4 heap sort 构建出大根堆之后，堆顶(也就是数组index=0)的元素就是最大值。此时，我们将数组第一个元素和最后一个元素交换位置，之后缩小数组长度再次从头到尾进行 heapify ，之后再交换，最后的结果就是 数组从尾巴到头的元素一次递减。\nfunc heapSort(arr []int) { buildHeap(arr) // 构建大根堆 // 最后一个元素 与 第一个元素(最大)交换，之后再次heapify，再交换，结果就是从尾到头数值依次减小 for i := len(arr) - 1; i \u0026gt;= 0; i-- { arr[0], arr[i] = arr[i], arr[0] heapify(arr, i, 0) } } 2. 插入排序 它的工作原理是构建有序序列，对于未排序的数据，在已经排好序的序列中从后向前扫描，放入合适的位置。\n优点是：对近乎有序的一组数排序，其时间复杂度可以接近线性。 这个特性非常重要！谨记！！\n步骤：\n第一步，将第一个元素看成有序序列，第二个元素到最后一个元素看成未排序的序列； 从头到尾扫描未排序的序列，将这个元素插入到前面的有序序列的合适位置。为了 稳定性 的目的，如果某个元素和有序序列中的某个元素相同，应该将这个元素放在有序序列元素的后面。 // insertionSort 插入排序 func insertionSort(arr []int) { sortedIndex := 0 // 有序序列的最后一个元素 // 遍历所有的未排序元素 for i := sortedIndex + 1; i \u0026lt; len(arr); i++ { // 从当前元素开始向前遍历有序序列 for j := i; j \u0026gt; 0; j-- { // 当前值大于等于前面的，终止循环 if arr[j-1] \u0026lt;= arr[j] { break } // 如果当前值比前一个小，交换，之后循环再不断交换 arr[j-1], arr[j] = arr[j], arr[j-1] } } } 3. 希尔排序 是插入排序的改进版本，更高效一些，但是它是不稳定的。具体步骤如下：\n以 gap 为间隔分组 分好的组内内部排好序 降低 gap，重复上述步骤，直到 gap 变成 1，此时变成对整个数组进行排序 有一个问题，组内排序，采用什么方法？答案是 插入排序法，原因就是，在 gap 不断减小的过程中，数组主键接近有序，此时借助插入排序的优点：对近乎有序的一组数排序，其时间复杂度可以接近线性。是一个不错的选择。\nfunc shellSort(arr []int) { gap := 1 // 计算gap，简单点，可以让gap变成数组长度的一半 for gap \u0026lt; len(arr)/3 { gap = gap*3 + 1 } for gap \u0026gt; 0 { for i := gap; i \u0026lt; len(arr); i++ { tmp := arr[i] j := i - gap // 每次之和当前组内前面的元素比较交换 for j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; tmp { arr[j+gap] = arr[j] j -= gap } arr[j+gap] = tmp } gap /= 3 // 更新gap } } 4. 快速排序 采用的是“分而治之”的思想。步骤如下：\n第一步，挑出基准元素(一般取第一个元素) 对数组进行排序，使得所有小于基准的排在前面，大于基准的排在基准后面。最后返回分区的位置。这个操作我们称之为 partition。 递归地 把小于基准值元素的子数列和大于基准值元素的子数列排序 func quickSort(arr []int) []int { return _QuickSort(arr, 0, len(arr)-1) } func _QuickSort(arr []int, left, right int) []int { if left \u0026lt; right { partitionIndex := partition(arr, left, right) _QuickSort(arr, left, partitionIndex-1) _QuickSort(arr, partitionIndex+1, right) } return arr } func partition(arr []int, startIndex, endIndex int) int { var ( pivot = arr[startIndex] // 基准 left = startIndex right = endIndex ) for left != right { // right指向倒数第一个小于基准的数 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026lt; arr[right] { right-- } // left指向顺数第一个大于基准的 for left \u0026lt; right \u0026amp;\u0026amp; pivot \u0026gt;= arr[left] { left++ } // 交换left和right处的值 if left \u0026lt; right { arr[left], arr[right] = arr[right], arr[left] } } // 此时left=right，将left与pivot处的值交换即可 arr[startIndex], arr[left] = arr[left], arr[startIndex] return left } ","permalink":"http://localhost:1313/posts/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","summary":"\u003ch2 id=\"1-堆排序\"\u003e1. 堆排序\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e堆\u003c/strong\u003e 是一种数据结构，它具有如下特征：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e是一棵完全二叉树\u003c/li\u003e\n\u003cli\u003e父节点的值 \u0026gt; 子节点的值\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"11-完全二叉树\"\u003e1.1 完全二叉树\u003c/h3\u003e\n\u003cp\u003e若设二叉树的深度为\u003ccode\u003eh\u003c/code\u003e，除第 \u003ccode\u003eh\u003c/code\u003e 层外，其它各层 \u003ccode\u003e(1～h-1)\u003c/code\u003e 的结点数都达到最大个数，第 \u003ccode\u003eh\u003c/code\u003e 层所有的结点都连续集中在最左边，这就是 \u003cstrong\u003e完全二叉树\u003c/strong\u003e。\u003c/p\u003e","title":"排序算法"},{"content":"位运算 位运算讲究技巧，需要多积累经验。\n一、背景知识 Go 语言支持的 位运算符 如下：\n运算符 描述 规则 \u0026amp; 按位 与 二者同为 1 时结果才为 1，否则为 0 | 按位 或 二者同为 0 时结果才为 0，否则是 1 ^ 按位 异或 相同为 0，相异为 1 \u0026laquo; 左移 n 位，相当于乘以 2 的 n 次方 后面补 0 \u0026raquo; 右移一位，相当于除以 2 的 n 次方 截掉最后一位 1. 与 将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的对应位同为 1 时，该位才为 1，否则为 0。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a \u0026amp; b) // 0001 0100 上述例子中，我们从最后一位开始，逐位运算。可以看到只有 倒数第3位 和 倒数第5位 都是 1，结果中也只有倒数第 3 位和倒数第 5 位是 1。\n规律：\n任何数 \u0026amp; 0 = 0； 任何数 \u0026amp; 任何数 = 任何数； 2.或 将参与运算的两个数 各对应的二进制位 相或。只有当二者对应位全部是 0 时，该位结果才是 0，其他情况结果全为 1。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0011 1111 规律：\n任何数 | 0 = 任何数 任何数 | 任何数 = 任何数 3. 异或 逐位异或，对应位相同，结果为 0，否则为 1——可以理解为 “抵消 1” 效果。\na := 60 // 0011 1100 b := 23 // 0001 0111 fmt.Println(a | b) // 0010 1011 规律：\n任何数 ^ 任何数 = 0 任何数 ^ 0 = 任何数 任何数 ^ 1 = ~任何数(按位取反) 二、经典题目 1. 二进制中 1 的个数 LeetCode 题目： 191. 位 1 的个数 1.1 题目描述 请实现一个函数，输入一个整数，输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n举例：\n输入：00000000000000000000000000001011 输出：3 解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 \u0026#39;1\u0026#39;。 1.2 思路 思路 1 最后一位通过和 1 进行 与运算，可以判断最后一位是否为 1；然后将要计算的数字向右移动 1 位，再计算是否最后一位是否为 1。逐渐循环，知道直到要计算的数变成 0。\nfunc hammingWeight(num uint32) int { result := 0 // 保存1出现的次数 for num \u0026gt; 0 { if num\u0026amp;1 == 1 { result++ // 最后一位是 1 } num \u0026gt;\u0026gt;= 1 // 将原数右移一位 } return result } 思路 2 某一位通过和 1 进行 与运算，可以判断该位是是否为 1。题目指定了 32 位无符号整数，那么循环 32 次，从最后一位开始逐位判断，如何向前移动？左移一位即可。\nfunc hammingWeight(num uint32) int { result := 0 base := uint32(1) for i := 0; i \u0026lt; 32; i++ { if base\u0026amp;num != 0 { result++ } base \u0026lt;\u0026lt;= 1 } return result } 思路 3 出发点：n \u0026amp; (n-1)，会消除 n 最后一个 1。因此，n \u0026amp; (n-1) 总是能把 n中最低位的 1 变成 0 ，并保持其他位不变。具体什么原因，暂时不做深究。\nfunc hammingWeight(num uint32) int { result := 0 for num \u0026gt; 0 { result++ num \u0026amp;= num - 1 } return result } 2. 判断一个数是否为 2 的幂 LeetCode 题目：231. 2 的幂 2.1 题目描述 给定一个整数，编写一个函数来判断它是否是 2 的幂次方。\n示例：\n输入: 1 输出: true 解释: 20 = 1 2.2 解题思路 如果将 2 的所有次幂的二进制写出来，你会发现这些数的规律：最高位都是 1，其余位全是 0。也就是说，如果一个数为 2 的次幂，那么它只有一个 1，而且是在最高位，同时也是最后一个 1。再回想一下上一题中的思路三，n \u0026amp; (n-1) 会消除最后一个 1，于是乎：\nfunc isPowerOfTwo(n int) bool { return n \u0026gt; 0 \u0026amp;\u0026amp; n\u0026amp;(n-1) == 0 } 3. 使用位运算求和 LeetCode 题目：剑指 Offer 65. 不用加减乘除做加法 3.1 题目描述 写一个函数，求两个整数之和，要求在函数体内不得使用 “+”、“-”、“*”、“/” 四则运算符号。\n举例：\n输入: a = 1, b = 1 输出: 2 提示：\na, b 均可能是负数或 0 结果不会溢出 32 位整数 3.2 解题思路 我们用 n 表示无进位和，c 表示进位，那么 sum = a + b = n + c，而位运算可以分别计算出 n 和 c。以两个 1 位的二进制数求和为例：\na b 无进位和 n 进位 c 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 10 从上表中可以看出，n = a ^ b，c = (a\u0026amp;b) \u0026lt;\u0026lt; 1。借用 leetcode 上大神的一张图：\n但是在 sum = n + c 中还是使用了加法，而这种情况我们依旧可以使用上面的规律。这里可以使用一个循环来解决，需要存储n 和 c，循环直到c = 0 时停止，而此时n 即为结果。\nfunc add(a,b int) int { /* * 循环解法 for b != 0 { b, a = (a\u0026amp;b) \u0026lt;\u0026lt; 1, a ^ b } return a */ /* * 递归解法，比上面的循环解法更清晰 if b == 0 { return a } return add(a ^ b, (a \u0026amp; b) \u0026lt;\u0026lt; 1) */ } 4. 数组中出现的次数 LeetCode 题目：136. 只出现一次的数字 4.1 题目描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,1] 输出: 1 4.2 解题思路 回想前面背景知识中的 异或 的特性：任何数 ^ 任何数 = 0，并且 任何数 ^ 0 = 任何数。所以思路很明显，全部进行 异或 操作，出现两次的都会被“抵消”，最后剩下那个“没人要的”，就是我们要找的。\nfunc singleNumber(nums []int) int { if len(nums) == 0 { return 0 } // 整体异或运算 for i:=1;i\u0026lt;len(nums);i++ { nums[0] ^= nums[i] // 使用已有数组的第0个位置，节省空间 } return nums[0] } 4.3 进阶——只出现一次的数字 II LeetCode 题目：137. 只出现一次的数字 II 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例：\n输入: [2,2,3,2] 输出: 3 使用一个 map 的解法这里没必要说了，因为使用了额外空间。\n思路 1 使用数学规律法——原数组去重、再乘以 3 得到的值，刚好就是要找的元素的 2 倍。Go 中没有 set 的这种数据结构，这里提供 Python 解法：\ndef singleNumber(nums){ return int((sum(set(nums))*3 - sum(nums))/2) } 思路 2 回想之前的 异或，发现有两个 1，该位结果是 0；二进制加法中，两个 1 相加，产生了进位，抛弃进位，其结果也是 0——这个过程，可以看成是对应位上 1 的个数对 2 取模的结果。如果是三个数呢？是不是三个数的对应位都是 1 的时候，该位结果才是 0，否则就是 1——对应位上的 1 的个数对 3 取模即可。\nfunc singleNumber(nums []int) int { result := 0 for i := 0; i \u0026lt; 64; i++ { // int至少32位，一般都是64位 // 初始化每一位1的个数为0 number := 0 for _, k := range nums { // 通过右移i位的方式，计算每一位1的个数 number += (k \u0026gt;\u0026gt; i) \u0026amp; 1 } // 对3取模后 最终将抵消后剩余的1放到对应的位数上 res |= (number) % 3 \u0026lt;\u0026lt; i } return res } 再如果 除 1 个元素外，每个元素出现了 4 次呢？原理一样，对 4 取模即可。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%BD%8D%E8%BF%90%E7%AE%97/","summary":"\u003ch1 id=\"位运算\"\u003e位运算\u003c/h1\u003e\n\u003cp\u003e位运算讲究技巧，需要多积累经验。\u003c/p\u003e\n\u003ch2 id=\"一背景知识\"\u003e一、背景知识\u003c/h2\u003e\n\u003cp\u003eGo 语言支持的 \u003cstrong\u003e位运算符\u003c/strong\u003e 如下：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e运算符\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e描述\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e规则\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026amp;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e与\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 1 时结果才为 1，否则为 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e|\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e二者同为 0 时结果才为 0，否则是 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e^\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e按位 \u003cstrong\u003e异或\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e相同为 0，相异为 1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026laquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e左移 n 位，相当于乘以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e后面补 0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u0026raquo;\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cstrong\u003e右移一位，相当于除以 2 的 n 次方\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e截掉最后一位\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"1-与\"\u003e1. 与\u003c/h3\u003e\n\u003cp\u003e将参与运算的两个数 各对应的二进制位 相与。只有当二者参与运算的\u003cstrong\u003e对应位同为 1 时，该位才为 1，否则为 0\u003c/strong\u003e。\u003c/p\u003e","title":"LeetCode-位运算"},{"content":"leetcode 上 三数之和 问题：\n15. 三数之和 259. 较小的三数之和 16. 最接近的三数之和 1. 题目描述 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素a，b，c ，使得 a + b + c = 0？请你找出所有满足条件且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例：\n给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 2. 解题思路 直接跳过暴力解法，说说此题的思路。\n首先，对这个数字排一下序；\n之后，采取固定一个数，同时用双指针来查找另外两个数的方式求解：\n比如，先固定第一个元素，下一个元素设置为 left 指针，最后一个元素设置为 right 指针； 计算这三个数之和是否为 0，如果是，这就是一组满足条件的三元组；如果不是，看结果与 0 的关系，如果小于 0，则 left 向右移动，再比较，如果大于 0，则 right 向左移动一位，再比较。 当然，如果当 固定元素+left \u0026gt; 0 或者 固定元素+right \u0026lt; 0 时，就没必要再去比较了。 以下是代码实现：\nfunc threeSum(nums []int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { // 最外层循环为 固定指针 pin = i left = i + 1 // left 为固定指针的下一个元素 right = l - 1 // right 为最后一个元素 // 如果最小的大于0，不用再循环了 if nums[pin] \u0026gt; 0 { break } // 跳过 pin 相同的 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 找到一个三元组 if nums[pin]+nums[left]+nums[right] == 0 { result = append(result, []int{nums[pin], nums[left], nums[right]}) // 跳过left相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } // 跳过 right 相同的 for left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1] { right-- } // 找到之后，同时改变 left++ right-- } else if nums[pin]+nums[left]+nums[right] \u0026lt; 0 { // 左指针向右移动 left++ } else { right-- } } } return result } 3. 进阶 1——较小的三数之和 给定一个长度为 n 的整数数组和一个目标值 target，寻找能够使条件 nums[i] + nums[j] + nums[k] \u0026lt; target 成立的三元组 i, j, k 个数（0 \u0026lt;= i \u0026lt; j \u0026lt; k \u0026lt; n）。\n示例：\n输入: nums = [-2,0,1,3], target = 2 输出: 2 解释: 因为一共有两个三元组满足累加和小于 2: [-2,0,1] [-2,0,3] 直接上代码：\nfunc threeSumSmaller(nums []int, target int) int { result := 0 // 满足条件的三元组数目 sort.Ints(nums) // 先排序 var pin, left, right int // 固定、左、右 指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-2; i++ { pin = i // 固定指针 left = i + 1 // 左指针指向固定指针的下一个 right = l - 1 // 右指针指向最后一个元素 for left \u0026lt; right { if nums[pin]+nums[left]+nums[right] \u0026gt;= target { // 说明这个 right 不能出现在三元组中, right 左移一位 right-- } else { // 从 left 到 right 之间的那几对都符合条件， left 右移一位 result += right - left left++ } } } return result } 4. 进阶 2——最接近的三数之和 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1 输出：2 解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 代码如下：\nfunc threeSumClosest(nums []int, target int) int { result := math.MaxInt32 // 结果 sort.Ints(nums) // 先排序 var pin, left, right int // 固定指针 左指针 右指针 l := len(nums) // 数组长度 // 求绝对值 abs := func(a int) int { if a \u0026lt; 0 { return -1 * a } return a } // 更新 result updateFunc := func(sum int) { if abs(sum-target) \u0026lt; abs(result-target) { result = sum } } for i := 0; i \u0026lt; l-2; i++ { pin = i left = i + 1 right = l - 1 // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[pin] == nums[pin-1] { continue } for left \u0026lt; right { // 如果 right 左移一位，结果离得更远了，说明需要left向右移 //result = min(result, nums[pin]+nums[left]+nums[right]) sum := nums[right] + nums[left] + nums[pin] if sum == target { return target } updateFunc(sum) if sum \u0026gt; target { // 此时需要向左移动 right，并且移动到下一个不相等的 tmp := right - 1 for left \u0026lt; tmp \u0026amp;\u0026amp; nums[tmp] == nums[right] { tmp-- } right = tmp } else { // 向右移动left tmp := left + 1 for tmp \u0026lt; right \u0026amp;\u0026amp; nums[tmp] == nums[left] { tmp++ } left = tmp } } } return result } 5. 总结 解决此类问题，一般都是 升序后，外层循环 + 内层双指针 思路。其中最关键的是 左右指针移动的条件，一般都是和 target 比大小，大于 target 就向左移动右指针，小于 target 就向右移动左指针。\n由此延伸到 四数之和 问题，解决思路与之类似，设置两个固定指针，即外层两个循环，剩下的处理逻辑与 三数之和 一样。\n看一下 四数之和：\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n注意：\n答案中不可以包含重复的四元组。\n示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { result := make([][]int, 0) sort.Ints(nums) // 先给nums排序 var pin1, pin2, left, right int // 固定 左 右指针 l := len(nums) // 数组长度 for i := 0; i \u0026lt; l-3; i++ { pin1 = i // 不要重复 if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] { continue } for j := i + 1; j \u0026lt; l-2; j++ { pin2 = j left = j + 1 right = l - 1 // 不要重复 if j \u0026gt; i+1 \u0026amp;\u0026amp; nums[j] == nums[j-1] { continue } for left \u0026lt; right { // 相等 if nums[pin1]+nums[pin2]+nums[left]+nums[right] == target { result = append(result, []int{nums[pin1], nums[pin2], nums[left], nums[right]}) for left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1] { left++ } for left \u0026lt; right \u0026amp;\u0026amp; nums[right-1] == nums[right] { right-- } left++ right-- } else if nums[pin1]+nums[pin2]+nums[left]+nums[right] \u0026gt; target { right-- } else { left++ } } } } return result } ","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003e三数之和\u003c/code\u003e 问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum/\"\u003e15. 三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-smaller/\"\u003e259. 较小的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/3sum-closest/\"\u003e16. 最接近的三数之和\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-题目描述\"\u003e1. 题目描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给你一个包含 \u003ccode\u003en\u003c/code\u003e 个整数的数组 \u003ccode\u003enums\u003c/code\u003e，判断 \u003ccode\u003enums\u003c/code\u003e 中是否存在三个元素\u003ccode\u003ea，b，c\u003c/code\u003e ，使得 \u003ccode\u003ea + b + c = 0\u003c/code\u003e？请你找出所有满足条件\u003cstrong\u003e且不重复\u003c/strong\u003e的三元组。\u003c/p\u003e","title":"LeetCode-三数之和问题"},{"content":"leetcode 上 twoSum 相关的问题：\n1. 两数之和 167. 两数之和 II - 输入有序数组 170. 两数之和 III .数据结构设计 1. 问题描述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 2. 解决思路 一般情况下，使用的是暴力穷举法，但是这种情况下时间复杂度为 $O(n^2)$，爆炸，不考虑。\n这里采用 空间换时间 的思路：\n设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的 索引i和 map[target-j] 即为所需要的。\n下面通过代码实现：\nfunc twoSum(nums []int, target int) []int { result := make([]int,0) m := make(map[int],int) for i,j := range nums { if v, ok := m[target-j]; ok { result = append(result, v) result = append(result, i) } m[j] = i } return result } 3. 进阶 设计并实现一个 TwoSum 的类，使该类需要支持 add 和 find 的操作。\nadd 操作 - 对内部数据结构增加一个数。\nfind 操作 - 寻找内部数据结构中是否存在一对整数，使得两数之和与给定的数相等。\n示例 1:\nadd(1); add(3); add(5); find(4) -\u0026gt; true find(7) -\u0026gt; false 示例 2:\nadd(3); add(1); add(2); find(3) -\u0026gt; true find(6) -\u0026gt; false 实现如下：\ntype TwoSum struct { M map[int]int } /** Initialize your data structure here. */ func Constructor() TwoSum { return TwoSum{M: make(map[int]int)} } /** Add the number to an internal data structure.. */ func (this *TwoSum) Add(number int) { this.M[number]++ // 这里的map中，key保存number，value保存出现的次数 } /** Find if there exists any pair of numbers which sum is equal to the value. */ func (this *TwoSum) Find(value int) bool { for key := range this.M { other := value - key // 第一种情况，针对出现了两次的元素、value为其2倍的，比如 [3,3]，value为6 if other == key \u0026amp;\u0026amp; this.M[other] \u0026gt; 1 { return true } // 第二种情况，针对出现过一次的元素，比如 [2,6], value 为8 if other != key \u0026amp;\u0026amp; this.M[other] \u0026gt; 0 { return true } } return false } 4. 总结 对于题目 1 和题目 167： 设置一个 map[int]int ，其中 key 存储数组中的元素，value 为数组中元素的索引值。之后遍历数组，设i,j 为当前索引和元素，如果 target-j在 map 中，则当前的索引i和 map[target-j] 即为所需。\n对于题目 170： 设计数据结构时，map 的 key 为元素，value 为该元素出现的此时。查找时，考虑两种情况：一种是 [3,3]--\u0026gt;6 的情况，一种是 [2,5] --\u0026gt; 7 的情况。\n","permalink":"http://localhost:1313/posts/leetcode-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e\u003ccode\u003eleetcode\u003c/code\u003e 上 \u003ccode\u003etwoSum\u003c/code\u003e 相关的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum/\"\u003e1. 两数之和\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/\"\u003e167. 两数之和 II - 输入有序数组\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://leetcode-cn.com/problems/two-sum-iii-data-structure-design/\"\u003e170. 两数之和 III .数据结构设计\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-问题描述\"\u003e1. 问题描述\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\u003c/p\u003e","title":"LeetCode-两数之和问题"},{"content":"一、设计原理 哈希表(也就是我们说的map)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是O(1)，是典型的 以空间换时间 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：哈希函数 和 冲突解决方法。\n1. 哈希函数 可以将任意长度的数据 映射 到有限长度的域上。通俗解释：你可以把它抽象成一个黑盒(一个函数 f)，它的输入是任意数据 m，输出是另一段固定范围的数据 n，即f(m) = n，n 可以作为 m 的特征(指纹)。\n对任意两个输入m1和m2，如果他们的输出均不同，则称这个函数为 完美哈希函数。如果存在m1和m2，有 f(m1) = f(m2)，则称这个函数为 不均匀哈希函数，这个现象称为 哈希碰撞。\n完美哈希函数很难找到，比较实际的做法是 让哈希函数的结果尽可能地分布均匀，然后通过工程上的手段解决哈希碰撞的问题。但是哈希的结果一定要尽可能均匀，结果不均匀的哈希函数会造成更多的冲突并导致更差的读写性能。\n2. 解决哈希冲突的方法 在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多最终也会造成冲突。\n然而我们的哈希函数往往都是不完美的，输出的范围是有限的，所以一定会发生哈希碰撞，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。\n2.1 开放寻址法 这种方法的核心思想在于 线性探测，通常情况下，这种哈希表的底层数据结构就是数组。先计算index，判断数组的这个index处是否有值，如果没有，直接存入；否则从这个index向后遍历，直到找到一个为空的index。可以大致用下面的代码表示：\nfunc hash1(source string) int { arr := make([]string,10,10) index := hash(source) % len(arr) tmp := index for { if arr[index%len(arr)] == \u0026#34;\u0026#34; { return index }else { index++ } if index == tmp { return -1 // 没找到 } } } 查找的时候，还是先计算 index ，如果数组在该位置的数刚好是要找的，直接返回，否则需要向后逐步遍历比较。在某些情况下，当装载的元素太多时，哈希表的性能会急剧下降，最差的结果就是每次增加和查找，都需要遍历整个数组，此时整个哈希表完全失效。\n2.2 拉链法 与开放地址法相比，拉链法是哈希表中最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。\n拉链法使用链表作为底层数据结构，我们把这个链表称为桶。这种方法对哈希冲突的解决方法是：直接在相同哈希值的结点后面增加一个链表结点。查询的时候，先找到对应链表第一个结点，之后遍历链表寻找符合要求的那个。\n在一个性能比较好的哈希表中，每一个桶中都应该有 01 个元素，有时会有 23 个，很少会超过这个数量，计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：\n装载因子 := 元素数量/桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。\n二、用到的数据结构 我的 Go 版本：\ngo version go1.14.6 darwin/amd64 Go 语言中对哈希表的实现方案是：使用拉链法解决哈希冲突。同时使用了多个数据结构组合来标识哈希表。\n在源码中，表示map 的结构体是 hmap：\n// A header for a Go map. type hmap struct { count int // 当前哈希表中元素个数，调用len(m)时直接返回此值 flags uint8 // B uint8 // 当前哈希表持有的 buckets 数量的对数，即 buckets数量 = 2^B noverflow uint16 // overflow 的 buckets 的近似数(buckets\u0026lt;16时是准确的) hash0 uint32 // 哈希种子，在创建哈希表时确定的随机数，并在调用哈希函数的时候作为参数传入 buckets unsafe.Pointer // 指向 buckets 数组，大小为 2^B，如果元素个数为0则为nil oldbuckets unsafe.Pointer // 渐进式扩容时用于保存之前的 buckets，扩容的时候，buckets 长度会是 oldbuckets 的两倍 nevacuate uintptr // 指示扩容进度，表示即将迁移的旧桶编号 extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. 溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 目前已经使用的溢出桶的地址 oldoverflow *[]*bmap // 在扩容阶段存储旧桶用到的溢出桶的地址 nextOverflow *bmap // 指向下一个空闲溢出桶 } buckets 是一个指针，最终指向的是一个结构体：\n// A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 } bmap 结构体其实不止包含 tophash 字段，由于哈希表中可能存储不同类型的键值对并且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导，这些字段在运行时也都是通过计算内存地址的方式直接访问的，所以它的定义中就没有包含这些字段，实际上的 bmap 是这样的：\ntype bmap struct { topbits [8]uint8 // tophash数组 keys [8]keytype // key数组 values [8]valuetype // value数组 pad uintptr overflow uintptr // 当当前桶存满时，发现还有可用的溢出桶，就会用此指针链接一个溢出桶，溢出桶也是 bmap 结构 } 如上图所示，hmap的桶就是 bmap，每一个 bmap 最多能存储 8 个键值对，这些键值对之所以会落在同一个桶，是因为他们经过哈希计算之后，得到的哈希结果是 “一类的”。当单个桶中存储的数据过多而无法装满时，就会使用 extra.overflow 中的桶存储溢出的数据。上面两种桶在内存中是连续的，我们暂且称之为 常规桶 和 溢出桶。\n我们来看看 bmap 的内部组成：\n最开始是 8 个 tophash，每个 tophash 都是对应哈希值的高 8 位。需要注意的是，key 和 value 是各自放在一起的，这样的好处是为了padding 时节省空间。每一个桶被设计成最多只能存放 8 个键值对，如果有第 9 个键值对落入当前的桶，那就需要再构建一个桶(溢出桶)，然后用 overflow 指针连接起来。\n三、使用 1. 初始化 无论是通过字面量还是运行时，最终底层都会调用 makemap 方法：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { // 计算哈希占用的内存是否溢出或者产出能分配的最大值 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } if h == nil { h = new(hmap) } // 获取随机的哈希种子 h.hash0 = fastrand() // 根据传入的hint计算需要的最少的桶的数量 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 创建用于保存桶的数组 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 需要注意的是 makeBucketArray 函数，这个函数会根据传入的 B 计算出的需要创建的桶的数量 在内存中分配一片连续的空间用于存储数据。当桶的数量小于 $2^4$ 时，由于数据较少，使用溢出桶的可能性比较低，这时会省略创建的过程以减少额外开销；当桶的数量多于 $2^4$ 时，就会额外创建 $2^{B-4}$ 个溢出桶。正常情况下，溢出桶和常规桶在内存中的存储空间是连续的，只不过被 hmap 的不同字段引用。\n另外注意makemap 的返回，是一个 *hmap ，指针类型，这个时候传给函数在函数中改变的就是原来的 map ，即 改变map类型的形参，是可以影响实参的。这一点和之前的 slice 不同，slice 返回的是一个 slice 结构体，虽底层共用数组，但是扩容后就与原来的数据脱钩了。\n举个例子，下面的代码：\nmap := make(map[string]string, 10) Go 源码中的负载因子是 6.5 ，在源码 /usr/local/go/src/runtime/map.go:70 可以找到：\n// Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 这里的map 的键值对个数是 10，根据 负载因子 = 键值对个数/桶个数，得到 需要的桶的个数为 2。此时不会创建更多的溢出桶。\n2. 写 源码中执行 写入 操作的是 mapassign 函数，该函数较长，我们分步来看(每一步我会在关键位置写上注释，也更容易理解过程)。\n首先，函数会根据传入的键计算哈希，确定所在的桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // a.调用key类型对应的哈希算法得到哈希 hash := t.hasher(key, uintptr(h.hash0)) // b.设置 写 标志位 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // c.根据 hash 计算位于哪个 bucket bucket := hash \u0026amp; bucketMask(h.B) if h.growing() { // d.如果 map 正在扩容，此操作确保此 bucket 已经从 hmap.oldbuckets 被搬运到 hmap.buckets growWork(t, h, bucket) } // e.取得 bucket 所在的内存地址 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) // f.计算此bucket中的tophash，方法是：取高8位 top := tophash(hash) // ... } 在 64 位机器上，步骤 a 计算得到的 hash 值共有 64 个 bit 位。之前提到过，hmap.B 表示桶的数量为 $2^{h.B}$。这里用得到的哈希值的最后 B 个 bit 位表示落在了哪个桶中，用哈希值的 高 8 位表示此 key 在 bucket 中的位置。\n还是以上面的map = make(map[string]int, 10)为例，计算可知 B=2，则应该用后 2 位用来选择桶，高 8 位用来表示 tophash。 某个 key 经过哈希之后得到的 hash=01100100 001011100001101110110010011011001000101111000111110010 01，后两位 01 代表 1 号桶。\n然后，会有两层循环，最外层循环 bucket 以及其链接的溢出桶(如果有的话)，内存逐个遍历所有的tophash： var inserti *uint8 // 目标元素在桶中的索引 var insertk unsafe.Pointer // 桶中键的相对地址 var elem unsafe.Pointer // 桶中值的相对地址 bucketloop: // 最外层是一个死循环，其实是当前 bucket 后面链接的溢出桶(overflow) for { // bucketCnt=8，因为一个bucket最多只能存储8个键值对 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 找到一个tophash不同的 if b.tophash[i] != top { // isEmpty判断当前tophash是否为正常tophash值而不是系统迁移标志 if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // 已经找到一个可以放置的位置了，为什么不直接break掉？是因为有可能K已经存在，需要找到对应位置然后更新掉 } // 如果余下位置都是空的，则不再需要往下找了 if b.tophash[i] == emptyRest { break bucketloop } continue } // tophash 相同后，还需要再比较实际的key是否相同 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // key已经在map中了，更新之 if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } // 外层循环接着遍历这个bucket后面链接的overflow ovf := b.overflow(t) if ovf == nil { break } b = ovf } 在上述代码中有出现isEmpty 以及 emptyRest 等标志位，这其实是 tophash 的状态值，在源码 /usr/local/go/src/runtime/map.go:92 中可以找到：\n// // Possible tophash values. We reserve a few possibilities for special marks. emptyRest = 0 // 这个 cell 是空的, 并且在当前bucket的更高的index 或者 overflow中，其他的都是空的 emptyOne = 1 // 这个 cell 是空的 evacuatedX = 2 // K-V 已经搬迁完毕，但是 key 在新的 bucket 的前半部分(扩容时会提到) evacuatedY = 3 // 同上，key 在新的 bucket 的后半部分 evacuatedEmpty = 4 // cell 是空的，并且已经被迁移到新的 bucket 上 minTopHash = 5 // 正常的 tophash 的最小值 由此也可知，正常的 tophash 是 大于 minTopHash 的。\n如果此时 (键值对数已经超过负载因子 或者 已经有太多的溢出桶) \u0026amp;\u0026amp; 当前没有处在扩容阶段，那么 开始扩容： // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } 具体的扩容过程后面再细说，这里暂不讨论。\n如果没有找到合适的 cell 来存放这个键值对(桶满了)，则 使用预先申请的保存在 hmap.extra.nextoverflow 指向的溢出桶 或者 创建新桶 来保存数据，之后将键值对插入到相应的位置： if inserti == nil { // all current buckets are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } // 将键值对移动到对应的空间 typedmemmove(t.key, insertk, key) *inserti = top h.count++ 而使用预分配的溢出桶还是申请新的桶，在 newoverflow 函数中：\nfunc (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap if h.extra != nil \u0026amp;\u0026amp; h.extra.nextOverflow != nil { // 如果有预分配的 bucket ovf = h.extra.nextOverflow if ovf.overflow(t) == nil { // 并且预分配的溢出桶还没有使用完，则使用这个溢出桶，并更新 h.extra.nextOverflow 指针 h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize))) } else { // 预分配的溢出桶已经用完了，则置空 h.extra.nextOverflow指针 ovf.setoverflow(t, nil) h.extra.nextOverflow = nil } } else { // 没有可用的溢出桶，则申请一个新桶 ovf = (*bmap)(newobject(t.bucket)) } // 更新h.noverflow(overflow的树木)，如果h.B \u0026lt; 16，则自增1，否则“看可能性”自增(没啥用，感兴趣可以自己研究一下) h.incrnoverflow() if t.bucket.ptrdata == 0 { h.createOverflow() *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) return ovf } 3. 读 我们再来说说 读 的过程。map 的读取有两种方式：带 comma 和 不带 comma 的。这两种方式，其实底层调用的分别是：\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer // v1 := m[key] func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) // v2, isExist := m[key] 这两个函数大同小异，我们只看 mapaccess1。我们还是采用分步的方式来从源码中探究细节：\n根据 key 计算得到 hash 值，同时确定在哪个 bucket 中寻找： // 这个函数永远不会返回 nil ，如果map是空的，则返回对应类型的 零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026amp;zeroVal[0]) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map read and map write\u0026#34;) } // 得到 hash 值 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // 本例中m=31 // 得到 bucket b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { // 正处在扩容阶段 // 如果不是等量扩容(后面会讲到) if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. // 非等量扩容，那就是渐进式扩容，在原来基础上增加了2倍，为了得到原来的，这里除以2 m \u0026gt;\u0026gt;= 1 // m=15 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 是否处于扩容阶段 if !evacuated(oldb) { b = oldb } } top := tophash(hash) 和前面 写 的过程类似，也是两个大循环，外层遍历 bucket 以及链接在后面的 溢出桶，内层遍历每个 bucket 中的 tophash，直至找到需要的 键值对： bucketloop: // 外层循环溢出桶 for ; b != nil; b = b.overflow(t) { // bucketCnt=8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { // 和当前index的tophash不相等，并且后面的cell都是空的，说明后面就没不要再去遍历了，直接退出循环，返回对应元素的零值 if b.tophash[i] == emptyRest { break bucketloop } continue } // 找到对应的 key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // tophash相同，还要判断完整的key是否相同 if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } // 根据偏移找到对应的value，直接返回 return e } } } // 没找到，返回对应类型的零值 return unsafe.Pointer(\u0026amp;zeroVal[0]) 另外，编译器还会根据 key 的类型，将具体的操作用更具体的函数替换，比如 string 对应的是 mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer，函数的参数直接就是具体的类型，这么做是因为提前知道了元素类型，而且由于 bmap 中 key 和 value 各自放在一起，内存布局非常清晰，这也是前面说的 “减少 padding 带来的浪费”的原因。\n4. 扩容 在前面介绍 写 过程时，我们跳过了有关扩容的内容，现在回过头来看一下：\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // ... if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } // ... } // 判断h是否正在扩容。 扩容结束之后，h.oldbuckets 会被置空 func (h *hmap) growing() bool { return h.oldbuckets != nil } // 判断map中的键值对数目与已有的buckets 是否超过负载因子 即 count/2^B 与 6.5的大小关系 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 是否有太多的bucket func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. if B \u0026gt; 15 { B = 15 } // 翻译一下这条语句： // 如果 B \u0026lt; 15， 即 bucket总数 \u0026lt; 2^15 时，overflow的bucket数目不超过 2^B // 如果 B \u0026gt;= 15，即 bucket总数 \u0026gt; 2^15 时，overflow的bucket数目不超过 2^15 // 即 noverflow \u0026gt;= 2^(min(B,15)) return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 从现实角度出发，会有以下两种情形：\n在没有溢出、且所有的桶都装满了的情况下，装载因子是 8，超过了 6.5，表明很多的 bucket 中都快装满了，读写效率都会降低，此时进行扩容是必要的； 当装载因子很小、但是 bucket 很多的时候，map 的读写效率也会很低。什么时候会出现 “键值对总数很小、但 bucket 很多”的情况呢？不停地插入、删除元素。当插入很多元素时，导致创建了更多的 bucket ，之后再删除，导致某个 bucket 中的键值对数量非常少。“这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。” 对于上述两种情况，Go 有着不同的策略：\n对于第一种情况，城中人多房少，直接将 B 加一，建更多的房子即可； 对第二种情况，新开辟一块同样大小的空间，然后将旧空间中的键值对全部搬运过去，然后重新组织。 扩容 最基础的一个操作是 将原有的键值对搬到新开辟的空间，如果键值对数量太多，将严重影响性能。因此对于情况一，Go 采取 渐进式扩容，并不会一次全部搬完，每次最多只搬迁 2 个 bucket；第二种情况，称之为 等量扩容 ，可以理解成“内存整理”。接下来我们通过源码来分析实际的过程：\n执行扩容的函数是 hashGrow ， hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数和 evacuate() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。\n我们来看看 hashGrow 函数：\nfunc hashGrow(t *maptype, h *hmap) { // If we\u0026#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026#34;grow\u0026#34; laterally. // 首先通过 是否超过负载因子 判断进行渐进式扩容还是等量扩容 bigger := uint8(1) // 默认等量扩容 if !overLoadFactor(h.count+1, h.B) { // 如果没有超过负载因子，则进行等量扩容 bigger = 0 h.flags |= sameSizeGrow } // 申请新的 bucket 空间，并将原来的 h.buckets 字段 转移到 h.oldbuckets oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) // 将以前原有的buckets的标志位也转移到新申请的buckets去 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 执行grow操作 (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 // h.nevacuate指示扩容进度，表示当前正在搬迁旧的第几个bucket h.noverflow = 0 // 将溢出桶个数置为零 // 将extra中的overflow扔到oldoverflow中去 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026#34;oldoverflow is not nil\u0026#34;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 第 17 行涉及到的 flag 如下：\n// flags iterator = 1 // 可能有迭代器使用 buckets oldIterator = 2 // 可能有迭代器使用 oldbuckets hashWriting = 4 // 有协程正在向 map 中写入 key sameSizeGrow = 8 // 等量扩容（对应第二种情况） 我们再来看看实际执行扩容的 growWork 和 evacuate：\nfunc growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 还没搬迁完成的话，再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) } } evacuate 函数非常长，我们还是逐步去深入：\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位到老的bucket b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() // 存放增长之前的bucket数，结果为 2^B if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. /* // evacDst表示搬迁的目的区域. type evacDst struct { b *bmap // 搬去的bucket i int // bucket中键值对的index k unsafe.Pointer // pointer to current key storage e unsafe.Pointer // pointer to current elem storage } */ // 这里设置两个目标桶，如果是等量扩容，则只会初始化其中一个； // xy 指向新空间的高低区间的起点 var xy [2]evacDst x := \u0026amp;xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 如果是翻倍扩容，则同时初始化，之后会将旧桶中的键值对“分流”到两个新的目标桶中 if !h.sameSizeGrow() { // Only calculate y pointers if we\u0026#39;re growing bigger. // Otherwise GC can see bad pointers. y := \u0026amp;xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell for i := 0; i \u0026lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 当前cell的tophash if isEmpty(top) { // 当前cell为空，即没有key，则标志其为 “搬迁过”，然后继续下一个 cell b.tophash[i] = evacuatedEmpty continue } // 正常情况下，tophash只能是 evacuatedEmpty 或者 正常的tophash(大于等于minTopHash) if top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // 计算如何分流(将这个键值对放到x中还是y中) // 计算方法与前面相同 hash := t.hasher(k2, uintptr(h.hash0)) // !t.key.equal(k2, k2)这种情况，只能是float的NaN了 // 没有协程正在使用map \u0026amp;\u0026amp; 不是float的NaN if h.flags\u0026amp;iterator != 0 \u0026amp;\u0026amp; !t.reflexivekey() \u0026amp;\u0026amp; !t.key.equal(k2, k2) { // 在这种情况下，我们使用 tophash 的低位来作为分流的标准 useY = top \u0026amp; 1 top = tophash(hash) } else { if hash\u0026amp;newbit != 0 { useY = 1 // 新的位置位于高区间 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\u0026#34;bad evacuatedN\u0026#34;) } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026amp;xy[useY] // 放到高位置还是低位置 // 是否要放到 overflow 中 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That\u0026#39;s ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.ptrdata != 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } // 最后会调用 advanceEvacuationMark 增加哈希的 nevacuate 计数器，在所有的旧桶都被分流后清空哈希的 oldbuckets 和 oldoverflow 字段 if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 简单总结一下分流规则：\n对于等量扩容，从旧的 bucket 到新的 bucket，数量不变，因此可以按照 bucket 一一对应，原来是 0 号，搬过去之后还是 0 号； 对于渐进式扩容，要重新计算 key 的 哈希，才能决定落在哪个 bucket 。原来只有 2^B 个bucket ，确定某个 key 位于哪个 bucket 需要使用最后B 位；现在 B 增加了 1，那就应该使用最后的 B+1 位，即向前看一位。比如原来的 B=3，key1和key2的哈希后四位分别是 0x0101 和 0x1101，因为二者的后三位相同，所以会落在同一个 bucket 中，现在进行渐进式扩容，需要多看一位，此时key1和key2的哈希后四位不相同，因为倒数第 4 位有 0 和 1 两种取值，这也就是我们源码中说的 X 和 Y，key1和key2也就会落入不同的 bucket 中——如果是 0，分配到X，如果是 1 ，分配到 Y。 还有一种情况是上面函数中第 64 行 !t.key.equal(k2, k2)，即相同的 key ，对它进行哈希计算，两次结果竟然不相同，这种情况来自于 math.NaN()，NaN 的意思是 Not a Number，在 Go 中是 float64 类型(打印出来直接显示 “NaN”)，当使用它作为某个 map 的 key 时，前后计算出来的哈希是不同的，这样的后果是，我们永远无法通过 GET 操作获取到这个键值对，即使用 map[math.NaN] 是取不到想要的结果的，只有在遍历整个 map 的时候才会出现。这种情况下，在决定分流到 X 还是 Y 中时，就只能 使用tophash的最低位来决定 这个策略了——如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。\n关于 NaN：In computing, NaN, standing for Not a Number, is a member of a numeric data type that can be interpreted as a value that is undefined or unrepresentable, especially in floating-point arithmetic.\n在计算机科学中，NaN 代表 Not a Number，是一个 能够被打印出来的 未定义或者不可预知的 数字类型。\n我们简单总结一下哈希表的扩容设计和原理，哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，整个扩容过程并不是原子的，而是通过 growWork增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流；除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 sameSizeGrow(等量扩容) 这一机制，在出现较多溢出桶时会对哈希进行『内存整理』减少对空间的占用。————Go 语言设计与实现 3.3 哈希表\n5. 删除 Go 语言中删除一个 map 中的 key，使用的是特定的关键字 delete(map, key)。在底层，实际调用的 /usr/local/go/src/runtime/map.go 中的 mapdelete。这个函数的执行过程和 写 过程类似，如果在删除期间当前操作的桶遇到了扩容，就会对该桶进行分流，分流之后找到同种的目标元素完成键值对的删除工作。\n6. 遍历 理论上map 的遍历比较简单——“遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。” 但实际情况是，当我们在遍历一个处在扩容阶段的 map 时，不仅要考虑到已经搬过去的位于 h.buckets 的，还要考虑还没有搬的位于 h.oldbuckets 中的。\n接下来我们还是通过源码的方式逐步探寻 map 遍历 的奥秘。\n与之相关的函数分别是 mapiterinit 和 mapiternext，前者会初始化一个迭代器，之后循环调用后者进行迭代。迭代器结构如下：\ntype hiter struct { key unsafe.Pointer // key的指针，必须放在第一位，nil表示迭代结束 elem unsafe.Pointer // value指针，必须放在第二位 t *maptype // map中key的类型 h *hmap // 指向map的指针 buckets unsafe.Pointer // 初始化时指向的 bucket bptr *bmap // 当前遍历到的 map overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // 起始迭代的 bucket 编号 offset uint8 // 遍历时的偏移量(可以理解成遍历开始的 cell 号) wrapped bool // 是否从头遍历 B uint8 // h.B i uint8 // 当前的 cell 编号 bucket uintptr // 当前的 bucket checkBucket uintptr // 因为扩容，需要检查的 bucket } mapiterinit 主要是对 hiter 的初始化，需要关注的是这几行：\nfunc mapiterinit(t *maptype, h *hmap, it *hiter) { // ... // decide where to start r := uintptr(fastrand()) // bucketCntBits=3 if h.B \u0026gt; 31-bucketCntBits { r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } // bucketMask 即 1\u0026lt;\u0026lt;h.B -1 it.startBucket = r \u0026amp; bucketMask(h.B) // bucketCnt=8 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // ... } r 是一个随机数，这里假设我们的 m = make(map[string]int)， h.B=2，即有 2^2=4 个桶，可以计算得到 bucketMask(h.B)=3，二进制表示为 0000 0011，将 r 与这个数相与，就能得到 0~3 的 bucket 序号；同样，第 12 行，7 的二进制表示为 0000 0111，将 r 右移两位之后，与 7 相与，可以得到 0~7 的一个 cell 序号。这就是 map 每次遍历的 key 都是无序的原因。\n之后，使用这个随机的 bucket ，在里面的随机的这个 cell 处开始遍历，取出其中的键值对，直到回到这个 bucket 。\n接下来我们看 mapiternext 的细节：\nfunc mapiternext(it *hiter) { h := it.h if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext)) } if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t bucket := it.bucket b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // 回到了最开始遍历的那个 bucket，说明遍历结束了，可以退出迭代了 it.key = nil it.elem = nil return } if h.growing() \u0026amp;\u0026amp; it.B == h.B { // 如果我们当前遍历的 bucket 对应的原来的老的 bucket 的状态位显示为 “未搬迁”，则不再遍历当前的 bucket 而去遍历老的 bucket oldbucket := bucket \u0026amp; it.h.oldbucketmask() b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) if !evacuated(b) { checkBucket = bucket } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // 当前 cell 是空的，继续下一个 cell if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() { // 正好遇上扩容但是扩容还没完成，如果我们当前遍历的 bucket 对应的老 bucket还没有进行迁移，那么需要去遍历未搬迁的老的 bucket，但是！并不是遍历对应的全部的老的 bucket，而是只遍历 分流后会落在当前 bucket 的那部分键值对 if t.reflexivekey() || t.key.equal(k, k) { // 对于老 bucket 中不会分流到这个 bucket 的键值对，直接跳过 hash := t.hasher(k, uintptr(h.hash0)) if hash\u0026amp;bucketMask(it.B) != checkBucket { continue } } else { // 处理 math.NaN 情况，还是一样，看最低位来决定是不是落在当前这个 bucket if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue } } } if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // 对于 math.NaN 情况，我们只能通过遍历找到，对它的增删改查都是不可能的(这也是比较幸运的一件事，最起码能访问到，否则那真就成了“幽灵”了——占用空间又无可奈何，而且还能同一个 key 无限制地添加) it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else { // 开始迭代的时候，已经完成了扩容。此时 math.NaN 已经被放置到了别的 bucket 中，这种情况下只需要处置已经被 更新、删除或者删除后重新插入的情况。需要注意的是那些在 equal() 函数中判断为真的但是实际上他们的 key 不相同的情况，比如 +0.0 vs -0.0 rk, re := mapaccessK(t, h, k) if rk == nil { continue // key 已经被删除 } it.key = rk it.elem = re } it.bucket = bucket if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b } it.i = i + 1 it.checkBucket = checkBucket return } b = b.overflow(t) i = 0 goto next } 在 码农桃花源 深度解密 Go 语言之 map 中 map 遍历 一节，作者举了一个非常通俗易懂的例子，非常推荐，建议去看一下加深理解。\n四、总结 这是我第一次非常深入地看源码，也领会到了一切疑难杂症都会在源码面前原形毕露。map 操作的核心，就在于如何在各种情况下定位到具体的 key，搞清楚了这一点，其他问题看源码会更清晰。\nGo 语言中，哈希表的实现采用的哈希查找表，使用拉链法解决哈希冲突。有空间换时间的思想体现(不同的 key 落到不同的 bucket，即定位bucket的过程)，也有 时间换空间 思想的体现(在一个 bucket 中，采用遍历的方式寻找 key 而不是再使用哈希)，同时渐进式扩容和等量扩容的思想也值得我们学习。\n","permalink":"http://localhost:1313/posts/golang-map%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"一设计原理\"\u003e一、设计原理\u003c/h2\u003e\n\u003cp\u003e哈希表(也就是我们说的\u003ccode\u003emap\u003c/code\u003e)是计算机应用领域非常重要的数据结构之一，读写的时间复杂度均是\u003ccode\u003eO(1)\u003c/code\u003e，是典型的 \u003cstrong\u003e以空间换时间\u003c/strong\u003e 设计。它的优点除了读写性能优异，还在于它提供了键值之间的映射，为程序设计提供了极大的方便。要想实现一个性能优异的哈希表，需要关注两个关键点：\u003cstrong\u003e哈希函数\u003c/strong\u003e 和 \u003cstrong\u003e冲突解决方法\u003c/strong\u003e。\u003c/p\u003e","title":"Golang-map详解"},{"content":"一、概述 1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器 主要解决系统线程太重的问题：\n创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大； 系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。 goroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\ngoroutine 是用户态线程，其创建和切换等，都是在用户态完成而无需进入操作系统内核，其开销相比系统线程要小很多； goroutine 启动时默认栈大小只有 2k，可以根据实际情况进行自动伸缩。 2. Go scheduler Go 程序的执行由两部分组成：Go Program 和 runtime，即 用户代码 和 运行时。这里的 runtime 和 Java、Python 中的不一样，Java 的是虚拟机，而Go 的 runtime 和用户代码一起编译到一个可执行文件中。用户代码和 runtime 除了代码组织上有界限之外，运行的时候并没有明显的界限，用户代码中，一些常用的关键字(如 go, new 等)被编译成 runtime 包下的一些函数调用。用户程序进行的系统调用都会被 runtime 拦截，以此来帮助 runtime 进行调度方面以及垃圾回收其他方面的工作。\n一张关系图如下：\n为什么需要 scheduler 呢？runtime 维护所有的 goroutine，就是通过 scheduler 来进行调度。goroutine 和系统线程是独立的，但是 goroutine 需要依赖系统线程才能执行。\n可以用一句话概括 Go scheduler 的目标：\nFor scheduling goroutines onto kernel threads.\nGo scheduler 的核心思想是：\nreuser 系统线程，限制同时运行(不包括阻塞的)的线程数为 N，其中 N 为 CPU 的核心数； 线程使用私有的本地运行队列，并且为了更高地使用 CPU，某个线程可以从其他线程偷 goroutine 来帮助运行，也可以在 goroutine 阻塞的时候将其传递给其他线程。 3. M:N 模型 goroutine 建立在操作系统线程之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。M:N 是指 M 的 goroutine 运行在 N 的操作系统线程上，内核负责对这 N 的操作系统线程进行调度，而 Go runtime 则负责将这 M 个 goroutine 调度运用在这 N 个操作系统线程上。\n简单理解，对 goroutine 的调度，是指程序代码按照一定的算法，在适当的时候挑选出合适的 goroutine 然后放到真正的线程上去执行的过程。其实并没有一个调度器实体，它只是一段代码的抽象化表示，具体来说是 需要发生调度时由操作系统线程执行runtime.schedule方法进行的。\nGo runtime 负责 goroutine 的生老病死，从创建、切换、销毁都一手包办。runtime 在启动的时候，会创建 M 个操作系统线程(CPU 内核执行调度的基本单位)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行。在同一时刻，一个系统线程上只能执行一个 goroutine，当 goroutine 发生阻塞时，runtime 会将当前 goroutine 调走，让其他的 goroutine 继续执行。这样做的目的是尽量提升性能，尽量让所有的系统线程上面都有代码在执行。\n4. GPM 模型 我们观察调度过程的进化，从进程到线程再到协程，其实是一个不断共享、不断减少切换成本的过程。\n要理解调度，需要理解两个概念：运行和阻塞。这里提供两个角度：我们觉得自己就是线程或者协程，运行就是在低头不断做事，阻塞就是我们目前做的事需要等待别人，然后就一直等着，等其他人做完了，我们接着做，这里我们是站在线程或者协程的角度去看的；另一个角度是，我们站在 CPU 的角度看，我正在敲代码写需求(一个线程或者协程)，发现依赖别人的函数还没有提交，那就把敲代码这事放在一边，最小化 IDE 然后点开钉钉沟通下一个需求，等依赖的函数提交了，又打开 IDE 继续敲代码——在 Linux 中，线程对应的是一个叫做task_struct的结构体，从本质上来说，线程并不是一个实体，线程只是代表一个执行流和其状态。真正驱动流程的是 CPU，CPU 根据 PC 寄存器从程序中取指令和操作数，从 RAM 中取数据,，进行计算、 处理、 跳转、 驱动执行流往前。 CPU 并不关注处理的是线程还是协程,，只需要设置 PC 寄存器， 设置栈指针等(这些称为上下文),，那么 CPU 就可以运行这个线程或者协程了。\n所以，线程的运行，其实是被运行；线程的阻塞，其实是换出调度队列，不再去执行这个执行流。协程同理，协程也是一个类似于task_struct数据结构，其作用也是一个执行流或者状态，记录运行什么函数，运行到什么程度，也就是上下文。\nGo 在用户态实现调度，所以 Go 也需要有代表协程这种执行体的数据结构，也要有保存和恢复上下文的处理过程以及调度队列。\n在这些数据结果中，最主要的是一下几个(以下结构体均位于runtime包的runtime.go文件中)：\ng: 它保存了 goroutine 的所有信息，该结构体的每一个实例对象都代表了一个goroutine。调度器代码会通过 g 对象来对 goroutine 进行调度——当 goroutine 被调离系统线程时，调度器负责把 CPU 相关寄存器值等上下文信息保存在 g 对象的成员变量中；当 goroutine 被重新拉起运行时，调度器又负责把 g 对象成员变量中所保存的上下文信息恢复到相关寄存器，也就是恢复了执行上下文。 schedt：一方面保存调度器本身的状态信息，另一方面它拥有一个用来保存 goroutine 的运行队列。因为每个 Go 程序只有一个调度器，所以在每个 Go 程序中 schedt 结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的 goroutine 运行队列，我们称这个运行队列为全局运行队列(GRQ)。 p：表示执行所需要的资源，其最大数量同时也是 Go 代码的最大并行度。每一个运行着 go 代码的工作线程都会与一个 p 结构体的实例对象关联在一起。全局运行队列是每一个工作线程都可以读写的，因此为了并发安全，访问时需要加锁，但加锁势必耗费性能进而称为瓶颈。于是调度器为每一个工作线程引入了一个 私有的 goroutine 运行队列，我们称之为“局部队列(LRQ)”，工作线程优先使用局部队列的 goroutine，只有必要时才会去访问全局队列(后面还会了解到，当一个 p 的局部队列使用完时，还会去别的 p 偷几个 g 过来运行)，这大大减少了锁冲突，提高了工作线程的并发性。 m：代表实际工作线程，每一个工作线程都有唯一的m与之对应。m 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 p 结构体的实例对象之间的绑定关系。于是，通过 m 既可以找到与之对应的工作线程正在运行的 goroutine，又可以找到工作线程的局部运行队列等资源。 他们之间的关系，可以使用下图表示：\n另有一张图可能更清晰形象：\nGo scheduler 的职责就是将所有处于 可运行状态 的 goroutines 均匀分布到在 P 上运行的 M。\n当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。这被称为 Work-stealing，Go 从 1.1 开始实现。\nGo scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。\n实际上，Go scheduler 每一轮调度要做的工作就是找到处于 runnable 的 goroutines，并执行它。寻找的顺序如下：\nruntime.schedule() { // 检查全局队列，防止全局队列中的G被饿死 // if not found, 检查局部队列 // if not found, // 尝试从其他的P偷一些G过来 // if not found, 从全局队列中去一些 // if not found, poll network } 上述任何一步找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来一半的 G。\n这样做的好处是，有更多的 P 可以一起工作，加速执行完所有的 G。\n5. goroutine 的状态 如下图：\n6. Go scheduler 的调度时机 在以下四种情况下，scheduler 可能会发生调度——“可能”意味着，scheduler 只是有机会调度，但并不一定会发生。\n情形 说明 使用关键字 go 创建一个新的 goroutine，scheduler 会考虑调度 GC 肯定会发生调度，因为 GC 必须要在 M 上运行。 发生系统调用 当一个 goroutine 发生系统调用时，会阻塞 M，此时它会被调走，同时调用新的 goroutine 在 M 上运行 内存同步访问 atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 7. 同步/异步系统调用概览 当一个正在执行的 G(goroutine)需要进行系统调用时，根据调用类型，它所依附的 M 有两种情况：同步(系统调用等) 和 异步(网络请求等)。\n同步情况下，M1 会被阻塞，进而从 P 上调度下来，此时 G1 依然依附在 M1 上执行，之后会有一个新的 M2 被调用到 P 上，接着执行 P 的本地运行队列 LRQ 中的 G。一旦系统调用完成，G1 会再次加入 P 的 LRQ 等待被调度，而之前的 M1 则会被隐藏，等到需要的时候再次被使用。\n异步情况下，M1 不会被阻塞，G1 的异步请求会被另一个组件Network Poller接手，而 G1 本身也会被绑定到Network Poller上，等到系统调用结束，G1 会再次回到 P 上。由于 M 没有被阻塞，它可以继续执行当前被绑定的 P 的 LRQ 里面的 G。\n可以看到，在异步情况下，通过调度，Go scheduler 成功地将 IO 任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，极大地提高了效率。\n二、具体实现 有时间再细究。\n未完，待续…\n","permalink":"http://localhost:1313/posts/golang-gpm%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86/","summary":"\u003ch2 id=\"一概述\"\u003e一、概述\u003c/h2\u003e\n\u003ch3 id=\"1-为什么在内核的线程调度器之外go-还需要实现一个自己的调度器\"\u003e1. 为什么在内核的线程调度器之外，Go 还需要实现一个自己的调度器\u003c/h3\u003e\n\u003cp\u003e主要解决\u003cstrong\u003e系统线程太重\u003c/strong\u003e的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大；\u003c/li\u003e\n\u003cli\u003e系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003egoroutine 是 Go 语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang 程序员不会直接面对系统线程，直接使用 goroutine 就可以了，而操作系统不会 care 什么 goroutine，只是执行设定好的系统线程就好了。这层抽象，就是 Go 的调度器，后面会详细说明。Go 很精巧地解决了上述两个问题：\u003c/p\u003e","title":"Golang-GPM调度原理"},{"content":"1. Go语言指针的限制 go语言中也有指针，但相对C语言的指针来说，有了很多限制，但这也算是go的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\ngo中指针不能进行数学运算; func main() { num := 1 pNum := \u0026amp;num pNum++ // invalid operation: p++ (non-numeric type *int) } 不同类型的指针不能相互转换 func main() { var a int a = 10 var f *float32 f = \u0026amp;a // cannot use \u0026amp;a (type *int) as type *float32 in assignment } 不同类型的指针之间不能使用==或!=进行比较，也不能相互赋值 func main() { var a int var b float32 a = 1 b = 3.14 pa := \u0026amp;a pb := \u0026amp;b fmt.Println(pa == nil) fmt.Println(pa == pb) // invalid operation: pa == pb (mismatched types *int and *float32) pa = pb // cannot use pb (type *float32) as type *int in assignment } 只有在两个指针类型相同或者可以相互转换的情况下，才可以对两者进行比较。另外，指针可以通过 == 和 != 直接和 nil 作比较。\n2. unsafe包介绍 unsafe 包，“不安全”，为何不安全？是因为它可以使得用户绕过 go 的类型规范检查，能够对指针以及其指向的区域进行读写操作，即“允许程序无视 type 体系对任意类型内存进行读写”。因此使用时要格外小心。\nunsafe包中只有很简单的几个函数和定义:\npackage unsafe // 任意go表达式的类型。只是为了文档而声明的类型，实际上它并不是unsafe包的一部分 type ArbitraryType int // 任意类型代表的指针 type Pointer *ArbitraryType // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr // 返回x所在结构体的起始内存地址到x所对应属性两者距离，单位为byte，参数x的格式应该是structValue.field func Offsetof(x ArbitraryType) uintptr // 内存对齐时使用，这里暂时不研究 func Alignof(x ArbitraryType) uintptr 与此同时，unsafe包提供了两个很重要的功能：\n任何类型的指针 和 unsafe.Pointer 可以相互转换。 uintptr 类型和 unsafe.Pointer 可以相互转换。 即 任何数据类型的指针 \u0026lt;----\u0026gt; unsafe.Pointer \u0026lt;----\u0026gt; uintptr\n上述的功能有何用途？答： Pointer允许程序无视 type 体系对任意类型内存进行读写。\n如何理解这句话？因为unsafe.Pointer不能直接进行数学运算，但是我们可以将其转换成uintptr，对uintptr进行对应的数学运算(比如内存复制与内存偏移计算)，计算之后再转换成unsafe.Pointer类型。\n有了这个基础，我们可以干好多“见不得光”的事，比如 底层类型相同的数组之间的转换、使用 sync/atomic 包中的一些函数、访问并修改 Struct 的私有字段等场景。\n3. unsafe包的使用场景 场景一：访问并修改 struct 的私有属性 先从一个 demo 开始：\npackage main // unsafe修改struct私有属性 type user struct { name string age int company string } func main() { u := new(user) // A fmt.Println(*u) // { 0} uName := (*string)(unsafe.Pointer(u)) // B *uName = \u0026#34;Jemmy\u0026#34; fmt.Println(*u) // {Jemmy 0} uAge := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.age))) // C *uAge = 23 fmt.Println(*u) // {Jemmy 23} uCompany := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.company))) // D *uCompany = \u0026#34;吹牛逼技术有限公司\u0026#34; fmt.Println(*u) // {Jemmy 23 吹牛逼技术有限公司} } 在 A 处，我们新建一个user对象，使用new直接返回此类对象的指针。在这里要注意，在go中，对一个struct进行内存分配，实际上是分配的一块连续的空间，而new返回的指针，其实是struct中第一个元素的地址。\n通过上面的介绍我们知道，unsafe.Offsetof(x ArbitraryType) 返回 x 所在结构体的起始内存地址到 x 所对应属性两者距离，单位为 byte，参数 x 的格式应该是 structValue.field，那么unsafe.Offsetof(u.name)指的就是 u的起始地址，到属性name之间有多少个byte。\n在 C 处，因为unsafe.Pointer不能直接参与数学运算，所以我们先转换成uintptr类型，然后与unsafe.Offsetof(u.age)相加，就是u的属性age的地址，为uintptr类型，之后再转换为unsafe.Pointer，即可通过强制类型转换，直接去修改该属性的值。\n再来看 B 处，因为u的地址就是其第一个属性name的地址，可以直接获取到。其实我们可以改成和 C 处相似的结构：uName := (*string)(unsafe.Pointer(uintptr(unsafe.Pointer(u)) + unsafe.Offsetof(u.name)))，效果一样。\n**注意!!!**上面 C 处的语句的加号两边的对象不能直接拆开去写，也就是说，不能写成:\ntmp := uintptr(unsafe.Pointer(u)) uAge := (*int)(unsafe.Pointer(tmp + unsafe.Offsetof(u.age))) 原因是，uintptr这个临时变量，本身就是一个很大的整数，而程序经过一些很大的计算之后，涉及到栈的扩容，扩容之后，原来的对象的内存位置发生了偏移，而 uintptr 所指的整数对应的地址也就发生了变化。这个时候再去使用，由于这个整数指的地址已经不是原来的地址了，会出现意想不到的 bug。\n场景二： 利用unsafe获取 slice 的长度 通过查看对应的源代码，我们知道slice header的结构体定义为：\ntype slice struct { array unsafe.Pointer // 元素指针 1字节 len int // 长度 1字节 cap int // 指针 1字节 } 当我们调用make函数创建一个新的slice后，底层调用的是makeslice，返回的是slice结构体:\nfunc makeslice(et *_type, len, cap int) slice 因此，我们可以通过unsafe.Pointer和uintptr进行转换，得到 slice 的字段值：\nfunc main() { s := make([]int, 10, 20) // slice结构体中，array类型为pointer，占1个字节8位，uintptr(unsafe.Pointer(\u0026amp;s))表示s的地址也是第一个属性array的地址，那么加上属性array的长度，就是下一个属性len的长度 var sLen = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(8))) fmt.Println(*sLen, len(s)) // 10 10 // 16的原因同上 var sCap = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + uintptr(16))) fmt.Println(*sCap, cap(s)) // 20 20 } 场景三：实现string和[]byte 的零拷贝转换 一般的做法，都需要遍历字符串或 bytes 切片，再挨个赋值。\n在反射包src/reflect/value.go中，有下面的结构体定义：\ntype StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } 因此，只需共享底层的Data和Len即可：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } 4. unsafe.Sizeof(struct) 的本质 先看源码注释：\n// Sizeof takes an expression x of any type and returns the size in bytes // of a hypothetical variable v as if v was declared via var v = x. // The size does not include any memory possibly referenced by x. // For instance, if x is a slice, Sizeof returns the size of the slice // descriptor, not the size of the memory referenced by the slice. // The return value of Sizeof is a Go constant. // 返回对象x所占有的的内存大小(byte为单位)，不包含x中引用类型所占有的内存大小 func Sizeof(x ArbitraryType) uintptr 这其中比较有意思的是 unsafe.Sizeof(a struct)的结果问题，即一个struct的 size 值为多少的问题。\n我们来观察一个有趣的事实：一个struct的 size 依赖于它内部的属性的排列顺序，即两个属性相同但排列顺序不同的struct的 size 值可能不同。\n比如，下面这个结构体 A 的 size 是 32：\ntype struct A{ a bool b string c bool } 而另一个和它有相同属性的结构体 B 的 size 是 24:\ntype struct B{ a bool c bool b string } 这都是 内存对齐在捣鬼。我们看一下 A 和 B 的内存位置：\n如上图所示，左边为struct A，右边为struct B。而Aligment可以使 1,2,4 或者 8。对 A 来说，a bool占一个 byte，而下一个属性是b string，占 16 个 byte(后面会说明为什么占 2 个字节)，因此无法进行内存对齐；而对 B 来说，a bool和c bool可以放在同一个 byte 中。\n在Golang中，各类型所占的 byte 如下\nbool,int8,uint8 \u0026ndash;\u0026gt; 1 byte int16,uint16 \u0026ndash;\u0026gt; 2 byte int32,uint32,float32 \u0026ndash;\u0026gt; 4 byte int,int64,uint64,float64,pointer \u0026ndash;\u0026gt; 8 byte string \u0026ndash;\u0026gt; 16 byte (两个字节) 任何 slice \u0026ndash;\u0026gt; 24 byte(3 个字节) 长度为 n 的 array \u0026ndash;\u0026gt; n*对应的 type 的长度 为什么string占到 2 个字节？因为 string 底层也是一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占 8 个字节；\n为什么任意类型的slice占到 3 个字节？同理，slice底层也是一个结构体，有三个域：\n// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 1个字节 len int // 长度 8个byte 1个字节 cap int // 容量 8个byte 1个字节 } 说到这里，你也应该明白了，unsafe.Sizeof总是在编译期就进行求值，而不是在运行时，而且是根据类型来求值，而和具体的值无关。(这意味着，unsafe.Sizeof的返回值可以赋值给const即常量)\n可以通过下面的 demo 输出，判断你的掌握程度：\npackage main type user struct { name string // 2字节 age int // 1字节 company string // 2字节 } func main(){ fmt.Println(unsafe.Sizeof(user{})) // 输出40，5个字节，看 struct user 注释 fmt.Println(unsafe.Sizeof(10)) // 输出8，因为int占1字节 fmt.Println(unsafe.Sizeof([]bool{true, false})) // 输出24，任何slice都输出24 fmt.Println(unsafe.Sizeof([][]string{})) // 输出24，任何slice都输出24，即使是多维数组 } 5. 参考文献 码农桃花源—标准库\u0026ndash;unsafe sizeof-struct-in-go ","permalink":"http://localhost:1313/posts/golang-unsafe%E5%8C%85%E8%AF%A6%E8%A7%A3/","summary":"\u003ch2 id=\"1-go语言指针的限制\"\u003e1. \u003ccode\u003eGo\u003c/code\u003e语言指针的限制\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ego\u003c/code\u003e语言中也有指针，但相对\u003ccode\u003eC语言\u003c/code\u003e的指针来说，有了很多限制，但这也算是\u003ccode\u003ego\u003c/code\u003e的成功之处：既可以享受指针带来的便利，又避免了指针过度使用带来的危险。主要的限制如下：\u003c/p\u003e","title":"Golang-unsafe包详解"},{"content":"在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\nGo 语言中数组、字符串和切片三者是密切相关的数据结构。这三种数据类型，在底层原始数据有着相同的内存结构，在上层，因为语法的限制而有着不同的行为表现。\n一、 数组(Array) 1. 概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存其中的元素，我们可以利用数组中元素的索引快速访问元素对应的存储地址。\n数组作为一种基本的数据类型，我们通常都会从两个维度描述数组：类型 和 大小(能够存储的最大元素个数)：\n// 源码位于 /usr/local/go/src/cmd/compile/internal/types/type.go // Array contains Type fields specific to array types. type Array struct { Elem *Type // element type 元素类型 Bound int64 // number of elements; \u0026lt;0 if unknown yet 最大元素个数，小于0表示未知 } // NewArray returns a new fixed-length array Type. func NewArray(elem *Type, bound int64) *Type { if bound \u0026lt; 0 { Fatalf(\u0026#34;NewArray: invalid bound %v\u0026#34;, bound) } t := New(TARRAY) t.Extra = \u0026amp;Array{Elem: elem, Bound: bound} t.SetNotInHeap(elem.NotInHeap()) return t } 从上述代码可以看出，类型Array包含两个属性，一个是数组类型Elem，另一个是数组大小Bound。另外需要注意的是：Go 语言中数组在初始化之后大小无法改变。\n2. 初始化 有两种初始化方式：\narray1 = [5]int{1, 2, 3, 4, 5} array2 = [...]int{1, 2, 3, 4, 5} 上述两种声明方式在运行期间得到的结果是完全相同的，后一种声明方式在编译期间就会被“转换”成为前一种，这也就是编译器对数组大小的推导。\n对第一种方式，那么变量的类型在编译进行到类型检查阶段就会被提取出来，随后会使用 NewArray函数创建包含数组大小的 Array 类型。\n对第二种方式，在第一步会创建一个Array{Elem: elem, Bound: -1}，即其大小会是-1，不过这里的-1只是一个占位符，编译器会在后面的 /usr/local/go/src/cmd/compile/internal/gc/typecheck.go 中对数组大小进行推导，并更新其 Bound 值：\n// The result of typecheckcomplit MUST be assigned back to n, e.g. // n.Left = typecheckcomplit(n.Left) func typecheckcomplit(n *Node) (res *Node) { ... // Need to handle [...]T arrays specially. if n.Right.Op == OTARRAY \u0026amp;\u0026amp; n.Right.Left != nil \u0026amp;\u0026amp; n.Right.Left.Op == ODDD { n.Right.Right = typecheck(n.Right.Right, ctxType) if n.Right.Right.Type == nil { n.Type = nil return n } elemType := n.Right.Right.Type // typecheckarraylit type-checks a sequence of slice/array literal elements. length := typecheckarraylit(elemType, -1, n.List.Slice(), \u0026#34;array literal\u0026#34;) n.Op = OARRAYLIT n.Type = types.NewArray(elemType, length) n.Right = nil return n } ... } 虽然在编译期这两种方式的实现方式不同，但在运行时这两中方式是完全等价的。事实上，[...]T 这种初始化方式也只是 Go 语言为我们提供的一种语法糖，当我们不想计算数组中的元素个数时可以偷个懒。\n另：变量初始化的位置：\n如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化；如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换之后代码才会继续进入 中间代码生成 和 机器码生成 两个阶段，最后生成可以执行的二进制文件。\n3. 赋值与访问 Go 语言中数组是值语义。一个数组变量即表示整个数组，它并不是隐式的指向第一个元素的指针（比如 C 语言的数组），而是一个完整的值。当一个数组变量被赋值或者被传递的时候，实际上会复制整个数组。如果数组较大的话，数组的赋值也会有较大的开销。为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。\nvar a = [...]int{1, 4, 3} // a 是一个数组 var b = \u0026amp;a // b 是指向数组的指针 fmt.Println(a[0], a[1]) // 打印数组的前2个元素 fmt.Println(b[0], b[1]) // 通过数组指针访问数组元素的方式和数组类似 for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v) } 我们可以用for循环来迭代数组。下面常见的几种方式都可以用来遍历数组：\nfmt.Println(\u0026#34;方式一：\u0026#34;) for i := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } fmt.Println(\u0026#34;方式二：\u0026#34;) for i, v := range a { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, v) } fmt.Println(\u0026#34;方式三：\u0026#34;) for i := 0; i \u0026lt; len(a); i++ { fmt.Printf(\u0026#34;a[%d]: %d\\n\u0026#34;, i, a[i]) } // 输出 方式一： a[0]: 1 a[1]: 4 a[2]: 3 方式二： a[0]: 1 a[1]: 4 a[2]: 3 方式三： a[0]: 1 a[1]: 4 a[2]: 3 用for range方式迭代的性能可能会更好一些，因为这种迭代可以保证不会出现数组越界的情形，每轮迭代对数组元素的访问时可以省去对下标越界的判断。\n需要注意的是 长度为 0 的数组。长度为 0 的数组在内存中并不占用空间，有时候可以用于强调某种特有类型的操作时避免分配额外的内存空间，比如用于管道的同步操作：\nc1 := make(chan [0]int) go func() { fmt.Println(\u0026#34;c1\u0026#34;) c1 \u0026lt;- [0]int{} }() \u0026lt;-c1 在此场景下我们并不关心管道中的具体数据以及类型，我们需要的只是管道的接收和发送操作用于消息的同步，此时，空数组作为管道类型可以减少管道元素赋值时的开销。当然一般更倾向于用无类型的匿名结构体代替：\nc2 := make(chan struct{}) go func() { fmt.Println(\u0026#34;c2\u0026#34;) c2 \u0026lt;- struct{}{} // struct{}部分是类型, {}表示对应的结构体值 }() \u0026lt;-c2 注：本节参考自Go 语言高级编程 1.4\n二、切片(Slice) 切片和数组非常类似，可以用下标的方式访问，也会在访问越界时发生panic。但它比数组更加灵活，可以自动扩容。\n1. 内部实现 源代码位于： /usr/local/go/src/runtime/slice.go\ntype slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 长度(已经存放了多少个元素) cap int // 容量(底层数组的元素个数)，其中 cap\u0026gt;=len } 需要注意的是，底层的数组是可以被多个 slice 同时指向的，因此，对一个 slice 元素进行操作可能会影响其他指向对应数组的 slice。\n2. slice 的创建 方式 代码示例 说明 直接声明 var arr1 []int 其实是一个nil slice，array=nil,len=0,cap=0。此时没有开辟内存作为底层数组。 new arr2 := *new([]int) 也是一个nil slice，没有开辟内存作为底层数组。也没有设置元素容量的地方，此时只能通过append来添加元素，不能使用下标。 字面量 arr3 := []int{1,2,3} make arr4 := make([]int,2,5) 切片类型、长度、容量，其中容量可以不传，默认等于长度。 从切片或数组“截取” arr5 := arr4[1:2] 3. 关于 make 创建 slice Go 编译器会在编译期，根据以下两个条件来判断在哪个位置创建 slice：\n切片的大小和容量是否足够小 切片是否发生了逃逸 当要创建的切片非常小并且不会发生逃逸时，这部分操作会在编译期完成，并且创建在栈上或者静态存储区。如 n := make([]int,3,4) 会被直接转化成如下所示的代码：\nvar arr = [4]int n := arr[:3] 当发生逃逸或者比较大时，会在运行时调用 runtime.makeslice 函数在堆上初始化。而runtime.makeslice函数非常简单：\n// et是元素类型 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断len cap参数是否合法 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 在堆上申请一片连续的内存 return mallocgc(mem, et, true) } 这个函数的主要作用就是 计算当前切片所占用的内存空间并在堆上申请一段连续的内存，所需的内存空间采用以下的方式计算：\n内存空间 = 元素类型大小 * 切片容量cap 而元素类型的大小参照如下：\n类型 大小 bool, int8, uint8 1 bit int16, uint16 2 bit int32, uint32, float32 4 bit int, int64, uint64, float64, pointer 8 bit (1 个字节) string 16 bit (2 个字节) 长度为 n 的 array n * (对应的 type 的长度) TIPS：1 字节(Byte） = 8 位(bit)\nmallocgc 是专门用于内存申请的函数，后面会详细讲解。\n4. 切片截取 截取 是创建切片的一种方式，可以从数组或者切片直接截取，同时需要制定截取的起始位置。\n需要关注的是下面这种截取方式： arr1 = data[low : high : max]。这里的三个数字都是指原数组或切片的索引值，而非数量。\n这里的 low是最低索引值，是闭区间，也就是说第一个元素是位于data位于low索引处的元素；high是开区间，表示最后一个元素只能索引到 high - 1处；max也是开区间，表示容量为 max - 1。其中：len = high - low，cap = max - low，max \u0026gt;= high \u0026gt;= low。用下面的图来帮助说明：\n基于已有的数组或者切片创建新的切片，新 slice 和老 slice 会公用底层的数组，新老 slice 对底层数组的更改都会影响彼此。需要注意的是，如果某一方执行了append操作引起了 扩容 ，移动到了新位置，两者就不会影响了。所以关键问题在于二者是否会共用底层数组。\n我们通过一个例子来说明，该例子来自于雨痕 Go 学习笔记 P43，做了一些改造：\npackage main import \u0026#34;fmt\u0026#34; func main() { slice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] s2 := s1[2:6:7] s2 = append(s2, 55) s2 = append(s2, 77) s1[2] = 66 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } // 输出 [7 6 66] [5 4 3 2 100 200] [9 8 7 6 66 4 3 2 100 0] 让我们一步步来分析：\n首先，创建 slice、s1 和 s2：\nslice := []int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} s1 := slice[2:5] // len为3，cap默认到底层数组的结尾 s2 := s1[2:6:7] // len为4，cap为5 // 以上三个底层数组相同 之后，向 s2 尾部追加一个元素：\ns2 = append(s2, 55) s2的容量刚好还剩一个，直接追加，不会扩容。因为这三者此时还都共用同一个底层数组，所以这一改动，slice和s1都会受到影响：\n再次向 s2 追加一个元素：\ns2 = append(s2, 77) 此时，s2 的容量不够用，需要扩容。简单来说，扩容是新申请一块更大(具体多大，后面会说到，假设为原来的 2 倍)的内存块，将原来的数据 copy 过去，s2 的array指针指向新申请的那块内存。再次 append 之后：\n最后，修改 s1 索引为 2 处的元素：\ns1[2] = 66 此时 s2 已经使用了新开辟的内存空间，不再指向slice和s1指向的那个数组，因此 s2 不会受影响：\n后面打印 s1 的时候，只会打印出 s1 长度以内的元素。所以，只会打印出 3 个元素，虽然它的底层数组不止 3 个元素。\n5. append 扩容规则 之前说过，扩容是新申请一块更大的内存块，将原来的数据 copy 过去，原来切片的array指针指向新申请的那块内存。这里我们探讨这个“更大”到底是多大：\n第一步，预估扩容后的容量 newCap：\ndata = []int{1,2} data = appand(data,3,4,5) 扩容前的容量 oldCap = 2，新增 3 个元素，理论上应该扩容到 cap=5，之后会进行预估，求得 newCap 规则如下：\n如果 $oldCap * 2 \u0026lt; cap$，那么 newCap = cap；\n否则\n如果 扩容前元素个数oldLen \u0026lt; 1024​ ，那么直接翻倍，即 newCap = oldCap * 2； 否则(即 扩容前元素个数oldLen \u0026gt;= 1024 )，就先扩容 四分之一，也就是 1.25 倍，即 newCap = oldCap * 1.25。 即：\n这段规则的源码位于 /usr/local/go/src/runtime/slice.go：\nfunc growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { if old.len \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } ... } 上述例子中，oldCap=2，至少需要扩容到cap=5，根据预估规则，因为 oldCap*2=4 \u0026lt; 5，因此 newCap=cap=5，即预估结果为newCap=5。\n第二步，确定实际分配的内存，匹配到合适的内存规格\n理论上所需要内存 = 预估容量 * 元素类型大小，难道直接就会分配这么多的内存吗？并不是。\n首先元素类型大小已在 “一.3”中说明过，此处 int 类型的大小是 8bit(1 个字节)。接着看growslice函数：\nfunc growslice(et *_type, old slice, cap int) slice { ... var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) .... } 在这里，sys.PtrSize = 8，et类型是 int，所以 et.size == sys.PtrSize为 true，则 newcap * sys.PtrSize = 5 * 8 = 40。我们看看 roundupsize这个函数，位于 /usr/local/go/src/runtime/msize.go：\n// Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { // ... } } ... } 其中，_MaxSmallSize = 32768，smallSizeMax = 1024，smallSizeDiv = 8，而传进来的 size = 40。而：\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31} 所以上面roundupsize会返回：\nclass_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] = 48 在growslice中，capmem = 48，则最后计算得到的 newcap = int(capmem / sys.PtrSize) = int(48 / 8) = 6，即最终扩容后的容量为 6。而不是之前预估的 5。\n总结一下，首先使用预估规则预估一下需要的容量(本例中为 5)，然后用这个容量乘以 slice 元素的大小(单位是 bit，本例中 int 为 8)，之后根据在 class_to_size 中选择合适大小的值，比如 40，那应该选择比 40 大的更小的那个 48，这就是申请到的真正的容量内存，最后用真正的容量大小除以元素大小，即可得到真正的扩容后的 slice 的cap。\n6. slice 作为函数参数 函数调用处的参数称为 实参，函数定义处的参数称为 形参。形参是实参的拷贝，会生成一个新的切片，但二者指向底层数组的指针相同。\n当函数中没有出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,66,3,4,5,6] } func t1(s []int) { s[1] = 66 } 当函数中出现扩容时：\nfunc main() { a := []int{1,2,3,4,5,6} fmt.Println(a) // 输出 [1,2,3,4,5,6] t1(a) fmt.Println(a) // 输出 [1,2,3,4,5,6] } func t2(s []int) { s = append(s, 66) } 扩容后，指向的底层数组不同，互不影响。\n三、字符串(String) 字符串是 Go 语言中最常用的基础数据类型之一，虽然字符串往往被看做一个整体，但是实际上字符串是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组。\n在设计上，Go 语言中的string是一个只读的字节数组。当然，只读只意味着字符串会分配到只读的内存空间并且这块内存不会被修改，在运行时我们其实还是可以将这段内存拷贝到堆或者栈上，将变量的类型转换成 []byte 之后就可以进行，修改后通过类型转换就可以变回 string，Go 语言只是不支持直接修改 string 类型变量的内存空间。\nstring的底层结构如下：\n// /usr/local/go/src/runtime/string.go type stringStruct struct { str unsafe.Pointer len int } 可以看到和上面的切片结构非常相似，只是少了表示容量的cap。这是因为，字符串作为只读类型，我们并不会对齐进行扩容操作进而改变其自身的内存空间，所有在字符串上执行的写入操作都是通过拷贝实现的。\n关于字符串，讨论最多的是 string和[]byte互相转换的性能问题，在底层是通过 stringtoslicebyte 和 slicebytetostring两个函数实现的，其中出现了内存分配的情况，这里不做细究。\n在说unsafe 那篇文章里，提到了 实现string和[]byte 的零拷贝转换：这里再复习一下：\nfunc stringToBytes(s string)[]byte{ return *(*[]byte)(unsafe.Pointer(\u0026amp;s)) } func bytesToString(b []byte)string{ return *(*string)(unsafe.Pointer(\u0026amp;b)) } ","permalink":"http://localhost:1313/posts/golang-%E6%95%B0%E7%BB%84-%E5%88%87%E7%89%87%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/","summary":"\u003cp\u003e在主流的编程语言中数组及其相关的数据结构是使用得最为频繁的，只有在它(们)不能满足时才会考虑链表、hash 表（hash 表可以看作是数组和链表的混合体）和更复杂的自定义数据结构。\u003c/p\u003e","title":"Golang-数组,切片和字符串"},{"content":"一、 前言 我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\n最上面为高地址，最下面为低地址，分配时由高地址向低地址增长。函数的地址由低地址向高地址方向存放。\n从高地址到低地址依次为 栈空间、堆空间、全局静态变量区(数据区)、代码区。\n二、函数栈帧 函数执行时需要由足够的内存空间，用于存放 局部变量、返回值、参数等，这段空间对应内存中的栈。栈最上面是高地址，向下增长。\n分配给函数的栈空间，称为 函数栈帧(function stack frame)，栈底称为 栈基(bp)，栈顶称为 栈指针(sp)。函数调用结束后又会释放这个栈帧。bp 和 sp 始终指向正在执行的函数的栈帧。如果出现 A 调用 B，B 调用 C，C 调用 D，那么会出现由上到下分别为A的栈帧-\u0026gt;B的栈帧-\u0026gt;C的栈帧-\u0026gt;D的栈帧的情况:\n计算机执行函数时，会有专门的寄存器存放栈基 bp、栈指针 sp 和下一条要执行的指令 ip。\n所有的函数的栈帧布局都遵循统一的约定，所以被调用者是通过栈指针加上偏移量来定位到每个参数和返回值的。\nGo 在分配栈帧时是 一次性分配(主要是为了防止栈访问越界) ：(首先函数栈帧的空间在编译时期是可以确定的)确定栈基 bp，然后直接将栈指针 sp 移到所需最大栈空间的位置。之后通过栈指针 sp+偏移值这种相对寻址方式来使用函数栈帧。(例如需要将 3 和 4 依次入栈，则对应的指令分别是 sp+16 处存放 3，sp+8 处存放 4)\n由于函数栈帧的大小，可以在编译时期确定，对于栈消耗较大的函数，Go 编译器会在函数头部加上检测代码，如果发现需要进行栈增长，就会另外分配一块足够大的栈空间，并把原来栈上的数据拷过来，同时释放掉原来的栈空间。\n三、函数调用过程 有两个指令：call 和 ret。函数 call 指令实现跳转，而每个函数开始时都会分配栈帧，结束前又会释放自己的栈帧，ret 指令又会把栈恢复到之前的样子。\ncall的过程：\n将下一条指令的地址入栈，这就是返回地址，被调用函数执行结束后会回到这里； 跳转到被调用函数的入口处执行，这后面就是被调用函数的栈帧了。 ret过程：\n弹出返回地址； 跳转到这个返回地址 Go 与 C 语言不同的是，C 是通过寄存器和栈传递参数和返回值的，而 Go 是通过栈。下面通过举例说明 Go 中一个栈帧的结构以及函数调用过程中栈帧的变化：\n设有函数 A 和 B，在 A 内部调用了 B：\nfunc A() { x,y := 2,3 z := B(x,y) fmt.Println(x,y,z) } func B(m, n int) k int { return m + n } 首先需要了解的是，**被调用者的参数和返回值，都在调用者的函数栈帧中。**它们在栈中的顺序由上到下依次是：\nA 的局部变量 被调用函数 B 的返回值 传递给被调用函数 B 的参数(注意，参数顺序与实际书写书序相反) B 调用结束后的返回地址(A 中调用 B 之后要执行的命令，即 fmt.Println(x, y, z)) 调用者 A 的 bp 结构如下：\n而具体执行上述代码第 3 行也就是函数调用的详细过程如下：\n执行 call 函数：\na. 将调用者的下一条指令(第 4 行代码)入栈，这就是返回地址，被调用函数执行结束后会回到这里；\nb. 跳转到被调用者处(修改 ip 寄存器的值) 在被调用函数开始处有三步：\na. 将 sp 向下移动到足够的空间处(如 sp-24 处)；\nb. 调用者栈基(当前 bp 的值)入栈(调用者栈)(如存放到 sp+16 处)； 此时 bp 的值是被调用者 B 的栈基 结果是：bp 和 sp 始终指向正在执行的函数的栈帧； 接下来执行被调用函数剩下的部分；\na. 被调用者结束调用时，在 ret 函数前面还有两步：\n​ 1). 恢复调用者的栈基 bp 地址——第 2 步中的第 2 步，将栈该处的值赋给寄存器 bp\n​ 2). 释放自己的栈帧空间——第 2 步中的第 1 步，分配时向下移动了 24，则释放时向上移动多少 结果是：此时 bp 和 sp 已经恢复到调用者的栈帧了 执行 ret 步骤：\na. 弹出 call 指令的返回地址(对应过程 1 中的第 1 步)\nb. 跳转到弹出的这个地址(修改 ip 寄存器) 结果是：“被调用者”调用完毕，执行的是调用者的下一个指令，即调用完成(执行完被调用者)后，继续执行调用者函数。 如果在 B 中出现了defer操作，那么应该先执行defer，还是先执行return呢，还是先执行ret过程呢？\n答案是：Go 中的 return 并不是真正的返回，真正的返回操作是ret操作，return的作用仅仅是给返回值赋值，之后再执行defer操作，最后才是ret过程(释放自己的栈帧)。\n四、传参与返回值 理论部分已经全部说完了，下面通过一些实战来加深理解：\n为何有时通过函数交换变量位置却不成功？ func swap(a, b int) { a,b = b,a } func main() { a,b := 1,2 swap(a, b) fmt.Println(a,b) // 输出 1 2 // 交换失败 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2, a=1(入栈顺序与调用顺序相反)(没有返回值，对应3.传递给被调用函数 B 的参数) 执行 “a,b = b,a”，交换的是第 7 行入栈的两个变量而不是第 6 行入栈的调用者的局部变量 执行 ret 过程，返回之后，栈中 A 的局部变量并没有被改变，所以还是 a=1, b=2 再看下面的函数：\nfunc swap(a, b *int) { *a, *b = *b, *a } func main() { a,b := 1,2 swap(\u0026amp;a, \u0026amp;b) fmt.Println(a,b) // 输出 2 1 // 交换成功 } 过程如下：\n函数第 6 行，栈中从上到下为 a=1, b=2（对应1.A 的局部变量） 函数第 7 行，栈中入栈 b=2 的地址, a=1 的地址(对应3.传递给被调用函数 B 的参数) 执行 “*a,*b = *b,*a”，传递的是 A 中变量的地址，实际上进行的是 A 中的变量的 b 和 A 中的变量的 a 交换 执行 ret 过程，返回之后，栈中 A 的局部变量被改变 有返回值，匿名返回值 func incr1(a int) int { var b int defer func() { a++ b++ }() a++ b = a return b } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 1 } 过程如下：前面说过，return 的作用相当于给返回值赋值，之后再执行 defer 函数，之后才是 ret 过程\n第 15 行，栈中从上到下为 a=0, b=0 第 16 行，incr1 的返回值，默认 0 值 第 2 行，incr1 的局部变量 b=0 第 9 行，incr1 的参数 a=0，自增后变成 2 第 10 行，incr1 的局部变量 b=1 第 11 行，incr1 的返回值被改变为 1 之后执行 defer 函数，incr1 的局部变量 a=3，incr1 的局部变量 b=1(注意，这里改变的是 incr1 的局部变量，而不是返回值) 返回，返回值依旧是 1 有返回值，非匿名返回值(命名返回值) func incr2(a int) (b int) { defer func() { a++ b++ }() a++ return a } func main() { var a, b int b = incr1(a) fmt.Println(a, b) // 输出 0 2 } 过程与上述类似，只不过返回值变成了 incr1 中的 b，在第 8 步时首先被赋值 1，之后再 defer 中又自增，变成 2，因此返回值变成了 2。\n","permalink":"http://localhost:1313/posts/golang-%E5%85%B3%E4%BA%8E%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/","summary":"\u003ch2 id=\"一-前言\"\u003e一、 前言\u003c/h2\u003e\n\u003cp\u003e我们完成程序的编写之后，经过编译，编译器会将我们的程序编译成一行行机器指令，放到一个可执行文件中；程序执行时，可执行文件被加载到内存，机器执行被放置到虚拟内存的“代码段”，并分配以及初始化程序运行过程中需要的堆栈。会形成如下的结构：\u003c/p\u003e","title":"Golang-关于函数调用"},{"content":"选择优化的数据类型 MySQL 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\n更小的通常更好\n一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 0 ~ 200 ，那么字段类型设置为 unsigned tinyint 更好。\n简单就好\n简单数据类型的操作通常需要更少的 CPU 周期。例如整形比字符串的操作代价更低，因为字符串还要考虑 字符集 和 排序规则 ，使得字符串的比较比整形更加复杂。这里有两个例子：存储日期时，应该使用 MySQL 的内建类型( date 、 time 、 datetime 、 timestamp 等)而不是使用字符串；存储 IP 地址时，应该使用整型而非字符串， MySQL 中有专门的处理函数：\nmysql\u0026gt; select INET_ATON(\u0026#34;172.16.11.102\u0026#34;); +----------------------------+ | INET_ATON(\u0026#34;172.16.11.102\u0026#34;) | +----------------------------+ | 2886732646 | +----------------------------+ mysql\u0026gt; select INET_NTOA(2886732646); +-----------------------+ | INET_NTOA(2886732646) | +-----------------------+ | 172.16.11.102 | +-----------------------+ 行属性尽量避免 NULL\n一般情况下，某一行的默认属性是 NULL 。书中(《高性能 MySQL》)建议，最好指定列为 NOT NULL ，除非真的需要存储 NULL 值。这只是一个建议——如果计划在列上建索引，应该尽量避免设计成 可为 NULL 的列。\n1. 数字 1.1 整型(Whole Number) 可使用类型如下：\n类型 位数 范围 TINYINT 8 位（1 字节） -128~127 SMALLINT 16 位（2 字节） -32768~32767 MEDIUMINT 24 位（3 字节） -8388608~8388607（830 万多） INT 32 位（4 字节） -2147483648~2147483647（21 亿多） BIGINT 64 位（8 字节） -9223372036854775808~922, 3372, 0368, 5477, 5807（900 亿亿，反正很大啦） 整型有可选的 unsigned ，表示 非负 ，这大致可使正数的上限提高一倍。\n有符号和无符号整数使用相同的存储空间，有相同的性能，可根据实际情况选择以适合自己业务。\nMySQL 可以为整数类型指定宽度，例如 INT(11)， 但绝大多数情况下没有意义：对于存储和计算来说，**INT(11)**和 **INT(20)**是相同的，宽度不会限制值的合法范围，只是规定了 MySQL 的一些交互工具用来显示字符的个数。\n1.2 实数类型(Real Number) 实数是指 带有小部分的数字。我们能接触到的有 FLOAT 、 DOUBLE 和 DECIMAL 。这三个可以进一步划分： FLOAT 、 DOUBLE 称为浮点型， DECIMAL 就是 DECIMAL 类型。\n我们知道，标准的浮点运算由于硬件原因（篇幅所限具体原因请自行寻找），进行的是近似运算，如 Python 3.8 中 $0.1 + 0.2 = 0.30000000000000004$， Golang go1.13.4 darwin/amd64 中 fmt.Println(fmt.Sprintf(\u0026quot;%0.20f\u0026quot;, 0.1+0.2)) 输出$0.29999999999999998890 $ ，而 FLOAT 和 DOUBLE 所属的 浮点型 进行的就是这种运算。\n而 DECIMAL 用于存储精确的小数。因为 CPU 不支持对 DECIMAL 的直接计算，因此 在 MySQL 5.0及以后的版本 中， MySQL 服务器自身实现了 DECIMAL 的高精度计算。因此我们可以说，后期版本中，MySQL 既支持精确类型，也支持不精确类型。 相对而言， CUP 直接支持原生浮点运算，所以浮点运算明显更快。\nMySQL 使用二进制的形式存储 DECIMAL 类型。使用方式为 DECIMAL(总位数，小数点后位数) ，其中总位数最大为 65，小数点后位数最大为 30；并且位数与字节大小的对应关系为 9位/4字节 ，即每 9 位占 4 个字节，同时小数点占用一个字节。比如 DECIMAL(20, 9)共占用 5 个字节——小数点左边占用 3 个字节，小数点一个字节，小数点右边共占一个字节。\n浮点类型在存储同样范围的值时，通常比 **DECIMAL**使用更少的空间。 FLOAT 使用 4 个字节存储， DOUBLE 占用 8 个字节。需要注意的是，我们能选择的只是类型，即表示的范围大小，和整形一样，在 MySQL 底层进行计算的时候，所有的实数进行计算时都会转换成 DOUBLE 类型。\n2. 字符串 2.1 VARCHAR(变长字符串) VARCHAR 用于存储可变长字符串，是最常见的字符串数据类型。它比定长类型(CHAR)更加节省空间，因为它仅使用必要的空间。\n变长字符串 VARCHAR 需要使用额外的 1 个或 2 个字节记录字符串的长度：如果列的最大长度\u0026lt;=255 字节，则使用 1 个字节表示，否则使用 2 个字节。\nVARCHAR 节省空间，这对性能提升也有帮助，但由于行长是变的，如果通过 UPDATE 操作使得行长变得比原来更长，那就需要做一些额外的工作。不同引擎有不同的处理结果。\n当 VARCHAR 过长时，InnerDB 会将其保存为 BLOB，同时使用专门的外部区域来保存大文件，行中只保存对应的地址。\n2.2 CHAR(定长字符串) 当使用 CHAR(n) 时，会一次性分配足够的空间，注意这里的 n 指的是字符数而不是字节数。当存储 CHAR 时，会自动去掉末尾的空格，而 VARCHAR 不会。\nCHAR 非常适合存储很短的字符串，或者长度都很接近的字符串，例如密码的 MD5 值，因为这是一个定长的值。对于非常短的列， CHAR 比 VARCHAR 在存储空间上更有效率。\n关于“末尾空格截断”，通过下面的例子说明：\n\u0026gt; mysql\u0026gt; CREATE TABLE t1 (cl CHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t1(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t1; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3\u0026#39; | \u0026gt; +--------------------+ \u0026gt; ``` \u0026gt; \u0026gt; 我们再看下VARCHAR： \u0026gt; \u0026gt; ``` mysq \u0026gt; mysql\u0026gt; CREATE TABLE t2 (cl VARCHAR(10)); \u0026gt; mysql\u0026gt; INSERT INTO t2(cl) VALUES(\u0026#39;string1\u0026#39;),(\u0026#39; string2\u0026#39;),(\u0026#39;string3 \u0026#39;); \u0026gt; # 执行查询 \u0026gt; mysql\u0026gt; SELECT CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) FROM t2; \u0026gt; +--------------------+ \u0026gt; | CONCAT(\u0026#34;\u0026#39;\u0026#34;,cl,\u0026#34;\u0026#39;\u0026#34;) | \u0026gt; +--------------------+ \u0026gt; | \u0026#39;string1\u0026#39; | \u0026gt; | \u0026#39; string2\u0026#39; | \u0026gt; | \u0026#39;string3 \u0026#39; | \u0026gt; +--------------------+ 区别主要在 string3 后面的空格是否被截断。\n2.3 BLOB 和 TEXT BLOB 和 TEXT 都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。\n它们属于不同的数据类型：字符类型有 TINYTEXT, SMQLLTEXT, TEXT, MEDIUMTEXT, LONGTEXT，对应的二进制类型有 TINYBLOB, SMQLLBLOB, BLOB, MEDIUMBLOB, LONGBLOB。其中 BLOB 是 SMALLBLOB 的同义词，TEXT 是 SMALLTEXT 的同义词。\n当 BLOB 和 TEXT 的值太大时，InnerDB 会使用专门的“外部存储区域”进行存储实际内容，而行内使用 1~4 个字节存储一个外部内容的指针。\nBLOB 和 TEXT 家族之间仅有的不同是：BLOB 存储的是二进制的数据，没有排序规则和字符集，而 TEXT 有字符集和排序规则。\nMySQL 对 BLOB 和 TEXT 进行排序时与其他类型是不同的：它只针对没个列的最前 max_sort_length 字节而不是对整个字符串进行排序。如果需要排序的字符更少，可以尝试减小 max_sort_length ，或者使用 ORDER BY SUSTRING(column,length) 。\nMySQL 不能将 BLOB 或者 TEXT 列全部长度的字符串作为索引！\n3. 枚举、集合和位 3.1 枚举(ENUM) 枚举可以将一些不重复的字符串放到一个预定义的集合中，使用时也只能插入这个预定义集合中的某一个。\nMySQL 在存储枚举值时非常紧凑，在内部保存时，会将每个值在列表中的位置保存为整数(从 1 开始编号)，并在表的.frm 文件中保存“数字-字符串”映射关系的“查找表”；数据保存在两个字节中，因此枚举中可以有 $2^{16} - 1 = 65535$个。\nmysql\u0026gt; CREATE TABLE t2(e ENUM(\u0026#39;fish\u0026#39;,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;)); mysql\u0026gt; INSERT INTO t2(e) VALUES(\u0026#39;fish\u0026#39;),(\u0026#39;dog\u0026#39;),(\u0026#39;apple\u0026#39;),(1); # 注意，这里也可以世界使用枚举值对应的位置，如1对应\u0026#39;apple\u0026#39; # 查询枚举值，默认字符串表示 mysql\u0026gt; SELECT * FROM t2; +-------+ | e | +-------+ | fish | | dog | | apple | | fish | +-------+ # 使用数字形式表示枚举值 mysql\u0026gt; SELECT e+0 FROM t2; +------+ | e+0 | +------+ | 1 | | 3 | | 2 | | 1 | +------+ 尽量不要使用数字作为 ENUM 枚举常量，这种双重性很容易导致混乱，例如 ENUM('1','2','3') 。\n**注意：枚举字段是按照内部存储的整数而不是字符串顺序进行排序的。**一种绕过这种限制的方式是 刚开始就按照字典顺序来定义枚举值，另一中方式是使用 FIELD(列名，'arg1','arg2',…) 函数：\nmysql\u0026gt; SELECT e FROM t2 ORDER BY FIELD(e,\u0026#39;apple\u0026#39;,\u0026#39;dog\u0026#39;,\u0026#39;fish\u0026#39;); +-------+ | e | +-------+ | apple | | dog | | fish | | fish | +-------+ 3.2 集合(SET) 如果说 ENUM 是单选的话，那 SET 就是多选。适合存储预定义集合中的多个值。同 ENUM 一样，其底层依旧通过整形存储。\n设定 set 的格式：\n字段名称 SET(\u0026#34;选项1\u0026#34;,\u0026#34;选项2\u0026#34;,...,\u0026#39;选项n\u0026#39;) 如 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); 同样的， SET 的每个选项值也对应一个数字，依次是 1，2，4，8，16...， 最多有 64 个选项。\n使用的时候，可以使用 set 选项的字符串本身（多个选项用逗号分隔），也可以使用多个选项的数字之和（比如：1+2+4=7）。\n通过实例来说明：\n# 建表 CREATE TABLE t3(hobby SET(\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;)); # 插入一个选项，字符串格式 INSERT INTO t3(hobby) VALUES(\u0026#39;swim\u0026#39;); # 插入多个选项，字符串格式，通过英文逗号分隔 INSERT INTO t3(hobby) VALUES(\u0026#39;swim,movie\u0026#39;); # 插入一个选项，数字格式 INSERT INTO t3(hobby) VALUES(1); # 等同于\u0026#39;swim\u0026#39; INSERT INTO t3(hobby) VALUES(4); # 等同于\u0026#39;movie\u0026#39; # 插入多个选项，数字格式 INSERT INTO t3(hobby) VALUES(7); # 等同于\u0026#39;swim,music,movie\u0026#39;，因为\u0026#39;swim\u0026#39;,\u0026#39;music\u0026#39;,\u0026#39;movie\u0026#39;,\u0026#39;football\u0026#39;分别为“1,2,4,8”，7=1+2+4. # 显示全部 mysql\u0026gt; SELECT * FROM t3; +------------------+ | hobby | +------------------+ | swim | | swim,movie | | swim | | movie | | swim,music,movie | +------------------+ # 查找包含movie的行 mysql\u0026gt; SELECT * FROM t3 WHERE FIND_IN_SET(\u0026#39;movie\u0026#39;,hobby) \u0026gt; 0; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 寻找包含排号为4的成员的行 mysql\u0026gt; SELECT * FROM t3 WHERE hobby \u0026amp; 4; +------------------+ | hobby | +------------------+ | swim,movie | | movie | | swim,music,movie | +------------------+ # 直接使用字符串匹配 mysql\u0026gt; SELECT * FROM t3 WHERE hobby = \u0026#39;swim,movie\u0026#39;; +------------+ | hobby | +------------+ | swim,movie | +------------+ 3.3 位(BIT) NySQL 把 BIT 当成字符串类型而不是数字类型来存储。但是它的存储结果根据上下文会出现不同：\nmysql\u0026gt; CREATE TABLE t4(a BIT(8)); mysql\u0026gt; INSERT INTO t4(a) VALUES(b\u0026#39;00111001\u0026#39;); mysql\u0026gt; SELECT a, a+0 ,BIN(a) FROM t4; # bin()表示整数类型对应的二进制 +------+------+--------+ | a | a+0 | BIN(a) | +------+------+--------+ | 9 | 57 | 111001 | +------+------+--------+ 默认显示数字代表的 ASCII 码字符。\n","permalink":"http://localhost:1313/posts/mysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E4%BC%98%E5%8C%96/","summary":"\u003ch2 id=\"选择优化的数据类型\"\u003e选择优化的数据类型\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMySQL\u003c/code\u003e 支持多种数据类型，但是每个类型都有自己适合的场景，选对类型对性能的提高至关重要。以下原则仅供参考：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e更小的通常更好\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一般情况下，应该尽量选择可以存储数据的最小数据类型。如只需要存 \u003ccode\u003e0 ~ 200\u003c/code\u003e ，那么字段类型设置为 \u003ccode\u003eunsigned tinyint\u003c/code\u003e 更好。\u003c/p\u003e","title":"MySQL数据类型与优化"},{"content":"Docker 一、前言 Docker 是一个开源的应用容器引擎，可以让开发者将他们的应用以及依赖打包到一个可移植的容器中，这个容器可以发布并运行在任何流行的 Linux 环境下。\n理解：Docker 是什么？Docker 是一个容器，这个容器是可以随便移动的，就像一个箱子；箱子里是什么东西呢？箱子里是开发者写好的应用以及这个应用运行时的环境，即箱子里面是一个可以独立运行的沙盒应用；这个箱子有什么特点呢？可以随便搬动，并且能在任何 Linux 系统上直接运行（现在主流的服务器应用大多数都部署在 Linux 系统中）。\nDocker 的构想是实现Build, Ship, Run Anywhere，即通过对应用的 封装(Packaging) 、 分发(Distribution) 、 部署(Deployment) 、 运行(Runtime) 的生命周期进行管理，达到应用组件级别的“一次封装，到处运行”。这里的应用组件，既可以是一个 web 应用、一个编译环境，也可以是拥有运行环境的 web 服务，也可以是一套数据库平台服务，甚至是一个操作系统或者集群。\n二、Docker 架构 Docker 使用客户端-服务端架构。服务端负责构建、运行应用和分发容器（这个过程我是这样理解的：从上图可以看到有几个不同的角色：Client、daemon、registry、image 和 container，其中 registry 代表的是仓库，用来存储 image，同时我们也可以把 registry 中的 image（镜像）pull 到本地，进行修改之后 commit 回去，形成新的 image 存放在 registry，同时我们可以基于某个 image，在其中创建新的容器，这个容器中就是我们的应用和环境），客户端负责提供用户界面；Docker 客户端和守护进程之间使用 RESTful API，通过 unix 套接字或者网络接口进行通信，当我们使用 docker run 这样的命令时，客户端会将这些命令发送给他们的守护进程，然后守护进程执行这些命令；守护进程监听 Docker 客户端的请求并且管理服务端已有的 Docker 对象，如镜像、容器、网络。\n1. Registry（注册表） Docker Registry 用来存储 Docker 镜像。Docker Hub 是任何人都可以使用的公共注册中心，Docker 配置为默认在 Docker Hub 上查找镜像。当然你也可以运行自己的私人 Registry。\n当我们使用 docker pull 或者 docker run 的时候，将会从配置的 Registry 中提取所需要的镜像；使用 docker push 时，当前的镜像也将被推送到配置的 Registry 中。\n2. Image（镜像） 镜像是只读的，是用于创建一个容器的指令模板。通常情况下，一个镜像是基于另一个镜像，再加上自己的一些自定义配置形成的。举个例子，我们可以基于 Ubuntu 系统，在其基础上安装 nginx 以及其他 webserver 服务，以及这个服务运行时的各种配置信息，这样就行成了一个新的镜像。\n常见的虚拟机镜像，通常是由提供者打包成镜像文件，安装者从网上下载或是其他方式获得，恢复到虚拟机中的文件系统里；而 Docker 的镜像必须通过 Docker 打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。这样虽然失去了灵活性，但固定的格式意味着可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，使得在不同的机器中传递和共享 Docker 变得非常方便，这也是 Docker 能够提升工作效率的一处体现。\n通俗地讲，可以将 Docker 镜像理解为包含应用程序以及运行环境的基础文件系统，在容器启动的过程中，它以只读的方式被用于创建容器的运行环境。\nDocker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。\n对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，足以保证全球唯一性，这种编码（64 长度的字符串）的形式在 Docker 很多地方都有体现。由于镜像每层都有唯一的编码，就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，允许在镜像之间共享镜像层。举一个例子，由 Docker 官方提供的两个镜像 ElasticSearch 镜像和 Jenkins 镜像都是在 OpenJDK 镜像之上修改而得，实际使用的时候，这两个镜像是可以共用 OpenJDK 镜像内部的镜像层的。这带来的一项好处就是让镜像可以共用存储空间，达到 1+1\u0026lt;2 的效果，为在同一台机器里存放众多镜像提供了可能。\n2.1 镜像的命名 镜像的命名由三部分组成：username、repository 和 tag，他们的组织规则入下：\nusername 指上传镜像的用户；repository 表示镜像内容，形成对镜像的表意描述。有的镜像没有 username，这表明此镜像是由 Docker 官方进行维护的。\nrepository 表示镜像内容，形成对镜像的表意描述，通常采用的是软件名，这样的原因是，通常情况下，我们只在一个容器中运行一个应用，这样的命名可以更加方便的帮助我们识别镜像中的内容。\ntag 表示镜像版本，是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化，使用 tag 可以很好的区分和标识这些变化。tag 一般以版本号来命名。\n2.3 Container（容器） **容器是镜像的可运行实例。**默认情况下，一个容器和另外的容器机器主机相隔离，但是这都是可配置的。\n三、 概念理解 先说结论：一个”容器“，实际上是由 Linux Namespace 、 Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。\n1. LXC(Linux Container) Docker 其实是容器化技术的具体实现之一，采用 Golang 语言开发。很多人认为 Docker 是一种更轻量级的虚拟机，但事实上不是这样的，Docker 和虚拟机有本质的区别。容器在本质上讲，就是运行在操作系统上的一个进程，只不过加入了对资源的隔离和限制。Docker 正是基于容器的这个设计思想，采用 Linux Container 技术实现的核心管理引擎。\n为什么要进行这种设计呢？在默认情况下，一个操作系统里所有运行的进程共享 CPU 和内存资源，如果设计不当，在最极端的情况下，如果某进程出现死循环可能会耗尽所有的系统资源，其他的进程也会受到影响，这在企业级产品的场景下是不可接受的。\n不过，对资源进行隔离并不是新的发明，Linux 系统本身就支持操作系统级层面的虚拟化技术，叫做 Linux Container，即 LXC 的全称，它的作用是在操作系统的层次上为进程提供虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的 cpu 和 memory 节点，分配特定比例的 cpu 时间、IO 时间，限制可以使用的内存大小（包括内存和是 swap 空间），提供 device 访问控制，提供独立的 namespace（网络、pid、ipc、mnt、uts）。\nLXC，一种“操作系统层虚拟化”技术，为“linux 内核”容器功能的一个“用户空间接口”。LXC(LinuxContainer)是来自于 Sourceforge 网站上的开源项目，LXC 给 Linux 用户提供了用户空间的工具集，用户可以通过 LXC 创建和管理容器，在容器中创建运行操作系统就可以有效的隔离多个操作系统，实现操作系统级的虚拟化。最初的 Docker 容器技术基于 LXC 进行构建，后来 Docker 在自己的内核中刨除了 LXC。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。\n从前面的介绍中我们可以了解到，LXC 能够创建容器用于 Linux 系统的虚拟化，而 LXC 作为用户层管理工具主要提供了管理容器的接口，对实现容器的机制进行了封装隐藏，下面将对 LXC 容器的实现机制进行分析。LXC 有三大特色： cgroup 、 namespace 和 unionFS 。\nnamespace 这是另一个维度的资源隔离技术，与我们平常 C++程序开发中的 namespace 可以相类比。\n如果 cgroup 设计出来是为了隔离上面所描述的物理资源，那么 namespace 则用来隔离 PID、IPC、NETWORK 等系统资源。每一个 namespace 中的资源对其他 namespace 都是透明的，互不干扰。在每一个 namespace 内部，每一个用户都拥有属于自己的 init 进程，pid = 1，对于该用户来说，仿佛他独占了一台物理的 Linux 虚拟机。但是事实上，这个 namespace 中的 pid，只是其父容器的一个子进程而已。\n通过下图来加深理解：\n父容器有两个子容器，父容器的命名空间里有两个进程，id 分别为 3 和 4, 映射到两个子命名空间后，分别成为其 init 进程，这样命名空间 A 和 B 的用户都认为自己独占整台服务器。对于每一个命名空间，从用户看起来，应该像一台单独的 Linux 计算机一样，有自己的 init 进程(PID 为 1)，其他进程的 PID 依次递增，A 和 B 空间都有 PID 为 1 的 init 进程，子容器的进程映射到父容器的进程上，父容器可以知道每一个子容器的运行状态，而子容器与子容器之间是隔离的。从图中我们可以看到，进程 3 在父命名空间里面 PID 为 3，但是在子命名空间内，他就是 1. 也就是说用户从子命名空间 A 内看进程 3 就像 init 进程一样，以为这个进程是自己的初始化进程，但是从整个 host 来看，他其实只是 3 号进程虚拟化出来的一个空间而已。\n【参考】 DOCKER 基础技术：LINUX NAMESPACE（上）\nDOCKER 基础技术：LINUX NAMESPACE（下）\ncgroup（control group） 前面，我们介绍了 Linux Namespace，但是Namespace 解决的问题主要是环境隔离的问题，这只是虚拟化中最最基础的一步，我们还需要解决对计算机资源使用上的隔离。也就是说，虽然你通过 Namespace 把我 Jail 到一个特定的环境中去了，但是我在其中的进程使用用 CPU、内存、磁盘等这些计算资源其实还是可以随心所欲的。所以，我们希望对进程进行资源利用上的限制或控制。这就是 Linux CGroup 出来了的原因。\ncgroup 用来限定一个进程的资源使用，由 Linux 内核支持，可以限制和隔离 Linux 进程组（process groups）所使用的资源，比如 CPU、内存、磁盘和网络 IO，是 LXC 技术的物理基础。\n主要提供了如下功能：\nResource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。\nPrioritization: 优先级控制，比如：CPU 利用和磁盘 IO 吞吐。\nAccounting: 一些审计或一些统计，主要目的是为了计费。\nControl: 挂起进程，恢复执行进程。\n使 ​​​ 用 ​​​ cgroup，系 ​​​ 统 ​​​ 管 ​​​ 理 ​​​ 员 ​​​ 可 ​​​ 更 ​​​ 具 ​​​ 体 ​​​ 地 ​​​ 控 ​​​ 制 ​​​ 对 ​​​ 系 ​​​ 统 ​​​ 资 ​​​ 源 ​​​ 的 ​​​ 分 ​​​ 配 ​​​、优先顺序、拒绝、监控和管理。可以更好地根据任务和用户分配硬件资源，提高总体效率。\n在实践中，系统管理员一般会利用 CGroup 做下面这些事（有点像为某个虚拟机分配资源似的）：\n隔离一个进程集合（比如：nginx 的所有进程），并限制他们所消费的资源，比如绑定 CPU 的核。\n为这组进程 分配其足够使用的内存\n为这组进程分配相应的网络带宽和磁盘存储限制\n限制访问某些设备（通过设置设备的白名单）\n【参考】DOCKER 基础技术：LINUX CGROUP\nunionFS unionFS 的含义是，可以把文件系统上多个目录内容联合挂载到同一个目录下，而目录的物理位置是分开的。\n我们来看一个例子(例子来自耗子叔的文章，但是原文中的不完善，我在这里补充一下)：\n首先我们建立两个目录(fruits 和 vegetables)，并在这两个目录中新建一些文件：\n# 创建目录 \u0026gt;\u0026gt;\u0026gt; mkdir fruits \u0026gt;\u0026gt;\u0026gt; mkdir vegetables \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;apple in fruits\u0026#34; \u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in fruits\u0026#34; \u0026gt; ./fruits/tomato \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;carrots in vegetables\u0026#34; \u0026gt; ./vegetables/carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;tomato in vegetables\u0026#34; \u0026gt; ./vegetables/tomato # 查看当前目录结构 \u0026gt;\u0026gt;\u0026gt; tree . . ├── fruits │ ├── apple │ └── tomato └── vegetables ├── carrots └── tomato 然后使用 aufs 进行 mount，注意 fruits 和 vegetables 的顺序：\n# 创建mount目录 \u0026gt;\u0026gt;\u0026gt; mkdir mnt # 把水果目录和蔬菜目录union mount到 ./mnt目录中 \u0026gt;\u0026gt;\u0026gt; sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt # 看一下当前的结构 \u0026gt;\u0026gt;\u0026gt; tree ./mnt ./mnt ├── apple ├── carrots └── tomato # 看一下mnt中的内容 \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables \u0026gt;\u0026gt;\u0026gt; cat ./mnt/tomato tomato in fruits 我们发现，fruits 和 vegetables 中的文件被 merge 到了一起，并且同名的文件只出现一次，默认以第一个文件夹为准。\n下面我们看一下 merge 后的文件和源文件之间的映射关系。第一步，修改源文件，merge 后的文件是否会受影响？\n# 修改fruits的apple \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 1 after fruits.apple\u0026#34; \u0026gt;\u0026gt; ./fruits/apple \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple # 查看mnt中的apple \u0026gt;\u0026gt;\u0026gt; cat ./mnt/apple apple in fruits append 1 after fruits.apple # 修改vevegtbles中的carrots echo \u0026#34;append 2 after vegetables.carrots\u0026#34; \u0026gt;\u0026gt; ./vevegtbles/carrots \u0026gt;\u0026gt;\u0026gt; cat ./vevegtbles/carrots carrots in vegetables append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots 由此可以得到：修改源文件，merge 后的文件也会同步改变。\n我们继续往下走：修改 mnt 中的文件，源文件会受到什么影响？\n\u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 3 after mnt.apple\u0026#34; \u0026gt;\u0026gt; ./mnt/apple # 查看源文件 \u0026gt;\u0026gt;\u0026gt; cat ./fruits/apple apple in fruits append 1 after fruits.apple append 3 after mnt.apple # 重点来了，修改mnt.carrots \u0026gt;\u0026gt;\u0026gt; echo \u0026#34;append 4 in mnt.carrots\u0026#34; \u0026gt;\u0026gt; ./mnt/carrots tree . . ├── fruits │ ├── apple │ ├── carrots | └── tomato └── vegetables ├── carrots └── tomato \u0026gt;\u0026gt;\u0026gt; cat ./fruits/carrots append 2 after vegetables.carrots # 查看mnt中的carrots \u0026gt;\u0026gt;\u0026gt; cat ./mnt/carrots carrots in vegetables append 2 after vegetables.carrots append 4 in mnt.carrots 我们 merge 后的第一个目录没有的文件，竟然将该文件复制进了第一个文件，然后进行了修改！\ndocker 通过一个叫做 copy-on-write (CoW) 的策略来保证 base 镜像的安全性，以及更高的性能和空间利用率。\nCopy-on-write is a strategy of sharing and copying files for maximum efficiency. If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it, it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container), the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers. These advantages are explained in more depth below.\n当容器需要读取文件的时候: 从最上层镜像开始查找，往下找，找到文件后读取并放入内存，若已经在内存中了，直接使用。(即，同一台机器上运行的 docker 容器共享运行时相同的文件)。 当容器需要添加文件的时候: 直接在最上面的容器层可写层添加文件，不会影响镜像层。 当容器需要修改文件的时候: 从上往下层寻找文件，找到后，复制到容器可写层，然后，对容器来说，可以看到的是容器层的这个文件，看不到镜像层里的文件。容器在容器层修改这个文件。 当容器需要删除文件的时候: 从上往下层寻找文件，找到后在容器中记录删除。即，并不会真正的删除文件，而是软删除。这将导致镜像体积只会增加，不会减少。 那么，这种 UnionFS 有什么用？\n历史上，有一个叫 Knoppix 的 Linux 发行版，其主要用于 Linux 演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把 CD/DVD 上的 image 运行在一个可写的存储设备上（比如一个 U 盘上），其实，也就是把 CD/DVD 这个文件系统和 USB 这个可写的系统给联合 mount 起来，这样你对 CD/DVD 上的 image 做的任何改动都会在被应用在 U 盘上，于是乎，你可以对 CD/DVD 上的内容进行任意的修改，因为改动都在 U 盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的 template，和另一个你的 working directory 给 union 在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个 ad hoc snapshot。\nDocker 把 UnionFS 的想像力发挥到了容器的镜像。你是否还记得我在介绍 Linux Namespace 上篇中用 mount namespace 和 chroot 山寨了一镜像。现在当你看过了这个 UnionFS 的技术后，你是不是就明白了，你完全可以用 UnionFS 这样的技术做出分层的镜像来。\n这就是 Docker 容器镜像分层实现的技术基础。所以我们说，Docker 中新的镜像并不是从头开始制作的，而是从一些 base 镜像的基础上创建并加上自定义修改而形成的，这些自定义的设置不会影响原来的 base 镜像。和 git 中的 commit 很像。这种设计的优点就是资源共享。试想一下，一台宿主机上运行 100 个基于 debian base 镜像的容器，难道每个容器中都保存一份重复的 debian 的拷贝吗？这显然不合理。借助 Linux 的 unionFS，宿主机只需要在磁盘上保存一份 base 镜像，内存中也加载一份，就能被所有基于这个 base 镜像的容器所共享。(举一个后面会遇到的例子：当我们使用 docker pull ubuntu:latest 这个命令的时候，可以看到如下的输出信息，从这个过程我们可以看出，镜像文件一般由若干层组成，使用 docker pull 下载中会获取并输出镜像的各层信息，当不同的镜像包括相同的层时，本地仅存了层的其中一份，减小了存储空间。)\n\u0026gt;\u0026gt;\u0026gt; docker pull ubuntu:latest latest: Pulling from library/ubuntu 35c102085707: Pull complete 251f5509d51d: Pull complete 8e829fe70a46: Pull complete 6001e1789921: Pull complete Digest: sha256:66cd4dd8aaefc3f19afd407391cda0bc5a0ade546e9819a392d8a4bd5056314e Status: Downloaded newer image for ubuntu:latest \u0026gt;\u0026gt;\u0026gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 5 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB 可以看到最新的 ubuntu 镜像只有 64M，而 centos 也只有 202M，是不是觉得太小了？这是因为 docker 在运行的时候直接使用了 docker 宿主机器的 kernel。\nLinux 操作系统由内核空间和用户空间组成。\n内核空间是 kernel，用户空间是 rootfs, 不同 Linux 发行版的区别主要是 rootfs. 比如 Ubuntu 14.04 使用 upstart 管理服务，apt 管理软件包；而 CentOS 7 使用 systemd 和 yum。这些都是用户空间上的区别，Linux kernel 差别不大。\n所以 Docker 可以同时支持多种 Linux 镜像，模拟出多种操作系统环境。\n需要注意的是，base 镜像只是用户空间和发行版一致。kernel 使用的是 docker 宿主机器的 kernel。例如 CentOS 7 使用 3.x.x 的 kernel，如果 Docker Host 是 Ubuntu 16.04（比如我们的实验环境），那么在 CentOS 容器中使用的实际是是 Host 4.x.x 的 kernel。\nAUFS 有所有 Union FS 的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被 mount 好的目录。AUFS 的 whiteout 的实现是通过在上层的可写的目录下建立对应的 whiteout 隐藏文件来实现的。也就是说，如果我们想要删除某个地分支的文件，只需要在高分支的可写目录下，建立一个 whiteout的名字是’.wh.\u0026lt;filename\u0026gt;’ ，那么对应的下层的 \u0026lt;filename\u0026gt; 就会被删除，即使不被删除，也会不可见。\n当用 docker run 启动某个容器的时候，实际上容器的顶部添加了一个新的可写层，这个可写层也叫容器层。容器启动后，它里面的所有对容器的修改包括文件的增删改都只会发生在最顶部的容器层，而对下面的只读镜像层没有影响。\n【参考】DOCKER 基础技术：AUFS\n四、 Docker 镜像 刚开始学习时，很多人会分不清 镜像(image) 和 容器(container) 的区别。这里引用 Stackverflow：What is the difference between a Docker image and a container?的解释：\nAn instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.\nthe image is the recipe, the container is the cake ; -) you can make as many cakes as you like with a given recipe.\n镜像可以理解为一种 构建时(build-in)结构 ，而容器可以理解为一种 运行时(run-time)结构 。我们通常使用 docker service create 和 docker container run 从某个镜像启动一个或者多个容器。一旦容器从镜像启动之后，二者就变成了互相依赖的关系，并且在镜像启动的容器全部停止之前，镜像是无法被删除的。\n1. 镜像命名 docker pull DNS名称/用户名/镜像名:tag名 上述命令可以简写成 docker pull 镜像名 ，表示从 Docker 官方仓库中，默认拉取 tag 为 latest 的镜像。\n2. 常用命令 docker image pull xxx: 下载镜像 docker image ls: 列出当前主机上的所有镜像(-a 列出所有 -p只列出id) docker image inspect xxx: 查看当前image的详情 docker image rm xxx: 删除某个镜像(docker image rm $(docker image ls -a) -f 删除本机上所有的镜像) docker container rm $(docker container ls -a | awk \u0026#39;$1 !=\u0026#34;CONTAINER\u0026#34; {print $1}\u0026#39;) -f：删除所有的container 四、 Dockerfile 在实际开发中，几乎都是采用 Dockerfile 来制作镜像，而很少会采用将容器整个提交的方式。Dockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件。在 Dockerfile 中，包含了构建一个镜像过程中需要执行的命令以及其他操作。常见的 Docker 命令如下：\nFROM 之前提到过，我们不会从 0 开始构建一个镜像，而是会选择一个已经存在的镜像作为 base。FROM 用于指定一个 base 镜像，之后的所有操作都是基于这个 base 镜像来执行的，Docker 会先获取这个给出的 base 镜像，然后在这个 base 镜像上进行后面的构建操作。FROM 支持三种格式：\nFROM \u0026lt;image\u0026gt; [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;] FROM \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] [AS \u0026lt;name\u0026gt;] 一般使用第二种，当 tag 不写时，默认为 latest。除了选择现有的镜像之外，Docker 还存在一个特殊的镜像，叫 scratch，它表示一个空白的镜像。如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。\nRUN RUN 用来在构建 docker 镜像的过程中执行命令行命令。但是并不建议一条 shell 命令一个 RUN。为什么呢？之前说过，Dockerfile 中的每一条指令都会建立一层，RUN 也不例外。每一个 RUN 行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这条命令，执行结束后，commit 这一层的修改，构成新的镜像。如果有很多 RUN，会出现很多运行时不需要的东西，结果就是产生了非常臃肿、非常多层的镜像, 不仅增加了构建部署的时间，也很容易出错。正确的做法是将这些命令通过\u0026amp;\u0026amp;符号串起来，如果需要换行就是用“\\”来连接两行，简化为一层，并且及时删除下载的 tgz 文件等。因此，在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\nENV 用于设置环境变量。例如：\nENV VERSION=1.0 DEBUG=on \\ NAME=\u0026#34;Happy Feet\u0026#34; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。\nWORKDIR Dockerfile 中的 WORKDIR 指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。相当于设置根目录。当使用相对目录的情况下，采用上一个 WORKDIR 指定的目录作为基准，相当与 cd 命令，但不同的是指定了 WORKDIR 后，容器启动时执行的命令会在该目录下执行。\nCMD 与 ENTRYPOINT 之前了解到，Docker 不是虚拟机，容器就是进程。既然是进程，那么启动容器的时候，需要指定所运行的程序以及参数。CMD 就是用于默认的容器主进程的启动命令的。当然 Dockerfile 中也可以没有 CMD，在运行时指定也可以。\n另外需要注意的是，容器中运行一个服务没有前后台的概念。为什么呢？对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。举个例子，我们使用了\nCMD service nginx start 然后发现容器执行后就立即退出了，甚至在容器内去使用 systemctl 命令发现根本执行不了。原因是使用“service nginx start”，则是希望 upstart 以后以后台守护进程的形式启动 nginx 服务，但是“CMD service nginx start”会被理解成 CMD [ \u0026ldquo;sh\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;service nginx start\u0026rdquo;]，因此主进程实际上是 sh，那么当 service nginx start 命令结束以后，sh 也就消失了，sh 作为主进程退出了，自然就会使容器退出。正确做法是直接执行 nginx 可执行文件，并且要以前台的形式运行，如\nCMD nginx -g \u0026#39;daemon off;\u0026#39; ENTRYPOINT 的目的和 CMD 一样，都是指定容器启动程序以及参数。当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为\n\u0026lt;ENTRYPOINT\u0026gt; \u0026#34;\u0026lt;CMD\u0026gt;\u0026#34; COPY 与 ADD COPY 指令将从构建上下文目录中 \u0026lt;源路径\u0026gt; 的文件/目录复制到新的一层的镜像内的 \u0026lt;目标路径\u0026gt; 位置。\u0026lt;源路径\u0026gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath. Match 规则，比如：\nCOPY package.json /usr/src/app/ \u0026lt;目标路径\u0026gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。\n在使用该指令的时候还可以加上 \u0026ndash;chown=: 选项来改变文件的所属用户及所属组。\nCOPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。使用 ADD 时，如果原路径是一个 url 或者压缩包，Docker 引擎会将这个 url 下载或者将压缩包解压之后再复制。看情况使用即可。\nEXPOSE 声明运行时容器提供服务的端口，这只是一个声明（即打算、推荐用这个端口），在运行是并不会因为这个声明而开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处：\n帮助镜像使用者理解这个镜像服务推荐使用的端口，以方便配置映射；\n在运行时使用端口映射，也就是 docker run -P 时( -P 表示随机映射)，会自动映射 EXPOSE 的端口。\n需要区分 docker run -P 和 docker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; ：\ndocker run -P 会随机映射宿主端口到 Dockerfile 中的 EXPOSE ，如： \u0026gt;\u0026gt;\u0026gt; cat Dockerfile FROM nginx:latest EXPOST 80 90 \u0026gt;\u0026gt;\u0026gt; docker build -t nginx-test . \u0026gt;\u0026gt;\u0026gt; docker run -d -P nginx-test \u0026gt;\u0026gt;\u0026gt; docker container ls # 输出 9e3f0b2d6569 nginx-test \u0026#34;/docker-entrypoint.…\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:32769-\u0026gt;80/tcp, 0.0.0.0:32768-\u0026gt;90/tcp compassionate_pascal 这其中会将本机的 32769 和 32768 暴露出来，同时映射到容器中的 80 和 90 。\ndocker run -p \u0026lt;宿主端口\u0026gt;:\u0026lt;容器端口\u0026gt; 指定宿主机和容器的端口： \u0026gt;\u0026gt;\u0026gt; docker run -d -p 8080:80 nginx-test 此时访问宿主机的 curl 宿主机IP:8080 会映射到容器内的 80 端口。\nVOLUMN docker 提供一种机制，可以将宿主机上的某个目录与容器的某个目录(称为挂载点，或者卷)关联起来，容器挂载点下的内容就是宿主机对应目录下的内容，可以有以下效果：\n容器基于镜像创建，容器的文件系统包括镜像的只读层+可写层，容器进程所产生的的数据均保存在可写层上，一旦容器删除，上面的数据就没有了，除非手动备份下来。而 卷挂载 机制可以让我们把容器中的某个目录和宿主机关联，让容器中的数据持久保存在宿主机上，即使容器删除，产生的数据仍在。 当我们开发一个应用时，开发环境在本机，运行环境启动在一个 docker 容器中，当我们修改一处之后想看到效果，需要重启容器，这显然比较麻烦。此时可以设置容器与本机的某个目录同步，当我们修改主机上的内容是，不需要同步容器，对容器来说是自动生效的，比如一个 web 应用，修改 index.html 后，刷新之后马上就能看到效果。 多个容器运行一组关联服务，共享一些数据。 通过一个 nginx 实例加深理解：\n1. 指明宿主机的目录\n# 拉取nginx镜像 docker pull nginx:latest # 创建宿主机目录 mkdir -p /Users/hujiaming/Downloads/nginx_test/index # 自定义欢迎页内容 cat \u0026#34;\u0026lt;h1\u0026gt; Hello World \u0026lt;/h1\u0026gt;\u0026#34; \u0026gt;\u0026gt;\u0026gt; /Users/hujiaming/Downloads/nginx_test/index/index.html # 将宿主机端口8080映射到容器端口80，将宿主机目录 /Users/hujiaming/Downloads/nginx_test/index 映射到容器目录 /usr/share/nginx/html(这个目录中存放nginx默认的欢迎页index.html) docker run -d -p 8080:80 -v /Users/hujiaming/Downloads/nginx_test/index:/usr/share/nginx/html --name nginx nginx 此时访问 宿主机 IP:8080，会出现 Hello World 而不是 nginx 的默认欢迎页，当我们修改 nginx_test/index/index.html 内容时，刷新浏览器发现也会同步刷新。\n2. 未指定关联的主机目录\ndocker run -d -p 8080:80 -v /data --name nginx nginx 上述命令只设置了容器的挂载点，并没有指定关联的主机目录。这时候 docker 会自动绑定主机上的一个目录。可以通过 docker inspect \u0026lt;name\u0026gt; 查看:\n\u0026gt;\u0026gt;\u0026gt; docker run -d -it -v /data nginx # 查看得到Container ID为： a369cc1f6efa \u0026gt;\u0026gt;\u0026gt; docker inspect a369cc1f6efa # 输出 ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/10be4368f4fc5671fd71456f72d4c8f33d9f003d30422aca936b8e56976a886a/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/data\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ], ... 上面 Mounts 下的每条信息记录了容器上一个挂载点的信息，\u0026ldquo;Destination\u0026rdquo; 值是容器的挂载点，\u0026ldquo;Source\u0026quot;值是对应的主机目录。可以看出这种方式对应的主机目录是自动创建的，其目的不是让在主机上修改，而是让多个容器共享。\n此外还可以使用 --volumn-from 参数指定和某个已经存在的容器共享挂载点。\n五、 实战 1. 在 Ubuntu19 中安装 docker # 旧版本中docker叫做 docker , docker.io , docker-engine，如果这些旧版本已经安装，先卸载掉他们 sudo apt-get remove docker docker-engine docker.io containerd runc # 添加依赖 sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 添加GPG curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 在 /etc/apt/sources.list中添加依赖 sudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # 更新 sudo apt-get update # 安装docker服务 sudo apt-get install docker-ce 2. 启动和关闭容器 # 查看当前已有的image \u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 67fa590cfc1c 10 hours ago 202MB ubuntu latest a2a15febcdf3 5 days ago 64.2MB nginx latest 53f3fd8007f7 3 months ago 109MB centos 7 9f38484d220f 5 months ago 202MB jenkins latest cd14cecfdb3a 13 months ago 696MB # 启动(-it 告诉docker，开启容器的交互模式并将读者当前的shell连接到容器的终端；/bin/bash 是说用户在容器内部想运行bash这个进程) \u0026gt;\u0026gt;\u0026gt; docker run -it ubuntu:latest /bin/bash # 不关闭容器而退出容器 \u0026gt;\u0026gt;\u0026gt; 组合键 ctrl + PQ # 在宿主机器上查看运行的机器 \u0026gt;\u0026gt;\u0026gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a847b8ed22b4 ubuntu:latest \u0026#34;/bin/bash\u0026#34; 41 seconds ago Up 40 seconds dreamy_bardeen 6ccf082c4be6 centos:7 \u0026#34;/bin/bash\u0026#34; 4 hours ago Up 4 hours heuristic_tu # 连接到运行中的容器(记得将下面的dreamy_bardeen换成你自己的容器名称，在docker container ls结果最后一列) \u0026gt;\u0026gt;\u0026gt; docker container exec -it dreamy_bardeen bash # 停止容器 \u0026gt;\u0026gt;\u0026gt; docker container stop dreamy_bardeen # 杀死容器 \u0026gt;\u0026gt;\u0026gt; docker container rm dreamy_bardeen 3. 多阶段构建 编写如下 go 文件：\n# main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { engine := gin.Default() engine.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { name := c.Query(\u0026#34;name\u0026#34;) fmt.Println(\u0026#34;hello \u0026#34; + name) c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hello \u0026#34; + name}) }) engine.Run(\u0026#34;:8899\u0026#34;) } 使用 go mod :\ngo mod init demo_go go mod tidy 对于 Dockerfile 的编写，有三种方案：\n方案一：直接使用 golang 全镜像\nFROM golang:1.14-alpine EXPOSE 8899 WORKDIR /go/src/demo_go COPY . /go/src/demo_go RUN GOPROXY=https://goproxy.cn,direct go build -v -o main *.go ENTRYPOINT [ \u0026#34;./main\u0026#34; ] 方案二：使用两个 Dockerfile，第一个编译出可执行二进制，第二个直接将二进制复制进去执行\n# cat Dockerfile.build FROM golang:1.14-alpine WORKDIR /apps/demo_go COPY . . RUN go build -v -o app *.go # cat Dockerfile.copy FROM golang:1.14-alpine WORKDIR /root/ COPY app /root/app RUN chmod a+x /root/app EXPOSE 8899 ENTRYPOINT [\u0026#34;/root/app\u0026#34;] # 这二者通过一个build.sh文件组合在一起 # cat build.sh #!/bin/bash echo \u0026#34;start build demo_go:stage1\u0026#34; docker build -t demo_go:build . -f Dockerfile.build docker create --name extract demo_go:build docker cp extract:/apps/demo_go/app ./app docker rm -f extract echo \u0026#34;start build demo_go:stage2\u0026#34; docker build --no-cache -t demo_go:install . -f Dockerfile.copy rm -rf ./app 方案三：多阶段构建\n# 第一阶段，编译出可执行文件 FROM golang:1.14-alpine as builder WORKDIR /apps COPY . . RUN CGO_ENABLED=0 GOOS=linux GOPROXY=https://goproxy.cn,direct go build -v -a -o app *.go # 第二阶段，将第一阶段编译好的二进制复制进最后一个阶段的容器即可 FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /apps/app . EXPOSE 8899 CMD [\u0026#34;./app\u0026#34;] 分别使用不同的执行构建 image：\n# 第一种 docker build -t demo_go:source -f Dockerfile . # 第二种 bash build.sh # 第三种 docker build -t demo_go:multi -f Dockerfile.multi . 这三种方案有什么区别？我们看一下各自 image 的大小：\n\u0026gt;\u0026gt;\u0026gt; docker image ls REPOSITORY TAG IMAGE ID SIZE demo_go copy ab80d3d110b6 401MB demo_go source 274bf686025c 474MB demo_go app 7e8207b60f07 394MB demo_go multi 62b316cc49bd 21.1MB 看出差距了？\n","permalink":"http://localhost:1313/posts/%E5%85%B3%E4%BA%8Edocker/","summary":"这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要","title":"关于docker"},{"content":" 关于我 你好！我是 hujm2023，欢迎来到我的个人技术博客。\n关于本站 这里是我分享技术经验、学习心得和编程实践的地方。主要内容包括：\n技术栈 编程语言: Golang、Python、Java 数据库: MySQL、Redis 工具: Git、Docker、Kubernetes 系统: Linux 博客内容 算法与数据结构: LeetCode 题解、经典算法实现 后端开发: Go 语言深入解析、并发编程、性能优化 数据库技术: MySQL 底层原理、Redis 源码分析 系统架构: 分布式系统设计、微服务架构 开发工具: 效率工具使用技巧、最佳实践分享 技术理念 追求代码质量和工程实践 重视基础理论与实际应用的结合 持续学习，保持技术敏感度 乐于分享，共同进步 联系方式 如果你对文章内容有疑问，或者想要技术交流，欢迎通过以下方式联系我：\n邮箱: hujm.net@gmail.com GitHub: github.com/hujm2023 声明 本博客所有文章均为个人原创（除特别注明外），转载请注明出处。文章中的观点仅代表个人看法，如有错误欢迎指正。\n感谢你的访问，希望这些内容对你有所帮助！\n","permalink":"http://localhost:1313/about/","summary":"关于本站和作者","title":"关于"}]